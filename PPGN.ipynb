{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f98075de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SABA\\anaconda3\\envs\\pytorch_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ActivationSigma(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return F.elu(x) + 1\n",
    "    \n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu') \n",
    "        if m.bias is not None:\n",
    "            torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "class ProbabilisticNN(nn.Module):\n",
    "    def __init__(self, num_features=6):\n",
    "        super().__init__()\n",
    "        self.selective_neurons = nn.ModuleList([nn.Linear(1, 1) for _ in range(num_features)])\n",
    "        self.feature_shared = nn.Linear(num_features, 10)\n",
    "        \n",
    "        self.mu_S_layer = nn.Linear(1, 5)\n",
    "        self.mu_R_layer = nn.Linear(1, 5)\n",
    "        self.sigma_S_layer = nn.Linear(1, 5)\n",
    "        self.sigma_R_layer = nn.Linear(1, 5)\n",
    "        \n",
    "        self.mu_final = nn.Linear(10, 1)\n",
    "        self.sigma_final = nn.Linear(10, 1)\n",
    "        \n",
    "        self.sigma_activation = ActivationSigma()\n",
    "        \n",
    "        self.mu_relax_layer = nn.Sequential(nn.Linear(2, 1))\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x_main, S, R):\n",
    "        batch_size = x_main.size(0)\n",
    "        selective_outputs = []\n",
    "        for i in range(6):\n",
    "            feature = x_main[:, i].view(-1, 1)\n",
    "            mask = (feature != 0).float()\n",
    "            out = torch.tanh(self.selective_neurons[i](feature)) * mask\n",
    "            selective_outputs.append(out)\n",
    "        \n",
    "        x_feat = torch.cat(selective_outputs, dim=1)  # shape [batch_size, 6]\n",
    "        shared_feat = torch.tanh(self.feature_shared(x_feat))  # shape [batch_size, 10]\n",
    "        \n",
    "        mu_feat = shared_feat[:, :5]\n",
    "        sigma_feat = shared_feat[:, 5:]\n",
    "        mu_feat = torch.sum(mu_feat, dim=1, keepdim=True)\n",
    "        sigma_feat = torch.sum(sigma_feat, dim=1, keepdim=True)\n",
    "        \n",
    "        mu_S = self.mu_S_layer(S)\n",
    "        mu_R = self.mu_R_layer(R)\n",
    "        mu_combined = torch.cat([mu_S, mu_R], dim=1)\n",
    "        mu_contrib = self.mu_final(mu_combined)\n",
    "        \n",
    "        sigma_S = torch.tanh(self.sigma_S_layer(S))\n",
    "        sigma_R = torch.tanh(self.sigma_R_layer(R))\n",
    "        sigma_combined = torch.cat([sigma_S, sigma_R], dim=1)\n",
    "        sigma_contrib = self.sigma_final(sigma_combined)\n",
    "        \n",
    "        mu = mu_feat + mu_contrib\n",
    "        sigma = self.sigma_activation(sigma_feat + sigma_contrib)\n",
    "        \n",
    "        mu_relaxed = self.mu_relax_layer(torch.cat([mu, sigma], dim=1))\n",
    "        \n",
    "        return mu_relaxed, sigma\n",
    "\n",
    "    def constrain_sigma(self):\n",
    "        with torch.no_grad():\n",
    "            sigma_S_weights = self.sigma_S_layer.weight.data.view(-1)\n",
    "            sigma_final_weights = self.sigma_final.weight.data.view(-1)\n",
    "            constrained = sigma_final_weights.clone()\n",
    "            constrained[:5] = -sigma_final_weights[:5].abs() * sigma_S_weights.sign()\n",
    "            self.sigma_final.weight.data.view(-1)[:5].copy_(constrained[:5])\n",
    "\n",
    "    def constrain_mu(self):\n",
    "        with torch.no_grad():\n",
    "            mu_R_weights = self.mu_R_layer.weight.data.view(-1)\n",
    "            mu_final_weights = self.mu_final.weight.data.view(-1)\n",
    "            constrained = mu_final_weights.clone()\n",
    "            constrained[5:10] = -mu_final_weights[5:10].abs() * mu_R_weights.sign()\n",
    "            self.mu_final.weight.data.view(-1)[5:10].copy_(constrained[5:10])\n",
    "\n",
    "    def constrain_mu2(self):\n",
    "        with torch.no_grad():\n",
    "            mu_S_weights = self.mu_S_layer.weight.data.view(-1)\n",
    "            mu_S_bias = self.mu_S_layer.bias.data.view(-1)\n",
    "            mu_final_weights = self.mu_final.weight.data.view(-1)\n",
    "            constrained = mu_final_weights.clone()\n",
    "            constrained[:5] = -mu_final_weights[:5].abs() * mu_S_weights.sign()\n",
    "            self.mu_final.weight.data.view(-1)[:5].copy_(constrained[:5])\n",
    "            \n",
    "            for i in range(5):\n",
    "                if constrained[i] < 0:\n",
    "                    mu_S_bias[i] = mu_S_bias[i].abs()\n",
    "                else:\n",
    "                    mu_S_bias[i] = -mu_S_bias[i].abs()\n",
    "            self.mu_S_layer.bias.data.copy_(mu_S_bias)\n",
    "\n",
    "def negative_log_likelihood_loss(targets, mean, std, delta, S, physics_lambda=1.0):\n",
    "    eps = 1e-6  # برای پایداری عددی\n",
    "    std = torch.clamp(std, min=eps)  # جلوگیری از std=0\n",
    "\n",
    "    dist = torch.distributions.Normal(mean, std)\n",
    "    \n",
    "    log_prob = dist.log_prob(targets)\n",
    "    cdf = dist.cdf(targets).clamp(min=eps, max=1 - eps)\n",
    "    \n",
    "    censored_log_prob = torch.log(1 - cdf + eps)\n",
    "    \n",
    "    loss = -delta * log_prob - (1 - delta) * censored_log_prob\n",
    "\n",
    "    nl_loss = torch.mean(loss)\n",
    "    \n",
    "    # Remove this unconditional gradient calculation:\n",
    "    # dmu_dS = torch.autograd.grad(mean, S, grad_outputs=torch.ones_like(mean), create_graph=True)[0]\n",
    "    # physics_penalty = torch.mean((dmu_dS + torch.abs(dmu_dS)) / 2.0)\n",
    "\n",
    "    if physics_lambda > 0.0 and S is not None and S.requires_grad:\n",
    "        dmu_dS = torch.autograd.grad(mean, S, grad_outputs=torch.ones_like(mean), create_graph=True)[0]\n",
    "        physics_penalty = torch.mean((dmu_dS + torch.abs(dmu_dS)) / 2.0)\n",
    "        \n",
    "        return nl_loss + physics_lambda * physics_penalty\n",
    "    else:\n",
    "        return nl_loss\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6203706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 45, Epoch [10/1000], Train Loss: 3.592614, Test Loss: 3.090812, LR: 0.050000\n",
      "Seed 45, Epoch [20/1000], Train Loss: 3.007341, Test Loss: 2.437475, LR: 0.050000\n",
      "Seed 45, Epoch [30/1000], Train Loss: 2.740576, Test Loss: 2.367459, LR: 0.050000\n",
      "Seed 45, Epoch [40/1000], Train Loss: 2.563333, Test Loss: 2.364479, LR: 0.050000\n",
      "Seed 45, Epoch [50/1000], Train Loss: 2.497670, Test Loss: 2.352516, LR: 0.050000\n",
      "Seed 45, Epoch [60/1000], Train Loss: 2.454579, Test Loss: 2.330561, LR: 0.050000\n",
      "Seed 45, Epoch [70/1000], Train Loss: 2.431744, Test Loss: 2.308995, LR: 0.050000\n",
      "Seed 45, Epoch [80/1000], Train Loss: 2.423231, Test Loss: 2.293739, LR: 0.050000\n",
      "Seed 45, Epoch [90/1000], Train Loss: 2.417137, Test Loss: 2.283777, LR: 0.050000\n",
      "Seed 45, Epoch [100/1000], Train Loss: 2.410395, Test Loss: 2.276402, LR: 0.050000\n",
      "Seed 45, Epoch [110/1000], Train Loss: 2.403293, Test Loss: 2.268870, LR: 0.050000\n",
      "Seed 45, Epoch [120/1000], Train Loss: 2.395935, Test Loss: 2.259825, LR: 0.050000\n",
      "Seed 45, Epoch [130/1000], Train Loss: 2.387931, Test Loss: 2.249465, LR: 0.050000\n",
      "Seed 45, Epoch [140/1000], Train Loss: 2.379347, Test Loss: 2.238588, LR: 0.050000\n",
      "Seed 45, Epoch [150/1000], Train Loss: 2.370139, Test Loss: 2.227628, LR: 0.050000\n",
      "Seed 45, Epoch [160/1000], Train Loss: 2.360202, Test Loss: 2.216495, LR: 0.050000\n",
      "Seed 45, Epoch [170/1000], Train Loss: 2.349477, Test Loss: 2.205069, LR: 0.050000\n",
      "Seed 45, Epoch [180/1000], Train Loss: 2.337859, Test Loss: 2.193474, LR: 0.050000\n",
      "Seed 45, Epoch [190/1000], Train Loss: 2.325238, Test Loss: 2.182042, LR: 0.050000\n",
      "Seed 45, Epoch [200/1000], Train Loss: 2.311481, Test Loss: 2.171144, LR: 0.050000\n",
      "Seed 45, Epoch [210/1000], Train Loss: 2.296427, Test Loss: 2.161180, LR: 0.050000\n",
      "Seed 45, Epoch [220/1000], Train Loss: 2.279862, Test Loss: 2.152600, LR: 0.050000\n",
      "Seed 45, Epoch [230/1000], Train Loss: 2.261543, Test Loss: 2.146021, LR: 0.050000\n",
      "Seed 45, Epoch [240/1000], Train Loss: 2.241144, Test Loss: 2.142066, LR: 0.050000\n",
      "Seed 45, Epoch [250/1000], Train Loss: 2.218289, Test Loss: 2.141341, LR: 0.050000\n",
      "Seed 45, Epoch [260/1000], Train Loss: 2.192460, Test Loss: 2.144035, LR: 0.050000\n",
      "Seed 45, Epoch [270/1000], Train Loss: 2.163141, Test Loss: 2.149627, LR: 0.050000\n",
      "Seed 45, Epoch [280/1000], Train Loss: 2.129836, Test Loss: 2.155430, LR: 0.050000\n",
      "Seed 45, Epoch [290/1000], Train Loss: 2.092439, Test Loss: 2.155217, LR: 0.050000\n",
      "Seed 45, Epoch [300/1000], Train Loss: 2.051317, Test Loss: 2.137350, LR: 0.050000\n",
      "Seed 45, Epoch [310/1000], Train Loss: 2.007011, Test Loss: 2.091323, LR: 0.050000\n",
      "Seed 45, Epoch [320/1000], Train Loss: 1.960500, Test Loss: 2.021958, LR: 0.050000\n",
      "Seed 45, Epoch [330/1000], Train Loss: 1.909608, Test Loss: 1.948549, LR: 0.050000\n",
      "Seed 45, Epoch [340/1000], Train Loss: 1.863661, Test Loss: 1.921941, LR: 0.050000\n",
      "Seed 45, Epoch [350/1000], Train Loss: 1.825225, Test Loss: 2.006136, LR: 0.050000\n",
      "Seed 45, Epoch [360/1000], Train Loss: 1.793889, Test Loss: 2.178235, LR: 0.050000\n",
      "Seed 45, Epoch [370/1000], Train Loss: 1.768283, Test Loss: 2.395252, LR: 0.050000\n",
      "Seed 45, Epoch [380/1000], Train Loss: 1.743788, Test Loss: 2.580147, LR: 0.050000\n",
      "Seed 45, Epoch [390/1000], Train Loss: 1.718134, Test Loss: 2.761117, LR: 0.050000\n",
      "Seed 45, Epoch [400/1000], Train Loss: 1.689371, Test Loss: 2.942744, LR: 0.050000\n",
      "Seed 45, Epoch [410/1000], Train Loss: 1.657851, Test Loss: 3.151512, LR: 0.050000\n",
      "Seed 45, Epoch [420/1000], Train Loss: 1.621933, Test Loss: 3.414970, LR: 0.050000\n",
      "Seed 45, Epoch [430/1000], Train Loss: 1.585138, Test Loss: 3.772413, LR: 0.050000\n",
      "Seed 45, Epoch [440/1000], Train Loss: 1.555501, Test Loss: 4.262226, LR: 0.050000\n",
      "Seed 45, Epoch [450/1000], Train Loss: 1.537937, Test Loss: 4.866370, LR: 0.050000\n",
      "Seed 45, Epoch [460/1000], Train Loss: 1.518178, Test Loss: 5.248985, LR: 0.050000\n",
      "Seed 45, Epoch [470/1000], Train Loss: 1.499406, Test Loss: 5.218862, LR: 0.050000\n",
      "Seed 45, Epoch [480/1000], Train Loss: 1.479847, Test Loss: 5.194425, LR: 0.050000\n",
      "Seed 45, Epoch [490/1000], Train Loss: 1.461728, Test Loss: 5.183304, LR: 0.050000\n",
      "Seed 45, Epoch [500/1000], Train Loss: 1.444523, Test Loss: 4.987092, LR: 0.050000\n",
      "Seed 45, Epoch [510/1000], Train Loss: 1.428935, Test Loss: 4.760536, LR: 0.050000\n",
      "Seed 45, Epoch [520/1000], Train Loss: 1.412176, Test Loss: 4.453043, LR: 0.050000\n",
      "Seed 45, Epoch [530/1000], Train Loss: 1.396254, Test Loss: 4.049309, LR: 0.050000\n",
      "Seed 45, Epoch [540/1000], Train Loss: 1.380378, Test Loss: 3.627181, LR: 0.050000\n",
      "Seed 45, Epoch [550/1000], Train Loss: 1.365064, Test Loss: 3.248794, LR: 0.050000\n",
      "Seed 45, Epoch [560/1000], Train Loss: 1.349380, Test Loss: 2.865583, LR: 0.050000\n",
      "Seed 45, Epoch [570/1000], Train Loss: 1.333453, Test Loss: 2.561829, LR: 0.050000\n",
      "Seed 45, Epoch [580/1000], Train Loss: 1.316295, Test Loss: 2.273287, LR: 0.050000\n",
      "Seed 45, Epoch [590/1000], Train Loss: 1.299257, Test Loss: 2.032585, LR: 0.050000\n",
      "Seed 45, Epoch [600/1000], Train Loss: 1.281600, Test Loss: 1.836456, LR: 0.050000\n",
      "Seed 45, Epoch [610/1000], Train Loss: 1.261501, Test Loss: 1.655595, LR: 0.050000\n",
      "Seed 45, Epoch [620/1000], Train Loss: 1.241369, Test Loss: 1.507280, LR: 0.050000\n",
      "Seed 45, Epoch [630/1000], Train Loss: 1.219306, Test Loss: 1.380720, LR: 0.050000\n",
      "Seed 45, Epoch [640/1000], Train Loss: 1.197597, Test Loss: 1.268494, LR: 0.050000\n",
      "Seed 45, Epoch [650/1000], Train Loss: 1.175554, Test Loss: 1.185633, LR: 0.050000\n",
      "Seed 45, Epoch [660/1000], Train Loss: 1.154833, Test Loss: 1.116179, LR: 0.050000\n",
      "Seed 45, Epoch [670/1000], Train Loss: 1.134787, Test Loss: 1.069582, LR: 0.050000\n",
      "Seed 45, Epoch [680/1000], Train Loss: 1.123389, Test Loss: 1.071645, LR: 0.050000\n",
      "Seed 45, Epoch [690/1000], Train Loss: 1.104443, Test Loss: 1.003590, LR: 0.050000\n",
      "Seed 45, Epoch [700/1000], Train Loss: 1.087822, Test Loss: 0.972495, LR: 0.050000\n",
      "Seed 45, Epoch [710/1000], Train Loss: 1.073779, Test Loss: 0.954109, LR: 0.050000\n",
      "Seed 45, Epoch [720/1000], Train Loss: 1.061154, Test Loss: 0.949025, LR: 0.050000\n",
      "Seed 45, Epoch [730/1000], Train Loss: 1.049829, Test Loss: 0.941075, LR: 0.050000\n",
      "Seed 45, Epoch [740/1000], Train Loss: 1.045687, Test Loss: 0.942585, LR: 0.050000\n",
      "Seed 45, Epoch [750/1000], Train Loss: 1.028808, Test Loss: 0.931762, LR: 0.050000\n",
      "Seed 45, Epoch [760/1000], Train Loss: 1.022404, Test Loss: 0.935050, LR: 0.050000\n",
      "Seed 45, Epoch [770/1000], Train Loss: 1.009814, Test Loss: 0.935880, LR: 0.050000\n",
      "Seed 45, Epoch [780/1000], Train Loss: 1.004574, Test Loss: 0.931347, LR: 0.050000\n",
      "Seed 45, Epoch [790/1000], Train Loss: 0.993061, Test Loss: 0.931679, LR: 0.050000\n",
      "Seed 45, Epoch [800/1000], Train Loss: 0.985518, Test Loss: 0.943903, LR: 0.050000\n",
      "Seed 45, Epoch [810/1000], Train Loss: 0.977341, Test Loss: 0.950767, LR: 0.050000\n",
      "Seed 45, Epoch [820/1000], Train Loss: 0.972397, Test Loss: 0.965252, LR: 0.050000\n",
      "Seed 45, Epoch [830/1000], Train Loss: 0.963434, Test Loss: 0.963741, LR: 0.050000\n",
      "Seed 45, Epoch [840/1000], Train Loss: 0.956366, Test Loss: 0.977912, LR: 0.050000\n",
      "Seed 45, Epoch [850/1000], Train Loss: 0.949587, Test Loss: 0.971245, LR: 0.050000\n",
      "Seed 45, Epoch [860/1000], Train Loss: 0.943203, Test Loss: 0.987966, LR: 0.050000\n",
      "Seed 45, Epoch [870/1000], Train Loss: 0.936608, Test Loss: 1.010782, LR: 0.050000\n",
      "Seed 45, Epoch [880/1000], Train Loss: 0.944712, Test Loss: 1.014478, LR: 0.050000\n",
      "Seed 45, Epoch [890/1000], Train Loss: 0.927634, Test Loss: 1.002099, LR: 0.050000\n",
      "Seed 45, Epoch [900/1000], Train Loss: 0.920311, Test Loss: 1.009133, LR: 0.050000\n",
      "Seed 45, Epoch [910/1000], Train Loss: 0.915454, Test Loss: 1.048498, LR: 0.050000\n",
      "Seed 45, Epoch [920/1000], Train Loss: 0.920996, Test Loss: 1.062470, LR: 0.050000\n",
      "Seed 45, Epoch [930/1000], Train Loss: 0.912566, Test Loss: 1.015394, LR: 0.050000\n",
      "Seed 45, Epoch [940/1000], Train Loss: 0.906538, Test Loss: 1.045070, LR: 0.050000\n",
      "Seed 45, Epoch [950/1000], Train Loss: 0.900777, Test Loss: 1.061852, LR: 0.050000\n",
      "Seed 45, Epoch [960/1000], Train Loss: 0.896271, Test Loss: 1.088685, LR: 0.050000\n",
      "Seed 45, Epoch [970/1000], Train Loss: 0.892001, Test Loss: 1.120081, LR: 0.050000\n",
      "Seed 45, Epoch [980/1000], Train Loss: 0.900698, Test Loss: 1.084469, LR: 0.050000\n",
      "Seed 45, Epoch [990/1000], Train Loss: 0.894448, Test Loss: 1.096373, LR: 0.050000\n",
      "Seed 45, Epoch [1000/1000], Train Loss: 0.883243, Test Loss: 1.095908, LR: 0.050000\n",
      "Seed 46, Epoch [10/1000], Train Loss: 2.760983, Test Loss: 2.597235, LR: 0.050000\n",
      "Seed 46, Epoch [20/1000], Train Loss: 2.604460, Test Loss: 2.496331, LR: 0.050000\n",
      "Seed 46, Epoch [30/1000], Train Loss: 2.616900, Test Loss: 2.483099, LR: 0.050000\n",
      "Seed 46, Epoch [40/1000], Train Loss: 2.607748, Test Loss: 2.459864, LR: 0.050000\n",
      "Seed 46, Epoch [50/1000], Train Loss: 2.571065, Test Loss: 2.416734, LR: 0.050000\n",
      "Seed 46, Epoch [60/1000], Train Loss: 2.523323, Test Loss: 2.366278, LR: 0.050000\n",
      "Seed 46, Epoch [70/1000], Train Loss: 2.473933, Test Loss: 2.317030, LR: 0.050000\n",
      "Seed 46, Epoch [80/1000], Train Loss: 2.425252, Test Loss: 2.272438, LR: 0.050000\n",
      "Seed 46, Epoch [90/1000], Train Loss: 2.378162, Test Loss: 2.227695, LR: 0.050000\n",
      "Seed 46, Epoch [100/1000], Train Loss: 2.334648, Test Loss: 2.189550, LR: 0.050000\n",
      "Seed 46, Epoch [110/1000], Train Loss: 2.292921, Test Loss: 2.160012, LR: 0.050000\n",
      "Seed 46, Epoch [120/1000], Train Loss: 2.245093, Test Loss: 2.134346, LR: 0.050000\n",
      "Seed 46, Epoch [130/1000], Train Loss: 2.187263, Test Loss: 2.103154, LR: 0.050000\n",
      "Seed 46, Epoch [140/1000], Train Loss: 2.124987, Test Loss: 2.064733, LR: 0.050000\n",
      "Seed 46, Epoch [150/1000], Train Loss: 2.053256, Test Loss: 2.017574, LR: 0.050000\n",
      "Seed 46, Epoch [160/1000], Train Loss: 1.942456, Test Loss: 1.962375, LR: 0.050000\n",
      "Seed 46, Epoch [170/1000], Train Loss: 1.766454, Test Loss: 1.853995, LR: 0.050000\n",
      "Seed 46, Epoch [180/1000], Train Loss: 1.579003, Test Loss: 1.690825, LR: 0.050000\n",
      "Seed 46, Epoch [190/1000], Train Loss: 1.596195, Test Loss: 1.823801, LR: 0.050000\n",
      "Seed 46, Epoch [200/1000], Train Loss: 1.436366, Test Loss: 1.743764, LR: 0.050000\n",
      "Seed 46, Epoch [210/1000], Train Loss: 1.363952, Test Loss: 1.754856, LR: 0.050000\n",
      "Seed 46, Epoch [220/1000], Train Loss: 1.282834, Test Loss: 1.745192, LR: 0.050000\n",
      "Seed 46, Epoch [230/1000], Train Loss: 1.211933, Test Loss: 1.737437, LR: 0.050000\n",
      "Seed 46, Epoch [240/1000], Train Loss: 1.159331, Test Loss: 1.774857, LR: 0.050000\n",
      "Seed 46, Epoch [250/1000], Train Loss: 1.091398, Test Loss: 1.807671, LR: 0.050000\n",
      "Seed 46, Epoch [260/1000], Train Loss: 1.125633, Test Loss: 1.912747, LR: 0.050000\n",
      "Seed 46, Epoch [270/1000], Train Loss: 1.025214, Test Loss: 1.893965, LR: 0.050000\n",
      "Seed 46, Epoch [280/1000], Train Loss: 1.045084, Test Loss: 1.991867, LR: 0.050000\n",
      "Seed 46, Epoch [290/1000], Train Loss: 0.982848, Test Loss: 2.001883, LR: 0.050000\n",
      "Seed 46, Epoch [300/1000], Train Loss: 0.954502, Test Loss: 2.052302, LR: 0.050000\n",
      "Seed 46, Epoch [310/1000], Train Loss: 0.987938, Test Loss: 2.143265, LR: 0.050000\n",
      "Seed 46, Epoch [320/1000], Train Loss: 0.949671, Test Loss: 2.190127, LR: 0.050000\n",
      "Seed 46, Epoch [330/1000], Train Loss: 0.928107, Test Loss: 2.182646, LR: 0.050000\n",
      "Seed 46, Epoch [340/1000], Train Loss: 0.958491, Test Loss: 2.301544, LR: 0.050000\n",
      "Seed 46, Epoch [350/1000], Train Loss: 0.892050, Test Loss: 2.300869, LR: 0.050000\n",
      "Seed 46, Epoch [360/1000], Train Loss: 0.896313, Test Loss: 2.359020, LR: 0.050000\n",
      "Seed 46, Epoch [370/1000], Train Loss: 1.297233, Test Loss: 2.748428, LR: 0.050000\n",
      "Seed 46, Epoch [380/1000], Train Loss: 1.003962, Test Loss: 2.565312, LR: 0.050000\n",
      "Seed 46, Epoch [390/1000], Train Loss: 0.975560, Test Loss: 2.518525, LR: 0.050000\n",
      "Seed 46, Epoch [400/1000], Train Loss: 0.858975, Test Loss: 2.517869, LR: 0.050000\n",
      "Seed 46, Epoch [410/1000], Train Loss: 0.831785, Test Loss: 2.584596, LR: 0.050000\n",
      "Seed 46, Epoch [420/1000], Train Loss: 0.994460, Test Loss: 2.717974, LR: 0.050000\n",
      "Seed 46, Epoch [430/1000], Train Loss: 0.861744, Test Loss: 2.611887, LR: 0.050000\n",
      "Seed 46, Epoch [440/1000], Train Loss: 0.794581, Test Loss: 2.531816, LR: 0.050000\n",
      "Seed 46, Epoch [450/1000], Train Loss: 0.800855, Test Loss: 2.573096, LR: 0.050000\n",
      "Seed 46, Epoch [460/1000], Train Loss: 0.771742, Test Loss: 2.737402, LR: 0.050000\n",
      "Seed 46, Epoch [470/1000], Train Loss: 0.852199, Test Loss: 2.596163, LR: 0.050000\n",
      "Seed 46, Epoch [480/1000], Train Loss: 0.862910, Test Loss: 2.708902, LR: 0.050000\n",
      "Seed 46, Epoch [490/1000], Train Loss: 0.781482, Test Loss: 2.606654, LR: 0.050000\n",
      "Seed 46, Epoch [500/1000], Train Loss: 0.771826, Test Loss: 2.712451, LR: 0.050000\n",
      "Seed 46, Epoch [510/1000], Train Loss: 0.816293, Test Loss: 2.715246, LR: 0.050000\n",
      "Seed 46, Epoch [520/1000], Train Loss: 0.760741, Test Loss: 2.660086, LR: 0.050000\n",
      "Seed 46, Epoch [530/1000], Train Loss: 0.741930, Test Loss: 2.782179, LR: 0.050000\n",
      "Seed 46, Epoch [540/1000], Train Loss: 0.755305, Test Loss: 2.711059, LR: 0.050000\n",
      "Seed 46, Epoch [550/1000], Train Loss: 0.779877, Test Loss: 3.016567, LR: 0.050000\n",
      "Seed 46, Epoch [560/1000], Train Loss: 0.800738, Test Loss: 2.818557, LR: 0.050000\n",
      "Seed 46, Epoch [570/1000], Train Loss: 0.755128, Test Loss: 2.830034, LR: 0.050000\n",
      "Seed 46, Epoch [580/1000], Train Loss: 0.789717, Test Loss: 2.794108, LR: 0.050000\n",
      "Seed 46, Epoch [590/1000], Train Loss: 0.793271, Test Loss: 2.787339, LR: 0.050000\n",
      "Seed 46, Epoch [600/1000], Train Loss: 0.738553, Test Loss: 2.914524, LR: 0.050000\n",
      "Seed 46, Epoch [610/1000], Train Loss: 0.831922, Test Loss: 2.786793, LR: 0.050000\n",
      "Seed 46, Epoch [620/1000], Train Loss: 0.794329, Test Loss: 2.823604, LR: 0.050000\n",
      "Seed 46, Epoch [630/1000], Train Loss: 0.735860, Test Loss: 2.869044, LR: 0.050000\n",
      "Seed 46, Epoch [640/1000], Train Loss: 0.783088, Test Loss: 2.858175, LR: 0.050000\n",
      "Seed 46, Epoch [650/1000], Train Loss: 0.895483, Test Loss: 2.628796, LR: 0.050000\n",
      "Seed 46, Epoch [660/1000], Train Loss: 0.785205, Test Loss: 2.871275, LR: 0.050000\n",
      "Seed 46, Epoch [670/1000], Train Loss: 0.745689, Test Loss: 2.893512, LR: 0.050000\n",
      "Seed 46, Epoch [680/1000], Train Loss: 1.201106, Test Loss: 3.336215, LR: 0.050000\n",
      "Early stopping at epoch 681 for seed 46\n",
      "Seed 47, Epoch [10/1000], Train Loss: 2.256555, Test Loss: 2.118211, LR: 0.050000\n",
      "Seed 47, Epoch [20/1000], Train Loss: 2.478718, Test Loss: 2.367114, LR: 0.050000\n",
      "Seed 47, Epoch [30/1000], Train Loss: 2.499665, Test Loss: 2.395586, LR: 0.050000\n",
      "Seed 47, Epoch [40/1000], Train Loss: 2.467701, Test Loss: 2.366994, LR: 0.050000\n",
      "Seed 47, Epoch [50/1000], Train Loss: 2.453820, Test Loss: 2.358397, LR: 0.050000\n",
      "Seed 47, Epoch [60/1000], Train Loss: 2.451459, Test Loss: 2.358545, LR: 0.050000\n",
      "Seed 47, Epoch [70/1000], Train Loss: 2.445316, Test Loss: 2.355418, LR: 0.050000\n",
      "Seed 47, Epoch [80/1000], Train Loss: 2.436588, Test Loss: 2.351106, LR: 0.050000\n",
      "Seed 47, Epoch [90/1000], Train Loss: 2.427673, Test Loss: 2.347176, LR: 0.050000\n",
      "Seed 47, Epoch [100/1000], Train Loss: 2.418153, Test Loss: 2.342736, LR: 0.050000\n",
      "Seed 47, Epoch [110/1000], Train Loss: 2.407917, Test Loss: 2.337587, LR: 0.050000\n",
      "Seed 47, Epoch [120/1000], Train Loss: 2.397176, Test Loss: 2.332056, LR: 0.050000\n",
      "Seed 47, Epoch [130/1000], Train Loss: 2.385966, Test Loss: 2.326321, LR: 0.050000\n",
      "Seed 47, Epoch [140/1000], Train Loss: 2.374313, Test Loss: 2.320366, LR: 0.050000\n",
      "Seed 47, Epoch [150/1000], Train Loss: 2.362256, Test Loss: 2.314081, LR: 0.050000\n",
      "Seed 47, Epoch [160/1000], Train Loss: 2.349821, Test Loss: 2.307441, LR: 0.050000\n",
      "Seed 47, Epoch [170/1000], Train Loss: 2.337046, Test Loss: 2.300551, LR: 0.050000\n",
      "Seed 47, Epoch [180/1000], Train Loss: 2.323980, Test Loss: 2.293536, LR: 0.050000\n",
      "Seed 47, Epoch [190/1000], Train Loss: 2.310679, Test Loss: 2.286465, LR: 0.050000\n",
      "Seed 47, Epoch [200/1000], Train Loss: 2.297204, Test Loss: 2.279378, LR: 0.050000\n",
      "Seed 47, Epoch [210/1000], Train Loss: 2.283599, Test Loss: 2.272335, LR: 0.050000\n",
      "Seed 47, Epoch [220/1000], Train Loss: 2.269879, Test Loss: 2.265394, LR: 0.050000\n",
      "Seed 47, Epoch [230/1000], Train Loss: 2.256006, Test Loss: 2.258563, LR: 0.050000\n",
      "Seed 47, Epoch [240/1000], Train Loss: 2.241858, Test Loss: 2.251775, LR: 0.050000\n",
      "Seed 47, Epoch [250/1000], Train Loss: 2.227211, Test Loss: 2.244894, LR: 0.050000\n",
      "Seed 47, Epoch [260/1000], Train Loss: 2.211721, Test Loss: 2.237695, LR: 0.050000\n",
      "Seed 47, Epoch [270/1000], Train Loss: 2.194916, Test Loss: 2.229838, LR: 0.050000\n",
      "Seed 47, Epoch [280/1000], Train Loss: 2.176194, Test Loss: 2.220863, LR: 0.050000\n",
      "Seed 47, Epoch [290/1000], Train Loss: 2.154791, Test Loss: 2.210178, LR: 0.050000\n",
      "Seed 47, Epoch [300/1000], Train Loss: 2.129846, Test Loss: 2.197208, LR: 0.050000\n",
      "Seed 47, Epoch [310/1000], Train Loss: 2.101194, Test Loss: 2.181241, LR: 0.050000\n",
      "Seed 47, Epoch [320/1000], Train Loss: 2.066675, Test Loss: 2.161238, LR: 0.050000\n",
      "Seed 47, Epoch [330/1000], Train Loss: 2.024692, Test Loss: 2.136084, LR: 0.050000\n",
      "Seed 47, Epoch [340/1000], Train Loss: 1.972566, Test Loss: 2.104129, LR: 0.050000\n",
      "Seed 47, Epoch [350/1000], Train Loss: 1.906693, Test Loss: 2.063352, LR: 0.050000\n",
      "Seed 47, Epoch [360/1000], Train Loss: 1.824975, Test Loss: 2.010010, LR: 0.050000\n",
      "Seed 47, Epoch [370/1000], Train Loss: 1.734754, Test Loss: 1.944327, LR: 0.050000\n",
      "Seed 47, Epoch [380/1000], Train Loss: 1.657098, Test Loss: 1.874240, LR: 0.050000\n",
      "Seed 47, Epoch [390/1000], Train Loss: 1.578460, Test Loss: 1.805856, LR: 0.050000\n",
      "Seed 47, Epoch [400/1000], Train Loss: 1.502610, Test Loss: 1.734600, LR: 0.050000\n",
      "Seed 47, Epoch [410/1000], Train Loss: 1.430744, Test Loss: 1.662160, LR: 0.050000\n",
      "Seed 47, Epoch [420/1000], Train Loss: 1.377780, Test Loss: 1.598619, LR: 0.050000\n",
      "Seed 47, Epoch [430/1000], Train Loss: 1.332930, Test Loss: 1.575717, LR: 0.050000\n",
      "Seed 47, Epoch [440/1000], Train Loss: 1.281639, Test Loss: 1.628126, LR: 0.050000\n",
      "Seed 47, Epoch [450/1000], Train Loss: 1.231311, Test Loss: 1.719976, LR: 0.050000\n",
      "Seed 47, Epoch [460/1000], Train Loss: 1.184210, Test Loss: 1.663210, LR: 0.050000\n",
      "Seed 47, Epoch [470/1000], Train Loss: 1.139507, Test Loss: 1.671284, LR: 0.050000\n",
      "Seed 47, Epoch [480/1000], Train Loss: 1.102953, Test Loss: 1.505700, LR: 0.050000\n",
      "Seed 47, Epoch [490/1000], Train Loss: 1.083818, Test Loss: 1.492056, LR: 0.050000\n",
      "Seed 47, Epoch [500/1000], Train Loss: 1.044076, Test Loss: 1.358467, LR: 0.050000\n",
      "Seed 47, Epoch [510/1000], Train Loss: 1.012363, Test Loss: 1.278029, LR: 0.050000\n",
      "Seed 47, Epoch [520/1000], Train Loss: 1.003836, Test Loss: 1.265012, LR: 0.050000\n",
      "Seed 47, Epoch [530/1000], Train Loss: 0.998899, Test Loss: 1.263918, LR: 0.050000\n",
      "Seed 47, Epoch [540/1000], Train Loss: 0.996222, Test Loss: 1.215013, LR: 0.050000\n",
      "Seed 47, Epoch [550/1000], Train Loss: 0.990685, Test Loss: 1.216951, LR: 0.050000\n",
      "Seed 47, Epoch [560/1000], Train Loss: 0.983836, Test Loss: 1.222523, LR: 0.050000\n",
      "Seed 47, Epoch [570/1000], Train Loss: 1.011384, Test Loss: 1.184435, LR: 0.050000\n",
      "Seed 47, Epoch [580/1000], Train Loss: 0.991283, Test Loss: 1.180366, LR: 0.050000\n",
      "Seed 47, Epoch [590/1000], Train Loss: 0.976724, Test Loss: 1.192821, LR: 0.050000\n",
      "Seed 47, Epoch [600/1000], Train Loss: 0.975508, Test Loss: 1.187324, LR: 0.050000\n",
      "Seed 47, Epoch [610/1000], Train Loss: 0.981378, Test Loss: 1.163226, LR: 0.050000\n",
      "Seed 47, Epoch [620/1000], Train Loss: 0.968866, Test Loss: 1.168921, LR: 0.050000\n",
      "Seed 47, Epoch [630/1000], Train Loss: 0.955788, Test Loss: 1.172374, LR: 0.050000\n",
      "Seed 47, Epoch [640/1000], Train Loss: 0.951054, Test Loss: 1.170970, LR: 0.050000\n",
      "Seed 47, Epoch [650/1000], Train Loss: 1.071212, Test Loss: 1.198419, LR: 0.050000\n",
      "Seed 47, Epoch [660/1000], Train Loss: 0.961043, Test Loss: 1.186163, LR: 0.050000\n",
      "Seed 47, Epoch [670/1000], Train Loss: 0.947301, Test Loss: 1.186369, LR: 0.050000\n",
      "Seed 47, Epoch [680/1000], Train Loss: 0.954608, Test Loss: 1.178455, LR: 0.050000\n",
      "Seed 47, Epoch [690/1000], Train Loss: 0.943626, Test Loss: 1.184367, LR: 0.050000\n",
      "Seed 47, Epoch [700/1000], Train Loss: 0.934528, Test Loss: 1.196669, LR: 0.050000\n",
      "Seed 47, Epoch [710/1000], Train Loss: 0.931614, Test Loss: 1.205962, LR: 0.050000\n",
      "Seed 47, Epoch [720/1000], Train Loss: 0.930210, Test Loss: 1.220883, LR: 0.050000\n",
      "Seed 47, Epoch [730/1000], Train Loss: 0.953910, Test Loss: 1.214338, LR: 0.050000\n",
      "Seed 47, Epoch [740/1000], Train Loss: 0.921342, Test Loss: 1.216420, LR: 0.050000\n",
      "Seed 47, Epoch [750/1000], Train Loss: 0.916682, Test Loss: 1.274730, LR: 0.050000\n",
      "Seed 47, Epoch [760/1000], Train Loss: 0.922421, Test Loss: 1.265479, LR: 0.050000\n",
      "Seed 47, Epoch [770/1000], Train Loss: 0.909127, Test Loss: 1.265872, LR: 0.050000\n",
      "Seed 47, Epoch [780/1000], Train Loss: 0.946892, Test Loss: 1.337997, LR: 0.050000\n",
      "Seed 47, Epoch [790/1000], Train Loss: 0.899995, Test Loss: 1.322114, LR: 0.050000\n",
      "Seed 47, Epoch [800/1000], Train Loss: 0.892010, Test Loss: 1.323055, LR: 0.050000\n",
      "Seed 47, Epoch [810/1000], Train Loss: 0.922587, Test Loss: 1.572787, LR: 0.050000\n",
      "Seed 47, Epoch [820/1000], Train Loss: 0.935842, Test Loss: 1.335268, LR: 0.050000\n",
      "Seed 47, Epoch [830/1000], Train Loss: 0.912661, Test Loss: 1.369605, LR: 0.050000\n",
      "Seed 47, Epoch [840/1000], Train Loss: 0.888789, Test Loss: 1.404511, LR: 0.050000\n",
      "Seed 47, Epoch [850/1000], Train Loss: 0.876202, Test Loss: 1.416763, LR: 0.050000\n",
      "Seed 47, Epoch [860/1000], Train Loss: 0.871626, Test Loss: 1.421072, LR: 0.050000\n",
      "Seed 47, Epoch [870/1000], Train Loss: 0.880354, Test Loss: 1.568726, LR: 0.050000\n",
      "Seed 47, Epoch [880/1000], Train Loss: 0.874675, Test Loss: 1.470548, LR: 0.050000\n",
      "Seed 47, Epoch [890/1000], Train Loss: 0.865107, Test Loss: 1.541721, LR: 0.050000\n",
      "Seed 47, Epoch [900/1000], Train Loss: 0.859906, Test Loss: 1.560507, LR: 0.050000\n",
      "Seed 47, Epoch [910/1000], Train Loss: 0.856277, Test Loss: 1.574406, LR: 0.050000\n",
      "Seed 47, Epoch [920/1000], Train Loss: 0.894113, Test Loss: 1.582870, LR: 0.050000\n",
      "Seed 47, Epoch [930/1000], Train Loss: 0.871141, Test Loss: 1.599360, LR: 0.050000\n",
      "Seed 47, Epoch [940/1000], Train Loss: 0.859794, Test Loss: 1.625709, LR: 0.050000\n",
      "Seed 47, Epoch [950/1000], Train Loss: 0.851866, Test Loss: 1.653800, LR: 0.050000\n",
      "Seed 47, Epoch [960/1000], Train Loss: 0.848876, Test Loss: 1.690854, LR: 0.050000\n",
      "Seed 47, Epoch [970/1000], Train Loss: 0.870085, Test Loss: 1.634313, LR: 0.050000\n",
      "Seed 47, Epoch [980/1000], Train Loss: 0.854941, Test Loss: 1.702764, LR: 0.050000\n",
      "Seed 47, Epoch [990/1000], Train Loss: 0.848033, Test Loss: 1.662055, LR: 0.050000\n",
      "Seed 47, Epoch [1000/1000], Train Loss: 0.850927, Test Loss: 1.695619, LR: 0.050000\n",
      "Seed 48, Epoch [10/1000], Train Loss: 3.481709, Test Loss: 2.632073, LR: 0.050000\n",
      "Seed 48, Epoch [20/1000], Train Loss: 3.133887, Test Loss: 2.132570, LR: 0.050000\n",
      "Seed 48, Epoch [30/1000], Train Loss: 2.964730, Test Loss: 2.130205, LR: 0.050000\n",
      "Seed 48, Epoch [40/1000], Train Loss: 2.890904, Test Loss: 2.142720, LR: 0.050000\n",
      "Seed 48, Epoch [50/1000], Train Loss: 2.714682, Test Loss: 2.136017, LR: 0.050000\n",
      "Seed 48, Epoch [60/1000], Train Loss: 2.561509, Test Loss: 2.126068, LR: 0.050000\n",
      "Seed 48, Epoch [70/1000], Train Loss: 2.439458, Test Loss: 2.116391, LR: 0.050000\n",
      "Seed 48, Epoch [80/1000], Train Loss: 2.340477, Test Loss: 2.107621, LR: 0.050000\n",
      "Seed 48, Epoch [90/1000], Train Loss: 2.258506, Test Loss: 2.098968, LR: 0.050000\n",
      "Seed 48, Epoch [100/1000], Train Loss: 2.223687, Test Loss: 2.091156, LR: 0.050000\n",
      "Seed 48, Epoch [110/1000], Train Loss: 2.210763, Test Loss: 2.083506, LR: 0.050000\n",
      "Seed 48, Epoch [120/1000], Train Loss: 2.198715, Test Loss: 2.075686, LR: 0.050000\n",
      "Seed 48, Epoch [130/1000], Train Loss: 2.186085, Test Loss: 2.067339, LR: 0.050000\n",
      "Seed 48, Epoch [140/1000], Train Loss: 2.172536, Test Loss: 2.058324, LR: 0.050000\n",
      "Seed 48, Epoch [150/1000], Train Loss: 2.157954, Test Loss: 2.048497, LR: 0.050000\n",
      "Seed 48, Epoch [160/1000], Train Loss: 2.142376, Test Loss: 2.038006, LR: 0.050000\n",
      "Seed 48, Epoch [170/1000], Train Loss: 2.125269, Test Loss: 2.026350, LR: 0.050000\n",
      "Seed 48, Epoch [180/1000], Train Loss: 2.106499, Test Loss: 2.013444, LR: 0.050000\n",
      "Seed 48, Epoch [190/1000], Train Loss: 2.085777, Test Loss: 1.999024, LR: 0.050000\n",
      "Seed 48, Epoch [200/1000], Train Loss: 2.062902, Test Loss: 1.982753, LR: 0.050000\n",
      "Seed 48, Epoch [210/1000], Train Loss: 2.037559, Test Loss: 1.964282, LR: 0.050000\n",
      "Seed 48, Epoch [220/1000], Train Loss: 2.009457, Test Loss: 1.943048, LR: 0.050000\n",
      "Seed 48, Epoch [230/1000], Train Loss: 1.978251, Test Loss: 1.918417, LR: 0.050000\n",
      "Seed 48, Epoch [240/1000], Train Loss: 1.943728, Test Loss: 1.889340, LR: 0.050000\n",
      "Seed 48, Epoch [250/1000], Train Loss: 1.905915, Test Loss: 1.855039, LR: 0.050000\n",
      "Seed 48, Epoch [260/1000], Train Loss: 1.865528, Test Loss: 1.814570, LR: 0.050000\n",
      "Seed 48, Epoch [270/1000], Train Loss: 1.824353, Test Loss: 1.767713, LR: 0.050000\n",
      "Seed 48, Epoch [280/1000], Train Loss: 1.787086, Test Loss: 1.716495, LR: 0.050000\n",
      "Seed 48, Epoch [290/1000], Train Loss: 1.758461, Test Loss: 1.667014, LR: 0.050000\n",
      "Seed 48, Epoch [300/1000], Train Loss: 1.736799, Test Loss: 1.624972, LR: 0.050000\n",
      "Seed 48, Epoch [310/1000], Train Loss: 1.716273, Test Loss: 1.598189, LR: 0.050000\n",
      "Seed 48, Epoch [320/1000], Train Loss: 1.697541, Test Loss: 1.583453, LR: 0.050000\n",
      "Seed 48, Epoch [330/1000], Train Loss: 1.680582, Test Loss: 1.576852, LR: 0.050000\n",
      "Seed 48, Epoch [340/1000], Train Loss: 1.662763, Test Loss: 1.572369, LR: 0.050000\n",
      "Seed 48, Epoch [350/1000], Train Loss: 1.643736, Test Loss: 1.569586, LR: 0.050000\n",
      "Seed 48, Epoch [360/1000], Train Loss: 1.623685, Test Loss: 1.568264, LR: 0.050000\n",
      "Seed 48, Epoch [370/1000], Train Loss: 1.600138, Test Loss: 1.572946, LR: 0.050000\n",
      "Seed 48, Epoch [380/1000], Train Loss: 1.575619, Test Loss: 1.583189, LR: 0.050000\n",
      "Seed 48, Epoch [390/1000], Train Loss: 1.549995, Test Loss: 1.597861, LR: 0.050000\n",
      "Seed 48, Epoch [400/1000], Train Loss: 1.523964, Test Loss: 1.605362, LR: 0.050000\n",
      "Seed 48, Epoch [410/1000], Train Loss: 1.497276, Test Loss: 1.601165, LR: 0.050000\n",
      "Seed 48, Epoch [420/1000], Train Loss: 1.471065, Test Loss: 1.574835, LR: 0.050000\n",
      "Seed 48, Epoch [430/1000], Train Loss: 1.443287, Test Loss: 1.527014, LR: 0.050000\n",
      "Seed 48, Epoch [440/1000], Train Loss: 1.417979, Test Loss: 1.450900, LR: 0.050000\n",
      "Seed 48, Epoch [450/1000], Train Loss: 1.393058, Test Loss: 1.368628, LR: 0.050000\n",
      "Seed 48, Epoch [460/1000], Train Loss: 1.368416, Test Loss: 1.293200, LR: 0.050000\n",
      "Seed 48, Epoch [470/1000], Train Loss: 1.343658, Test Loss: 1.225225, LR: 0.050000\n",
      "Seed 48, Epoch [480/1000], Train Loss: 1.319396, Test Loss: 1.162337, LR: 0.050000\n",
      "Seed 48, Epoch [490/1000], Train Loss: 1.293146, Test Loss: 1.117409, LR: 0.050000\n",
      "Seed 48, Epoch [500/1000], Train Loss: 1.268375, Test Loss: 1.087833, LR: 0.050000\n",
      "Seed 48, Epoch [510/1000], Train Loss: 1.244073, Test Loss: 1.074293, LR: 0.050000\n",
      "Seed 48, Epoch [520/1000], Train Loss: 1.221417, Test Loss: 1.066656, LR: 0.050000\n",
      "Seed 48, Epoch [530/1000], Train Loss: 1.200365, Test Loss: 1.067534, LR: 0.050000\n",
      "Seed 48, Epoch [540/1000], Train Loss: 1.182446, Test Loss: 1.068745, LR: 0.050000\n",
      "Seed 48, Epoch [550/1000], Train Loss: 1.165459, Test Loss: 1.079749, LR: 0.050000\n",
      "Seed 48, Epoch [560/1000], Train Loss: 1.151839, Test Loss: 1.089661, LR: 0.050000\n",
      "Seed 48, Epoch [570/1000], Train Loss: 1.139399, Test Loss: 1.102822, LR: 0.050000\n",
      "Seed 48, Epoch [580/1000], Train Loss: 1.128417, Test Loss: 1.111660, LR: 0.050000\n",
      "Seed 48, Epoch [590/1000], Train Loss: 1.118374, Test Loss: 1.126672, LR: 0.050000\n",
      "Seed 48, Epoch [600/1000], Train Loss: 1.109676, Test Loss: 1.136615, LR: 0.050000\n",
      "Seed 48, Epoch [610/1000], Train Loss: 1.100621, Test Loss: 1.154988, LR: 0.050000\n",
      "Seed 48, Epoch [620/1000], Train Loss: 1.092853, Test Loss: 1.170576, LR: 0.050000\n",
      "Seed 48, Epoch [630/1000], Train Loss: 1.085120, Test Loss: 1.192378, LR: 0.050000\n",
      "Seed 48, Epoch [640/1000], Train Loss: 1.077619, Test Loss: 1.210596, LR: 0.050000\n",
      "Seed 48, Epoch [650/1000], Train Loss: 1.070197, Test Loss: 1.239706, LR: 0.050000\n",
      "Seed 48, Epoch [660/1000], Train Loss: 1.063644, Test Loss: 1.262064, LR: 0.050000\n",
      "Seed 48, Epoch [670/1000], Train Loss: 1.056839, Test Loss: 1.292230, LR: 0.050000\n",
      "Seed 48, Epoch [680/1000], Train Loss: 1.050822, Test Loss: 1.316706, LR: 0.050000\n",
      "Seed 48, Epoch [690/1000], Train Loss: 1.044528, Test Loss: 1.352285, LR: 0.050000\n",
      "Seed 48, Epoch [700/1000], Train Loss: 1.038754, Test Loss: 1.378450, LR: 0.050000\n",
      "Seed 48, Epoch [710/1000], Train Loss: 1.033516, Test Loss: 1.405000, LR: 0.050000\n",
      "Seed 48, Epoch [720/1000], Train Loss: 1.028386, Test Loss: 1.438241, LR: 0.050000\n",
      "Seed 48, Epoch [730/1000], Train Loss: 1.023153, Test Loss: 1.465816, LR: 0.050000\n",
      "Seed 48, Epoch [740/1000], Train Loss: 1.018791, Test Loss: 1.497565, LR: 0.050000\n",
      "Seed 48, Epoch [750/1000], Train Loss: 1.014460, Test Loss: 1.514377, LR: 0.050000\n",
      "Seed 48, Epoch [760/1000], Train Loss: 1.011069, Test Loss: 1.535166, LR: 0.050000\n",
      "Seed 48, Epoch [770/1000], Train Loss: 1.006343, Test Loss: 1.566148, LR: 0.050000\n",
      "Seed 48, Epoch [780/1000], Train Loss: 1.002643, Test Loss: 1.605696, LR: 0.050000\n",
      "Seed 48, Epoch [790/1000], Train Loss: 0.999543, Test Loss: 1.613330, LR: 0.050000\n",
      "Seed 48, Epoch [800/1000], Train Loss: 0.995938, Test Loss: 1.648286, LR: 0.050000\n",
      "Seed 48, Epoch [810/1000], Train Loss: 0.993079, Test Loss: 1.654976, LR: 0.050000\n",
      "Seed 48, Epoch [820/1000], Train Loss: 0.990518, Test Loss: 1.672200, LR: 0.050000\n",
      "Seed 48, Epoch [830/1000], Train Loss: 0.987018, Test Loss: 1.688508, LR: 0.050000\n",
      "Seed 48, Epoch [840/1000], Train Loss: 0.984848, Test Loss: 1.714948, LR: 0.050000\n",
      "Seed 48, Epoch [850/1000], Train Loss: 0.982318, Test Loss: 1.721871, LR: 0.050000\n",
      "Seed 48, Epoch [860/1000], Train Loss: 0.979022, Test Loss: 1.735664, LR: 0.050000\n",
      "Seed 48, Epoch [870/1000], Train Loss: 0.977295, Test Loss: 1.742680, LR: 0.050000\n",
      "Seed 48, Epoch [880/1000], Train Loss: 0.974950, Test Loss: 1.779444, LR: 0.050000\n",
      "Seed 48, Epoch [890/1000], Train Loss: 0.972340, Test Loss: 1.767010, LR: 0.050000\n",
      "Seed 48, Epoch [900/1000], Train Loss: 0.970293, Test Loss: 1.786982, LR: 0.050000\n",
      "Seed 48, Epoch [910/1000], Train Loss: 0.968124, Test Loss: 1.765068, LR: 0.050000\n",
      "Seed 48, Epoch [920/1000], Train Loss: 0.966370, Test Loss: 1.766854, LR: 0.050000\n",
      "Seed 48, Epoch [930/1000], Train Loss: 1.389276, Test Loss: 2.144129, LR: 0.050000\n",
      "Seed 48, Epoch [940/1000], Train Loss: 1.239213, Test Loss: 2.168080, LR: 0.050000\n",
      "Seed 48, Epoch [950/1000], Train Loss: 1.118433, Test Loss: 1.309083, LR: 0.050000\n",
      "Seed 48, Epoch [960/1000], Train Loss: 1.065559, Test Loss: 1.257003, LR: 0.050000\n",
      "Seed 48, Epoch [970/1000], Train Loss: 0.998895, Test Loss: 1.490003, LR: 0.050000\n",
      "Seed 48, Epoch [980/1000], Train Loss: 0.984490, Test Loss: 1.434308, LR: 0.050000\n",
      "Seed 48, Epoch [990/1000], Train Loss: 0.972794, Test Loss: 1.439984, LR: 0.050000\n",
      "Seed 48, Epoch [1000/1000], Train Loss: 0.965077, Test Loss: 1.495890, LR: 0.050000\n",
      "Seed 49, Epoch [10/1000], Train Loss: 3.195864, Test Loss: 2.652612, LR: 0.050000\n",
      "Seed 49, Epoch [20/1000], Train Loss: 2.354620, Test Loss: 2.265422, LR: 0.050000\n",
      "Seed 49, Epoch [30/1000], Train Loss: 2.456224, Test Loss: 2.340342, LR: 0.050000\n",
      "Seed 49, Epoch [40/1000], Train Loss: 2.419564, Test Loss: 2.316858, LR: 0.050000\n",
      "Seed 49, Epoch [50/1000], Train Loss: 2.381121, Test Loss: 2.293367, LR: 0.050000\n",
      "Seed 49, Epoch [60/1000], Train Loss: 2.334945, Test Loss: 2.260539, LR: 0.050000\n",
      "Seed 49, Epoch [70/1000], Train Loss: 2.262002, Test Loss: 2.204165, LR: 0.050000\n",
      "Seed 49, Epoch [80/1000], Train Loss: 2.184422, Test Loss: 2.111082, LR: 0.050000\n",
      "Seed 49, Epoch [90/1000], Train Loss: 1.994921, Test Loss: 1.977581, LR: 0.050000\n",
      "Seed 49, Epoch [100/1000], Train Loss: 1.919612, Test Loss: 1.933981, LR: 0.050000\n",
      "Seed 49, Epoch [110/1000], Train Loss: 1.914463, Test Loss: 1.935542, LR: 0.050000\n",
      "Seed 49, Epoch [120/1000], Train Loss: 1.789449, Test Loss: 1.756366, LR: 0.050000\n",
      "Seed 49, Epoch [130/1000], Train Loss: 1.694926, Test Loss: 1.760692, LR: 0.050000\n",
      "Seed 49, Epoch [140/1000], Train Loss: 1.507368, Test Loss: 1.547785, LR: 0.050000\n",
      "Seed 49, Epoch [150/1000], Train Loss: 1.421840, Test Loss: 1.522218, LR: 0.050000\n",
      "Seed 49, Epoch [160/1000], Train Loss: 1.352617, Test Loss: 1.397239, LR: 0.050000\n",
      "Seed 49, Epoch [170/1000], Train Loss: 1.294913, Test Loss: 1.383003, LR: 0.050000\n",
      "Seed 49, Epoch [180/1000], Train Loss: 1.242318, Test Loss: 1.259153, LR: 0.050000\n",
      "Seed 49, Epoch [190/1000], Train Loss: 1.195952, Test Loss: 1.135955, LR: 0.050000\n",
      "Seed 49, Epoch [200/1000], Train Loss: 1.162482, Test Loss: 1.072643, LR: 0.050000\n",
      "Seed 49, Epoch [210/1000], Train Loss: 1.132467, Test Loss: 1.051613, LR: 0.050000\n",
      "Seed 49, Epoch [220/1000], Train Loss: 1.105686, Test Loss: 1.041854, LR: 0.050000\n",
      "Seed 49, Epoch [230/1000], Train Loss: 1.079017, Test Loss: 1.034120, LR: 0.050000\n",
      "Seed 49, Epoch [240/1000], Train Loss: 1.050032, Test Loss: 1.071470, LR: 0.050000\n",
      "Seed 49, Epoch [250/1000], Train Loss: 1.023274, Test Loss: 1.123075, LR: 0.050000\n",
      "Seed 49, Epoch [260/1000], Train Loss: 1.014496, Test Loss: 1.179216, LR: 0.050000\n",
      "Seed 49, Epoch [270/1000], Train Loss: 0.982281, Test Loss: 1.218645, LR: 0.050000\n",
      "Seed 49, Epoch [280/1000], Train Loss: 0.958643, Test Loss: 1.296030, LR: 0.050000\n",
      "Seed 49, Epoch [290/1000], Train Loss: 0.958336, Test Loss: 1.408522, LR: 0.050000\n",
      "Seed 49, Epoch [300/1000], Train Loss: 0.954798, Test Loss: 1.328376, LR: 0.050000\n",
      "Seed 49, Epoch [310/1000], Train Loss: 0.963819, Test Loss: 1.439737, LR: 0.050000\n",
      "Seed 49, Epoch [320/1000], Train Loss: 0.942318, Test Loss: 1.295596, LR: 0.050000\n",
      "Seed 49, Epoch [330/1000], Train Loss: 0.928594, Test Loss: 1.345628, LR: 0.050000\n",
      "Seed 49, Epoch [340/1000], Train Loss: 0.910241, Test Loss: 1.416662, LR: 0.050000\n",
      "Seed 49, Epoch [350/1000], Train Loss: 0.897147, Test Loss: 1.360313, LR: 0.050000\n",
      "Seed 49, Epoch [360/1000], Train Loss: 0.888410, Test Loss: 1.345124, LR: 0.050000\n",
      "Seed 49, Epoch [370/1000], Train Loss: 0.894162, Test Loss: 1.261374, LR: 0.050000\n",
      "Seed 49, Epoch [380/1000], Train Loss: 0.894470, Test Loss: 1.260699, LR: 0.050000\n",
      "Seed 49, Epoch [390/1000], Train Loss: 0.875388, Test Loss: 1.291097, LR: 0.050000\n",
      "Seed 49, Epoch [400/1000], Train Loss: 0.866695, Test Loss: 1.282217, LR: 0.050000\n",
      "Seed 49, Epoch [410/1000], Train Loss: 0.863638, Test Loss: 1.286853, LR: 0.050000\n",
      "Seed 49, Epoch [420/1000], Train Loss: 0.856876, Test Loss: 1.237397, LR: 0.050000\n",
      "Seed 49, Epoch [430/1000], Train Loss: 0.917481, Test Loss: 1.548401, LR: 0.050000\n",
      "Seed 49, Epoch [440/1000], Train Loss: 1.054648, Test Loss: 1.624878, LR: 0.050000\n",
      "Seed 49, Epoch [450/1000], Train Loss: 1.114986, Test Loss: 1.359379, LR: 0.050000\n",
      "Seed 49, Epoch [460/1000], Train Loss: 0.900718, Test Loss: 0.998900, LR: 0.050000\n",
      "Seed 49, Epoch [470/1000], Train Loss: 0.873737, Test Loss: 0.969044, LR: 0.050000\n",
      "Seed 49, Epoch [480/1000], Train Loss: 0.851641, Test Loss: 1.035747, LR: 0.050000\n",
      "Seed 49, Epoch [490/1000], Train Loss: 0.844375, Test Loss: 1.092847, LR: 0.050000\n",
      "Seed 49, Epoch [500/1000], Train Loss: 0.834997, Test Loss: 1.109217, LR: 0.050000\n",
      "Seed 49, Epoch [510/1000], Train Loss: 0.830071, Test Loss: 1.129219, LR: 0.050000\n",
      "Seed 49, Epoch [520/1000], Train Loss: 0.826166, Test Loss: 1.113647, LR: 0.050000\n",
      "Seed 49, Epoch [530/1000], Train Loss: 0.818171, Test Loss: 1.053998, LR: 0.050000\n",
      "Seed 49, Epoch [540/1000], Train Loss: 0.815243, Test Loss: 1.035343, LR: 0.050000\n",
      "Seed 49, Epoch [550/1000], Train Loss: 0.809747, Test Loss: 1.027567, LR: 0.050000\n",
      "Seed 49, Epoch [560/1000], Train Loss: 0.807250, Test Loss: 1.046827, LR: 0.050000\n",
      "Seed 49, Epoch [570/1000], Train Loss: 0.832281, Test Loss: 1.092080, LR: 0.050000\n",
      "Seed 49, Epoch [580/1000], Train Loss: 0.813978, Test Loss: 1.056482, LR: 0.050000\n",
      "Seed 49, Epoch [590/1000], Train Loss: 0.802561, Test Loss: 1.054393, LR: 0.050000\n",
      "Seed 49, Epoch [600/1000], Train Loss: 0.804834, Test Loss: 0.906899, LR: 0.050000\n",
      "Seed 49, Epoch [610/1000], Train Loss: 0.792574, Test Loss: 0.881256, LR: 0.050000\n",
      "Seed 49, Epoch [620/1000], Train Loss: 0.790863, Test Loss: 0.861136, LR: 0.050000\n",
      "Seed 49, Epoch [630/1000], Train Loss: 0.795461, Test Loss: 0.989976, LR: 0.050000\n",
      "Seed 49, Epoch [640/1000], Train Loss: 0.813648, Test Loss: 0.848217, LR: 0.050000\n",
      "Seed 49, Epoch [650/1000], Train Loss: 0.789290, Test Loss: 0.873206, LR: 0.050000\n",
      "Seed 49, Epoch [660/1000], Train Loss: 0.793816, Test Loss: 0.939442, LR: 0.050000\n",
      "Seed 49, Epoch [670/1000], Train Loss: 0.849991, Test Loss: 0.804149, LR: 0.050000\n",
      "Seed 49, Epoch [680/1000], Train Loss: 0.813616, Test Loss: 0.793889, LR: 0.050000\n",
      "Seed 49, Epoch [690/1000], Train Loss: 0.787121, Test Loss: 0.767844, LR: 0.050000\n",
      "Seed 49, Epoch [700/1000], Train Loss: 1.220875, Test Loss: 1.203442, LR: 0.050000\n",
      "Seed 49, Epoch [710/1000], Train Loss: 0.978545, Test Loss: 0.975748, LR: 0.050000\n",
      "Seed 49, Epoch [720/1000], Train Loss: 0.867426, Test Loss: 0.792608, LR: 0.050000\n",
      "Seed 49, Epoch [730/1000], Train Loss: 0.821988, Test Loss: 0.805701, LR: 0.050000\n",
      "Seed 49, Epoch [740/1000], Train Loss: 0.794767, Test Loss: 0.771075, LR: 0.050000\n",
      "Seed 49, Epoch [750/1000], Train Loss: 0.795403, Test Loss: 0.754193, LR: 0.050000\n",
      "Seed 49, Epoch [760/1000], Train Loss: 0.800360, Test Loss: 0.738679, LR: 0.050000\n",
      "Seed 49, Epoch [770/1000], Train Loss: 0.807415, Test Loss: 0.838491, LR: 0.050000\n",
      "Seed 49, Epoch [780/1000], Train Loss: 0.810593, Test Loss: 0.760131, LR: 0.050000\n",
      "Seed 49, Epoch [790/1000], Train Loss: 0.779669, Test Loss: 0.754154, LR: 0.050000\n",
      "Seed 49, Epoch [800/1000], Train Loss: 0.845421, Test Loss: 0.715352, LR: 0.050000\n",
      "Seed 49, Epoch [810/1000], Train Loss: 0.804415, Test Loss: 0.789230, LR: 0.050000\n",
      "Seed 49, Epoch [820/1000], Train Loss: 0.840614, Test Loss: 0.858907, LR: 0.050000\n",
      "Seed 49, Epoch [830/1000], Train Loss: 0.809673, Test Loss: 0.833277, LR: 0.050000\n",
      "Seed 49, Epoch [840/1000], Train Loss: 0.785222, Test Loss: 0.749235, LR: 0.050000\n",
      "Seed 49, Epoch [850/1000], Train Loss: 0.840164, Test Loss: 0.971499, LR: 0.050000\n",
      "Seed 49, Epoch [860/1000], Train Loss: 0.793542, Test Loss: 0.783432, LR: 0.050000\n",
      "Seed 49, Epoch [870/1000], Train Loss: 0.783245, Test Loss: 0.748250, LR: 0.050000\n",
      "Seed 49, Epoch [880/1000], Train Loss: 0.798494, Test Loss: 0.884840, LR: 0.050000\n",
      "Seed 49, Epoch [890/1000], Train Loss: 0.822471, Test Loss: 0.760284, LR: 0.050000\n",
      "Seed 49, Epoch [900/1000], Train Loss: 0.790331, Test Loss: 0.724540, LR: 0.050000\n",
      "Seed 49, Epoch [910/1000], Train Loss: 0.838811, Test Loss: 0.724983, LR: 0.050000\n",
      "Seed 49, Epoch [920/1000], Train Loss: 0.945789, Test Loss: 0.782915, LR: 0.050000\n",
      "Seed 49, Epoch [930/1000], Train Loss: 0.854849, Test Loss: 0.779135, LR: 0.050000\n",
      "Seed 49, Epoch [940/1000], Train Loss: 3.754264, Test Loss: 3.861165, LR: 0.050000\n",
      "Seed 49, Epoch [950/1000], Train Loss: 1.785733, Test Loss: 1.750860, LR: 0.050000\n",
      "Seed 49, Epoch [960/1000], Train Loss: 1.890128, Test Loss: 1.713837, LR: 0.050000\n",
      "Seed 49, Epoch [970/1000], Train Loss: 1.822915, Test Loss: 1.678009, LR: 0.050000\n",
      "Seed 49, Epoch [980/1000], Train Loss: 1.705383, Test Loss: 1.606817, LR: 0.050000\n",
      "Seed 49, Epoch [990/1000], Train Loss: 1.554738, Test Loss: 1.465025, LR: 0.050000\n",
      "Seed 49, Epoch [1000/1000], Train Loss: 1.368206, Test Loss: 1.285722, LR: 0.050000\n",
      "Seed 50, Epoch [10/1000], Train Loss: 2.963280, Test Loss: 2.571889, LR: 0.050000\n",
      "Seed 50, Epoch [20/1000], Train Loss: 2.489538, Test Loss: 2.374368, LR: 0.050000\n",
      "Seed 50, Epoch [30/1000], Train Loss: 2.483238, Test Loss: 2.364506, LR: 0.050000\n",
      "Seed 50, Epoch [40/1000], Train Loss: 2.467277, Test Loss: 2.345538, LR: 0.050000\n",
      "Seed 50, Epoch [50/1000], Train Loss: 2.425046, Test Loss: 2.304534, LR: 0.050000\n",
      "Seed 50, Epoch [60/1000], Train Loss: 2.377302, Test Loss: 2.255984, LR: 0.050000\n",
      "Seed 50, Epoch [70/1000], Train Loss: 2.314801, Test Loss: 2.187689, LR: 0.050000\n",
      "Seed 50, Epoch [80/1000], Train Loss: 2.220998, Test Loss: 2.090106, LR: 0.050000\n",
      "Seed 50, Epoch [90/1000], Train Loss: 2.086668, Test Loss: 1.964448, LR: 0.050000\n",
      "Seed 50, Epoch [100/1000], Train Loss: 1.891818, Test Loss: 1.760537, LR: 0.050000\n",
      "Seed 50, Epoch [110/1000], Train Loss: 1.647439, Test Loss: 1.487461, LR: 0.050000\n",
      "Seed 50, Epoch [120/1000], Train Loss: 1.468109, Test Loss: 1.401312, LR: 0.050000\n",
      "Seed 50, Epoch [130/1000], Train Loss: 1.367822, Test Loss: 1.376858, LR: 0.050000\n",
      "Seed 50, Epoch [140/1000], Train Loss: 1.317423, Test Loss: 1.342545, LR: 0.050000\n",
      "Seed 50, Epoch [150/1000], Train Loss: 1.276330, Test Loss: 1.381005, LR: 0.050000\n",
      "Seed 50, Epoch [160/1000], Train Loss: 1.252785, Test Loss: 1.397402, LR: 0.050000\n",
      "Seed 50, Epoch [170/1000], Train Loss: 1.234217, Test Loss: 1.406891, LR: 0.050000\n",
      "Seed 50, Epoch [180/1000], Train Loss: 1.203807, Test Loss: 1.245738, LR: 0.050000\n",
      "Seed 50, Epoch [190/1000], Train Loss: 1.173845, Test Loss: 1.165292, LR: 0.050000\n",
      "Seed 50, Epoch [200/1000], Train Loss: 1.153763, Test Loss: 1.093109, LR: 0.050000\n",
      "Seed 50, Epoch [210/1000], Train Loss: 1.127735, Test Loss: 1.100788, LR: 0.050000\n",
      "Seed 50, Epoch [220/1000], Train Loss: 1.157059, Test Loss: 1.102271, LR: 0.050000\n",
      "Seed 50, Epoch [230/1000], Train Loss: 1.105199, Test Loss: 1.064195, LR: 0.050000\n",
      "Seed 50, Epoch [240/1000], Train Loss: 1.065945, Test Loss: 1.215402, LR: 0.050000\n",
      "Seed 50, Epoch [250/1000], Train Loss: 1.324288, Test Loss: 1.154634, LR: 0.050000\n",
      "Seed 50, Epoch [260/1000], Train Loss: 1.081718, Test Loss: 1.439797, LR: 0.050000\n",
      "Seed 50, Epoch [270/1000], Train Loss: 1.035819, Test Loss: 1.506177, LR: 0.050000\n",
      "Seed 50, Epoch [280/1000], Train Loss: 0.992118, Test Loss: 1.544516, LR: 0.050000\n",
      "Seed 50, Epoch [290/1000], Train Loss: 1.033871, Test Loss: 1.892749, LR: 0.050000\n",
      "Seed 50, Epoch [300/1000], Train Loss: 1.000940, Test Loss: 1.742586, LR: 0.050000\n",
      "Seed 50, Epoch [310/1000], Train Loss: 0.969934, Test Loss: 1.617732, LR: 0.050000\n",
      "Seed 50, Epoch [320/1000], Train Loss: 0.963951, Test Loss: 1.716144, LR: 0.050000\n",
      "Seed 50, Epoch [330/1000], Train Loss: 0.981115, Test Loss: 1.814734, LR: 0.050000\n",
      "Seed 50, Epoch [340/1000], Train Loss: 0.950351, Test Loss: 1.827505, LR: 0.050000\n",
      "Seed 50, Epoch [350/1000], Train Loss: 1.021717, Test Loss: 1.647183, LR: 0.050000\n",
      "Seed 50, Epoch [360/1000], Train Loss: 0.998739, Test Loss: 2.039382, LR: 0.050000\n",
      "Seed 50, Epoch [370/1000], Train Loss: 1.027489, Test Loss: 1.659275, LR: 0.050000\n",
      "Seed 50, Epoch [380/1000], Train Loss: 0.951627, Test Loss: 1.638326, LR: 0.050000\n",
      "Seed 50, Epoch [390/1000], Train Loss: 0.931017, Test Loss: 1.692389, LR: 0.050000\n",
      "Seed 50, Epoch [400/1000], Train Loss: 0.918728, Test Loss: 1.730358, LR: 0.050000\n",
      "Seed 50, Epoch [410/1000], Train Loss: 0.911533, Test Loss: 1.809011, LR: 0.050000\n",
      "Seed 50, Epoch [420/1000], Train Loss: 0.910849, Test Loss: 1.728515, LR: 0.050000\n",
      "Seed 50, Epoch [430/1000], Train Loss: 1.015145, Test Loss: 1.899179, LR: 0.050000\n",
      "Seed 50, Epoch [440/1000], Train Loss: 0.941899, Test Loss: 1.680893, LR: 0.050000\n",
      "Seed 50, Epoch [450/1000], Train Loss: 0.909651, Test Loss: 1.492829, LR: 0.050000\n",
      "Seed 50, Epoch [460/1000], Train Loss: 0.918225, Test Loss: 1.796382, LR: 0.050000\n",
      "Seed 50, Epoch [470/1000], Train Loss: 0.894366, Test Loss: 1.629308, LR: 0.050000\n",
      "Seed 50, Epoch [480/1000], Train Loss: 0.887362, Test Loss: 1.650561, LR: 0.050000\n",
      "Seed 50, Epoch [490/1000], Train Loss: 0.906484, Test Loss: 1.524591, LR: 0.050000\n",
      "Seed 50, Epoch [500/1000], Train Loss: 1.030487, Test Loss: 1.907373, LR: 0.050000\n",
      "Seed 50, Epoch [510/1000], Train Loss: 0.930572, Test Loss: 1.242697, LR: 0.050000\n",
      "Seed 50, Epoch [520/1000], Train Loss: 0.914559, Test Loss: 1.258443, LR: 0.050000\n",
      "Seed 50, Epoch [530/1000], Train Loss: 0.883400, Test Loss: 1.381331, LR: 0.050000\n",
      "Seed 50, Epoch [540/1000], Train Loss: 0.870314, Test Loss: 1.436467, LR: 0.050000\n",
      "Seed 50, Epoch [550/1000], Train Loss: 0.867261, Test Loss: 1.396605, LR: 0.050000\n",
      "Seed 50, Epoch [560/1000], Train Loss: 0.883056, Test Loss: 1.561866, LR: 0.050000\n",
      "Seed 50, Epoch [570/1000], Train Loss: 0.869212, Test Loss: 1.383885, LR: 0.050000\n",
      "Seed 50, Epoch [580/1000], Train Loss: 0.882172, Test Loss: 1.105260, LR: 0.050000\n",
      "Seed 50, Epoch [590/1000], Train Loss: 0.869153, Test Loss: 1.129211, LR: 0.050000\n",
      "Seed 50, Epoch [600/1000], Train Loss: 0.878084, Test Loss: 0.983557, LR: 0.050000\n",
      "Seed 50, Epoch [610/1000], Train Loss: 0.863970, Test Loss: 1.130060, LR: 0.050000\n",
      "Seed 50, Epoch [620/1000], Train Loss: 0.840157, Test Loss: 0.974939, LR: 0.050000\n",
      "Seed 50, Epoch [630/1000], Train Loss: 1.260727, Test Loss: 1.316135, LR: 0.050000\n",
      "Seed 50, Epoch [640/1000], Train Loss: 1.070456, Test Loss: 1.042903, LR: 0.050000\n",
      "Seed 50, Epoch [650/1000], Train Loss: 0.942849, Test Loss: 0.848135, LR: 0.050000\n",
      "Seed 50, Epoch [660/1000], Train Loss: 0.892086, Test Loss: 0.852488, LR: 0.050000\n",
      "Seed 50, Epoch [670/1000], Train Loss: 0.847502, Test Loss: 0.933922, LR: 0.050000\n",
      "Seed 50, Epoch [680/1000], Train Loss: 0.850769, Test Loss: 0.947502, LR: 0.050000\n",
      "Seed 50, Epoch [690/1000], Train Loss: 1.273415, Test Loss: 1.365387, LR: 0.050000\n",
      "Seed 50, Epoch [700/1000], Train Loss: 1.047705, Test Loss: 0.935175, LR: 0.050000\n",
      "Seed 50, Epoch [710/1000], Train Loss: 0.941067, Test Loss: 0.847377, LR: 0.050000\n",
      "Seed 50, Epoch [720/1000], Train Loss: 0.870698, Test Loss: 0.817646, LR: 0.050000\n",
      "Seed 50, Epoch [730/1000], Train Loss: 0.836090, Test Loss: 0.984662, LR: 0.050000\n",
      "Seed 50, Epoch [740/1000], Train Loss: 1.344487, Test Loss: 1.702316, LR: 0.050000\n",
      "Seed 50, Epoch [750/1000], Train Loss: 1.051812, Test Loss: 1.053572, LR: 0.050000\n",
      "Seed 50, Epoch [760/1000], Train Loss: 0.911503, Test Loss: 0.989249, LR: 0.050000\n",
      "Seed 50, Epoch [770/1000], Train Loss: 0.861452, Test Loss: 0.957526, LR: 0.050000\n",
      "Seed 50, Epoch [780/1000], Train Loss: 0.830618, Test Loss: 1.089471, LR: 0.050000\n",
      "Seed 50, Epoch [790/1000], Train Loss: 1.553989, Test Loss: 2.379279, LR: 0.050000\n",
      "Seed 50, Epoch [800/1000], Train Loss: 1.528827, Test Loss: 1.421481, LR: 0.050000\n",
      "Seed 50, Epoch [810/1000], Train Loss: 1.246199, Test Loss: 1.551027, LR: 0.050000\n",
      "Seed 50, Epoch [820/1000], Train Loss: 1.042040, Test Loss: 0.963305, LR: 0.050000\n",
      "Seed 50, Epoch [830/1000], Train Loss: 0.922050, Test Loss: 0.810714, LR: 0.050000\n",
      "Seed 50, Epoch [840/1000], Train Loss: 0.864829, Test Loss: 0.896195, LR: 0.050000\n",
      "Seed 50, Epoch [850/1000], Train Loss: 0.835847, Test Loss: 1.074007, LR: 0.050000\n",
      "Seed 50, Epoch [860/1000], Train Loss: 1.503670, Test Loss: 1.718258, LR: 0.050000\n",
      "Seed 50, Epoch [870/1000], Train Loss: 1.131255, Test Loss: 1.355488, LR: 0.050000\n",
      "Seed 50, Epoch [880/1000], Train Loss: 1.018973, Test Loss: 1.050841, LR: 0.050000\n",
      "Seed 50, Epoch [890/1000], Train Loss: 0.927816, Test Loss: 0.922215, LR: 0.050000\n",
      "Seed 50, Epoch [900/1000], Train Loss: 0.860846, Test Loss: 0.987751, LR: 0.050000\n",
      "Seed 50, Epoch [910/1000], Train Loss: 0.947239, Test Loss: 1.068677, LR: 0.050000\n",
      "Seed 50, Epoch [920/1000], Train Loss: 0.840968, Test Loss: 1.181897, LR: 0.050000\n",
      "Seed 50, Epoch [930/1000], Train Loss: 0.850329, Test Loss: 1.218524, LR: 0.050000\n",
      "Seed 50, Epoch [940/1000], Train Loss: 0.844419, Test Loss: 1.342059, LR: 0.050000\n",
      "Seed 50, Epoch [950/1000], Train Loss: 1.072104, Test Loss: 1.678548, LR: 0.050000\n",
      "Seed 50, Epoch [960/1000], Train Loss: 1.020527, Test Loss: 1.339243, LR: 0.050000\n",
      "Seed 50, Epoch [970/1000], Train Loss: 0.923000, Test Loss: 1.220000, LR: 0.050000\n",
      "Seed 50, Epoch [980/1000], Train Loss: 0.884890, Test Loss: 1.068592, LR: 0.050000\n",
      "Seed 50, Epoch [990/1000], Train Loss: 0.915289, Test Loss: 1.395359, LR: 0.050000\n",
      "Seed 50, Epoch [1000/1000], Train Loss: 0.853190, Test Loss: 1.292719, LR: 0.050000\n",
      "Seed 51, Epoch [10/1000], Train Loss: 3.307949, Test Loss: 2.496677, LR: 0.050000\n",
      "Seed 51, Epoch [20/1000], Train Loss: 2.346846, Test Loss: 2.187456, LR: 0.050000\n",
      "Seed 51, Epoch [30/1000], Train Loss: 2.258739, Test Loss: 2.176903, LR: 0.050000\n",
      "Seed 51, Epoch [40/1000], Train Loss: 2.247990, Test Loss: 2.182389, LR: 0.050000\n",
      "Seed 51, Epoch [50/1000], Train Loss: 2.085116, Test Loss: 2.106807, LR: 0.050000\n",
      "Seed 51, Epoch [60/1000], Train Loss: 2.492216, Test Loss: 1.881217, LR: 0.050000\n",
      "Seed 51, Epoch [70/1000], Train Loss: 1.692772, Test Loss: 1.744856, LR: 0.050000\n",
      "Seed 51, Epoch [80/1000], Train Loss: 1.582395, Test Loss: 1.577845, LR: 0.050000\n",
      "Seed 51, Epoch [90/1000], Train Loss: 1.563670, Test Loss: 1.593252, LR: 0.050000\n",
      "Seed 51, Epoch [100/1000], Train Loss: 1.674276, Test Loss: 1.668974, LR: 0.050000\n",
      "Seed 51, Epoch [110/1000], Train Loss: 1.569107, Test Loss: 1.529619, LR: 0.050000\n",
      "Seed 51, Epoch [120/1000], Train Loss: 1.543219, Test Loss: 1.521636, LR: 0.050000\n",
      "Seed 51, Epoch [130/1000], Train Loss: 1.517992, Test Loss: 1.505687, LR: 0.050000\n",
      "Seed 51, Epoch [140/1000], Train Loss: 1.492324, Test Loss: 1.453826, LR: 0.050000\n",
      "Seed 51, Epoch [150/1000], Train Loss: 1.460120, Test Loss: 1.403710, LR: 0.050000\n",
      "Seed 51, Epoch [160/1000], Train Loss: 1.415846, Test Loss: 1.331727, LR: 0.050000\n",
      "Seed 51, Epoch [170/1000], Train Loss: 1.351725, Test Loss: 1.231904, LR: 0.050000\n",
      "Seed 51, Epoch [180/1000], Train Loss: 1.264054, Test Loss: 1.129992, LR: 0.050000\n",
      "Seed 51, Epoch [190/1000], Train Loss: 1.192954, Test Loss: 1.104350, LR: 0.050000\n",
      "Seed 51, Epoch [200/1000], Train Loss: 1.123743, Test Loss: 1.235888, LR: 0.050000\n",
      "Seed 51, Epoch [210/1000], Train Loss: 1.061229, Test Loss: 1.405035, LR: 0.050000\n",
      "Seed 51, Epoch [220/1000], Train Loss: 1.010251, Test Loss: 1.639354, LR: 0.050000\n",
      "Seed 51, Epoch [230/1000], Train Loss: 1.058831, Test Loss: 1.674902, LR: 0.050000\n",
      "Seed 51, Epoch [240/1000], Train Loss: 1.532704, Test Loss: 1.777376, LR: 0.050000\n",
      "Seed 51, Epoch [250/1000], Train Loss: 1.341052, Test Loss: 1.557531, LR: 0.050000\n",
      "Seed 51, Epoch [260/1000], Train Loss: 1.148962, Test Loss: 1.446910, LR: 0.050000\n",
      "Seed 51, Epoch [270/1000], Train Loss: 1.054695, Test Loss: 1.522133, LR: 0.050000\n",
      "Seed 51, Epoch [280/1000], Train Loss: 1.006402, Test Loss: 1.457249, LR: 0.050000\n",
      "Seed 51, Epoch [290/1000], Train Loss: 0.967389, Test Loss: 1.596516, LR: 0.050000\n",
      "Seed 51, Epoch [300/1000], Train Loss: 0.936097, Test Loss: 1.619107, LR: 0.050000\n",
      "Seed 51, Epoch [310/1000], Train Loss: 0.908614, Test Loss: 1.631008, LR: 0.050000\n",
      "Seed 51, Epoch [320/1000], Train Loss: 0.885016, Test Loss: 1.560236, LR: 0.050000\n",
      "Seed 51, Epoch [330/1000], Train Loss: 0.882408, Test Loss: 1.646832, LR: 0.050000\n",
      "Seed 51, Epoch [340/1000], Train Loss: 0.927187, Test Loss: 1.520642, LR: 0.050000\n",
      "Seed 51, Epoch [350/1000], Train Loss: 0.867219, Test Loss: 1.384673, LR: 0.050000\n",
      "Seed 51, Epoch [360/1000], Train Loss: 0.842447, Test Loss: 1.492026, LR: 0.050000\n",
      "Seed 51, Epoch [370/1000], Train Loss: 0.827887, Test Loss: 1.496938, LR: 0.050000\n",
      "Seed 51, Epoch [380/1000], Train Loss: 1.190835, Test Loss: 1.666320, LR: 0.050000\n",
      "Seed 51, Epoch [390/1000], Train Loss: 0.857215, Test Loss: 1.541142, LR: 0.050000\n",
      "Seed 51, Epoch [400/1000], Train Loss: 0.837897, Test Loss: 1.408685, LR: 0.050000\n",
      "Seed 51, Epoch [410/1000], Train Loss: 0.815668, Test Loss: 1.521424, LR: 0.050000\n",
      "Seed 51, Epoch [420/1000], Train Loss: 0.806450, Test Loss: 1.609773, LR: 0.050000\n",
      "Seed 51, Epoch [430/1000], Train Loss: 0.808796, Test Loss: 1.537209, LR: 0.050000\n",
      "Seed 51, Epoch [440/1000], Train Loss: 0.810263, Test Loss: 1.541190, LR: 0.050000\n",
      "Seed 51, Epoch [450/1000], Train Loss: 0.812400, Test Loss: 1.519661, LR: 0.050000\n",
      "Seed 51, Epoch [460/1000], Train Loss: 0.797581, Test Loss: 1.537087, LR: 0.050000\n",
      "Seed 51, Epoch [470/1000], Train Loss: 0.815736, Test Loss: 1.555383, LR: 0.050000\n",
      "Seed 51, Epoch [480/1000], Train Loss: 0.793437, Test Loss: 1.628693, LR: 0.050000\n",
      "Seed 51, Epoch [490/1000], Train Loss: 1.028724, Test Loss: 1.499705, LR: 0.050000\n",
      "Seed 51, Epoch [500/1000], Train Loss: 0.812099, Test Loss: 1.376715, LR: 0.050000\n",
      "Seed 51, Epoch [510/1000], Train Loss: 0.824644, Test Loss: 1.438485, LR: 0.050000\n",
      "Seed 51, Epoch [520/1000], Train Loss: 0.804706, Test Loss: 1.540474, LR: 0.050000\n",
      "Seed 51, Epoch [530/1000], Train Loss: 0.788665, Test Loss: 1.520511, LR: 0.050000\n",
      "Seed 51, Epoch [540/1000], Train Loss: 0.795007, Test Loss: 1.693647, LR: 0.050000\n",
      "Seed 51, Epoch [550/1000], Train Loss: 0.839320, Test Loss: 1.583376, LR: 0.050000\n",
      "Seed 51, Epoch [560/1000], Train Loss: 0.792211, Test Loss: 1.524775, LR: 0.050000\n",
      "Seed 51, Epoch [570/1000], Train Loss: 0.807823, Test Loss: 1.669039, LR: 0.050000\n",
      "Seed 51, Epoch [580/1000], Train Loss: 0.794571, Test Loss: 1.633522, LR: 0.050000\n",
      "Seed 51, Epoch [590/1000], Train Loss: 0.807524, Test Loss: 1.693547, LR: 0.050000\n",
      "Seed 51, Epoch [600/1000], Train Loss: 0.804089, Test Loss: 1.679712, LR: 0.050000\n",
      "Seed 51, Epoch [610/1000], Train Loss: 0.810138, Test Loss: 1.557362, LR: 0.050000\n",
      "Seed 51, Epoch [620/1000], Train Loss: 0.977800, Test Loss: 1.791203, LR: 0.050000\n",
      "Seed 51, Epoch [630/1000], Train Loss: 0.824830, Test Loss: 1.576896, LR: 0.050000\n",
      "Seed 51, Epoch [640/1000], Train Loss: 0.802665, Test Loss: 1.478674, LR: 0.050000\n",
      "Seed 51, Epoch [650/1000], Train Loss: 0.785161, Test Loss: 1.535529, LR: 0.050000\n",
      "Seed 51, Epoch [660/1000], Train Loss: 0.805478, Test Loss: 1.640451, LR: 0.050000\n",
      "Seed 51, Epoch [670/1000], Train Loss: 0.821800, Test Loss: 1.723562, LR: 0.050000\n",
      "Seed 51, Epoch [680/1000], Train Loss: 0.890369, Test Loss: 1.430184, LR: 0.050000\n",
      "Early stopping at epoch 686 for seed 51\n",
      "Seed 52, Epoch [10/1000], Train Loss: 5.107976, Test Loss: 3.848993, LR: 0.050000\n",
      "Seed 52, Epoch [20/1000], Train Loss: 2.993198, Test Loss: 2.712702, LR: 0.050000\n",
      "Seed 52, Epoch [30/1000], Train Loss: 2.799584, Test Loss: 2.560698, LR: 0.050000\n",
      "Seed 52, Epoch [40/1000], Train Loss: 2.628810, Test Loss: 2.459707, LR: 0.050000\n",
      "Seed 52, Epoch [50/1000], Train Loss: 2.521772, Test Loss: 2.393426, LR: 0.050000\n",
      "Seed 52, Epoch [60/1000], Train Loss: 2.446991, Test Loss: 2.346733, LR: 0.050000\n",
      "Seed 52, Epoch [70/1000], Train Loss: 2.393091, Test Loss: 2.313624, LR: 0.050000\n",
      "Seed 52, Epoch [80/1000], Train Loss: 2.353864, Test Loss: 2.290500, LR: 0.050000\n",
      "Seed 52, Epoch [90/1000], Train Loss: 2.325146, Test Loss: 2.274679, LR: 0.050000\n",
      "Seed 52, Epoch [100/1000], Train Loss: 2.303898, Test Loss: 2.264042, LR: 0.050000\n",
      "Seed 52, Epoch [110/1000], Train Loss: 2.287823, Test Loss: 2.256907, LR: 0.050000\n",
      "Seed 52, Epoch [120/1000], Train Loss: 2.275182, Test Loss: 2.251974, LR: 0.050000\n",
      "Seed 52, Epoch [130/1000], Train Loss: 2.264688, Test Loss: 2.248284, LR: 0.050000\n",
      "Seed 52, Epoch [140/1000], Train Loss: 2.255424, Test Loss: 2.245168, LR: 0.050000\n",
      "Seed 52, Epoch [150/1000], Train Loss: 2.246767, Test Loss: 2.242194, LR: 0.050000\n",
      "Seed 52, Epoch [160/1000], Train Loss: 2.238311, Test Loss: 2.239113, LR: 0.050000\n",
      "Seed 52, Epoch [170/1000], Train Loss: 2.229810, Test Loss: 2.235807, LR: 0.050000\n",
      "Seed 52, Epoch [180/1000], Train Loss: 2.221129, Test Loss: 2.232250, LR: 0.050000\n",
      "Seed 52, Epoch [190/1000], Train Loss: 2.212200, Test Loss: 2.228477, LR: 0.050000\n",
      "Seed 52, Epoch [200/1000], Train Loss: 2.203001, Test Loss: 2.224559, LR: 0.050000\n",
      "Seed 52, Epoch [210/1000], Train Loss: 2.193542, Test Loss: 2.220591, LR: 0.050000\n",
      "Seed 52, Epoch [220/1000], Train Loss: 2.183850, Test Loss: 2.216688, LR: 0.050000\n",
      "Seed 52, Epoch [230/1000], Train Loss: 2.173975, Test Loss: 2.212983, LR: 0.050000\n",
      "Seed 52, Epoch [240/1000], Train Loss: 2.163975, Test Loss: 2.209627, LR: 0.050000\n",
      "Seed 52, Epoch [250/1000], Train Loss: 2.153919, Test Loss: 2.206762, LR: 0.050000\n",
      "Seed 52, Epoch [260/1000], Train Loss: 2.143903, Test Loss: 2.204458, LR: 0.050000\n",
      "Seed 52, Epoch [270/1000], Train Loss: 2.134077, Test Loss: 2.202642, LR: 0.050000\n",
      "Seed 52, Epoch [280/1000], Train Loss: 2.124616, Test Loss: 2.201109, LR: 0.050000\n",
      "Seed 52, Epoch [290/1000], Train Loss: 2.115617, Test Loss: 2.199652, LR: 0.050000\n",
      "Seed 52, Epoch [300/1000], Train Loss: 2.107063, Test Loss: 2.198112, LR: 0.050000\n",
      "Seed 52, Epoch [310/1000], Train Loss: 2.098857, Test Loss: 2.196316, LR: 0.050000\n",
      "Seed 52, Epoch [320/1000], Train Loss: 2.090876, Test Loss: 2.194043, LR: 0.050000\n",
      "Seed 52, Epoch [330/1000], Train Loss: 2.082995, Test Loss: 2.191032, LR: 0.050000\n",
      "Seed 52, Epoch [340/1000], Train Loss: 2.075094, Test Loss: 2.187046, LR: 0.050000\n",
      "Seed 52, Epoch [350/1000], Train Loss: 2.067058, Test Loss: 2.181916, LR: 0.050000\n",
      "Seed 52, Epoch [360/1000], Train Loss: 2.058792, Test Loss: 2.175556, LR: 0.050000\n",
      "Seed 52, Epoch [370/1000], Train Loss: 2.050225, Test Loss: 2.167949, LR: 0.050000\n",
      "Seed 52, Epoch [380/1000], Train Loss: 2.041303, Test Loss: 2.159130, LR: 0.050000\n",
      "Seed 52, Epoch [390/1000], Train Loss: 2.031996, Test Loss: 2.149171, LR: 0.050000\n",
      "Seed 52, Epoch [400/1000], Train Loss: 2.022294, Test Loss: 2.138173, LR: 0.050000\n",
      "Seed 52, Epoch [410/1000], Train Loss: 2.012200, Test Loss: 2.126248, LR: 0.050000\n",
      "Seed 52, Epoch [420/1000], Train Loss: 2.001733, Test Loss: 2.113504, LR: 0.050000\n",
      "Seed 52, Epoch [430/1000], Train Loss: 1.990933, Test Loss: 2.099972, LR: 0.050000\n",
      "Seed 52, Epoch [440/1000], Train Loss: 1.979824, Test Loss: 2.085773, LR: 0.050000\n",
      "Seed 52, Epoch [450/1000], Train Loss: 1.968433, Test Loss: 2.071003, LR: 0.050000\n",
      "Seed 52, Epoch [460/1000], Train Loss: 1.956780, Test Loss: 2.055685, LR: 0.050000\n",
      "Seed 52, Epoch [470/1000], Train Loss: 1.944873, Test Loss: 2.039798, LR: 0.050000\n",
      "Seed 52, Epoch [480/1000], Train Loss: 1.932702, Test Loss: 2.023307, LR: 0.050000\n",
      "Seed 52, Epoch [490/1000], Train Loss: 1.920242, Test Loss: 2.006158, LR: 0.050000\n",
      "Seed 52, Epoch [500/1000], Train Loss: 1.907442, Test Loss: 1.988266, LR: 0.050000\n",
      "Seed 52, Epoch [510/1000], Train Loss: 1.894231, Test Loss: 1.969511, LR: 0.050000\n",
      "Seed 52, Epoch [520/1000], Train Loss: 1.880536, Test Loss: 1.949658, LR: 0.050000\n",
      "Seed 52, Epoch [530/1000], Train Loss: 1.866262, Test Loss: 1.928222, LR: 0.050000\n",
      "Seed 52, Epoch [540/1000], Train Loss: 1.851194, Test Loss: 1.905283, LR: 0.050000\n",
      "Seed 52, Epoch [550/1000], Train Loss: 1.835081, Test Loss: 1.880360, LR: 0.050000\n",
      "Seed 52, Epoch [560/1000], Train Loss: 1.817571, Test Loss: 1.852510, LR: 0.050000\n",
      "Seed 52, Epoch [570/1000], Train Loss: 1.798325, Test Loss: 1.820693, LR: 0.050000\n",
      "Seed 52, Epoch [580/1000], Train Loss: 1.776602, Test Loss: 1.782755, LR: 0.050000\n",
      "Seed 52, Epoch [590/1000], Train Loss: 1.751485, Test Loss: 1.736036, LR: 0.050000\n",
      "Seed 52, Epoch [600/1000], Train Loss: 1.721702, Test Loss: 1.676874, LR: 0.050000\n",
      "Seed 52, Epoch [610/1000], Train Loss: 1.686305, Test Loss: 1.602522, LR: 0.050000\n",
      "Seed 52, Epoch [620/1000], Train Loss: 1.646584, Test Loss: 1.518542, LR: 0.050000\n",
      "Seed 52, Epoch [630/1000], Train Loss: 1.608101, Test Loss: 1.446116, LR: 0.050000\n",
      "Seed 52, Epoch [640/1000], Train Loss: 1.575995, Test Loss: 1.401051, LR: 0.050000\n",
      "Seed 52, Epoch [650/1000], Train Loss: 1.546245, Test Loss: 1.374642, LR: 0.050000\n",
      "Seed 52, Epoch [660/1000], Train Loss: 1.512695, Test Loss: 1.354837, LR: 0.050000\n",
      "Seed 52, Epoch [670/1000], Train Loss: 1.476002, Test Loss: 1.335271, LR: 0.050000\n",
      "Seed 52, Epoch [680/1000], Train Loss: 1.436524, Test Loss: 1.308481, LR: 0.050000\n",
      "Seed 52, Epoch [690/1000], Train Loss: 1.393897, Test Loss: 1.276227, LR: 0.050000\n",
      "Seed 52, Epoch [700/1000], Train Loss: 1.351153, Test Loss: 1.245790, LR: 0.050000\n",
      "Seed 52, Epoch [710/1000], Train Loss: 1.306878, Test Loss: 1.210231, LR: 0.050000\n",
      "Seed 52, Epoch [720/1000], Train Loss: 1.262506, Test Loss: 1.173963, LR: 0.050000\n",
      "Seed 52, Epoch [730/1000], Train Loss: 1.219332, Test Loss: 1.138262, LR: 0.050000\n",
      "Seed 52, Epoch [740/1000], Train Loss: 1.189350, Test Loss: 1.100683, LR: 0.050000\n",
      "Seed 52, Epoch [750/1000], Train Loss: 1.170270, Test Loss: 1.044904, LR: 0.050000\n",
      "Seed 52, Epoch [760/1000], Train Loss: 1.152642, Test Loss: 1.014833, LR: 0.050000\n",
      "Seed 52, Epoch [770/1000], Train Loss: 1.136754, Test Loss: 0.991041, LR: 0.050000\n",
      "Seed 52, Epoch [780/1000], Train Loss: 1.120113, Test Loss: 0.954143, LR: 0.050000\n",
      "Seed 52, Epoch [790/1000], Train Loss: 1.105621, Test Loss: 0.926000, LR: 0.050000\n",
      "Seed 52, Epoch [800/1000], Train Loss: 1.092814, Test Loss: 0.897537, LR: 0.050000\n",
      "Seed 52, Epoch [810/1000], Train Loss: 1.082361, Test Loss: 0.878469, LR: 0.050000\n",
      "Seed 52, Epoch [820/1000], Train Loss: 1.071003, Test Loss: 0.863425, LR: 0.050000\n",
      "Seed 52, Epoch [830/1000], Train Loss: 1.062309, Test Loss: 0.853644, LR: 0.050000\n",
      "Seed 52, Epoch [840/1000], Train Loss: 1.053573, Test Loss: 0.843982, LR: 0.050000\n",
      "Seed 52, Epoch [850/1000], Train Loss: 1.044887, Test Loss: 0.838449, LR: 0.050000\n",
      "Seed 52, Epoch [860/1000], Train Loss: 1.037058, Test Loss: 0.831319, LR: 0.050000\n",
      "Seed 52, Epoch [870/1000], Train Loss: 1.029124, Test Loss: 0.831494, LR: 0.050000\n",
      "Seed 52, Epoch [880/1000], Train Loss: 1.022024, Test Loss: 0.822857, LR: 0.050000\n",
      "Seed 52, Epoch [890/1000], Train Loss: 1.013819, Test Loss: 0.823158, LR: 0.050000\n",
      "Seed 52, Epoch [900/1000], Train Loss: 2.003628, Test Loss: 2.472886, LR: 0.050000\n",
      "Seed 52, Epoch [910/1000], Train Loss: 1.299914, Test Loss: 1.408922, LR: 0.050000\n",
      "Seed 52, Epoch [920/1000], Train Loss: 1.212717, Test Loss: 1.029218, LR: 0.050000\n",
      "Seed 52, Epoch [930/1000], Train Loss: 1.124551, Test Loss: 0.984631, LR: 0.050000\n",
      "Seed 52, Epoch [940/1000], Train Loss: 1.042559, Test Loss: 0.937202, LR: 0.050000\n",
      "Seed 52, Epoch [950/1000], Train Loss: 1.011749, Test Loss: 0.840060, LR: 0.050000\n",
      "Seed 52, Epoch [960/1000], Train Loss: 1.001060, Test Loss: 0.828104, LR: 0.050000\n",
      "Seed 52, Epoch [970/1000], Train Loss: 0.989915, Test Loss: 0.828876, LR: 0.050000\n",
      "Seed 52, Epoch [980/1000], Train Loss: 0.979958, Test Loss: 0.832049, LR: 0.050000\n",
      "Seed 52, Epoch [990/1000], Train Loss: 0.972905, Test Loss: 0.826596, LR: 0.050000\n",
      "Seed 52, Epoch [1000/1000], Train Loss: 0.965211, Test Loss: 0.823245, LR: 0.050000\n",
      "Seed 53, Epoch [10/1000], Train Loss: 2.279259, Test Loss: 2.172902, LR: 0.050000\n",
      "Seed 53, Epoch [20/1000], Train Loss: 2.311116, Test Loss: 2.176823, LR: 0.050000\n",
      "Seed 53, Epoch [30/1000], Train Loss: 1.878489, Test Loss: 1.658101, LR: 0.050000\n",
      "Seed 53, Epoch [40/1000], Train Loss: 1.665450, Test Loss: 1.398219, LR: 0.050000\n",
      "Seed 53, Epoch [50/1000], Train Loss: 1.433284, Test Loss: 1.305307, LR: 0.050000\n",
      "Seed 53, Epoch [60/1000], Train Loss: 1.374243, Test Loss: 1.299661, LR: 0.050000\n",
      "Seed 53, Epoch [70/1000], Train Loss: 1.290595, Test Loss: 1.285971, LR: 0.050000\n",
      "Seed 53, Epoch [80/1000], Train Loss: 1.213612, Test Loss: 1.218574, LR: 0.050000\n",
      "Seed 53, Epoch [90/1000], Train Loss: 1.145002, Test Loss: 1.227711, LR: 0.050000\n",
      "Seed 53, Epoch [100/1000], Train Loss: 1.183375, Test Loss: 1.307069, LR: 0.050000\n",
      "Seed 53, Epoch [110/1000], Train Loss: 1.118626, Test Loss: 1.117337, LR: 0.050000\n",
      "Seed 53, Epoch [120/1000], Train Loss: 1.093766, Test Loss: 1.088634, LR: 0.050000\n",
      "Seed 53, Epoch [130/1000], Train Loss: 1.061930, Test Loss: 1.110877, LR: 0.050000\n",
      "Seed 53, Epoch [140/1000], Train Loss: 1.043402, Test Loss: 1.119908, LR: 0.050000\n",
      "Seed 53, Epoch [150/1000], Train Loss: 1.014956, Test Loss: 1.168538, LR: 0.050000\n",
      "Seed 53, Epoch [160/1000], Train Loss: 0.983390, Test Loss: 1.185779, LR: 0.050000\n",
      "Seed 53, Epoch [170/1000], Train Loss: 0.970220, Test Loss: 1.393878, LR: 0.050000\n",
      "Seed 53, Epoch [180/1000], Train Loss: 0.947855, Test Loss: 1.498577, LR: 0.050000\n",
      "Seed 53, Epoch [190/1000], Train Loss: 1.433593, Test Loss: 2.165439, LR: 0.050000\n",
      "Seed 53, Epoch [200/1000], Train Loss: 0.999826, Test Loss: 1.430817, LR: 0.050000\n",
      "Seed 53, Epoch [210/1000], Train Loss: 0.954264, Test Loss: 1.428823, LR: 0.050000\n",
      "Seed 53, Epoch [220/1000], Train Loss: 0.936026, Test Loss: 1.267670, LR: 0.050000\n",
      "Seed 53, Epoch [230/1000], Train Loss: 0.888781, Test Loss: 1.353210, LR: 0.050000\n",
      "Seed 53, Epoch [240/1000], Train Loss: 0.894678, Test Loss: 1.299157, LR: 0.050000\n",
      "Seed 53, Epoch [250/1000], Train Loss: 0.852553, Test Loss: 1.446361, LR: 0.050000\n",
      "Seed 53, Epoch [260/1000], Train Loss: 0.839789, Test Loss: 1.369814, LR: 0.050000\n",
      "Seed 53, Epoch [270/1000], Train Loss: 0.835204, Test Loss: 1.409624, LR: 0.050000\n",
      "Seed 53, Epoch [280/1000], Train Loss: 0.833784, Test Loss: 1.462519, LR: 0.050000\n",
      "Seed 53, Epoch [290/1000], Train Loss: 0.842571, Test Loss: 1.334019, LR: 0.050000\n",
      "Seed 53, Epoch [300/1000], Train Loss: 0.829449, Test Loss: 1.427747, LR: 0.050000\n",
      "Seed 53, Epoch [310/1000], Train Loss: 0.861851, Test Loss: 1.268270, LR: 0.050000\n",
      "Seed 53, Epoch [320/1000], Train Loss: 0.822752, Test Loss: 1.306058, LR: 0.050000\n",
      "Seed 53, Epoch [330/1000], Train Loss: 0.879940, Test Loss: 1.635062, LR: 0.050000\n",
      "Seed 53, Epoch [340/1000], Train Loss: 1.731165, Test Loss: 2.618493, LR: 0.050000\n",
      "Seed 53, Epoch [350/1000], Train Loss: 1.736436, Test Loss: 1.500143, LR: 0.050000\n",
      "Seed 53, Epoch [360/1000], Train Loss: 1.342741, Test Loss: 1.553358, LR: 0.050000\n",
      "Seed 53, Epoch [370/1000], Train Loss: 1.089698, Test Loss: 1.446163, LR: 0.050000\n",
      "Seed 53, Epoch [380/1000], Train Loss: 0.992146, Test Loss: 1.369222, LR: 0.050000\n",
      "Seed 53, Epoch [390/1000], Train Loss: 0.908965, Test Loss: 1.410871, LR: 0.050000\n",
      "Seed 53, Epoch [400/1000], Train Loss: 0.856174, Test Loss: 1.610869, LR: 0.050000\n",
      "Seed 53, Epoch [410/1000], Train Loss: 0.839142, Test Loss: 1.688249, LR: 0.050000\n",
      "Seed 53, Epoch [420/1000], Train Loss: 0.829700, Test Loss: 1.665497, LR: 0.050000\n",
      "Seed 53, Epoch [430/1000], Train Loss: 0.829457, Test Loss: 1.605615, LR: 0.050000\n",
      "Seed 53, Epoch [440/1000], Train Loss: 0.825468, Test Loss: 1.600118, LR: 0.050000\n",
      "Seed 53, Epoch [450/1000], Train Loss: 0.816468, Test Loss: 1.580009, LR: 0.050000\n",
      "Seed 53, Epoch [460/1000], Train Loss: 0.813509, Test Loss: 1.605307, LR: 0.050000\n",
      "Seed 53, Epoch [470/1000], Train Loss: 0.826875, Test Loss: 1.617214, LR: 0.050000\n",
      "Seed 53, Epoch [480/1000], Train Loss: 0.811084, Test Loss: 1.659856, LR: 0.050000\n",
      "Seed 53, Epoch [490/1000], Train Loss: 0.814339, Test Loss: 1.764728, LR: 0.050000\n",
      "Seed 53, Epoch [500/1000], Train Loss: 0.810451, Test Loss: 1.735428, LR: 0.050000\n",
      "Seed 53, Epoch [510/1000], Train Loss: 0.817757, Test Loss: 1.796622, LR: 0.050000\n",
      "Seed 53, Epoch [520/1000], Train Loss: 0.809245, Test Loss: 1.772059, LR: 0.050000\n",
      "Seed 53, Epoch [530/1000], Train Loss: 0.831286, Test Loss: 1.927369, LR: 0.050000\n",
      "Seed 53, Epoch [540/1000], Train Loss: 0.969602, Test Loss: 1.678548, LR: 0.050000\n",
      "Seed 53, Epoch [550/1000], Train Loss: 0.882705, Test Loss: 1.581180, LR: 0.050000\n",
      "Seed 53, Epoch [560/1000], Train Loss: 0.828960, Test Loss: 1.677222, LR: 0.050000\n",
      "Seed 53, Epoch [570/1000], Train Loss: 0.809903, Test Loss: 1.765847, LR: 0.050000\n",
      "Seed 53, Epoch [580/1000], Train Loss: 0.811002, Test Loss: 1.849882, LR: 0.050000\n",
      "Seed 53, Epoch [590/1000], Train Loss: 0.833243, Test Loss: 1.915557, LR: 0.050000\n",
      "Seed 53, Epoch [600/1000], Train Loss: 0.809290, Test Loss: 1.884086, LR: 0.050000\n",
      "Seed 53, Epoch [610/1000], Train Loss: 0.803945, Test Loss: 1.870124, LR: 0.050000\n",
      "Seed 53, Epoch [620/1000], Train Loss: 0.806920, Test Loss: 1.894512, LR: 0.050000\n",
      "Seed 53, Epoch [630/1000], Train Loss: 0.830096, Test Loss: 1.981239, LR: 0.050000\n",
      "Seed 53, Epoch [640/1000], Train Loss: 0.803002, Test Loss: 1.908475, LR: 0.050000\n",
      "Seed 53, Epoch [650/1000], Train Loss: 0.808286, Test Loss: 1.951613, LR: 0.050000\n",
      "Seed 53, Epoch [660/1000], Train Loss: 0.816731, Test Loss: 1.977484, LR: 0.050000\n",
      "Seed 53, Epoch [670/1000], Train Loss: 0.834149, Test Loss: 1.941689, LR: 0.050000\n",
      "Seed 53, Epoch [680/1000], Train Loss: 0.806206, Test Loss: 1.880268, LR: 0.050000\n",
      "Seed 53, Epoch [690/1000], Train Loss: 0.805587, Test Loss: 1.899711, LR: 0.050000\n",
      "Seed 53, Epoch [700/1000], Train Loss: 0.922573, Test Loss: 2.151043, LR: 0.050000\n",
      "Seed 53, Epoch [710/1000], Train Loss: 0.952657, Test Loss: 2.007389, LR: 0.050000\n",
      "Early stopping at epoch 716 for seed 53\n",
      "Seed 54, Epoch [10/1000], Train Loss: 4.788439, Test Loss: 4.908546, LR: 0.050000\n",
      "Seed 54, Epoch [20/1000], Train Loss: 2.382612, Test Loss: 2.440428, LR: 0.050000\n",
      "Seed 54, Epoch [30/1000], Train Loss: 2.203525, Test Loss: 2.088933, LR: 0.050000\n",
      "Seed 54, Epoch [40/1000], Train Loss: 2.181833, Test Loss: 2.005416, LR: 0.050000\n",
      "Seed 54, Epoch [50/1000], Train Loss: 2.176808, Test Loss: 1.973868, LR: 0.050000\n",
      "Seed 54, Epoch [60/1000], Train Loss: 2.173847, Test Loss: 1.957669, LR: 0.050000\n",
      "Seed 54, Epoch [70/1000], Train Loss: 2.171058, Test Loss: 1.947121, LR: 0.050000\n",
      "Seed 54, Epoch [80/1000], Train Loss: 2.168259, Test Loss: 1.938985, LR: 0.050000\n",
      "Seed 54, Epoch [90/1000], Train Loss: 2.165456, Test Loss: 1.932023, LR: 0.050000\n",
      "Seed 54, Epoch [100/1000], Train Loss: 2.162661, Test Loss: 1.925733, LR: 0.050000\n",
      "Seed 54, Epoch [110/1000], Train Loss: 2.159875, Test Loss: 1.919908, LR: 0.050000\n",
      "Seed 54, Epoch [120/1000], Train Loss: 2.157084, Test Loss: 1.914448, LR: 0.050000\n",
      "Seed 54, Epoch [130/1000], Train Loss: 2.154273, Test Loss: 1.909293, LR: 0.050000\n",
      "Seed 54, Epoch [140/1000], Train Loss: 2.151424, Test Loss: 1.904402, LR: 0.050000\n",
      "Seed 54, Epoch [150/1000], Train Loss: 2.148523, Test Loss: 1.899739, LR: 0.050000\n",
      "Seed 54, Epoch [160/1000], Train Loss: 2.145556, Test Loss: 1.895270, LR: 0.050000\n",
      "Seed 54, Epoch [170/1000], Train Loss: 2.142509, Test Loss: 1.890965, LR: 0.050000\n",
      "Seed 54, Epoch [180/1000], Train Loss: 2.139373, Test Loss: 1.886794, LR: 0.050000\n",
      "Seed 54, Epoch [190/1000], Train Loss: 2.136137, Test Loss: 1.882728, LR: 0.050000\n",
      "Seed 54, Epoch [200/1000], Train Loss: 2.132790, Test Loss: 1.878742, LR: 0.050000\n",
      "Seed 54, Epoch [210/1000], Train Loss: 2.129324, Test Loss: 1.874811, LR: 0.050000\n",
      "Seed 54, Epoch [220/1000], Train Loss: 2.125729, Test Loss: 1.870914, LR: 0.050000\n",
      "Seed 54, Epoch [230/1000], Train Loss: 2.121997, Test Loss: 1.867032, LR: 0.050000\n",
      "Seed 54, Epoch [240/1000], Train Loss: 2.118118, Test Loss: 1.863148, LR: 0.050000\n",
      "Seed 54, Epoch [250/1000], Train Loss: 2.114084, Test Loss: 1.859247, LR: 0.050000\n",
      "Seed 54, Epoch [260/1000], Train Loss: 2.109886, Test Loss: 1.855317, LR: 0.050000\n",
      "Seed 54, Epoch [270/1000], Train Loss: 2.105516, Test Loss: 1.851344, LR: 0.050000\n",
      "Seed 54, Epoch [280/1000], Train Loss: 2.100969, Test Loss: 1.847317, LR: 0.050000\n",
      "Seed 54, Epoch [290/1000], Train Loss: 2.096236, Test Loss: 1.843225, LR: 0.050000\n",
      "Seed 54, Epoch [300/1000], Train Loss: 2.091311, Test Loss: 1.839054, LR: 0.050000\n",
      "Seed 54, Epoch [310/1000], Train Loss: 2.086191, Test Loss: 1.834795, LR: 0.050000\n",
      "Seed 54, Epoch [320/1000], Train Loss: 2.080871, Test Loss: 1.830432, LR: 0.050000\n",
      "Seed 54, Epoch [330/1000], Train Loss: 2.075348, Test Loss: 1.825954, LR: 0.050000\n",
      "Seed 54, Epoch [340/1000], Train Loss: 2.069623, Test Loss: 1.821347, LR: 0.050000\n",
      "Seed 54, Epoch [350/1000], Train Loss: 2.063697, Test Loss: 1.816597, LR: 0.050000\n",
      "Seed 54, Epoch [360/1000], Train Loss: 2.057573, Test Loss: 1.811692, LR: 0.050000\n",
      "Seed 54, Epoch [370/1000], Train Loss: 2.051257, Test Loss: 1.806617, LR: 0.050000\n",
      "Seed 54, Epoch [380/1000], Train Loss: 2.044758, Test Loss: 1.801361, LR: 0.050000\n",
      "Seed 54, Epoch [390/1000], Train Loss: 2.038084, Test Loss: 1.795911, LR: 0.050000\n",
      "Seed 54, Epoch [400/1000], Train Loss: 2.031250, Test Loss: 1.790257, LR: 0.050000\n",
      "Seed 54, Epoch [410/1000], Train Loss: 2.024268, Test Loss: 1.784391, LR: 0.050000\n",
      "Seed 54, Epoch [420/1000], Train Loss: 2.017154, Test Loss: 1.778306, LR: 0.050000\n",
      "Seed 54, Epoch [430/1000], Train Loss: 2.009921, Test Loss: 1.771999, LR: 0.050000\n",
      "Seed 54, Epoch [440/1000], Train Loss: 2.002582, Test Loss: 1.765468, LR: 0.050000\n",
      "Seed 54, Epoch [450/1000], Train Loss: 1.995147, Test Loss: 1.758717, LR: 0.050000\n",
      "Seed 54, Epoch [460/1000], Train Loss: 1.987622, Test Loss: 1.751752, LR: 0.050000\n",
      "Seed 54, Epoch [470/1000], Train Loss: 1.980010, Test Loss: 1.744582, LR: 0.050000\n",
      "Seed 54, Epoch [480/1000], Train Loss: 1.972306, Test Loss: 1.737221, LR: 0.050000\n",
      "Seed 54, Epoch [490/1000], Train Loss: 1.964504, Test Loss: 1.729687, LR: 0.050000\n",
      "Seed 54, Epoch [500/1000], Train Loss: 1.956590, Test Loss: 1.721997, LR: 0.050000\n",
      "Seed 54, Epoch [510/1000], Train Loss: 1.948550, Test Loss: 1.714172, LR: 0.050000\n",
      "Seed 54, Epoch [520/1000], Train Loss: 1.940367, Test Loss: 1.706230, LR: 0.050000\n",
      "Seed 54, Epoch [530/1000], Train Loss: 1.932021, Test Loss: 1.698191, LR: 0.050000\n",
      "Seed 54, Epoch [540/1000], Train Loss: 1.923496, Test Loss: 1.690069, LR: 0.050000\n",
      "Seed 54, Epoch [550/1000], Train Loss: 1.914774, Test Loss: 1.681874, LR: 0.050000\n",
      "Seed 54, Epoch [560/1000], Train Loss: 1.905836, Test Loss: 1.673612, LR: 0.050000\n",
      "Seed 54, Epoch [570/1000], Train Loss: 1.896669, Test Loss: 1.665279, LR: 0.050000\n",
      "Seed 54, Epoch [580/1000], Train Loss: 1.887255, Test Loss: 1.656869, LR: 0.050000\n",
      "Seed 54, Epoch [590/1000], Train Loss: 1.877577, Test Loss: 1.648368, LR: 0.050000\n",
      "Seed 54, Epoch [600/1000], Train Loss: 1.867618, Test Loss: 1.639759, LR: 0.050000\n",
      "Seed 54, Epoch [610/1000], Train Loss: 1.857357, Test Loss: 1.631021, LR: 0.050000\n",
      "Seed 54, Epoch [620/1000], Train Loss: 1.846771, Test Loss: 1.622124, LR: 0.050000\n",
      "Seed 54, Epoch [630/1000], Train Loss: 1.835848, Test Loss: 1.612989, LR: 0.050000\n",
      "Seed 54, Epoch [640/1000], Train Loss: 1.824571, Test Loss: 1.603585, LR: 0.050000\n",
      "Seed 54, Epoch [650/1000], Train Loss: 1.812938, Test Loss: 1.593855, LR: 0.050000\n",
      "Seed 54, Epoch [660/1000], Train Loss: 1.854321, Test Loss: 1.716623, LR: 0.050000\n",
      "Seed 54, Epoch [670/1000], Train Loss: 1.824264, Test Loss: 1.626645, LR: 0.050000\n",
      "Seed 54, Epoch [680/1000], Train Loss: 1.799351, Test Loss: 1.525874, LR: 0.050000\n",
      "Seed 54, Epoch [690/1000], Train Loss: 1.802114, Test Loss: 1.632074, LR: 0.050000\n",
      "Seed 54, Epoch [700/1000], Train Loss: 1.793841, Test Loss: 1.645690, LR: 0.050000\n",
      "Seed 54, Epoch [710/1000], Train Loss: 1.781135, Test Loss: 1.631566, LR: 0.050000\n",
      "Seed 54, Epoch [720/1000], Train Loss: 1.766235, Test Loss: 1.606603, LR: 0.050000\n",
      "Seed 54, Epoch [730/1000], Train Loss: 1.728779, Test Loss: 1.597162, LR: 0.050000\n",
      "Seed 54, Epoch [740/1000], Train Loss: 1.715035, Test Loss: 1.466359, LR: 0.050000\n",
      "Seed 54, Epoch [750/1000], Train Loss: 1.701155, Test Loss: 1.583014, LR: 0.050000\n",
      "Seed 54, Epoch [760/1000], Train Loss: 1.687349, Test Loss: 1.573098, LR: 0.050000\n",
      "Seed 54, Epoch [770/1000], Train Loss: 1.695574, Test Loss: 1.559127, LR: 0.050000\n",
      "Seed 54, Epoch [780/1000], Train Loss: 1.679543, Test Loss: 1.414992, LR: 0.050000\n",
      "Seed 54, Epoch [790/1000], Train Loss: 1.641721, Test Loss: 1.400892, LR: 0.050000\n",
      "Seed 54, Epoch [800/1000], Train Loss: 1.625470, Test Loss: 1.388136, LR: 0.050000\n",
      "Seed 54, Epoch [810/1000], Train Loss: 1.607602, Test Loss: 1.378404, LR: 0.050000\n",
      "Seed 54, Epoch [820/1000], Train Loss: 1.605751, Test Loss: 1.523037, LR: 0.050000\n",
      "Seed 54, Epoch [830/1000], Train Loss: 1.585046, Test Loss: 1.357556, LR: 0.050000\n",
      "Seed 54, Epoch [840/1000], Train Loss: 1.548012, Test Loss: 1.349800, LR: 0.050000\n",
      "Seed 54, Epoch [850/1000], Train Loss: 1.526399, Test Loss: 1.340765, LR: 0.050000\n",
      "Seed 54, Epoch [860/1000], Train Loss: 1.514515, Test Loss: 1.533594, LR: 0.050000\n",
      "Seed 54, Epoch [870/1000], Train Loss: 1.488145, Test Loss: 1.569547, LR: 0.050000\n",
      "Seed 54, Epoch [880/1000], Train Loss: 1.459034, Test Loss: 1.610225, LR: 0.050000\n",
      "Seed 54, Epoch [890/1000], Train Loss: 1.426550, Test Loss: 1.622055, LR: 0.050000\n",
      "Seed 54, Epoch [900/1000], Train Loss: 1.393938, Test Loss: 1.688830, LR: 0.050000\n",
      "Seed 54, Epoch [910/1000], Train Loss: 1.358793, Test Loss: 1.710307, LR: 0.050000\n",
      "Seed 54, Epoch [920/1000], Train Loss: 1.324909, Test Loss: 1.530945, LR: 0.050000\n",
      "Seed 54, Epoch [930/1000], Train Loss: 1.292799, Test Loss: 1.789883, LR: 0.050000\n",
      "Seed 54, Epoch [940/1000], Train Loss: 1.268399, Test Loss: 1.528962, LR: 0.050000\n",
      "Seed 54, Epoch [950/1000], Train Loss: 1.249385, Test Loss: 1.760429, LR: 0.050000\n",
      "Seed 54, Epoch [960/1000], Train Loss: 1.236865, Test Loss: 1.494955, LR: 0.050000\n",
      "Seed 54, Epoch [970/1000], Train Loss: 1.219286, Test Loss: 1.684491, LR: 0.050000\n",
      "Seed 54, Epoch [980/1000], Train Loss: 1.206917, Test Loss: 1.520118, LR: 0.050000\n",
      "Seed 54, Epoch [990/1000], Train Loss: 1.197290, Test Loss: 1.594073, LR: 0.050000\n",
      "Seed 54, Epoch [1000/1000], Train Loss: 1.189297, Test Loss: 1.497278, LR: 0.050000\n",
      "Seed 55, Epoch [10/1000], Train Loss: 3.760360, Test Loss: 2.737916, LR: 0.050000\n",
      "Seed 55, Epoch [20/1000], Train Loss: 2.771174, Test Loss: 2.266135, LR: 0.050000\n",
      "Seed 55, Epoch [30/1000], Train Loss: 2.518435, Test Loss: 2.257685, LR: 0.050000\n",
      "Seed 55, Epoch [40/1000], Train Loss: 2.480072, Test Loss: 2.236488, LR: 0.050000\n",
      "Seed 55, Epoch [50/1000], Train Loss: 2.430454, Test Loss: 2.209730, LR: 0.050000\n",
      "Seed 55, Epoch [60/1000], Train Loss: 2.409446, Test Loss: 2.199040, LR: 0.050000\n",
      "Seed 55, Epoch [70/1000], Train Loss: 2.360243, Test Loss: 2.124637, LR: 0.050000\n",
      "Seed 55, Epoch [80/1000], Train Loss: 2.317624, Test Loss: 2.064522, LR: 0.050000\n",
      "Seed 55, Epoch [90/1000], Train Loss: 2.262203, Test Loss: 1.994392, LR: 0.050000\n",
      "Seed 55, Epoch [100/1000], Train Loss: 2.204170, Test Loss: 1.913119, LR: 0.050000\n",
      "Seed 55, Epoch [110/1000], Train Loss: 2.128533, Test Loss: 1.822201, LR: 0.050000\n",
      "Seed 55, Epoch [120/1000], Train Loss: 2.040097, Test Loss: 1.737887, LR: 0.050000\n",
      "Seed 55, Epoch [130/1000], Train Loss: 1.922881, Test Loss: 1.609460, LR: 0.050000\n",
      "Seed 55, Epoch [140/1000], Train Loss: 1.781610, Test Loss: 1.558351, LR: 0.050000\n",
      "Seed 55, Epoch [150/1000], Train Loss: 1.612076, Test Loss: 1.550548, LR: 0.050000\n",
      "Seed 55, Epoch [160/1000], Train Loss: 1.550114, Test Loss: 1.557661, LR: 0.050000\n",
      "Seed 55, Epoch [170/1000], Train Loss: 1.536195, Test Loss: 1.511546, LR: 0.050000\n",
      "Seed 55, Epoch [180/1000], Train Loss: 1.511758, Test Loss: 1.487294, LR: 0.050000\n",
      "Seed 55, Epoch [190/1000], Train Loss: 1.488048, Test Loss: 1.443574, LR: 0.050000\n",
      "Seed 55, Epoch [200/1000], Train Loss: 1.456044, Test Loss: 1.410854, LR: 0.050000\n",
      "Seed 55, Epoch [210/1000], Train Loss: 1.412343, Test Loss: 1.422904, LR: 0.050000\n",
      "Seed 55, Epoch [220/1000], Train Loss: 1.357449, Test Loss: 1.498853, LR: 0.050000\n",
      "Seed 55, Epoch [230/1000], Train Loss: 1.302457, Test Loss: 1.527651, LR: 0.050000\n",
      "Seed 55, Epoch [240/1000], Train Loss: 1.257550, Test Loss: 1.447970, LR: 0.050000\n",
      "Seed 55, Epoch [250/1000], Train Loss: 1.219973, Test Loss: 1.300797, LR: 0.050000\n",
      "Seed 55, Epoch [260/1000], Train Loss: 1.185288, Test Loss: 1.166420, LR: 0.050000\n",
      "Seed 55, Epoch [270/1000], Train Loss: 1.149494, Test Loss: 1.077210, LR: 0.050000\n",
      "Seed 55, Epoch [280/1000], Train Loss: 1.123827, Test Loss: 1.029863, LR: 0.050000\n",
      "Seed 55, Epoch [290/1000], Train Loss: 1.162235, Test Loss: 0.992149, LR: 0.050000\n",
      "Seed 55, Epoch [300/1000], Train Loss: 1.110815, Test Loss: 0.972939, LR: 0.050000\n",
      "Seed 55, Epoch [310/1000], Train Loss: 1.084860, Test Loss: 0.948601, LR: 0.050000\n",
      "Seed 55, Epoch [320/1000], Train Loss: 1.062635, Test Loss: 0.945068, LR: 0.050000\n",
      "Seed 55, Epoch [330/1000], Train Loss: 1.049114, Test Loss: 0.965633, LR: 0.050000\n",
      "Seed 55, Epoch [340/1000], Train Loss: 1.035591, Test Loss: 0.989494, LR: 0.050000\n",
      "Seed 55, Epoch [350/1000], Train Loss: 1.023895, Test Loss: 1.003269, LR: 0.050000\n",
      "Seed 55, Epoch [360/1000], Train Loss: 1.012344, Test Loss: 1.033074, LR: 0.050000\n",
      "Seed 55, Epoch [370/1000], Train Loss: 1.001705, Test Loss: 1.034827, LR: 0.050000\n",
      "Seed 55, Epoch [380/1000], Train Loss: 0.991482, Test Loss: 1.066535, LR: 0.050000\n",
      "Seed 55, Epoch [390/1000], Train Loss: 0.982946, Test Loss: 1.077687, LR: 0.050000\n",
      "Seed 55, Epoch [400/1000], Train Loss: 0.975925, Test Loss: 1.059732, LR: 0.050000\n",
      "Seed 55, Epoch [410/1000], Train Loss: 0.983003, Test Loss: 1.167567, LR: 0.050000\n",
      "Seed 55, Epoch [420/1000], Train Loss: 0.957754, Test Loss: 1.092762, LR: 0.050000\n",
      "Seed 55, Epoch [430/1000], Train Loss: 0.949849, Test Loss: 1.133276, LR: 0.050000\n",
      "Seed 55, Epoch [440/1000], Train Loss: 0.945840, Test Loss: 1.126802, LR: 0.050000\n",
      "Seed 55, Epoch [450/1000], Train Loss: 0.933691, Test Loss: 1.115731, LR: 0.050000\n",
      "Seed 55, Epoch [460/1000], Train Loss: 0.923999, Test Loss: 1.104596, LR: 0.050000\n",
      "Seed 55, Epoch [470/1000], Train Loss: 0.950237, Test Loss: 1.292499, LR: 0.050000\n",
      "Seed 55, Epoch [480/1000], Train Loss: 0.906796, Test Loss: 1.019875, LR: 0.050000\n",
      "Seed 55, Epoch [490/1000], Train Loss: 0.881932, Test Loss: 0.978539, LR: 0.050000\n",
      "Seed 55, Epoch [500/1000], Train Loss: 1.218507, Test Loss: 1.660556, LR: 0.050000\n",
      "Seed 55, Epoch [510/1000], Train Loss: 0.961881, Test Loss: 0.977483, LR: 0.050000\n",
      "Seed 55, Epoch [520/1000], Train Loss: 0.915300, Test Loss: 0.957315, LR: 0.050000\n",
      "Seed 55, Epoch [530/1000], Train Loss: 0.876299, Test Loss: 0.964385, LR: 0.050000\n",
      "Seed 55, Epoch [540/1000], Train Loss: 0.851261, Test Loss: 0.986497, LR: 0.050000\n",
      "Seed 55, Epoch [550/1000], Train Loss: 0.842670, Test Loss: 0.985793, LR: 0.050000\n",
      "Seed 55, Epoch [560/1000], Train Loss: 0.839513, Test Loss: 0.950957, LR: 0.050000\n",
      "Seed 55, Epoch [570/1000], Train Loss: 0.863419, Test Loss: 0.997986, LR: 0.050000\n",
      "Seed 55, Epoch [580/1000], Train Loss: 0.877806, Test Loss: 0.900125, LR: 0.050000\n",
      "Seed 55, Epoch [590/1000], Train Loss: 0.870079, Test Loss: 0.889041, LR: 0.050000\n",
      "Seed 55, Epoch [600/1000], Train Loss: 0.832980, Test Loss: 0.879932, LR: 0.050000\n",
      "Seed 55, Epoch [610/1000], Train Loss: 0.861047, Test Loss: 0.881742, LR: 0.050000\n",
      "Seed 55, Epoch [620/1000], Train Loss: 0.838383, Test Loss: 0.929125, LR: 0.050000\n",
      "Seed 55, Epoch [630/1000], Train Loss: 0.844410, Test Loss: 0.901750, LR: 0.050000\n",
      "Seed 55, Epoch [640/1000], Train Loss: 0.866063, Test Loss: 0.954148, LR: 0.050000\n",
      "Seed 55, Epoch [650/1000], Train Loss: 0.831542, Test Loss: 0.836345, LR: 0.050000\n",
      "Seed 55, Epoch [660/1000], Train Loss: 0.821188, Test Loss: 0.853321, LR: 0.050000\n",
      "Seed 55, Epoch [670/1000], Train Loss: 0.873746, Test Loss: 0.855484, LR: 0.050000\n",
      "Seed 55, Epoch [680/1000], Train Loss: 0.824494, Test Loss: 0.837934, LR: 0.050000\n",
      "Seed 55, Epoch [690/1000], Train Loss: 0.847145, Test Loss: 0.990059, LR: 0.050000\n",
      "Seed 55, Epoch [700/1000], Train Loss: 0.831624, Test Loss: 0.864619, LR: 0.050000\n",
      "Seed 55, Epoch [710/1000], Train Loss: 0.845194, Test Loss: 0.790987, LR: 0.050000\n",
      "Seed 55, Epoch [720/1000], Train Loss: 0.812946, Test Loss: 0.821780, LR: 0.050000\n",
      "Seed 55, Epoch [730/1000], Train Loss: 1.136954, Test Loss: 1.738467, LR: 0.050000\n",
      "Seed 55, Epoch [740/1000], Train Loss: 1.250670, Test Loss: 0.911550, LR: 0.050000\n",
      "Seed 55, Epoch [750/1000], Train Loss: 0.927546, Test Loss: 1.019388, LR: 0.050000\n",
      "Seed 55, Epoch [760/1000], Train Loss: 0.922495, Test Loss: 0.842186, LR: 0.050000\n",
      "Seed 55, Epoch [770/1000], Train Loss: 0.855189, Test Loss: 0.796259, LR: 0.050000\n",
      "Seed 55, Epoch [780/1000], Train Loss: 0.825128, Test Loss: 0.785203, LR: 0.050000\n",
      "Seed 55, Epoch [790/1000], Train Loss: 0.820853, Test Loss: 0.785871, LR: 0.050000\n",
      "Seed 55, Epoch [800/1000], Train Loss: 0.859483, Test Loss: 0.789992, LR: 0.050000\n",
      "Seed 55, Epoch [810/1000], Train Loss: 0.823023, Test Loss: 0.779434, LR: 0.050000\n",
      "Seed 55, Epoch [820/1000], Train Loss: 0.822128, Test Loss: 0.797165, LR: 0.050000\n",
      "Seed 55, Epoch [830/1000], Train Loss: 0.906251, Test Loss: 0.757647, LR: 0.050000\n",
      "Seed 55, Epoch [840/1000], Train Loss: 1.014696, Test Loss: 1.025632, LR: 0.050000\n",
      "Seed 55, Epoch [850/1000], Train Loss: 0.925090, Test Loss: 0.823973, LR: 0.050000\n",
      "Seed 55, Epoch [860/1000], Train Loss: 0.859466, Test Loss: 0.813536, LR: 0.050000\n",
      "Seed 55, Epoch [870/1000], Train Loss: 0.824449, Test Loss: 0.776727, LR: 0.050000\n",
      "Seed 55, Epoch [880/1000], Train Loss: 0.832562, Test Loss: 0.805740, LR: 0.050000\n",
      "Seed 55, Epoch [890/1000], Train Loss: 0.822939, Test Loss: 0.774761, LR: 0.050000\n",
      "Seed 55, Epoch [900/1000], Train Loss: 0.821103, Test Loss: 0.751354, LR: 0.050000\n",
      "Seed 55, Epoch [910/1000], Train Loss: 0.854547, Test Loss: 0.870831, LR: 0.050000\n",
      "Seed 55, Epoch [920/1000], Train Loss: 0.825062, Test Loss: 0.793780, LR: 0.050000\n",
      "Seed 55, Epoch [930/1000], Train Loss: 0.818152, Test Loss: 0.770795, LR: 0.050000\n",
      "Seed 55, Epoch [940/1000], Train Loss: 0.817668, Test Loss: 0.808802, LR: 0.050000\n",
      "Seed 55, Epoch [950/1000], Train Loss: 0.978628, Test Loss: 1.035294, LR: 0.050000\n",
      "Seed 55, Epoch [960/1000], Train Loss: 0.898334, Test Loss: 0.888067, LR: 0.050000\n",
      "Seed 55, Epoch [970/1000], Train Loss: 0.843633, Test Loss: 0.798431, LR: 0.050000\n",
      "Seed 55, Epoch [980/1000], Train Loss: 0.820208, Test Loss: 0.778734, LR: 0.050000\n",
      "Seed 55, Epoch [990/1000], Train Loss: 1.093150, Test Loss: 0.979664, LR: 0.050000\n",
      "Seed 55, Epoch [1000/1000], Train Loss: 0.877198, Test Loss: 1.026208, LR: 0.050000\n",
      "Seed 56, Epoch [10/1000], Train Loss: 2.260748, Test Loss: 2.111080, LR: 0.050000\n",
      "Seed 56, Epoch [20/1000], Train Loss: 2.357126, Test Loss: 2.219708, LR: 0.050000\n",
      "Seed 56, Epoch [30/1000], Train Loss: 2.362196, Test Loss: 2.220986, LR: 0.050000\n",
      "Seed 56, Epoch [40/1000], Train Loss: 2.251908, Test Loss: 2.161216, LR: 0.050000\n",
      "Seed 56, Epoch [50/1000], Train Loss: 2.184971, Test Loss: 2.117384, LR: 0.050000\n",
      "Seed 56, Epoch [60/1000], Train Loss: 2.088450, Test Loss: 2.052876, LR: 0.050000\n",
      "Seed 56, Epoch [70/1000], Train Loss: 1.914819, Test Loss: 1.967060, LR: 0.050000\n",
      "Seed 56, Epoch [80/1000], Train Loss: 1.700598, Test Loss: 1.865294, LR: 0.050000\n",
      "Seed 56, Epoch [90/1000], Train Loss: 1.560266, Test Loss: 1.711068, LR: 0.050000\n",
      "Seed 56, Epoch [100/1000], Train Loss: 1.451319, Test Loss: 1.490433, LR: 0.050000\n",
      "Seed 56, Epoch [110/1000], Train Loss: 1.345734, Test Loss: 1.273529, LR: 0.050000\n",
      "Seed 56, Epoch [120/1000], Train Loss: 1.568730, Test Loss: 1.150543, LR: 0.050000\n",
      "Seed 56, Epoch [130/1000], Train Loss: 1.305225, Test Loss: 1.301329, LR: 0.050000\n",
      "Seed 56, Epoch [140/1000], Train Loss: 1.234170, Test Loss: 1.183141, LR: 0.050000\n",
      "Seed 56, Epoch [150/1000], Train Loss: 1.205908, Test Loss: 1.304796, LR: 0.050000\n",
      "Seed 56, Epoch [160/1000], Train Loss: 1.169315, Test Loss: 1.266760, LR: 0.050000\n",
      "Seed 56, Epoch [170/1000], Train Loss: 1.144474, Test Loss: 1.192816, LR: 0.050000\n",
      "Seed 56, Epoch [180/1000], Train Loss: 1.127148, Test Loss: 1.129639, LR: 0.050000\n",
      "Seed 56, Epoch [190/1000], Train Loss: 1.108947, Test Loss: 1.021662, LR: 0.050000\n",
      "Seed 56, Epoch [200/1000], Train Loss: 1.092179, Test Loss: 0.956684, LR: 0.050000\n",
      "Seed 56, Epoch [210/1000], Train Loss: 1.074870, Test Loss: 0.913308, LR: 0.050000\n",
      "Seed 56, Epoch [220/1000], Train Loss: 2.887767, Test Loss: 2.922427, LR: 0.050000\n",
      "Seed 56, Epoch [230/1000], Train Loss: 2.134155, Test Loss: 2.266216, LR: 0.050000\n",
      "Seed 56, Epoch [240/1000], Train Loss: 2.141406, Test Loss: 2.191959, LR: 0.050000\n",
      "Seed 56, Epoch [250/1000], Train Loss: 2.062521, Test Loss: 2.154988, LR: 0.050000\n",
      "Seed 56, Epoch [260/1000], Train Loss: 1.975700, Test Loss: 2.065713, LR: 0.050000\n",
      "Seed 56, Epoch [270/1000], Train Loss: 1.884796, Test Loss: 1.972611, LR: 0.050000\n",
      "Seed 56, Epoch [280/1000], Train Loss: 1.768126, Test Loss: 1.923480, LR: 0.050000\n",
      "Seed 56, Epoch [290/1000], Train Loss: 1.628696, Test Loss: 1.816893, LR: 0.050000\n",
      "Seed 56, Epoch [300/1000], Train Loss: 1.481130, Test Loss: 1.655473, LR: 0.050000\n",
      "Seed 56, Epoch [310/1000], Train Loss: 1.361486, Test Loss: 1.395444, LR: 0.050000\n",
      "Seed 56, Epoch [320/1000], Train Loss: 1.254253, Test Loss: 1.211678, LR: 0.050000\n",
      "Seed 56, Epoch [330/1000], Train Loss: 1.195416, Test Loss: 1.118029, LR: 0.050000\n",
      "Seed 56, Epoch [340/1000], Train Loss: 1.152614, Test Loss: 1.020237, LR: 0.050000\n",
      "Seed 56, Epoch [350/1000], Train Loss: 1.115826, Test Loss: 1.030944, LR: 0.050000\n",
      "Seed 56, Epoch [360/1000], Train Loss: 1.071372, Test Loss: 1.066330, LR: 0.050000\n",
      "Seed 56, Epoch [370/1000], Train Loss: 1.037513, Test Loss: 1.124002, LR: 0.050000\n",
      "Seed 56, Epoch [380/1000], Train Loss: 1.009633, Test Loss: 1.147712, LR: 0.050000\n",
      "Seed 56, Epoch [390/1000], Train Loss: 0.988746, Test Loss: 1.235140, LR: 0.050000\n",
      "Seed 56, Epoch [400/1000], Train Loss: 0.972961, Test Loss: 1.290012, LR: 0.050000\n",
      "Seed 56, Epoch [410/1000], Train Loss: 0.960694, Test Loss: 1.331606, LR: 0.050000\n",
      "Seed 56, Epoch [420/1000], Train Loss: 0.949209, Test Loss: 1.350440, LR: 0.050000\n",
      "Seed 56, Epoch [430/1000], Train Loss: 0.937074, Test Loss: 1.348903, LR: 0.050000\n",
      "Seed 56, Epoch [440/1000], Train Loss: 0.926100, Test Loss: 1.342203, LR: 0.050000\n",
      "Seed 56, Epoch [450/1000], Train Loss: 0.913836, Test Loss: 1.345979, LR: 0.050000\n",
      "Seed 56, Epoch [460/1000], Train Loss: 0.900880, Test Loss: 1.335827, LR: 0.050000\n",
      "Seed 56, Epoch [470/1000], Train Loss: 0.887602, Test Loss: 1.329319, LR: 0.050000\n",
      "Seed 56, Epoch [480/1000], Train Loss: 0.872530, Test Loss: 1.342165, LR: 0.050000\n",
      "Seed 56, Epoch [490/1000], Train Loss: 0.857646, Test Loss: 1.344311, LR: 0.050000\n",
      "Seed 56, Epoch [500/1000], Train Loss: 0.840744, Test Loss: 1.344357, LR: 0.050000\n",
      "Seed 56, Epoch [510/1000], Train Loss: 0.823908, Test Loss: 1.358927, LR: 0.050000\n",
      "Seed 56, Epoch [520/1000], Train Loss: 0.807670, Test Loss: 1.391953, LR: 0.050000\n",
      "Seed 56, Epoch [530/1000], Train Loss: 0.793586, Test Loss: 1.416254, LR: 0.050000\n",
      "Seed 56, Epoch [540/1000], Train Loss: 0.781287, Test Loss: 1.419679, LR: 0.050000\n",
      "Seed 56, Epoch [550/1000], Train Loss: 0.769468, Test Loss: 1.478300, LR: 0.050000\n",
      "Seed 56, Epoch [560/1000], Train Loss: 0.784906, Test Loss: 1.637422, LR: 0.050000\n",
      "Seed 56, Epoch [570/1000], Train Loss: 0.762309, Test Loss: 1.396920, LR: 0.050000\n",
      "Seed 56, Epoch [580/1000], Train Loss: 0.752291, Test Loss: 1.472676, LR: 0.050000\n",
      "Seed 56, Epoch [590/1000], Train Loss: 0.755467, Test Loss: 1.401108, LR: 0.050000\n",
      "Seed 56, Epoch [600/1000], Train Loss: 0.757605, Test Loss: 1.283710, LR: 0.050000\n",
      "Seed 56, Epoch [610/1000], Train Loss: 0.741035, Test Loss: 1.409857, LR: 0.050000\n",
      "Seed 56, Epoch [620/1000], Train Loss: 0.735741, Test Loss: 1.455159, LR: 0.050000\n",
      "Seed 56, Epoch [630/1000], Train Loss: 0.740286, Test Loss: 1.340300, LR: 0.050000\n",
      "Seed 56, Epoch [640/1000], Train Loss: 0.732905, Test Loss: 1.369835, LR: 0.050000\n",
      "Seed 56, Epoch [650/1000], Train Loss: 0.772979, Test Loss: 1.654885, LR: 0.050000\n",
      "Seed 56, Epoch [660/1000], Train Loss: 0.728870, Test Loss: 1.371100, LR: 0.050000\n",
      "Seed 56, Epoch [670/1000], Train Loss: 0.732546, Test Loss: 1.206731, LR: 0.050000\n",
      "Seed 56, Epoch [680/1000], Train Loss: 0.741245, Test Loss: 1.252756, LR: 0.050000\n",
      "Seed 56, Epoch [690/1000], Train Loss: 0.714790, Test Loss: 1.320232, LR: 0.050000\n",
      "Seed 56, Epoch [700/1000], Train Loss: 0.710517, Test Loss: 1.377452, LR: 0.050000\n",
      "Seed 56, Epoch [710/1000], Train Loss: 0.942113, Test Loss: 1.547945, LR: 0.050000\n",
      "Early stopping at epoch 712 for seed 56\n",
      "Seed 57, Epoch [10/1000], Train Loss: 3.268800, Test Loss: 2.917267, LR: 0.050000\n",
      "Seed 57, Epoch [20/1000], Train Loss: 2.603142, Test Loss: 2.502269, LR: 0.050000\n",
      "Seed 57, Epoch [30/1000], Train Loss: 2.524216, Test Loss: 2.437449, LR: 0.050000\n",
      "Seed 57, Epoch [40/1000], Train Loss: 2.497013, Test Loss: 2.418284, LR: 0.050000\n",
      "Seed 57, Epoch [50/1000], Train Loss: 2.459764, Test Loss: 2.393416, LR: 0.050000\n",
      "Seed 57, Epoch [60/1000], Train Loss: 2.389205, Test Loss: 2.342993, LR: 0.050000\n",
      "Seed 57, Epoch [70/1000], Train Loss: 2.273389, Test Loss: 2.251178, LR: 0.050000\n",
      "Seed 57, Epoch [80/1000], Train Loss: 2.097154, Test Loss: 2.074553, LR: 0.050000\n",
      "Seed 57, Epoch [90/1000], Train Loss: 1.788099, Test Loss: 1.747670, LR: 0.050000\n",
      "Seed 57, Epoch [100/1000], Train Loss: 1.623916, Test Loss: 1.580969, LR: 0.050000\n",
      "Seed 57, Epoch [110/1000], Train Loss: 1.511415, Test Loss: 1.301786, LR: 0.050000\n",
      "Seed 57, Epoch [120/1000], Train Loss: 1.496433, Test Loss: 1.248883, LR: 0.050000\n",
      "Seed 57, Epoch [130/1000], Train Loss: 1.433000, Test Loss: 1.291765, LR: 0.050000\n",
      "Seed 57, Epoch [140/1000], Train Loss: 1.421334, Test Loss: 1.326336, LR: 0.050000\n",
      "Seed 57, Epoch [150/1000], Train Loss: 1.323779, Test Loss: 1.103927, LR: 0.050000\n",
      "Seed 57, Epoch [160/1000], Train Loss: 1.272012, Test Loss: 1.049786, LR: 0.050000\n",
      "Seed 57, Epoch [170/1000], Train Loss: 1.243233, Test Loss: 0.921661, LR: 0.050000\n",
      "Seed 57, Epoch [180/1000], Train Loss: 1.227032, Test Loss: 1.317742, LR: 0.050000\n",
      "Seed 57, Epoch [190/1000], Train Loss: 1.289176, Test Loss: 0.980359, LR: 0.050000\n",
      "Seed 57, Epoch [200/1000], Train Loss: 1.240004, Test Loss: 0.925439, LR: 0.050000\n",
      "Seed 57, Epoch [210/1000], Train Loss: 1.256631, Test Loss: 0.953527, LR: 0.050000\n",
      "Seed 57, Epoch [220/1000], Train Loss: 1.242037, Test Loss: 0.956622, LR: 0.050000\n",
      "Seed 57, Epoch [230/1000], Train Loss: 1.217566, Test Loss: 0.792015, LR: 0.050000\n",
      "Seed 57, Epoch [240/1000], Train Loss: 1.332072, Test Loss: 0.955690, LR: 0.050000\n",
      "Seed 57, Epoch [250/1000], Train Loss: 1.256619, Test Loss: 0.775898, LR: 0.050000\n",
      "Seed 57, Epoch [260/1000], Train Loss: 1.180141, Test Loss: 0.810032, LR: 0.050000\n",
      "Seed 57, Epoch [270/1000], Train Loss: 1.190041, Test Loss: 0.851521, LR: 0.050000\n",
      "Seed 57, Epoch [280/1000], Train Loss: 1.167542, Test Loss: 0.763389, LR: 0.050000\n",
      "Seed 57, Epoch [290/1000], Train Loss: 1.149127, Test Loss: 0.942525, LR: 0.050000\n",
      "Seed 57, Epoch [300/1000], Train Loss: 1.190329, Test Loss: 0.743843, LR: 0.050000\n",
      "Seed 57, Epoch [310/1000], Train Loss: 1.130997, Test Loss: 0.779416, LR: 0.050000\n",
      "Seed 57, Epoch [320/1000], Train Loss: 1.175458, Test Loss: 0.780256, LR: 0.050000\n",
      "Seed 57, Epoch [330/1000], Train Loss: 1.183221, Test Loss: 0.762445, LR: 0.050000\n",
      "Seed 57, Epoch [340/1000], Train Loss: 1.107737, Test Loss: 0.734824, LR: 0.050000\n",
      "Seed 57, Epoch [350/1000], Train Loss: 1.080866, Test Loss: 0.747824, LR: 0.050000\n",
      "Seed 57, Epoch [360/1000], Train Loss: 1.081443, Test Loss: 0.702685, LR: 0.050000\n",
      "Seed 57, Epoch [370/1000], Train Loss: 1.045058, Test Loss: 0.689036, LR: 0.050000\n",
      "Seed 57, Epoch [380/1000], Train Loss: 1.028695, Test Loss: 0.811255, LR: 0.050000\n",
      "Seed 57, Epoch [390/1000], Train Loss: 1.039796, Test Loss: 0.691246, LR: 0.050000\n",
      "Seed 57, Epoch [400/1000], Train Loss: 0.988934, Test Loss: 0.730903, LR: 0.050000\n",
      "Seed 57, Epoch [410/1000], Train Loss: 0.950536, Test Loss: 0.811933, LR: 0.050000\n",
      "Seed 57, Epoch [420/1000], Train Loss: 0.927160, Test Loss: 0.975579, LR: 0.050000\n",
      "Seed 57, Epoch [430/1000], Train Loss: 0.885287, Test Loss: 1.218559, LR: 0.050000\n",
      "Seed 57, Epoch [440/1000], Train Loss: 0.858871, Test Loss: 1.282019, LR: 0.050000\n",
      "Seed 57, Epoch [450/1000], Train Loss: 0.914935, Test Loss: 1.144745, LR: 0.050000\n",
      "Seed 57, Epoch [460/1000], Train Loss: 0.840588, Test Loss: 1.014180, LR: 0.050000\n",
      "Seed 57, Epoch [470/1000], Train Loss: 0.810383, Test Loss: 1.178175, LR: 0.050000\n",
      "Seed 57, Epoch [480/1000], Train Loss: 0.788247, Test Loss: 1.224814, LR: 0.050000\n",
      "Seed 57, Epoch [490/1000], Train Loss: 0.811874, Test Loss: 1.590826, LR: 0.050000\n",
      "Seed 57, Epoch [500/1000], Train Loss: 0.792964, Test Loss: 1.152884, LR: 0.050000\n",
      "Seed 57, Epoch [510/1000], Train Loss: 0.763240, Test Loss: 1.420199, LR: 0.050000\n",
      "Seed 57, Epoch [520/1000], Train Loss: 0.763652, Test Loss: 1.749862, LR: 0.050000\n",
      "Seed 57, Epoch [530/1000], Train Loss: 0.762744, Test Loss: 1.489508, LR: 0.050000\n",
      "Seed 57, Epoch [540/1000], Train Loss: 0.763809, Test Loss: 1.814413, LR: 0.050000\n",
      "Seed 57, Epoch [550/1000], Train Loss: 0.748873, Test Loss: 1.717022, LR: 0.050000\n",
      "Seed 57, Epoch [560/1000], Train Loss: 0.743350, Test Loss: 1.704541, LR: 0.050000\n",
      "Seed 57, Epoch [570/1000], Train Loss: 0.744628, Test Loss: 2.081800, LR: 0.050000\n",
      "Seed 57, Epoch [580/1000], Train Loss: 0.739426, Test Loss: 1.884402, LR: 0.050000\n",
      "Seed 57, Epoch [590/1000], Train Loss: 0.739427, Test Loss: 1.903018, LR: 0.050000\n",
      "Seed 57, Epoch [600/1000], Train Loss: 0.732835, Test Loss: 1.869709, LR: 0.050000\n",
      "Seed 57, Epoch [610/1000], Train Loss: 0.730617, Test Loss: 1.798187, LR: 0.050000\n",
      "Seed 57, Epoch [620/1000], Train Loss: 0.740273, Test Loss: 2.193743, LR: 0.050000\n",
      "Seed 57, Epoch [630/1000], Train Loss: 0.749516, Test Loss: 1.349138, LR: 0.050000\n",
      "Seed 57, Epoch [640/1000], Train Loss: 0.722647, Test Loss: 1.390576, LR: 0.050000\n",
      "Seed 57, Epoch [650/1000], Train Loss: 0.768961, Test Loss: 1.865777, LR: 0.050000\n",
      "Seed 57, Epoch [660/1000], Train Loss: 0.711330, Test Loss: 1.719611, LR: 0.050000\n",
      "Seed 57, Epoch [670/1000], Train Loss: 0.743454, Test Loss: 1.698907, LR: 0.050000\n",
      "Seed 57, Epoch [680/1000], Train Loss: 0.703392, Test Loss: 1.726487, LR: 0.050000\n",
      "Seed 57, Epoch [690/1000], Train Loss: 0.696200, Test Loss: 1.917064, LR: 0.050000\n",
      "Seed 57, Epoch [700/1000], Train Loss: 0.697565, Test Loss: 2.031958, LR: 0.050000\n",
      "Seed 57, Epoch [710/1000], Train Loss: 0.690725, Test Loss: 2.022163, LR: 0.050000\n",
      "Seed 57, Epoch [720/1000], Train Loss: 0.696656, Test Loss: 2.099180, LR: 0.050000\n",
      "Seed 57, Epoch [730/1000], Train Loss: 0.689018, Test Loss: 2.012604, LR: 0.050000\n",
      "Seed 57, Epoch [740/1000], Train Loss: 0.711122, Test Loss: 1.968397, LR: 0.050000\n",
      "Seed 57, Epoch [750/1000], Train Loss: 0.707908, Test Loss: 1.883219, LR: 0.050000\n",
      "Seed 57, Epoch [760/1000], Train Loss: 0.703878, Test Loss: 2.038328, LR: 0.050000\n",
      "Seed 57, Epoch [770/1000], Train Loss: 0.683227, Test Loss: 2.300441, LR: 0.050000\n",
      "Seed 57, Epoch [780/1000], Train Loss: 0.714787, Test Loss: 2.098523, LR: 0.050000\n",
      "Seed 57, Epoch [790/1000], Train Loss: 0.679260, Test Loss: 2.182183, LR: 0.050000\n",
      "Seed 57, Epoch [800/1000], Train Loss: 0.674147, Test Loss: 2.303302, LR: 0.050000\n",
      "Seed 57, Epoch [810/1000], Train Loss: 0.682164, Test Loss: 2.486116, LR: 0.050000\n",
      "Seed 57, Epoch [820/1000], Train Loss: 0.693162, Test Loss: 2.293226, LR: 0.050000\n",
      "Seed 57, Epoch [830/1000], Train Loss: 0.662898, Test Loss: 2.340789, LR: 0.050000\n",
      "Seed 57, Epoch [840/1000], Train Loss: 0.681523, Test Loss: 2.595866, LR: 0.050000\n",
      "Seed 57, Epoch [850/1000], Train Loss: 0.674271, Test Loss: 2.427003, LR: 0.050000\n",
      "Seed 57, Epoch [860/1000], Train Loss: 0.657454, Test Loss: 2.422601, LR: 0.050000\n",
      "Seed 57, Epoch [870/1000], Train Loss: 0.656286, Test Loss: 2.536778, LR: 0.050000\n",
      "Early stopping at epoch 872 for seed 57\n",
      "Seed 58, Epoch [10/1000], Train Loss: 3.175346, Test Loss: 2.714172, LR: 0.050000\n",
      "Seed 58, Epoch [20/1000], Train Loss: 2.508940, Test Loss: 2.350995, LR: 0.050000\n",
      "Seed 58, Epoch [30/1000], Train Loss: 2.533903, Test Loss: 2.395928, LR: 0.050000\n",
      "Seed 58, Epoch [40/1000], Train Loss: 2.545908, Test Loss: 2.403150, LR: 0.050000\n",
      "Seed 58, Epoch [50/1000], Train Loss: 2.566462, Test Loss: 2.419969, LR: 0.050000\n",
      "Seed 58, Epoch [60/1000], Train Loss: 2.542178, Test Loss: 2.394433, LR: 0.050000\n",
      "Seed 58, Epoch [70/1000], Train Loss: 2.519088, Test Loss: 2.380319, LR: 0.050000\n",
      "Seed 58, Epoch [80/1000], Train Loss: 2.501804, Test Loss: 2.361193, LR: 0.050000\n",
      "Seed 58, Epoch [90/1000], Train Loss: 2.480668, Test Loss: 2.336234, LR: 0.050000\n",
      "Seed 58, Epoch [100/1000], Train Loss: 2.458139, Test Loss: 2.309095, LR: 0.050000\n",
      "Seed 58, Epoch [110/1000], Train Loss: 2.432855, Test Loss: 2.279040, LR: 0.050000\n",
      "Seed 58, Epoch [120/1000], Train Loss: 2.403896, Test Loss: 2.245159, LR: 0.050000\n",
      "Seed 58, Epoch [130/1000], Train Loss: 2.370780, Test Loss: 2.207292, LR: 0.050000\n",
      "Seed 58, Epoch [140/1000], Train Loss: 2.332280, Test Loss: 2.166161, LR: 0.050000\n",
      "Seed 58, Epoch [150/1000], Train Loss: 2.286059, Test Loss: 2.123650, LR: 0.050000\n",
      "Seed 58, Epoch [160/1000], Train Loss: 2.227728, Test Loss: 2.082153, LR: 0.050000\n",
      "Seed 58, Epoch [170/1000], Train Loss: 2.149888, Test Loss: 2.044236, LR: 0.050000\n",
      "Seed 58, Epoch [180/1000], Train Loss: 2.042823, Test Loss: 2.013725, LR: 0.050000\n",
      "Seed 58, Epoch [190/1000], Train Loss: 1.893918, Test Loss: 1.993357, LR: 0.050000\n",
      "Seed 58, Epoch [200/1000], Train Loss: 1.700368, Test Loss: 1.972919, LR: 0.050000\n",
      "Seed 58, Epoch [210/1000], Train Loss: 1.581208, Test Loss: 1.950098, LR: 0.050000\n",
      "Seed 58, Epoch [220/1000], Train Loss: 1.557257, Test Loss: 1.942018, LR: 0.050000\n",
      "Seed 58, Epoch [230/1000], Train Loss: 1.537880, Test Loss: 1.938355, LR: 0.050000\n",
      "Seed 58, Epoch [240/1000], Train Loss: 1.525299, Test Loss: 1.930622, LR: 0.050000\n",
      "Seed 58, Epoch [250/1000], Train Loss: 1.511562, Test Loss: 1.918016, LR: 0.050000\n",
      "Seed 58, Epoch [260/1000], Train Loss: 1.496370, Test Loss: 1.905474, LR: 0.050000\n",
      "Seed 58, Epoch [270/1000], Train Loss: 1.479254, Test Loss: 1.896401, LR: 0.050000\n",
      "Seed 58, Epoch [280/1000], Train Loss: 1.462416, Test Loss: 1.890035, LR: 0.050000\n",
      "Seed 58, Epoch [290/1000], Train Loss: 1.448391, Test Loss: 1.884367, LR: 0.050000\n",
      "Seed 58, Epoch [300/1000], Train Loss: 1.437505, Test Loss: 1.876712, LR: 0.050000\n",
      "Seed 58, Epoch [310/1000], Train Loss: 1.428288, Test Loss: 1.864362, LR: 0.050000\n",
      "Seed 58, Epoch [320/1000], Train Loss: 1.418920, Test Loss: 1.844983, LR: 0.050000\n",
      "Seed 58, Epoch [330/1000], Train Loss: 1.407426, Test Loss: 1.814662, LR: 0.050000\n",
      "Seed 58, Epoch [340/1000], Train Loss: 1.389200, Test Loss: 1.762890, LR: 0.050000\n",
      "Seed 58, Epoch [350/1000], Train Loss: 1.349852, Test Loss: 1.660800, LR: 0.050000\n",
      "Seed 58, Epoch [360/1000], Train Loss: 1.257409, Test Loss: 1.451417, LR: 0.050000\n",
      "Seed 58, Epoch [370/1000], Train Loss: 1.231436, Test Loss: 1.395859, LR: 0.050000\n",
      "Seed 58, Epoch [380/1000], Train Loss: 1.220637, Test Loss: 1.365732, LR: 0.050000\n",
      "Seed 58, Epoch [390/1000], Train Loss: 1.209262, Test Loss: 1.398972, LR: 0.050000\n",
      "Seed 58, Epoch [400/1000], Train Loss: 1.200776, Test Loss: 1.410834, LR: 0.050000\n",
      "Seed 58, Epoch [410/1000], Train Loss: 1.191658, Test Loss: 1.410138, LR: 0.050000\n",
      "Seed 58, Epoch [420/1000], Train Loss: 1.180584, Test Loss: 1.410144, LR: 0.050000\n",
      "Seed 58, Epoch [430/1000], Train Loss: 1.164833, Test Loss: 1.427307, LR: 0.050000\n",
      "Seed 58, Epoch [440/1000], Train Loss: 1.142527, Test Loss: 1.406364, LR: 0.050000\n",
      "Seed 58, Epoch [450/1000], Train Loss: 1.125163, Test Loss: 1.450134, LR: 0.050000\n",
      "Seed 58, Epoch [460/1000], Train Loss: 1.088821, Test Loss: 1.760242, LR: 0.050000\n",
      "Seed 58, Epoch [470/1000], Train Loss: 1.080018, Test Loss: 1.700733, LR: 0.050000\n",
      "Seed 58, Epoch [480/1000], Train Loss: 1.067422, Test Loss: 1.753702, LR: 0.050000\n",
      "Seed 58, Epoch [490/1000], Train Loss: 1.061652, Test Loss: 1.902960, LR: 0.050000\n",
      "Seed 58, Epoch [500/1000], Train Loss: 1.065473, Test Loss: 2.085778, LR: 0.050000\n",
      "Seed 58, Epoch [510/1000], Train Loss: 1.056947, Test Loss: 1.912828, LR: 0.050000\n",
      "Seed 58, Epoch [520/1000], Train Loss: 1.054471, Test Loss: 2.283663, LR: 0.050000\n",
      "Seed 58, Epoch [530/1000], Train Loss: 1.060961, Test Loss: 1.925656, LR: 0.050000\n",
      "Seed 58, Epoch [540/1000], Train Loss: 1.045403, Test Loss: 2.211858, LR: 0.050000\n",
      "Seed 58, Epoch [550/1000], Train Loss: 1.044203, Test Loss: 2.159665, LR: 0.050000\n",
      "Seed 58, Epoch [560/1000], Train Loss: 1.039415, Test Loss: 2.355462, LR: 0.050000\n",
      "Seed 58, Epoch [570/1000], Train Loss: 1.036130, Test Loss: 2.243034, LR: 0.050000\n",
      "Seed 58, Epoch [580/1000], Train Loss: 1.032027, Test Loss: 2.374951, LR: 0.050000\n",
      "Seed 58, Epoch [590/1000], Train Loss: 1.030480, Test Loss: 2.480782, LR: 0.050000\n",
      "Seed 58, Epoch [600/1000], Train Loss: 1.024225, Test Loss: 2.358817, LR: 0.050000\n",
      "Seed 58, Epoch [610/1000], Train Loss: 1.016825, Test Loss: 2.335388, LR: 0.050000\n",
      "Seed 58, Epoch [620/1000], Train Loss: 1.010640, Test Loss: 2.387095, LR: 0.050000\n",
      "Seed 58, Epoch [630/1000], Train Loss: 1.011195, Test Loss: 2.171260, LR: 0.050000\n",
      "Seed 58, Epoch [640/1000], Train Loss: 0.998798, Test Loss: 1.909786, LR: 0.050000\n",
      "Seed 58, Epoch [650/1000], Train Loss: 0.986684, Test Loss: 2.502120, LR: 0.050000\n",
      "Seed 58, Epoch [660/1000], Train Loss: 0.975398, Test Loss: 2.492948, LR: 0.050000\n",
      "Seed 58, Epoch [670/1000], Train Loss: 0.965035, Test Loss: 2.342612, LR: 0.050000\n",
      "Seed 58, Epoch [680/1000], Train Loss: 0.962629, Test Loss: 2.766034, LR: 0.050000\n",
      "Seed 58, Epoch [690/1000], Train Loss: 0.973830, Test Loss: 2.223154, LR: 0.050000\n",
      "Seed 58, Epoch [700/1000], Train Loss: 0.940326, Test Loss: 2.255098, LR: 0.050000\n",
      "Seed 58, Epoch [710/1000], Train Loss: 0.912652, Test Loss: 2.395165, LR: 0.050000\n",
      "Seed 58, Epoch [720/1000], Train Loss: 0.998007, Test Loss: 2.692080, LR: 0.050000\n",
      "Seed 58, Epoch [730/1000], Train Loss: 0.906741, Test Loss: 2.147710, LR: 0.050000\n",
      "Seed 58, Epoch [740/1000], Train Loss: 0.867073, Test Loss: 2.624093, LR: 0.050000\n",
      "Seed 58, Epoch [750/1000], Train Loss: 0.908749, Test Loss: 2.982763, LR: 0.050000\n",
      "Seed 58, Epoch [760/1000], Train Loss: 0.861348, Test Loss: 2.341996, LR: 0.050000\n",
      "Seed 58, Epoch [770/1000], Train Loss: 0.871319, Test Loss: 3.179702, LR: 0.050000\n",
      "Seed 58, Epoch [780/1000], Train Loss: 0.831914, Test Loss: 2.563512, LR: 0.050000\n",
      "Seed 58, Epoch [790/1000], Train Loss: 0.821263, Test Loss: 2.435032, LR: 0.050000\n",
      "Seed 58, Epoch [800/1000], Train Loss: 0.975784, Test Loss: 3.654795, LR: 0.050000\n",
      "Seed 58, Epoch [810/1000], Train Loss: 0.886773, Test Loss: 2.149240, LR: 0.050000\n",
      "Seed 58, Epoch [820/1000], Train Loss: 0.811915, Test Loss: 2.465246, LR: 0.050000\n",
      "Seed 58, Epoch [830/1000], Train Loss: 0.798325, Test Loss: 2.638259, LR: 0.050000\n",
      "Seed 58, Epoch [840/1000], Train Loss: 0.776910, Test Loss: 2.833877, LR: 0.050000\n",
      "Seed 58, Epoch [850/1000], Train Loss: 0.868965, Test Loss: 2.672257, LR: 0.050000\n",
      "Seed 58, Epoch [860/1000], Train Loss: 0.827144, Test Loss: 2.055119, LR: 0.050000\n",
      "Seed 58, Epoch [870/1000], Train Loss: 0.769029, Test Loss: 2.642217, LR: 0.050000\n",
      "Seed 58, Epoch [880/1000], Train Loss: 0.761803, Test Loss: 2.542936, LR: 0.050000\n",
      "Seed 58, Epoch [890/1000], Train Loss: 0.749416, Test Loss: 2.632541, LR: 0.050000\n",
      "Seed 58, Epoch [900/1000], Train Loss: 0.832124, Test Loss: 2.321941, LR: 0.050000\n",
      "Seed 58, Epoch [910/1000], Train Loss: 0.745154, Test Loss: 2.481970, LR: 0.050000\n",
      "Seed 58, Epoch [920/1000], Train Loss: 0.805135, Test Loss: 2.244462, LR: 0.050000\n",
      "Seed 58, Epoch [930/1000], Train Loss: 0.747357, Test Loss: 2.372511, LR: 0.050000\n",
      "Seed 58, Epoch [940/1000], Train Loss: 0.728119, Test Loss: 2.438180, LR: 0.050000\n",
      "Early stopping at epoch 942 for seed 58\n",
      "Seed 59, Epoch [10/1000], Train Loss: 3.315849, Test Loss: 2.567337, LR: 0.050000\n",
      "Seed 59, Epoch [20/1000], Train Loss: 2.466589, Test Loss: 2.382854, LR: 0.050000\n",
      "Seed 59, Epoch [30/1000], Train Loss: 2.484317, Test Loss: 2.391972, LR: 0.050000\n",
      "Seed 59, Epoch [40/1000], Train Loss: 2.492143, Test Loss: 2.393354, LR: 0.050000\n",
      "Seed 59, Epoch [50/1000], Train Loss: 2.493406, Test Loss: 2.391744, LR: 0.050000\n",
      "Seed 59, Epoch [60/1000], Train Loss: 2.491864, Test Loss: 2.388962, LR: 0.050000\n",
      "Seed 59, Epoch [70/1000], Train Loss: 2.489223, Test Loss: 2.385749, LR: 0.050000\n",
      "Seed 59, Epoch [80/1000], Train Loss: 2.486175, Test Loss: 2.382397, LR: 0.050000\n",
      "Seed 59, Epoch [90/1000], Train Loss: 2.482996, Test Loss: 2.379020, LR: 0.050000\n",
      "Seed 59, Epoch [100/1000], Train Loss: 2.479785, Test Loss: 2.375652, LR: 0.050000\n",
      "Seed 59, Epoch [110/1000], Train Loss: 2.476583, Test Loss: 2.372314, LR: 0.050000\n",
      "Seed 59, Epoch [120/1000], Train Loss: 2.473395, Test Loss: 2.369005, LR: 0.050000\n",
      "Seed 59, Epoch [130/1000], Train Loss: 2.470213, Test Loss: 2.365716, LR: 0.050000\n",
      "Seed 59, Epoch [140/1000], Train Loss: 2.467022, Test Loss: 2.362432, LR: 0.050000\n",
      "Seed 59, Epoch [150/1000], Train Loss: 2.463804, Test Loss: 2.359139, LR: 0.050000\n",
      "Seed 59, Epoch [160/1000], Train Loss: 2.460540, Test Loss: 2.355818, LR: 0.050000\n",
      "Seed 59, Epoch [170/1000], Train Loss: 2.457211, Test Loss: 2.352456, LR: 0.050000\n",
      "Seed 59, Epoch [180/1000], Train Loss: 2.453800, Test Loss: 2.349036, LR: 0.050000\n",
      "Seed 59, Epoch [190/1000], Train Loss: 2.450292, Test Loss: 2.345546, LR: 0.050000\n",
      "Seed 59, Epoch [200/1000], Train Loss: 2.446670, Test Loss: 2.341975, LR: 0.050000\n",
      "Seed 59, Epoch [210/1000], Train Loss: 2.442921, Test Loss: 2.338312, LR: 0.050000\n",
      "Seed 59, Epoch [220/1000], Train Loss: 2.439032, Test Loss: 2.334548, LR: 0.050000\n",
      "Seed 59, Epoch [230/1000], Train Loss: 2.434992, Test Loss: 2.330674, LR: 0.050000\n",
      "Seed 59, Epoch [240/1000], Train Loss: 2.430787, Test Loss: 2.326684, LR: 0.050000\n",
      "Seed 59, Epoch [250/1000], Train Loss: 2.426409, Test Loss: 2.322572, LR: 0.050000\n",
      "Seed 59, Epoch [260/1000], Train Loss: 2.421845, Test Loss: 2.318332, LR: 0.050000\n",
      "Seed 59, Epoch [270/1000], Train Loss: 2.417085, Test Loss: 2.313959, LR: 0.050000\n",
      "Seed 59, Epoch [280/1000], Train Loss: 2.412122, Test Loss: 2.309448, LR: 0.050000\n",
      "Seed 59, Epoch [290/1000], Train Loss: 2.406946, Test Loss: 2.304793, LR: 0.050000\n",
      "Seed 59, Epoch [300/1000], Train Loss: 2.401548, Test Loss: 2.299991, LR: 0.050000\n",
      "Seed 59, Epoch [310/1000], Train Loss: 2.395925, Test Loss: 2.295038, LR: 0.050000\n",
      "Seed 59, Epoch [320/1000], Train Loss: 2.390070, Test Loss: 2.289929, LR: 0.050000\n",
      "Seed 59, Epoch [330/1000], Train Loss: 2.383984, Test Loss: 2.284660, LR: 0.050000\n",
      "Seed 59, Epoch [340/1000], Train Loss: 2.377667, Test Loss: 2.279229, LR: 0.050000\n",
      "Seed 59, Epoch [350/1000], Train Loss: 2.371124, Test Loss: 2.273631, LR: 0.050000\n",
      "Seed 59, Epoch [360/1000], Train Loss: 2.364364, Test Loss: 2.267864, LR: 0.050000\n",
      "Seed 59, Epoch [370/1000], Train Loss: 2.357398, Test Loss: 2.261927, LR: 0.050000\n",
      "Seed 59, Epoch [380/1000], Train Loss: 2.350241, Test Loss: 2.255818, LR: 0.050000\n",
      "Seed 59, Epoch [390/1000], Train Loss: 2.342911, Test Loss: 2.249538, LR: 0.050000\n",
      "Seed 59, Epoch [400/1000], Train Loss: 2.335428, Test Loss: 2.243088, LR: 0.050000\n",
      "Seed 59, Epoch [410/1000], Train Loss: 2.327811, Test Loss: 2.236472, LR: 0.050000\n",
      "Seed 59, Epoch [420/1000], Train Loss: 2.320084, Test Loss: 2.229694, LR: 0.050000\n",
      "Seed 59, Epoch [430/1000], Train Loss: 2.312266, Test Loss: 2.222762, LR: 0.050000\n",
      "Seed 59, Epoch [440/1000], Train Loss: 2.304380, Test Loss: 2.215682, LR: 0.050000\n",
      "Seed 59, Epoch [450/1000], Train Loss: 2.296446, Test Loss: 2.208467, LR: 0.050000\n",
      "Seed 59, Epoch [460/1000], Train Loss: 2.288488, Test Loss: 2.201131, LR: 0.050000\n",
      "Seed 59, Epoch [470/1000], Train Loss: 2.280528, Test Loss: 2.193691, LR: 0.050000\n",
      "Seed 59, Epoch [480/1000], Train Loss: 2.272591, Test Loss: 2.186164, LR: 0.050000\n",
      "Seed 59, Epoch [490/1000], Train Loss: 2.264701, Test Loss: 2.178577, LR: 0.050000\n",
      "Seed 59, Epoch [500/1000], Train Loss: 2.256889, Test Loss: 2.170954, LR: 0.050000\n",
      "Seed 59, Epoch [510/1000], Train Loss: 2.249181, Test Loss: 2.163327, LR: 0.050000\n",
      "Seed 59, Epoch [520/1000], Train Loss: 2.241611, Test Loss: 2.155730, LR: 0.050000\n",
      "Seed 59, Epoch [530/1000], Train Loss: 2.234208, Test Loss: 2.148202, LR: 0.050000\n",
      "Seed 59, Epoch [540/1000], Train Loss: 2.227005, Test Loss: 2.140786, LR: 0.050000\n",
      "Seed 59, Epoch [550/1000], Train Loss: 2.220027, Test Loss: 2.133526, LR: 0.050000\n",
      "Seed 59, Epoch [560/1000], Train Loss: 2.213300, Test Loss: 2.126468, LR: 0.050000\n",
      "Seed 59, Epoch [570/1000], Train Loss: 2.206838, Test Loss: 2.119657, LR: 0.050000\n",
      "Seed 59, Epoch [580/1000], Train Loss: 2.200650, Test Loss: 2.113134, LR: 0.050000\n",
      "Seed 59, Epoch [590/1000], Train Loss: 2.194734, Test Loss: 2.106936, LR: 0.050000\n",
      "Seed 59, Epoch [600/1000], Train Loss: 2.189073, Test Loss: 2.101086, LR: 0.050000\n",
      "Seed 59, Epoch [610/1000], Train Loss: 2.183645, Test Loss: 2.095598, LR: 0.050000\n",
      "Seed 59, Epoch [620/1000], Train Loss: 2.178416, Test Loss: 2.090461, LR: 0.050000\n",
      "Seed 59, Epoch [630/1000], Train Loss: 2.173342, Test Loss: 2.085663, LR: 0.050000\n",
      "Seed 59, Epoch [640/1000], Train Loss: 2.168378, Test Loss: 2.081173, LR: 0.050000\n",
      "Seed 59, Epoch [650/1000], Train Loss: 2.163474, Test Loss: 2.076947, LR: 0.050000\n",
      "Seed 59, Epoch [660/1000], Train Loss: 2.158581, Test Loss: 2.072930, LR: 0.050000\n",
      "Seed 59, Epoch [670/1000], Train Loss: 2.153647, Test Loss: 2.069066, LR: 0.050000\n",
      "Seed 59, Epoch [680/1000], Train Loss: 2.148627, Test Loss: 2.065296, LR: 0.050000\n",
      "Seed 59, Epoch [690/1000], Train Loss: 2.143474, Test Loss: 2.061564, LR: 0.050000\n",
      "Seed 59, Epoch [700/1000], Train Loss: 2.138143, Test Loss: 2.057819, LR: 0.050000\n",
      "Seed 59, Epoch [710/1000], Train Loss: 2.132590, Test Loss: 2.054016, LR: 0.050000\n",
      "Seed 59, Epoch [720/1000], Train Loss: 2.126772, Test Loss: 2.050117, LR: 0.050000\n",
      "Seed 59, Epoch [730/1000], Train Loss: 2.120640, Test Loss: 2.046088, LR: 0.050000\n",
      "Seed 59, Epoch [740/1000], Train Loss: 2.114146, Test Loss: 2.041905, LR: 0.050000\n",
      "Seed 59, Epoch [750/1000], Train Loss: 2.107233, Test Loss: 2.037549, LR: 0.050000\n",
      "Seed 59, Epoch [760/1000], Train Loss: 2.099835, Test Loss: 2.033008, LR: 0.050000\n",
      "Seed 59, Epoch [770/1000], Train Loss: 2.091873, Test Loss: 2.028283, LR: 0.050000\n",
      "Seed 59, Epoch [780/1000], Train Loss: 2.083247, Test Loss: 2.023385, LR: 0.050000\n",
      "Seed 59, Epoch [790/1000], Train Loss: 2.073829, Test Loss: 2.018339, LR: 0.050000\n",
      "Seed 59, Epoch [800/1000], Train Loss: 2.063446, Test Loss: 2.013192, LR: 0.050000\n",
      "Seed 59, Epoch [810/1000], Train Loss: 2.051869, Test Loss: 2.008009, LR: 0.050000\n",
      "Seed 59, Epoch [820/1000], Train Loss: 2.038790, Test Loss: 2.002874, LR: 0.050000\n",
      "Seed 59, Epoch [830/1000], Train Loss: 2.023812, Test Loss: 1.997886, LR: 0.050000\n",
      "Seed 59, Epoch [840/1000], Train Loss: 2.006465, Test Loss: 1.993133, LR: 0.050000\n",
      "Seed 59, Epoch [850/1000], Train Loss: 1.986293, Test Loss: 1.988641, LR: 0.050000\n",
      "Seed 59, Epoch [860/1000], Train Loss: 1.963078, Test Loss: 1.984227, LR: 0.050000\n",
      "Seed 59, Epoch [870/1000], Train Loss: 1.937259, Test Loss: 1.979231, LR: 0.050000\n",
      "Seed 59, Epoch [880/1000], Train Loss: 1.910383, Test Loss: 1.972060, LR: 0.050000\n",
      "Seed 59, Epoch [890/1000], Train Loss: 1.885012, Test Loss: 1.960058, LR: 0.050000\n",
      "Seed 59, Epoch [900/1000], Train Loss: 1.864327, Test Loss: 1.942232, LR: 0.050000\n",
      "Seed 59, Epoch [910/1000], Train Loss: 1.849787, Test Loss: 1.925025, LR: 0.050000\n",
      "Seed 59, Epoch [920/1000], Train Loss: 1.837171, Test Loss: 1.916788, LR: 0.050000\n",
      "Seed 59, Epoch [930/1000], Train Loss: 1.824234, Test Loss: 1.913095, LR: 0.050000\n",
      "Seed 59, Epoch [940/1000], Train Loss: 1.811486, Test Loss: 1.907642, LR: 0.050000\n",
      "Seed 59, Epoch [950/1000], Train Loss: 1.798616, Test Loss: 1.899750, LR: 0.050000\n",
      "Seed 59, Epoch [960/1000], Train Loss: 1.785298, Test Loss: 1.889517, LR: 0.050000\n",
      "Seed 59, Epoch [970/1000], Train Loss: 1.771410, Test Loss: 1.878149, LR: 0.050000\n",
      "Seed 59, Epoch [980/1000], Train Loss: 1.756830, Test Loss: 1.866715, LR: 0.050000\n",
      "Seed 59, Epoch [990/1000], Train Loss: 1.741448, Test Loss: 1.854838, LR: 0.050000\n",
      "Seed 59, Epoch [1000/1000], Train Loss: 1.725163, Test Loss: 1.842380, LR: 0.050000\n",
      "Seed 60, Epoch [10/1000], Train Loss: 2.844039, Test Loss: 2.730051, LR: 0.050000\n",
      "Seed 60, Epoch [20/1000], Train Loss: 2.435185, Test Loss: 2.282948, LR: 0.050000\n",
      "Seed 60, Epoch [30/1000], Train Loss: 2.490724, Test Loss: 2.298728, LR: 0.050000\n",
      "Seed 60, Epoch [40/1000], Train Loss: 2.442948, Test Loss: 2.242250, LR: 0.050000\n",
      "Seed 60, Epoch [50/1000], Train Loss: 2.331962, Test Loss: 2.135824, LR: 0.050000\n",
      "Seed 60, Epoch [60/1000], Train Loss: 2.196467, Test Loss: 1.972995, LR: 0.050000\n",
      "Seed 60, Epoch [70/1000], Train Loss: 2.028958, Test Loss: 1.769076, LR: 0.050000\n",
      "Seed 60, Epoch [80/1000], Train Loss: 1.748663, Test Loss: 1.268752, LR: 0.050000\n",
      "Seed 60, Epoch [90/1000], Train Loss: 1.585476, Test Loss: 1.408293, LR: 0.050000\n",
      "Seed 60, Epoch [100/1000], Train Loss: 1.478509, Test Loss: 1.433836, LR: 0.050000\n",
      "Seed 60, Epoch [110/1000], Train Loss: 1.340815, Test Loss: 1.395133, LR: 0.050000\n",
      "Seed 60, Epoch [120/1000], Train Loss: 1.199623, Test Loss: 1.176266, LR: 0.050000\n",
      "Seed 60, Epoch [130/1000], Train Loss: 1.097383, Test Loss: 1.108236, LR: 0.050000\n",
      "Seed 60, Epoch [140/1000], Train Loss: 1.032866, Test Loss: 1.152360, LR: 0.050000\n",
      "Seed 60, Epoch [150/1000], Train Loss: 0.987537, Test Loss: 1.215099, LR: 0.050000\n",
      "Seed 60, Epoch [160/1000], Train Loss: 0.971603, Test Loss: 1.378213, LR: 0.050000\n",
      "Seed 60, Epoch [170/1000], Train Loss: 1.600906, Test Loss: 1.801475, LR: 0.050000\n",
      "Seed 60, Epoch [180/1000], Train Loss: 1.603001, Test Loss: 1.608766, LR: 0.050000\n",
      "Seed 60, Epoch [190/1000], Train Loss: 1.125615, Test Loss: 1.228757, LR: 0.050000\n",
      "Seed 60, Epoch [200/1000], Train Loss: 1.019465, Test Loss: 1.252810, LR: 0.050000\n",
      "Seed 60, Epoch [210/1000], Train Loss: 0.949448, Test Loss: 1.167658, LR: 0.050000\n",
      "Seed 60, Epoch [220/1000], Train Loss: 0.894672, Test Loss: 1.236159, LR: 0.050000\n",
      "Seed 60, Epoch [230/1000], Train Loss: 1.270130, Test Loss: 2.390538, LR: 0.050000\n",
      "Seed 60, Epoch [240/1000], Train Loss: 1.933646, Test Loss: 2.411260, LR: 0.050000\n",
      "Seed 60, Epoch [250/1000], Train Loss: 1.611112, Test Loss: 1.743874, LR: 0.050000\n",
      "Seed 60, Epoch [260/1000], Train Loss: 1.361046, Test Loss: 1.545048, LR: 0.050000\n",
      "Seed 60, Epoch [270/1000], Train Loss: 1.179128, Test Loss: 1.471165, LR: 0.050000\n",
      "Seed 60, Epoch [280/1000], Train Loss: 1.033723, Test Loss: 1.228758, LR: 0.050000\n",
      "Seed 60, Epoch [290/1000], Train Loss: 0.919195, Test Loss: 1.136059, LR: 0.050000\n",
      "Seed 60, Epoch [300/1000], Train Loss: 0.880651, Test Loss: 1.323312, LR: 0.050000\n",
      "Seed 60, Epoch [310/1000], Train Loss: 0.848863, Test Loss: 1.418128, LR: 0.050000\n",
      "Seed 60, Epoch [320/1000], Train Loss: 0.825076, Test Loss: 1.536683, LR: 0.050000\n",
      "Seed 60, Epoch [330/1000], Train Loss: 0.808306, Test Loss: 1.644846, LR: 0.050000\n",
      "Seed 60, Epoch [340/1000], Train Loss: 0.801062, Test Loss: 1.686521, LR: 0.050000\n",
      "Seed 60, Epoch [350/1000], Train Loss: 0.826764, Test Loss: 1.779832, LR: 0.050000\n",
      "Seed 60, Epoch [360/1000], Train Loss: 0.817261, Test Loss: 1.697283, LR: 0.050000\n",
      "Seed 60, Epoch [370/1000], Train Loss: 0.773846, Test Loss: 1.656132, LR: 0.050000\n",
      "Seed 60, Epoch [380/1000], Train Loss: 0.778401, Test Loss: 1.541224, LR: 0.050000\n",
      "Seed 60, Epoch [390/1000], Train Loss: 0.767336, Test Loss: 1.568535, LR: 0.050000\n",
      "Seed 60, Epoch [400/1000], Train Loss: 0.767364, Test Loss: 1.402389, LR: 0.050000\n",
      "Seed 60, Epoch [410/1000], Train Loss: 0.817485, Test Loss: 1.567111, LR: 0.050000\n",
      "Seed 60, Epoch [420/1000], Train Loss: 0.799941, Test Loss: 1.487369, LR: 0.050000\n",
      "Seed 60, Epoch [430/1000], Train Loss: 0.759548, Test Loss: 1.409840, LR: 0.050000\n",
      "Seed 60, Epoch [440/1000], Train Loss: 0.740131, Test Loss: 1.373651, LR: 0.050000\n",
      "Seed 60, Epoch [450/1000], Train Loss: 0.730246, Test Loss: 1.380732, LR: 0.050000\n",
      "Seed 60, Epoch [460/1000], Train Loss: 0.766659, Test Loss: 1.455341, LR: 0.050000\n",
      "Seed 60, Epoch [470/1000], Train Loss: 0.754705, Test Loss: 1.374148, LR: 0.050000\n",
      "Seed 60, Epoch [480/1000], Train Loss: 0.793905, Test Loss: 1.280856, LR: 0.050000\n",
      "Seed 60, Epoch [490/1000], Train Loss: 0.741167, Test Loss: 1.247438, LR: 0.050000\n",
      "Seed 60, Epoch [500/1000], Train Loss: 0.743917, Test Loss: 1.231116, LR: 0.050000\n",
      "Seed 60, Epoch [510/1000], Train Loss: 0.846091, Test Loss: 1.276920, LR: 0.050000\n",
      "Seed 60, Epoch [520/1000], Train Loss: 0.807881, Test Loss: 1.244365, LR: 0.050000\n",
      "Seed 60, Epoch [530/1000], Train Loss: 0.761711, Test Loss: 1.139343, LR: 0.050000\n",
      "Seed 60, Epoch [540/1000], Train Loss: 0.721455, Test Loss: 1.167850, LR: 0.050000\n",
      "Seed 60, Epoch [550/1000], Train Loss: 0.712860, Test Loss: 1.233339, LR: 0.050000\n",
      "Seed 60, Epoch [560/1000], Train Loss: 0.858032, Test Loss: 1.227691, LR: 0.050000\n",
      "Seed 60, Epoch [570/1000], Train Loss: 0.732084, Test Loss: 1.219031, LR: 0.050000\n",
      "Seed 60, Epoch [580/1000], Train Loss: 0.687645, Test Loss: 1.170526, LR: 0.050000\n",
      "Seed 60, Epoch [590/1000], Train Loss: 0.820599, Test Loss: 1.218697, LR: 0.050000\n",
      "Seed 60, Epoch [600/1000], Train Loss: 0.800664, Test Loss: 1.223543, LR: 0.050000\n",
      "Seed 60, Epoch [610/1000], Train Loss: 0.716356, Test Loss: 1.121234, LR: 0.050000\n",
      "Seed 60, Epoch [620/1000], Train Loss: 0.755975, Test Loss: 1.189962, LR: 0.050000\n",
      "Seed 60, Epoch [630/1000], Train Loss: 1.003418, Test Loss: 1.276390, LR: 0.050000\n",
      "Seed 60, Epoch [640/1000], Train Loss: 0.747000, Test Loss: 1.101529, LR: 0.050000\n",
      "Seed 60, Epoch [650/1000], Train Loss: 0.725017, Test Loss: 1.022989, LR: 0.050000\n",
      "Seed 60, Epoch [660/1000], Train Loss: 0.674401, Test Loss: 1.024475, LR: 0.050000\n",
      "Seed 60, Epoch [670/1000], Train Loss: 0.712198, Test Loss: 1.076101, LR: 0.050000\n",
      "Seed 60, Epoch [680/1000], Train Loss: 0.694873, Test Loss: 1.132901, LR: 0.050000\n",
      "Seed 60, Epoch [690/1000], Train Loss: 0.658486, Test Loss: 1.106017, LR: 0.050000\n",
      "Seed 60, Epoch [700/1000], Train Loss: 0.843022, Test Loss: 1.071559, LR: 0.050000\n",
      "Seed 60, Epoch [710/1000], Train Loss: 0.738748, Test Loss: 1.033546, LR: 0.050000\n",
      "Seed 60, Epoch [720/1000], Train Loss: 0.674773, Test Loss: 1.087435, LR: 0.050000\n",
      "Seed 60, Epoch [730/1000], Train Loss: 0.832717, Test Loss: 1.097811, LR: 0.050000\n",
      "Seed 60, Epoch [740/1000], Train Loss: 0.678421, Test Loss: 1.040575, LR: 0.050000\n",
      "Seed 60, Epoch [750/1000], Train Loss: 0.705277, Test Loss: 0.954598, LR: 0.050000\n",
      "Seed 60, Epoch [760/1000], Train Loss: 0.683977, Test Loss: 0.994735, LR: 0.050000\n",
      "Seed 60, Epoch [770/1000], Train Loss: 0.711358, Test Loss: 1.084546, LR: 0.050000\n",
      "Seed 60, Epoch [780/1000], Train Loss: 0.948495, Test Loss: 1.154044, LR: 0.050000\n",
      "Seed 60, Epoch [790/1000], Train Loss: 0.767003, Test Loss: 1.014709, LR: 0.050000\n",
      "Seed 60, Epoch [800/1000], Train Loss: 0.736832, Test Loss: 0.969903, LR: 0.050000\n",
      "Seed 60, Epoch [810/1000], Train Loss: 0.690382, Test Loss: 0.941043, LR: 0.050000\n",
      "Seed 60, Epoch [820/1000], Train Loss: 0.664841, Test Loss: 1.019796, LR: 0.050000\n",
      "Seed 60, Epoch [830/1000], Train Loss: 0.744515, Test Loss: 1.062591, LR: 0.050000\n",
      "Seed 60, Epoch [840/1000], Train Loss: 0.807376, Test Loss: 1.088820, LR: 0.050000\n",
      "Seed 60, Epoch [850/1000], Train Loss: 0.763375, Test Loss: 1.015118, LR: 0.050000\n",
      "Seed 60, Epoch [860/1000], Train Loss: 0.716276, Test Loss: 0.979955, LR: 0.050000\n",
      "Seed 60, Epoch [870/1000], Train Loss: 0.720878, Test Loss: 0.912443, LR: 0.050000\n",
      "Seed 60, Epoch [880/1000], Train Loss: 0.671119, Test Loss: 0.948666, LR: 0.050000\n",
      "Seed 60, Epoch [890/1000], Train Loss: 0.739258, Test Loss: 1.024506, LR: 0.050000\n",
      "Seed 60, Epoch [900/1000], Train Loss: 0.687286, Test Loss: 0.934607, LR: 0.050000\n",
      "Seed 60, Epoch [910/1000], Train Loss: 0.778587, Test Loss: 1.026787, LR: 0.050000\n",
      "Seed 60, Epoch [920/1000], Train Loss: 0.843857, Test Loss: 0.927823, LR: 0.050000\n",
      "Seed 60, Epoch [930/1000], Train Loss: 0.699183, Test Loss: 0.989405, LR: 0.050000\n",
      "Seed 60, Epoch [940/1000], Train Loss: 0.700345, Test Loss: 0.962015, LR: 0.050000\n",
      "Seed 60, Epoch [950/1000], Train Loss: 0.790420, Test Loss: 0.975781, LR: 0.050000\n",
      "Seed 60, Epoch [960/1000], Train Loss: 1.001160, Test Loss: 1.185637, LR: 0.050000\n",
      "Seed 60, Epoch [970/1000], Train Loss: 0.869973, Test Loss: 0.916348, LR: 0.050000\n",
      "Seed 60, Epoch [980/1000], Train Loss: 0.751401, Test Loss: 0.911684, LR: 0.050000\n",
      "Seed 60, Epoch [990/1000], Train Loss: 0.695387, Test Loss: 0.886722, LR: 0.050000\n",
      "Seed 60, Epoch [1000/1000], Train Loss: 0.905011, Test Loss: 1.013015, LR: 0.050000\n",
      "Seed 61, Epoch [10/1000], Train Loss: 2.409761, Test Loss: 2.265865, LR: 0.050000\n",
      "Seed 61, Epoch [20/1000], Train Loss: 2.297659, Test Loss: 2.127254, LR: 0.050000\n",
      "Seed 61, Epoch [30/1000], Train Loss: 2.435652, Test Loss: 2.224169, LR: 0.050000\n",
      "Seed 61, Epoch [40/1000], Train Loss: 2.438714, Test Loss: 2.218463, LR: 0.050000\n",
      "Seed 61, Epoch [50/1000], Train Loss: 2.389157, Test Loss: 2.179936, LR: 0.050000\n",
      "Seed 61, Epoch [60/1000], Train Loss: 2.341955, Test Loss: 2.153957, LR: 0.050000\n",
      "Seed 61, Epoch [70/1000], Train Loss: 2.306364, Test Loss: 2.139702, LR: 0.050000\n",
      "Seed 61, Epoch [80/1000], Train Loss: 2.274761, Test Loss: 2.124377, LR: 0.050000\n",
      "Seed 61, Epoch [90/1000], Train Loss: 2.240455, Test Loss: 2.102592, LR: 0.050000\n",
      "Seed 61, Epoch [100/1000], Train Loss: 2.201581, Test Loss: 2.073972, LR: 0.050000\n",
      "Seed 61, Epoch [110/1000], Train Loss: 2.158359, Test Loss: 2.040642, LR: 0.050000\n",
      "Seed 61, Epoch [120/1000], Train Loss: 2.111575, Test Loss: 2.005521, LR: 0.050000\n",
      "Seed 61, Epoch [130/1000], Train Loss: 2.061537, Test Loss: 1.971783, LR: 0.050000\n",
      "Seed 61, Epoch [140/1000], Train Loss: 2.007461, Test Loss: 1.943665, LR: 0.050000\n",
      "Seed 61, Epoch [150/1000], Train Loss: 1.947921, Test Loss: 1.928931, LR: 0.050000\n",
      "Seed 61, Epoch [160/1000], Train Loss: 1.883080, Test Loss: 1.937409, LR: 0.050000\n",
      "Seed 61, Epoch [170/1000], Train Loss: 1.820429, Test Loss: 1.968881, LR: 0.050000\n",
      "Seed 61, Epoch [180/1000], Train Loss: 1.766238, Test Loss: 1.996577, LR: 0.050000\n",
      "Seed 61, Epoch [190/1000], Train Loss: 1.709862, Test Loss: 1.967461, LR: 0.050000\n",
      "Seed 61, Epoch [200/1000], Train Loss: 1.651308, Test Loss: 1.874507, LR: 0.050000\n",
      "Seed 61, Epoch [210/1000], Train Loss: 1.586961, Test Loss: 1.755715, LR: 0.050000\n",
      "Seed 61, Epoch [220/1000], Train Loss: 1.515201, Test Loss: 1.613323, LR: 0.050000\n",
      "Seed 61, Epoch [230/1000], Train Loss: 1.434978, Test Loss: 1.432997, LR: 0.050000\n",
      "Seed 61, Epoch [240/1000], Train Loss: 1.349512, Test Loss: 1.261451, LR: 0.050000\n",
      "Seed 61, Epoch [250/1000], Train Loss: 1.262057, Test Loss: 1.088569, LR: 0.050000\n",
      "Seed 61, Epoch [260/1000], Train Loss: 1.182109, Test Loss: 6.746003, LR: 0.050000\n",
      "Seed 61, Epoch [270/1000], Train Loss: 3.003606, Test Loss: 2.753925, LR: 0.050000\n",
      "Seed 61, Epoch [280/1000], Train Loss: 2.020151, Test Loss: 1.854362, LR: 0.050000\n",
      "Seed 61, Epoch [290/1000], Train Loss: 2.032815, Test Loss: 1.860363, LR: 0.050000\n",
      "Seed 61, Epoch [300/1000], Train Loss: 1.935633, Test Loss: 1.755497, LR: 0.050000\n",
      "Seed 61, Epoch [310/1000], Train Loss: 1.982012, Test Loss: 1.749371, LR: 0.050000\n",
      "Seed 61, Epoch [320/1000], Train Loss: 1.819288, Test Loss: 1.578162, LR: 0.050000\n",
      "Seed 61, Epoch [330/1000], Train Loss: 1.707872, Test Loss: 1.509910, LR: 0.050000\n",
      "Seed 61, Epoch [340/1000], Train Loss: 1.616654, Test Loss: 1.437657, LR: 0.050000\n",
      "Seed 61, Epoch [350/1000], Train Loss: 1.500474, Test Loss: 1.261638, LR: 0.050000\n",
      "Seed 61, Epoch [360/1000], Train Loss: 1.356676, Test Loss: 1.104629, LR: 0.050000\n",
      "Seed 61, Epoch [370/1000], Train Loss: 1.197155, Test Loss: 0.962926, LR: 0.050000\n",
      "Seed 61, Epoch [380/1000], Train Loss: 1.090005, Test Loss: 0.947931, LR: 0.050000\n",
      "Seed 61, Epoch [390/1000], Train Loss: 1.066837, Test Loss: 1.046683, LR: 0.050000\n",
      "Seed 61, Epoch [400/1000], Train Loss: 1.046998, Test Loss: 1.150270, LR: 0.050000\n",
      "Seed 61, Epoch [410/1000], Train Loss: 1.032721, Test Loss: 1.150221, LR: 0.050000\n",
      "Seed 61, Epoch [420/1000], Train Loss: 1.017996, Test Loss: 1.221681, LR: 0.050000\n",
      "Seed 61, Epoch [430/1000], Train Loss: 0.997772, Test Loss: 1.347904, LR: 0.050000\n",
      "Seed 61, Epoch [440/1000], Train Loss: 0.981193, Test Loss: 1.411881, LR: 0.050000\n",
      "Seed 61, Epoch [450/1000], Train Loss: 0.967411, Test Loss: 1.390410, LR: 0.050000\n",
      "Seed 61, Epoch [460/1000], Train Loss: 0.954019, Test Loss: 1.429601, LR: 0.050000\n",
      "Seed 61, Epoch [470/1000], Train Loss: 0.940455, Test Loss: 1.482439, LR: 0.050000\n",
      "Seed 61, Epoch [480/1000], Train Loss: 0.926592, Test Loss: 1.562767, LR: 0.050000\n",
      "Seed 61, Epoch [490/1000], Train Loss: 0.912599, Test Loss: 1.656073, LR: 0.050000\n",
      "Seed 61, Epoch [500/1000], Train Loss: 0.898898, Test Loss: 1.771005, LR: 0.050000\n",
      "Seed 61, Epoch [510/1000], Train Loss: 0.885988, Test Loss: 1.883745, LR: 0.050000\n",
      "Seed 61, Epoch [520/1000], Train Loss: 1.412660, Test Loss: 3.982658, LR: 0.050000\n",
      "Seed 61, Epoch [530/1000], Train Loss: 1.006098, Test Loss: 0.862402, LR: 0.050000\n",
      "Seed 61, Epoch [540/1000], Train Loss: 0.969704, Test Loss: 0.949056, LR: 0.050000\n",
      "Seed 61, Epoch [550/1000], Train Loss: 0.910226, Test Loss: 0.929650, LR: 0.050000\n",
      "Seed 61, Epoch [560/1000], Train Loss: 0.878620, Test Loss: 1.233305, LR: 0.050000\n",
      "Seed 61, Epoch [570/1000], Train Loss: 0.862607, Test Loss: 1.632784, LR: 0.050000\n",
      "Seed 61, Epoch [580/1000], Train Loss: 0.849424, Test Loss: 1.765762, LR: 0.050000\n",
      "Seed 61, Epoch [590/1000], Train Loss: 0.839071, Test Loss: 1.931861, LR: 0.050000\n",
      "Seed 61, Epoch [600/1000], Train Loss: 0.831927, Test Loss: 1.960161, LR: 0.050000\n",
      "Seed 61, Epoch [610/1000], Train Loss: 0.826064, Test Loss: 2.044312, LR: 0.050000\n",
      "Seed 61, Epoch [620/1000], Train Loss: 0.821200, Test Loss: 2.039696, LR: 0.050000\n",
      "Seed 61, Epoch [630/1000], Train Loss: 0.825546, Test Loss: 1.834882, LR: 0.050000\n",
      "Seed 61, Epoch [640/1000], Train Loss: 0.822322, Test Loss: 1.284421, LR: 0.050000\n",
      "Seed 61, Epoch [650/1000], Train Loss: 0.830203, Test Loss: 1.489211, LR: 0.050000\n",
      "Seed 61, Epoch [660/1000], Train Loss: 0.812014, Test Loss: 1.801803, LR: 0.050000\n",
      "Seed 61, Epoch [670/1000], Train Loss: 0.803097, Test Loss: 2.211713, LR: 0.050000\n",
      "Seed 61, Epoch [680/1000], Train Loss: 0.798300, Test Loss: 2.237357, LR: 0.050000\n",
      "Seed 61, Epoch [690/1000], Train Loss: 0.796773, Test Loss: 2.153656, LR: 0.050000\n",
      "Seed 61, Epoch [700/1000], Train Loss: 0.790639, Test Loss: 2.262790, LR: 0.050000\n",
      "Seed 61, Epoch [710/1000], Train Loss: 0.786708, Test Loss: 2.373790, LR: 0.050000\n",
      "Seed 61, Epoch [720/1000], Train Loss: 0.846280, Test Loss: 1.750219, LR: 0.050000\n",
      "Seed 61, Epoch [730/1000], Train Loss: 0.838512, Test Loss: 1.287424, LR: 0.050000\n",
      "Seed 61, Epoch [740/1000], Train Loss: 0.819975, Test Loss: 1.633242, LR: 0.050000\n",
      "Seed 61, Epoch [750/1000], Train Loss: 0.785259, Test Loss: 1.971281, LR: 0.050000\n",
      "Seed 61, Epoch [760/1000], Train Loss: 0.778601, Test Loss: 2.698732, LR: 0.050000\n",
      "Seed 61, Epoch [770/1000], Train Loss: 0.773030, Test Loss: 2.781561, LR: 0.050000\n",
      "Seed 61, Epoch [780/1000], Train Loss: 0.766823, Test Loss: 2.657640, LR: 0.050000\n",
      "Seed 61, Epoch [790/1000], Train Loss: 0.763379, Test Loss: 2.630397, LR: 0.050000\n",
      "Seed 61, Epoch [800/1000], Train Loss: 0.760217, Test Loss: 2.664542, LR: 0.050000\n",
      "Seed 61, Epoch [810/1000], Train Loss: 0.757050, Test Loss: 2.779640, LR: 0.050000\n",
      "Seed 61, Epoch [820/1000], Train Loss: 0.785324, Test Loss: 3.186177, LR: 0.050000\n",
      "Seed 61, Epoch [830/1000], Train Loss: 0.778358, Test Loss: 2.427598, LR: 0.050000\n",
      "Seed 61, Epoch [840/1000], Train Loss: 0.752547, Test Loss: 2.508960, LR: 0.050000\n",
      "Seed 61, Epoch [850/1000], Train Loss: 0.748684, Test Loss: 2.889207, LR: 0.050000\n",
      "Seed 61, Epoch [860/1000], Train Loss: 0.742747, Test Loss: 2.745466, LR: 0.050000\n",
      "Seed 61, Epoch [870/1000], Train Loss: 0.747430, Test Loss: 2.631052, LR: 0.050000\n",
      "Seed 61, Epoch [880/1000], Train Loss: 0.741936, Test Loss: 2.417999, LR: 0.050000\n",
      "Seed 61, Epoch [890/1000], Train Loss: 0.733926, Test Loss: 2.539628, LR: 0.050000\n",
      "Seed 61, Epoch [900/1000], Train Loss: 0.727877, Test Loss: 2.831046, LR: 0.050000\n",
      "Seed 61, Epoch [910/1000], Train Loss: 0.729635, Test Loss: 1.927344, LR: 0.050000\n",
      "Seed 61, Epoch [920/1000], Train Loss: 0.769881, Test Loss: 1.932360, LR: 0.050000\n",
      "Seed 61, Epoch [930/1000], Train Loss: 0.726519, Test Loss: 2.389733, LR: 0.050000\n",
      "Seed 61, Epoch [940/1000], Train Loss: 0.726189, Test Loss: 2.879183, LR: 0.050000\n",
      "Seed 61, Epoch [950/1000], Train Loss: 0.715275, Test Loss: 2.384336, LR: 0.050000\n",
      "Seed 61, Epoch [960/1000], Train Loss: 0.707867, Test Loss: 2.382880, LR: 0.050000\n",
      "Seed 61, Epoch [970/1000], Train Loss: 0.711551, Test Loss: 2.720461, LR: 0.050000\n",
      "Seed 61, Epoch [980/1000], Train Loss: 0.718343, Test Loss: 2.211480, LR: 0.050000\n",
      "Seed 61, Epoch [990/1000], Train Loss: 0.720469, Test Loss: 2.153494, LR: 0.050000\n",
      "Seed 61, Epoch [1000/1000], Train Loss: 0.694437, Test Loss: 2.319410, LR: 0.050000\n",
      "Seed 62, Epoch [10/1000], Train Loss: 2.261110, Test Loss: 2.045626, LR: 0.050000\n",
      "Seed 62, Epoch [20/1000], Train Loss: 2.345894, Test Loss: 2.242409, LR: 0.050000\n",
      "Seed 62, Epoch [30/1000], Train Loss: 2.450552, Test Loss: 2.342602, LR: 0.050000\n",
      "Seed 62, Epoch [40/1000], Train Loss: 2.397778, Test Loss: 2.303463, LR: 0.050000\n",
      "Seed 62, Epoch [50/1000], Train Loss: 2.314050, Test Loss: 2.244024, LR: 0.050000\n",
      "Seed 62, Epoch [60/1000], Train Loss: 2.255216, Test Loss: 2.198133, LR: 0.050000\n",
      "Seed 62, Epoch [70/1000], Train Loss: 2.202858, Test Loss: 2.151742, LR: 0.050000\n",
      "Seed 62, Epoch [80/1000], Train Loss: 2.132530, Test Loss: 2.091545, LR: 0.050000\n",
      "Seed 62, Epoch [90/1000], Train Loss: 2.053654, Test Loss: 2.005461, LR: 0.050000\n",
      "Seed 62, Epoch [100/1000], Train Loss: 1.961197, Test Loss: 1.860240, LR: 0.050000\n",
      "Seed 62, Epoch [110/1000], Train Loss: 1.788398, Test Loss: 1.588297, LR: 0.050000\n",
      "Seed 62, Epoch [120/1000], Train Loss: 1.728492, Test Loss: 1.548484, LR: 0.050000\n",
      "Seed 62, Epoch [130/1000], Train Loss: 1.562040, Test Loss: 1.524566, LR: 0.050000\n",
      "Seed 62, Epoch [140/1000], Train Loss: 1.389657, Test Loss: 2.526568, LR: 0.050000\n",
      "Seed 62, Epoch [150/1000], Train Loss: 1.364237, Test Loss: 2.290481, LR: 0.050000\n",
      "Seed 62, Epoch [160/1000], Train Loss: 1.293825, Test Loss: 3.294427, LR: 0.050000\n",
      "Seed 62, Epoch [170/1000], Train Loss: 1.240526, Test Loss: 2.441823, LR: 0.050000\n",
      "Seed 62, Epoch [180/1000], Train Loss: 1.217470, Test Loss: 2.179549, LR: 0.050000\n",
      "Seed 62, Epoch [190/1000], Train Loss: 1.174469, Test Loss: 2.636519, LR: 0.050000\n",
      "Seed 62, Epoch [200/1000], Train Loss: 1.192395, Test Loss: 1.922371, LR: 0.050000\n",
      "Seed 62, Epoch [210/1000], Train Loss: 1.120536, Test Loss: 2.421929, LR: 0.050000\n",
      "Seed 62, Epoch [220/1000], Train Loss: 1.090244, Test Loss: 1.986105, LR: 0.050000\n",
      "Seed 62, Epoch [230/1000], Train Loss: 1.189906, Test Loss: 1.593414, LR: 0.050000\n",
      "Seed 62, Epoch [240/1000], Train Loss: 1.144881, Test Loss: 1.507722, LR: 0.050000\n",
      "Seed 62, Epoch [250/1000], Train Loss: 1.077230, Test Loss: 1.577458, LR: 0.050000\n",
      "Seed 62, Epoch [260/1000], Train Loss: 1.043395, Test Loss: 1.636925, LR: 0.050000\n",
      "Seed 62, Epoch [270/1000], Train Loss: 1.021268, Test Loss: 1.558626, LR: 0.050000\n",
      "Seed 62, Epoch [280/1000], Train Loss: 0.993940, Test Loss: 1.568446, LR: 0.050000\n",
      "Seed 62, Epoch [290/1000], Train Loss: 0.969603, Test Loss: 1.537391, LR: 0.050000\n",
      "Seed 62, Epoch [300/1000], Train Loss: 0.950646, Test Loss: 1.408068, LR: 0.050000\n",
      "Seed 62, Epoch [310/1000], Train Loss: 0.936560, Test Loss: 1.337185, LR: 0.050000\n",
      "Seed 62, Epoch [320/1000], Train Loss: 0.913881, Test Loss: 1.299667, LR: 0.050000\n",
      "Seed 62, Epoch [330/1000], Train Loss: 0.910398, Test Loss: 1.175553, LR: 0.050000\n",
      "Seed 62, Epoch [340/1000], Train Loss: 0.963691, Test Loss: 1.015664, LR: 0.050000\n",
      "Seed 62, Epoch [350/1000], Train Loss: 0.899826, Test Loss: 1.060151, LR: 0.050000\n",
      "Seed 62, Epoch [360/1000], Train Loss: 0.885194, Test Loss: 1.104782, LR: 0.050000\n",
      "Seed 62, Epoch [370/1000], Train Loss: 0.866435, Test Loss: 1.125581, LR: 0.050000\n",
      "Seed 62, Epoch [380/1000], Train Loss: 0.914959, Test Loss: 1.098500, LR: 0.050000\n",
      "Seed 62, Epoch [390/1000], Train Loss: 0.852724, Test Loss: 1.138179, LR: 0.050000\n",
      "Seed 62, Epoch [400/1000], Train Loss: 0.858324, Test Loss: 1.128510, LR: 0.050000\n",
      "Seed 62, Epoch [410/1000], Train Loss: 0.845616, Test Loss: 1.057143, LR: 0.050000\n",
      "Seed 62, Epoch [420/1000], Train Loss: 0.861804, Test Loss: 1.058022, LR: 0.050000\n",
      "Seed 62, Epoch [430/1000], Train Loss: 0.849816, Test Loss: 1.134946, LR: 0.050000\n",
      "Seed 62, Epoch [440/1000], Train Loss: 0.835862, Test Loss: 1.089880, LR: 0.050000\n",
      "Seed 62, Epoch [450/1000], Train Loss: 0.848855, Test Loss: 1.267095, LR: 0.050000\n",
      "Seed 62, Epoch [460/1000], Train Loss: 1.003505, Test Loss: 1.308517, LR: 0.050000\n",
      "Seed 62, Epoch [470/1000], Train Loss: 0.890756, Test Loss: 0.958660, LR: 0.050000\n",
      "Seed 62, Epoch [480/1000], Train Loss: 0.832564, Test Loss: 1.010072, LR: 0.050000\n",
      "Seed 62, Epoch [490/1000], Train Loss: 0.820661, Test Loss: 1.009671, LR: 0.050000\n",
      "Seed 62, Epoch [500/1000], Train Loss: 0.811505, Test Loss: 1.013518, LR: 0.050000\n",
      "Seed 62, Epoch [510/1000], Train Loss: 0.805382, Test Loss: 1.047358, LR: 0.050000\n",
      "Seed 62, Epoch [520/1000], Train Loss: 0.802567, Test Loss: 1.038085, LR: 0.050000\n",
      "Seed 62, Epoch [530/1000], Train Loss: 0.798197, Test Loss: 1.053932, LR: 0.050000\n",
      "Seed 62, Epoch [540/1000], Train Loss: 0.915595, Test Loss: 1.225665, LR: 0.050000\n",
      "Seed 62, Epoch [550/1000], Train Loss: 0.855160, Test Loss: 1.124743, LR: 0.050000\n",
      "Seed 62, Epoch [560/1000], Train Loss: 0.804782, Test Loss: 1.011411, LR: 0.050000\n",
      "Seed 62, Epoch [570/1000], Train Loss: 0.794651, Test Loss: 1.012690, LR: 0.050000\n",
      "Seed 62, Epoch [580/1000], Train Loss: 0.787259, Test Loss: 1.031054, LR: 0.050000\n",
      "Seed 62, Epoch [590/1000], Train Loss: 0.895292, Test Loss: 0.943933, LR: 0.050000\n",
      "Seed 62, Epoch [600/1000], Train Loss: 0.814445, Test Loss: 1.059491, LR: 0.050000\n",
      "Seed 62, Epoch [610/1000], Train Loss: 0.809700, Test Loss: 0.932394, LR: 0.050000\n",
      "Seed 62, Epoch [620/1000], Train Loss: 0.843209, Test Loss: 1.019426, LR: 0.050000\n",
      "Seed 62, Epoch [630/1000], Train Loss: 0.799622, Test Loss: 0.946166, LR: 0.050000\n",
      "Seed 62, Epoch [640/1000], Train Loss: 0.783811, Test Loss: 1.017867, LR: 0.050000\n",
      "Seed 62, Epoch [650/1000], Train Loss: 0.870357, Test Loss: 1.112978, LR: 0.050000\n",
      "Seed 62, Epoch [660/1000], Train Loss: 0.793633, Test Loss: 0.941338, LR: 0.050000\n",
      "Seed 62, Epoch [670/1000], Train Loss: 0.803743, Test Loss: 1.053430, LR: 0.050000\n",
      "Seed 62, Epoch [680/1000], Train Loss: 0.784299, Test Loss: 0.937913, LR: 0.050000\n",
      "Seed 62, Epoch [690/1000], Train Loss: 0.778909, Test Loss: 1.039271, LR: 0.050000\n",
      "Seed 62, Epoch [700/1000], Train Loss: 0.916741, Test Loss: 1.116166, LR: 0.050000\n",
      "Seed 62, Epoch [710/1000], Train Loss: 0.811802, Test Loss: 0.981456, LR: 0.050000\n",
      "Seed 62, Epoch [720/1000], Train Loss: 0.781976, Test Loss: 0.855560, LR: 0.050000\n",
      "Seed 62, Epoch [730/1000], Train Loss: 0.837281, Test Loss: 0.858644, LR: 0.050000\n",
      "Seed 62, Epoch [740/1000], Train Loss: 0.787414, Test Loss: 0.918166, LR: 0.050000\n",
      "Seed 62, Epoch [750/1000], Train Loss: 0.771027, Test Loss: 0.958171, LR: 0.050000\n",
      "Seed 62, Epoch [760/1000], Train Loss: 0.818140, Test Loss: 1.135141, LR: 0.050000\n",
      "Seed 62, Epoch [770/1000], Train Loss: 0.807046, Test Loss: 0.886849, LR: 0.050000\n",
      "Seed 62, Epoch [780/1000], Train Loss: 0.767862, Test Loss: 0.850448, LR: 0.050000\n",
      "Seed 62, Epoch [790/1000], Train Loss: 1.006506, Test Loss: 1.075846, LR: 0.050000\n",
      "Seed 62, Epoch [800/1000], Train Loss: 0.850520, Test Loss: 0.897846, LR: 0.050000\n",
      "Seed 62, Epoch [810/1000], Train Loss: 0.795010, Test Loss: 0.791141, LR: 0.050000\n",
      "Seed 62, Epoch [820/1000], Train Loss: 0.820195, Test Loss: 0.789333, LR: 0.050000\n",
      "Seed 62, Epoch [830/1000], Train Loss: 0.811763, Test Loss: 1.010633, LR: 0.050000\n",
      "Seed 62, Epoch [840/1000], Train Loss: 0.797322, Test Loss: 0.874070, LR: 0.050000\n",
      "Seed 62, Epoch [850/1000], Train Loss: 0.797706, Test Loss: 0.819467, LR: 0.050000\n",
      "Seed 62, Epoch [860/1000], Train Loss: 0.964442, Test Loss: 0.772955, LR: 0.050000\n",
      "Seed 62, Epoch [870/1000], Train Loss: 0.818665, Test Loss: 0.852166, LR: 0.050000\n",
      "Seed 62, Epoch [880/1000], Train Loss: 0.770651, Test Loss: 0.802544, LR: 0.050000\n",
      "Seed 62, Epoch [890/1000], Train Loss: 0.762953, Test Loss: 0.802785, LR: 0.050000\n",
      "Seed 62, Epoch [900/1000], Train Loss: 0.822723, Test Loss: 0.851386, LR: 0.050000\n",
      "Seed 62, Epoch [910/1000], Train Loss: 0.878704, Test Loss: 0.866325, LR: 0.050000\n",
      "Seed 62, Epoch [920/1000], Train Loss: 0.798300, Test Loss: 0.785190, LR: 0.050000\n",
      "Seed 62, Epoch [930/1000], Train Loss: 0.781446, Test Loss: 0.849640, LR: 0.050000\n",
      "Seed 62, Epoch [940/1000], Train Loss: 0.822910, Test Loss: 0.883023, LR: 0.050000\n",
      "Seed 62, Epoch [950/1000], Train Loss: 0.791257, Test Loss: 0.781504, LR: 0.050000\n",
      "Seed 62, Epoch [960/1000], Train Loss: 0.770105, Test Loss: 0.792138, LR: 0.050000\n",
      "Seed 62, Epoch [970/1000], Train Loss: 1.059845, Test Loss: 0.971810, LR: 0.050000\n",
      "Seed 62, Epoch [980/1000], Train Loss: 0.942355, Test Loss: 0.840208, LR: 0.050000\n",
      "Seed 62, Epoch [990/1000], Train Loss: 0.826976, Test Loss: 0.770678, LR: 0.050000\n",
      "Seed 62, Epoch [1000/1000], Train Loss: 0.801406, Test Loss: 0.845319, LR: 0.050000\n",
      "Seed 63, Epoch [10/1000], Train Loss: 2.295083, Test Loss: 1.963266, LR: 0.050000\n",
      "Seed 63, Epoch [20/1000], Train Loss: 2.348587, Test Loss: 2.239255, LR: 0.050000\n",
      "Seed 63, Epoch [30/1000], Train Loss: 2.342136, Test Loss: 2.271623, LR: 0.050000\n",
      "Seed 63, Epoch [40/1000], Train Loss: 2.118908, Test Loss: 2.160021, LR: 0.050000\n",
      "Seed 63, Epoch [50/1000], Train Loss: 2.063362, Test Loss: 2.093191, LR: 0.050000\n",
      "Seed 63, Epoch [60/1000], Train Loss: 1.934204, Test Loss: 2.022289, LR: 0.050000\n",
      "Seed 63, Epoch [70/1000], Train Loss: 1.775107, Test Loss: 1.967718, LR: 0.050000\n",
      "Seed 63, Epoch [80/1000], Train Loss: 1.655109, Test Loss: 1.794873, LR: 0.050000\n",
      "Seed 63, Epoch [90/1000], Train Loss: 1.551377, Test Loss: 1.694213, LR: 0.050000\n",
      "Seed 63, Epoch [100/1000], Train Loss: 1.482472, Test Loss: 1.617319, LR: 0.050000\n",
      "Seed 63, Epoch [110/1000], Train Loss: 1.417824, Test Loss: 1.547110, LR: 0.050000\n",
      "Seed 63, Epoch [120/1000], Train Loss: 1.353574, Test Loss: 1.447235, LR: 0.050000\n",
      "Seed 63, Epoch [130/1000], Train Loss: 1.291617, Test Loss: 1.335012, LR: 0.050000\n",
      "Seed 63, Epoch [140/1000], Train Loss: 1.237545, Test Loss: 1.246122, LR: 0.050000\n",
      "Seed 63, Epoch [150/1000], Train Loss: 1.190914, Test Loss: 1.182865, LR: 0.050000\n",
      "Seed 63, Epoch [160/1000], Train Loss: 1.151676, Test Loss: 1.133383, LR: 0.050000\n",
      "Seed 63, Epoch [170/1000], Train Loss: 1.120920, Test Loss: 1.087375, LR: 0.050000\n",
      "Seed 63, Epoch [180/1000], Train Loss: 1.096541, Test Loss: 1.044018, LR: 0.050000\n",
      "Seed 63, Epoch [190/1000], Train Loss: 1.076093, Test Loss: 0.998087, LR: 0.050000\n",
      "Seed 63, Epoch [200/1000], Train Loss: 1.053290, Test Loss: 0.965634, LR: 0.050000\n",
      "Seed 63, Epoch [210/1000], Train Loss: 1.028538, Test Loss: 0.939277, LR: 0.050000\n",
      "Seed 63, Epoch [220/1000], Train Loss: 1.007897, Test Loss: 0.924697, LR: 0.050000\n",
      "Seed 63, Epoch [230/1000], Train Loss: 0.993668, Test Loss: 0.924921, LR: 0.050000\n",
      "Seed 63, Epoch [240/1000], Train Loss: 0.970493, Test Loss: 0.928080, LR: 0.050000\n",
      "Seed 63, Epoch [250/1000], Train Loss: 0.952875, Test Loss: 0.939846, LR: 0.050000\n",
      "Seed 63, Epoch [260/1000], Train Loss: 0.941175, Test Loss: 0.957617, LR: 0.050000\n",
      "Seed 63, Epoch [270/1000], Train Loss: 0.935781, Test Loss: 0.991800, LR: 0.050000\n",
      "Seed 63, Epoch [280/1000], Train Loss: 0.934300, Test Loss: 1.030190, LR: 0.050000\n",
      "Seed 63, Epoch [290/1000], Train Loss: 0.925232, Test Loss: 1.046647, LR: 0.050000\n",
      "Seed 63, Epoch [300/1000], Train Loss: 0.909271, Test Loss: 1.049606, LR: 0.050000\n",
      "Seed 63, Epoch [310/1000], Train Loss: 1.093577, Test Loss: 1.264283, LR: 0.050000\n",
      "Seed 63, Epoch [320/1000], Train Loss: 0.954815, Test Loss: 1.193941, LR: 0.050000\n",
      "Seed 63, Epoch [330/1000], Train Loss: 0.917593, Test Loss: 1.087245, LR: 0.050000\n",
      "Seed 63, Epoch [340/1000], Train Loss: 0.900835, Test Loss: 1.054095, LR: 0.050000\n",
      "Seed 63, Epoch [350/1000], Train Loss: 0.909578, Test Loss: 1.125310, LR: 0.050000\n",
      "Seed 63, Epoch [360/1000], Train Loss: 0.892277, Test Loss: 1.096498, LR: 0.050000\n",
      "Seed 63, Epoch [370/1000], Train Loss: 0.881531, Test Loss: 1.124799, LR: 0.050000\n",
      "Seed 63, Epoch [380/1000], Train Loss: 0.873134, Test Loss: 1.135002, LR: 0.050000\n",
      "Seed 63, Epoch [390/1000], Train Loss: 0.867476, Test Loss: 1.151817, LR: 0.050000\n",
      "Seed 63, Epoch [400/1000], Train Loss: 0.876362, Test Loss: 1.164418, LR: 0.050000\n",
      "Seed 63, Epoch [410/1000], Train Loss: 0.863168, Test Loss: 1.240652, LR: 0.050000\n",
      "Seed 63, Epoch [420/1000], Train Loss: 0.852552, Test Loss: 1.219972, LR: 0.050000\n",
      "Seed 63, Epoch [430/1000], Train Loss: 0.847254, Test Loss: 1.268931, LR: 0.050000\n",
      "Seed 63, Epoch [440/1000], Train Loss: 0.867539, Test Loss: 1.287858, LR: 0.050000\n",
      "Seed 63, Epoch [450/1000], Train Loss: 0.838816, Test Loss: 1.299872, LR: 0.050000\n",
      "Seed 63, Epoch [460/1000], Train Loss: 0.847112, Test Loss: 1.400405, LR: 0.050000\n",
      "Seed 63, Epoch [470/1000], Train Loss: 0.827926, Test Loss: 1.375466, LR: 0.050000\n",
      "Seed 63, Epoch [480/1000], Train Loss: 0.853704, Test Loss: 1.592521, LR: 0.050000\n",
      "Seed 63, Epoch [490/1000], Train Loss: 0.830785, Test Loss: 1.485828, LR: 0.050000\n",
      "Seed 63, Epoch [500/1000], Train Loss: 0.826248, Test Loss: 1.520626, LR: 0.050000\n",
      "Seed 63, Epoch [510/1000], Train Loss: 0.970435, Test Loss: 1.534392, LR: 0.050000\n",
      "Seed 63, Epoch [520/1000], Train Loss: 0.821967, Test Loss: 1.638826, LR: 0.050000\n",
      "Seed 63, Epoch [530/1000], Train Loss: 0.809977, Test Loss: 1.632343, LR: 0.050000\n",
      "Seed 63, Epoch [540/1000], Train Loss: 0.878020, Test Loss: 1.861129, LR: 0.050000\n",
      "Seed 63, Epoch [550/1000], Train Loss: 0.838440, Test Loss: 1.733179, LR: 0.050000\n",
      "Seed 63, Epoch [560/1000], Train Loss: 0.818169, Test Loss: 1.731482, LR: 0.050000\n",
      "Seed 63, Epoch [570/1000], Train Loss: 0.828776, Test Loss: 1.625320, LR: 0.050000\n",
      "Seed 63, Epoch [580/1000], Train Loss: 0.817449, Test Loss: 1.689832, LR: 0.050000\n",
      "Seed 63, Epoch [590/1000], Train Loss: 0.816690, Test Loss: 1.729221, LR: 0.050000\n",
      "Seed 63, Epoch [600/1000], Train Loss: 0.806472, Test Loss: 1.876010, LR: 0.050000\n",
      "Seed 63, Epoch [610/1000], Train Loss: 0.948288, Test Loss: 1.979491, LR: 0.050000\n",
      "Seed 63, Epoch [620/1000], Train Loss: 0.987230, Test Loss: 2.215087, LR: 0.050000\n",
      "Seed 63, Epoch [630/1000], Train Loss: 0.860376, Test Loss: 1.576684, LR: 0.050000\n",
      "Seed 63, Epoch [640/1000], Train Loss: 0.873899, Test Loss: 1.752476, LR: 0.050000\n",
      "Seed 63, Epoch [650/1000], Train Loss: 0.801531, Test Loss: 1.830635, LR: 0.050000\n",
      "Seed 63, Epoch [660/1000], Train Loss: 0.870860, Test Loss: 2.053422, LR: 0.050000\n",
      "Seed 63, Epoch [670/1000], Train Loss: 0.825847, Test Loss: 1.978837, LR: 0.050000\n",
      "Seed 63, Epoch [680/1000], Train Loss: 0.802862, Test Loss: 1.848239, LR: 0.050000\n",
      "Seed 63, Epoch [690/1000], Train Loss: 0.785274, Test Loss: 1.937926, LR: 0.050000\n",
      "Seed 63, Epoch [700/1000], Train Loss: 0.790908, Test Loss: 1.969954, LR: 0.050000\n",
      "Seed 63, Epoch [710/1000], Train Loss: 0.795510, Test Loss: 2.100873, LR: 0.050000\n",
      "Seed 63, Epoch [720/1000], Train Loss: 0.805545, Test Loss: 2.059156, LR: 0.050000\n",
      "Early stopping at epoch 728 for seed 63\n",
      "Seed 64, Epoch [10/1000], Train Loss: 2.132074, Test Loss: 2.001800, LR: 0.050000\n",
      "Seed 64, Epoch [20/1000], Train Loss: 2.520983, Test Loss: 2.221282, LR: 0.050000\n",
      "Seed 64, Epoch [30/1000], Train Loss: 2.434565, Test Loss: 2.154423, LR: 0.050000\n",
      "Seed 64, Epoch [40/1000], Train Loss: 2.322905, Test Loss: 2.091868, LR: 0.050000\n",
      "Seed 64, Epoch [50/1000], Train Loss: 2.253246, Test Loss: 2.041245, LR: 0.050000\n",
      "Seed 64, Epoch [60/1000], Train Loss: 2.135607, Test Loss: 1.900463, LR: 0.050000\n",
      "Seed 64, Epoch [70/1000], Train Loss: 1.945114, Test Loss: 1.657933, LR: 0.050000\n",
      "Seed 64, Epoch [80/1000], Train Loss: 1.693617, Test Loss: 1.273551, LR: 0.050000\n",
      "Seed 64, Epoch [90/1000], Train Loss: 1.456707, Test Loss: 1.854904, LR: 0.050000\n",
      "Seed 64, Epoch [100/1000], Train Loss: 1.340135, Test Loss: 1.614145, LR: 0.050000\n",
      "Seed 64, Epoch [110/1000], Train Loss: 1.263961, Test Loss: 1.314514, LR: 0.050000\n",
      "Seed 64, Epoch [120/1000], Train Loss: 1.202478, Test Loss: 1.079448, LR: 0.050000\n",
      "Seed 64, Epoch [130/1000], Train Loss: 1.144605, Test Loss: 1.066802, LR: 0.050000\n",
      "Seed 64, Epoch [140/1000], Train Loss: 1.089309, Test Loss: 1.217495, LR: 0.050000\n",
      "Seed 64, Epoch [150/1000], Train Loss: 1.023686, Test Loss: 1.352420, LR: 0.050000\n",
      "Seed 64, Epoch [160/1000], Train Loss: 0.967617, Test Loss: 1.391114, LR: 0.050000\n",
      "Seed 64, Epoch [170/1000], Train Loss: 0.995990, Test Loss: 1.445332, LR: 0.050000\n",
      "Seed 64, Epoch [180/1000], Train Loss: 0.901841, Test Loss: 1.519874, LR: 0.050000\n",
      "Seed 64, Epoch [190/1000], Train Loss: 0.860747, Test Loss: 1.540261, LR: 0.050000\n",
      "Seed 64, Epoch [200/1000], Train Loss: 0.879791, Test Loss: 1.697591, LR: 0.050000\n",
      "Seed 64, Epoch [210/1000], Train Loss: 0.842234, Test Loss: 1.655446, LR: 0.050000\n",
      "Seed 64, Epoch [220/1000], Train Loss: 0.832469, Test Loss: 1.588823, LR: 0.050000\n",
      "Seed 64, Epoch [230/1000], Train Loss: 0.855374, Test Loss: 1.773730, LR: 0.050000\n",
      "Seed 64, Epoch [240/1000], Train Loss: 0.820684, Test Loss: 1.726216, LR: 0.050000\n",
      "Seed 64, Epoch [250/1000], Train Loss: 0.790606, Test Loss: 1.685368, LR: 0.050000\n",
      "Seed 64, Epoch [260/1000], Train Loss: 0.780138, Test Loss: 1.690874, LR: 0.050000\n",
      "Seed 64, Epoch [270/1000], Train Loss: 1.121214, Test Loss: 1.744886, LR: 0.050000\n",
      "Seed 64, Epoch [280/1000], Train Loss: 0.828796, Test Loss: 1.438015, LR: 0.050000\n",
      "Seed 64, Epoch [290/1000], Train Loss: 0.788066, Test Loss: 1.434237, LR: 0.050000\n",
      "Seed 64, Epoch [300/1000], Train Loss: 0.762800, Test Loss: 1.369611, LR: 0.050000\n",
      "Seed 64, Epoch [310/1000], Train Loss: 0.745272, Test Loss: 1.359142, LR: 0.050000\n",
      "Seed 64, Epoch [320/1000], Train Loss: 0.765516, Test Loss: 1.226267, LR: 0.050000\n",
      "Seed 64, Epoch [330/1000], Train Loss: 0.763499, Test Loss: 1.196149, LR: 0.050000\n",
      "Seed 64, Epoch [340/1000], Train Loss: 0.752838, Test Loss: 1.207234, LR: 0.050000\n",
      "Seed 64, Epoch [350/1000], Train Loss: 0.732477, Test Loss: 1.134320, LR: 0.050000\n",
      "Seed 64, Epoch [360/1000], Train Loss: 0.849699, Test Loss: 1.305310, LR: 0.050000\n",
      "Seed 64, Epoch [370/1000], Train Loss: 0.746086, Test Loss: 1.028167, LR: 0.050000\n",
      "Seed 64, Epoch [380/1000], Train Loss: 0.725852, Test Loss: 1.043358, LR: 0.050000\n",
      "Seed 64, Epoch [390/1000], Train Loss: 0.705832, Test Loss: 1.023086, LR: 0.050000\n",
      "Seed 64, Epoch [400/1000], Train Loss: 0.761113, Test Loss: 1.049493, LR: 0.050000\n",
      "Seed 64, Epoch [410/1000], Train Loss: 0.790150, Test Loss: 1.011166, LR: 0.050000\n",
      "Seed 64, Epoch [420/1000], Train Loss: 0.751296, Test Loss: 0.941215, LR: 0.050000\n",
      "Seed 64, Epoch [430/1000], Train Loss: 0.710949, Test Loss: 0.963946, LR: 0.050000\n",
      "Seed 64, Epoch [440/1000], Train Loss: 0.690422, Test Loss: 0.951093, LR: 0.050000\n",
      "Seed 64, Epoch [450/1000], Train Loss: 1.012872, Test Loss: 0.978774, LR: 0.050000\n",
      "Seed 64, Epoch [460/1000], Train Loss: 0.773354, Test Loss: 1.142793, LR: 0.050000\n",
      "Seed 64, Epoch [470/1000], Train Loss: 0.728987, Test Loss: 1.026634, LR: 0.050000\n",
      "Seed 64, Epoch [480/1000], Train Loss: 0.696147, Test Loss: 0.886969, LR: 0.050000\n",
      "Seed 64, Epoch [490/1000], Train Loss: 0.686703, Test Loss: 0.945493, LR: 0.050000\n",
      "Seed 64, Epoch [500/1000], Train Loss: 0.677177, Test Loss: 0.946296, LR: 0.050000\n",
      "Seed 64, Epoch [510/1000], Train Loss: 0.785287, Test Loss: 1.005990, LR: 0.050000\n",
      "Seed 64, Epoch [520/1000], Train Loss: 0.736546, Test Loss: 0.963421, LR: 0.050000\n",
      "Seed 64, Epoch [530/1000], Train Loss: 0.683939, Test Loss: 0.921263, LR: 0.050000\n",
      "Seed 64, Epoch [540/1000], Train Loss: 0.671470, Test Loss: 0.939220, LR: 0.050000\n",
      "Seed 64, Epoch [550/1000], Train Loss: 0.682264, Test Loss: 1.026896, LR: 0.050000\n",
      "Seed 64, Epoch [560/1000], Train Loss: 0.685115, Test Loss: 0.928599, LR: 0.050000\n",
      "Seed 64, Epoch [570/1000], Train Loss: 0.676055, Test Loss: 0.889315, LR: 0.050000\n",
      "Seed 64, Epoch [580/1000], Train Loss: 0.744776, Test Loss: 1.102393, LR: 0.050000\n",
      "Seed 64, Epoch [590/1000], Train Loss: 0.710521, Test Loss: 0.919943, LR: 0.050000\n",
      "Seed 64, Epoch [600/1000], Train Loss: 0.686670, Test Loss: 0.857486, LR: 0.050000\n",
      "Seed 64, Epoch [610/1000], Train Loss: 0.675648, Test Loss: 0.927288, LR: 0.050000\n",
      "Seed 64, Epoch [620/1000], Train Loss: 1.039084, Test Loss: 1.152399, LR: 0.050000\n",
      "Seed 64, Epoch [630/1000], Train Loss: 0.727906, Test Loss: 0.815650, LR: 0.050000\n",
      "Seed 64, Epoch [640/1000], Train Loss: 0.698920, Test Loss: 0.844093, LR: 0.050000\n",
      "Seed 64, Epoch [650/1000], Train Loss: 0.683943, Test Loss: 0.844047, LR: 0.050000\n",
      "Seed 64, Epoch [660/1000], Train Loss: 0.666947, Test Loss: 0.867711, LR: 0.050000\n",
      "Seed 64, Epoch [670/1000], Train Loss: 1.020630, Test Loss: 1.044947, LR: 0.050000\n",
      "Seed 64, Epoch [680/1000], Train Loss: 0.782724, Test Loss: 0.905670, LR: 0.050000\n",
      "Seed 64, Epoch [690/1000], Train Loss: 0.703520, Test Loss: 0.816409, LR: 0.050000\n",
      "Seed 64, Epoch [700/1000], Train Loss: 0.664853, Test Loss: 0.832490, LR: 0.050000\n",
      "Seed 64, Epoch [710/1000], Train Loss: 0.658698, Test Loss: 0.842957, LR: 0.050000\n",
      "Seed 64, Epoch [720/1000], Train Loss: 0.712103, Test Loss: 0.857087, LR: 0.050000\n",
      "Seed 64, Epoch [730/1000], Train Loss: 0.698668, Test Loss: 0.808760, LR: 0.050000\n",
      "Seed 64, Epoch [740/1000], Train Loss: 0.691473, Test Loss: 0.790689, LR: 0.050000\n",
      "Seed 64, Epoch [750/1000], Train Loss: 0.688916, Test Loss: 0.848102, LR: 0.050000\n",
      "Seed 64, Epoch [760/1000], Train Loss: 0.677858, Test Loss: 0.889577, LR: 0.050000\n",
      "Seed 64, Epoch [770/1000], Train Loss: 0.717211, Test Loss: 0.843002, LR: 0.050000\n",
      "Seed 64, Epoch [780/1000], Train Loss: 0.738501, Test Loss: 0.863917, LR: 0.050000\n",
      "Seed 64, Epoch [790/1000], Train Loss: 0.675400, Test Loss: 0.824403, LR: 0.050000\n",
      "Seed 64, Epoch [800/1000], Train Loss: 0.679463, Test Loss: 0.826677, LR: 0.050000\n",
      "Seed 64, Epoch [810/1000], Train Loss: 0.659701, Test Loss: 0.833301, LR: 0.050000\n",
      "Seed 64, Epoch [820/1000], Train Loss: 0.966143, Test Loss: 0.898984, LR: 0.050000\n",
      "Seed 64, Epoch [830/1000], Train Loss: 0.806982, Test Loss: 1.291589, LR: 0.050000\n",
      "Seed 64, Epoch [840/1000], Train Loss: 0.723202, Test Loss: 0.919944, LR: 0.050000\n",
      "Seed 64, Epoch [850/1000], Train Loss: 0.670409, Test Loss: 0.800239, LR: 0.050000\n",
      "Seed 64, Epoch [860/1000], Train Loss: 0.665386, Test Loss: 0.840602, LR: 0.050000\n",
      "Seed 64, Epoch [870/1000], Train Loss: 1.648171, Test Loss: 1.751212, LR: 0.050000\n",
      "Seed 64, Epoch [880/1000], Train Loss: 1.497000, Test Loss: 1.817923, LR: 0.050000\n",
      "Seed 64, Epoch [890/1000], Train Loss: 1.190513, Test Loss: 1.756866, LR: 0.050000\n",
      "Seed 64, Epoch [900/1000], Train Loss: 0.914447, Test Loss: 1.310318, LR: 0.050000\n",
      "Seed 64, Epoch [910/1000], Train Loss: 0.767630, Test Loss: 2.788940, LR: 0.050000\n",
      "Seed 64, Epoch [920/1000], Train Loss: 0.711023, Test Loss: 2.620889, LR: 0.050000\n",
      "Seed 64, Epoch [930/1000], Train Loss: 0.675014, Test Loss: 1.761657, LR: 0.050000\n",
      "Seed 64, Epoch [940/1000], Train Loss: 1.013703, Test Loss: 2.451213, LR: 0.050000\n",
      "Seed 64, Epoch [950/1000], Train Loss: 1.233973, Test Loss: 1.000418, LR: 0.050000\n",
      "Seed 64, Epoch [960/1000], Train Loss: 0.944336, Test Loss: 0.949154, LR: 0.050000\n",
      "Seed 64, Epoch [970/1000], Train Loss: 0.830135, Test Loss: 0.962428, LR: 0.050000\n",
      "Seed 64, Epoch [980/1000], Train Loss: 0.735690, Test Loss: 1.350858, LR: 0.050000\n",
      "Seed 64, Epoch [990/1000], Train Loss: 0.716407, Test Loss: 1.777201, LR: 0.050000\n",
      "Seed 64, Epoch [1000/1000], Train Loss: 0.688982, Test Loss: 1.413047, LR: 0.050000\n",
      "Seed 65, Epoch [10/1000], Train Loss: 3.458751, Test Loss: 2.863680, LR: 0.050000\n",
      "Seed 65, Epoch [20/1000], Train Loss: 2.393082, Test Loss: 2.229374, LR: 0.050000\n",
      "Seed 65, Epoch [30/1000], Train Loss: 2.461400, Test Loss: 2.322267, LR: 0.050000\n",
      "Seed 65, Epoch [40/1000], Train Loss: 2.396137, Test Loss: 2.297644, LR: 0.050000\n",
      "Seed 65, Epoch [50/1000], Train Loss: 2.366032, Test Loss: 2.278585, LR: 0.050000\n",
      "Seed 65, Epoch [60/1000], Train Loss: 2.329987, Test Loss: 2.249807, LR: 0.050000\n",
      "Seed 65, Epoch [70/1000], Train Loss: 2.278107, Test Loss: 2.211199, LR: 0.050000\n",
      "Seed 65, Epoch [80/1000], Train Loss: 2.214689, Test Loss: 2.156459, LR: 0.050000\n",
      "Seed 65, Epoch [90/1000], Train Loss: 2.126309, Test Loss: 2.078207, LR: 0.050000\n",
      "Seed 65, Epoch [100/1000], Train Loss: 2.000623, Test Loss: 1.958621, LR: 0.050000\n",
      "Seed 65, Epoch [110/1000], Train Loss: 1.857784, Test Loss: 1.779794, LR: 0.050000\n",
      "Seed 65, Epoch [120/1000], Train Loss: 1.785761, Test Loss: 1.627597, LR: 0.050000\n",
      "Seed 65, Epoch [130/1000], Train Loss: 1.714326, Test Loss: 1.575677, LR: 0.050000\n",
      "Seed 65, Epoch [140/1000], Train Loss: 1.639941, Test Loss: 1.514075, LR: 0.050000\n",
      "Seed 65, Epoch [150/1000], Train Loss: 1.570230, Test Loss: 1.471652, LR: 0.050000\n",
      "Seed 65, Epoch [160/1000], Train Loss: 1.506779, Test Loss: 1.434404, LR: 0.050000\n",
      "Seed 65, Epoch [170/1000], Train Loss: 1.450239, Test Loss: 1.435272, LR: 0.050000\n",
      "Seed 65, Epoch [180/1000], Train Loss: 1.397750, Test Loss: 1.424101, LR: 0.050000\n",
      "Seed 65, Epoch [190/1000], Train Loss: 1.346989, Test Loss: 1.412121, LR: 0.050000\n",
      "Seed 65, Epoch [200/1000], Train Loss: 1.293286, Test Loss: 1.311609, LR: 0.050000\n",
      "Seed 65, Epoch [210/1000], Train Loss: 1.238460, Test Loss: 1.206203, LR: 0.050000\n",
      "Seed 65, Epoch [220/1000], Train Loss: 1.186828, Test Loss: 1.193506, LR: 0.050000\n",
      "Seed 65, Epoch [230/1000], Train Loss: 1.135433, Test Loss: 1.231774, LR: 0.050000\n",
      "Seed 65, Epoch [240/1000], Train Loss: 1.233166, Test Loss: 1.207003, LR: 0.050000\n",
      "Seed 65, Epoch [250/1000], Train Loss: 1.088300, Test Loss: 1.178525, LR: 0.050000\n",
      "Seed 65, Epoch [260/1000], Train Loss: 1.052692, Test Loss: 1.382000, LR: 0.050000\n",
      "Seed 65, Epoch [270/1000], Train Loss: 1.024909, Test Loss: 1.498230, LR: 0.050000\n",
      "Seed 65, Epoch [280/1000], Train Loss: 3.073707, Test Loss: 3.313005, LR: 0.050000\n",
      "Seed 65, Epoch [290/1000], Train Loss: 2.282702, Test Loss: 2.514475, LR: 0.050000\n",
      "Seed 65, Epoch [300/1000], Train Loss: 2.153572, Test Loss: 2.314136, LR: 0.050000\n",
      "Seed 65, Epoch [310/1000], Train Loss: 2.127168, Test Loss: 2.210201, LR: 0.050000\n",
      "Seed 65, Epoch [320/1000], Train Loss: 2.069206, Test Loss: 2.129171, LR: 0.050000\n",
      "Seed 65, Epoch [330/1000], Train Loss: 1.980176, Test Loss: 2.048655, LR: 0.050000\n",
      "Seed 65, Epoch [340/1000], Train Loss: 1.870605, Test Loss: 1.936540, LR: 0.050000\n",
      "Seed 65, Epoch [350/1000], Train Loss: 1.756964, Test Loss: 1.808780, LR: 0.050000\n",
      "Seed 65, Epoch [360/1000], Train Loss: 1.631442, Test Loss: 1.715124, LR: 0.050000\n",
      "Seed 65, Epoch [370/1000], Train Loss: 1.489908, Test Loss: 1.605868, LR: 0.050000\n",
      "Seed 65, Epoch [380/1000], Train Loss: 1.326103, Test Loss: 1.441833, LR: 0.050000\n",
      "Seed 65, Epoch [390/1000], Train Loss: 1.263965, Test Loss: 1.275634, LR: 0.050000\n",
      "Seed 65, Epoch [400/1000], Train Loss: 1.229461, Test Loss: 1.275671, LR: 0.050000\n",
      "Seed 65, Epoch [410/1000], Train Loss: 1.204661, Test Loss: 1.206160, LR: 0.050000\n",
      "Seed 65, Epoch [420/1000], Train Loss: 1.176980, Test Loss: 1.122021, LR: 0.050000\n",
      "Seed 65, Epoch [430/1000], Train Loss: 1.155470, Test Loss: 1.077425, LR: 0.050000\n",
      "Seed 65, Epoch [440/1000], Train Loss: 1.136836, Test Loss: 1.046351, LR: 0.050000\n",
      "Seed 65, Epoch [450/1000], Train Loss: 1.121523, Test Loss: 1.002935, LR: 0.050000\n",
      "Seed 65, Epoch [460/1000], Train Loss: 1.108046, Test Loss: 0.983944, LR: 0.050000\n",
      "Seed 65, Epoch [470/1000], Train Loss: 1.095844, Test Loss: 0.964593, LR: 0.050000\n",
      "Seed 65, Epoch [480/1000], Train Loss: 1.084608, Test Loss: 0.946342, LR: 0.050000\n",
      "Seed 65, Epoch [490/1000], Train Loss: 1.073290, Test Loss: 0.936250, LR: 0.050000\n",
      "Seed 65, Epoch [500/1000], Train Loss: 1.061530, Test Loss: 0.933652, LR: 0.050000\n",
      "Seed 65, Epoch [510/1000], Train Loss: 1.047518, Test Loss: 0.945016, LR: 0.050000\n",
      "Seed 65, Epoch [520/1000], Train Loss: 1.032445, Test Loss: 0.972030, LR: 0.050000\n",
      "Seed 65, Epoch [530/1000], Train Loss: 1.015193, Test Loss: 1.013240, LR: 0.050000\n",
      "Seed 65, Epoch [540/1000], Train Loss: 0.998255, Test Loss: 1.081246, LR: 0.050000\n",
      "Seed 65, Epoch [550/1000], Train Loss: 0.983366, Test Loss: 1.152914, LR: 0.050000\n",
      "Seed 65, Epoch [560/1000], Train Loss: 0.970467, Test Loss: 1.237998, LR: 0.050000\n",
      "Seed 65, Epoch [570/1000], Train Loss: 0.962858, Test Loss: 1.296894, LR: 0.050000\n",
      "Seed 65, Epoch [580/1000], Train Loss: 0.957885, Test Loss: 1.404835, LR: 0.050000\n",
      "Seed 65, Epoch [590/1000], Train Loss: 0.951175, Test Loss: 1.411785, LR: 0.050000\n",
      "Seed 65, Epoch [600/1000], Train Loss: 0.975535, Test Loss: 1.571435, LR: 0.050000\n",
      "Seed 65, Epoch [610/1000], Train Loss: 0.948582, Test Loss: 1.498389, LR: 0.050000\n",
      "Seed 65, Epoch [620/1000], Train Loss: 1.115842, Test Loss: 1.553241, LR: 0.050000\n",
      "Seed 65, Epoch [630/1000], Train Loss: 0.972035, Test Loss: 1.628437, LR: 0.050000\n",
      "Seed 65, Epoch [640/1000], Train Loss: 0.944598, Test Loss: 1.471820, LR: 0.050000\n",
      "Seed 65, Epoch [650/1000], Train Loss: 0.935010, Test Loss: 1.550976, LR: 0.050000\n",
      "Seed 65, Epoch [660/1000], Train Loss: 0.927184, Test Loss: 1.559335, LR: 0.050000\n",
      "Seed 65, Epoch [670/1000], Train Loss: 0.984448, Test Loss: 1.578656, LR: 0.050000\n",
      "Seed 65, Epoch [680/1000], Train Loss: 0.940712, Test Loss: 1.456414, LR: 0.050000\n",
      "Seed 65, Epoch [690/1000], Train Loss: 0.924193, Test Loss: 1.598834, LR: 0.050000\n",
      "Seed 65, Epoch [700/1000], Train Loss: 0.919205, Test Loss: 1.566331, LR: 0.050000\n",
      "Seed 65, Epoch [710/1000], Train Loss: 0.988667, Test Loss: 1.434565, LR: 0.050000\n",
      "Seed 65, Epoch [720/1000], Train Loss: 0.988486, Test Loss: 1.726664, LR: 0.050000\n",
      "Seed 65, Epoch [730/1000], Train Loss: 0.946145, Test Loss: 1.635434, LR: 0.050000\n",
      "Seed 65, Epoch [740/1000], Train Loss: 0.925596, Test Loss: 1.593898, LR: 0.050000\n",
      "Seed 65, Epoch [750/1000], Train Loss: 0.911435, Test Loss: 1.556504, LR: 0.050000\n",
      "Seed 65, Epoch [760/1000], Train Loss: 0.900634, Test Loss: 1.486228, LR: 0.050000\n",
      "Seed 65, Epoch [770/1000], Train Loss: 0.894915, Test Loss: 1.344367, LR: 0.050000\n",
      "Seed 65, Epoch [780/1000], Train Loss: 0.910314, Test Loss: 1.319253, LR: 0.050000\n",
      "Seed 65, Epoch [790/1000], Train Loss: 0.897894, Test Loss: 1.249623, LR: 0.050000\n",
      "Seed 65, Epoch [800/1000], Train Loss: 0.880036, Test Loss: 1.236630, LR: 0.050000\n",
      "Seed 65, Epoch [810/1000], Train Loss: 1.041785, Test Loss: 1.718751, LR: 0.050000\n",
      "Seed 65, Epoch [820/1000], Train Loss: 0.958463, Test Loss: 1.314321, LR: 0.050000\n",
      "Seed 65, Epoch [830/1000], Train Loss: 0.891384, Test Loss: 1.132948, LR: 0.050000\n",
      "Seed 65, Epoch [840/1000], Train Loss: 0.874098, Test Loss: 1.095044, LR: 0.050000\n",
      "Seed 65, Epoch [850/1000], Train Loss: 0.901505, Test Loss: 1.138312, LR: 0.050000\n",
      "Seed 65, Epoch [860/1000], Train Loss: 0.868032, Test Loss: 1.034839, LR: 0.050000\n",
      "Seed 65, Epoch [870/1000], Train Loss: 0.866260, Test Loss: 0.930763, LR: 0.050000\n",
      "Seed 65, Epoch [880/1000], Train Loss: 0.869037, Test Loss: 1.001409, LR: 0.050000\n",
      "Seed 65, Epoch [890/1000], Train Loss: 0.923096, Test Loss: 1.077276, LR: 0.050000\n",
      "Seed 65, Epoch [900/1000], Train Loss: 0.881420, Test Loss: 0.859235, LR: 0.050000\n",
      "Seed 65, Epoch [910/1000], Train Loss: 0.879786, Test Loss: 0.806505, LR: 0.050000\n",
      "Seed 65, Epoch [920/1000], Train Loss: 0.894645, Test Loss: 1.027768, LR: 0.050000\n",
      "Seed 65, Epoch [930/1000], Train Loss: 0.894755, Test Loss: 0.823459, LR: 0.050000\n",
      "Seed 65, Epoch [940/1000], Train Loss: 0.860431, Test Loss: 0.803302, LR: 0.050000\n",
      "Seed 65, Epoch [950/1000], Train Loss: 0.912498, Test Loss: 0.870651, LR: 0.050000\n",
      "Seed 65, Epoch [960/1000], Train Loss: 0.862231, Test Loss: 0.853489, LR: 0.050000\n",
      "Seed 65, Epoch [970/1000], Train Loss: 0.850178, Test Loss: 0.759749, LR: 0.050000\n",
      "Seed 65, Epoch [980/1000], Train Loss: 0.959290, Test Loss: 0.889962, LR: 0.050000\n",
      "Seed 65, Epoch [990/1000], Train Loss: 0.946280, Test Loss: 1.129582, LR: 0.050000\n",
      "Seed 65, Epoch [1000/1000], Train Loss: 0.879620, Test Loss: 0.736120, LR: 0.050000\n",
      "Seed 66, Epoch [10/1000], Train Loss: 2.311016, Test Loss: 2.160416, LR: 0.050000\n",
      "Seed 66, Epoch [20/1000], Train Loss: 2.394138, Test Loss: 2.410550, LR: 0.050000\n",
      "Seed 66, Epoch [30/1000], Train Loss: 2.445343, Test Loss: 2.462047, LR: 0.050000\n",
      "Seed 66, Epoch [40/1000], Train Loss: 2.312489, Test Loss: 2.356031, LR: 0.050000\n",
      "Seed 66, Epoch [50/1000], Train Loss: 2.290545, Test Loss: 2.337674, LR: 0.050000\n",
      "Seed 66, Epoch [60/1000], Train Loss: 2.247962, Test Loss: 2.298239, LR: 0.050000\n",
      "Seed 66, Epoch [70/1000], Train Loss: 2.191606, Test Loss: 2.229980, LR: 0.050000\n",
      "Seed 66, Epoch [80/1000], Train Loss: 2.162889, Test Loss: 2.167948, LR: 0.050000\n",
      "Seed 66, Epoch [90/1000], Train Loss: 2.136097, Test Loss: 2.179135, LR: 0.050000\n",
      "Seed 66, Epoch [100/1000], Train Loss: 2.114678, Test Loss: 2.194390, LR: 0.050000\n",
      "Seed 66, Epoch [110/1000], Train Loss: 2.091169, Test Loss: 2.175481, LR: 0.050000\n",
      "Seed 66, Epoch [120/1000], Train Loss: 2.065852, Test Loss: 2.178091, LR: 0.050000\n",
      "Seed 66, Epoch [130/1000], Train Loss: 2.036503, Test Loss: 2.178237, LR: 0.050000\n",
      "Seed 66, Epoch [140/1000], Train Loss: 2.001415, Test Loss: 2.172359, LR: 0.050000\n",
      "Seed 66, Epoch [150/1000], Train Loss: 1.958294, Test Loss: 2.173595, LR: 0.050000\n",
      "Seed 66, Epoch [160/1000], Train Loss: 1.903677, Test Loss: 2.171154, LR: 0.050000\n",
      "Seed 66, Epoch [170/1000], Train Loss: 1.832154, Test Loss: 2.172723, LR: 0.050000\n",
      "Seed 66, Epoch [180/1000], Train Loss: 1.776795, Test Loss: 2.157902, LR: 0.050000\n",
      "Seed 66, Epoch [190/1000], Train Loss: 1.665214, Test Loss: 2.080866, LR: 0.050000\n",
      "Seed 66, Epoch [200/1000], Train Loss: 1.704051, Test Loss: 2.160915, LR: 0.050000\n",
      "Seed 66, Epoch [210/1000], Train Loss: 1.519596, Test Loss: 2.165967, LR: 0.050000\n",
      "Seed 66, Epoch [220/1000], Train Loss: 1.485157, Test Loss: 2.156310, LR: 0.050000\n",
      "Seed 66, Epoch [230/1000], Train Loss: 1.424048, Test Loss: 2.049180, LR: 0.050000\n",
      "Seed 66, Epoch [240/1000], Train Loss: 1.383937, Test Loss: 1.973362, LR: 0.050000\n",
      "Seed 66, Epoch [250/1000], Train Loss: 1.355707, Test Loss: 1.931655, LR: 0.050000\n",
      "Seed 66, Epoch [260/1000], Train Loss: 1.336401, Test Loss: 1.910930, LR: 0.050000\n",
      "Seed 66, Epoch [270/1000], Train Loss: 1.318193, Test Loss: 1.894660, LR: 0.050000\n",
      "Seed 66, Epoch [280/1000], Train Loss: 1.302258, Test Loss: 1.869762, LR: 0.050000\n",
      "Seed 66, Epoch [290/1000], Train Loss: 1.287678, Test Loss: 1.855400, LR: 0.050000\n",
      "Seed 66, Epoch [300/1000], Train Loss: 1.273826, Test Loss: 1.838446, LR: 0.050000\n",
      "Seed 66, Epoch [310/1000], Train Loss: 1.260686, Test Loss: 1.822163, LR: 0.050000\n",
      "Seed 66, Epoch [320/1000], Train Loss: 1.248199, Test Loss: 1.811952, LR: 0.050000\n",
      "Seed 66, Epoch [330/1000], Train Loss: 1.235954, Test Loss: 1.808149, LR: 0.050000\n",
      "Seed 66, Epoch [340/1000], Train Loss: 1.223696, Test Loss: 1.807788, LR: 0.050000\n",
      "Seed 66, Epoch [350/1000], Train Loss: 1.211308, Test Loss: 1.808336, LR: 0.050000\n",
      "Seed 66, Epoch [360/1000], Train Loss: 1.198624, Test Loss: 1.808503, LR: 0.050000\n",
      "Seed 66, Epoch [370/1000], Train Loss: 1.185473, Test Loss: 1.808406, LR: 0.050000\n",
      "Seed 66, Epoch [380/1000], Train Loss: 1.171757, Test Loss: 1.809142, LR: 0.050000\n",
      "Seed 66, Epoch [390/1000], Train Loss: 1.157443, Test Loss: 1.810743, LR: 0.050000\n",
      "Seed 66, Epoch [400/1000], Train Loss: 1.142500, Test Loss: 1.813272, LR: 0.050000\n",
      "Seed 66, Epoch [410/1000], Train Loss: 1.127022, Test Loss: 1.817091, LR: 0.050000\n",
      "Seed 66, Epoch [420/1000], Train Loss: 1.111323, Test Loss: 1.822787, LR: 0.050000\n",
      "Seed 66, Epoch [430/1000], Train Loss: 1.137836, Test Loss: 1.959694, LR: 0.050000\n",
      "Seed 66, Epoch [440/1000], Train Loss: 1.372262, Test Loss: 1.851504, LR: 0.050000\n",
      "Seed 66, Epoch [450/1000], Train Loss: 1.114124, Test Loss: 1.918536, LR: 0.050000\n",
      "Seed 66, Epoch [460/1000], Train Loss: 1.136616, Test Loss: 1.870537, LR: 0.050000\n",
      "Seed 66, Epoch [470/1000], Train Loss: 1.106546, Test Loss: 1.796283, LR: 0.050000\n",
      "Seed 66, Epoch [480/1000], Train Loss: 1.050938, Test Loss: 1.940395, LR: 0.050000\n",
      "Seed 66, Epoch [490/1000], Train Loss: 1.215980, Test Loss: 2.003956, LR: 0.050000\n",
      "Seed 66, Epoch [500/1000], Train Loss: 1.069229, Test Loss: 1.863788, LR: 0.050000\n",
      "Seed 66, Epoch [510/1000], Train Loss: 1.057967, Test Loss: 1.721074, LR: 0.050000\n",
      "Seed 66, Epoch [520/1000], Train Loss: 1.007764, Test Loss: 1.837272, LR: 0.050000\n",
      "Seed 66, Epoch [530/1000], Train Loss: 1.096486, Test Loss: 1.852082, LR: 0.050000\n",
      "Seed 66, Epoch [540/1000], Train Loss: 1.014644, Test Loss: 1.771737, LR: 0.050000\n",
      "Seed 66, Epoch [550/1000], Train Loss: 0.968309, Test Loss: 1.838345, LR: 0.050000\n",
      "Seed 66, Epoch [560/1000], Train Loss: 0.987901, Test Loss: 1.798243, LR: 0.050000\n",
      "Seed 66, Epoch [570/1000], Train Loss: 0.950014, Test Loss: 1.794666, LR: 0.050000\n",
      "Seed 66, Epoch [580/1000], Train Loss: 0.956124, Test Loss: 1.724715, LR: 0.050000\n",
      "Seed 66, Epoch [590/1000], Train Loss: 0.929914, Test Loss: 1.746166, LR: 0.050000\n",
      "Seed 66, Epoch [600/1000], Train Loss: 0.921980, Test Loss: 1.692333, LR: 0.050000\n",
      "Seed 66, Epoch [610/1000], Train Loss: 0.932130, Test Loss: 1.629851, LR: 0.050000\n",
      "Seed 66, Epoch [620/1000], Train Loss: 0.924066, Test Loss: 1.675759, LR: 0.050000\n",
      "Seed 66, Epoch [630/1000], Train Loss: 0.893886, Test Loss: 1.560802, LR: 0.050000\n",
      "Seed 66, Epoch [640/1000], Train Loss: 0.881567, Test Loss: 1.480007, LR: 0.050000\n",
      "Seed 66, Epoch [650/1000], Train Loss: 0.876368, Test Loss: 1.403586, LR: 0.050000\n",
      "Seed 66, Epoch [660/1000], Train Loss: 0.872911, Test Loss: 1.402622, LR: 0.050000\n",
      "Seed 66, Epoch [670/1000], Train Loss: 0.875702, Test Loss: 1.348394, LR: 0.050000\n",
      "Seed 66, Epoch [680/1000], Train Loss: 0.859793, Test Loss: 1.254691, LR: 0.050000\n",
      "Seed 66, Epoch [690/1000], Train Loss: 0.853200, Test Loss: 1.223331, LR: 0.050000\n",
      "Seed 66, Epoch [700/1000], Train Loss: 0.847980, Test Loss: 1.204855, LR: 0.050000\n",
      "Seed 66, Epoch [710/1000], Train Loss: 0.842651, Test Loss: 1.172446, LR: 0.050000\n",
      "Seed 66, Epoch [720/1000], Train Loss: 0.833767, Test Loss: 1.173080, LR: 0.050000\n",
      "Seed 66, Epoch [730/1000], Train Loss: 0.818638, Test Loss: 1.251897, LR: 0.050000\n",
      "Seed 66, Epoch [740/1000], Train Loss: 0.847450, Test Loss: 1.394758, LR: 0.050000\n",
      "Seed 66, Epoch [750/1000], Train Loss: 0.809700, Test Loss: 1.294269, LR: 0.050000\n",
      "Seed 66, Epoch [760/1000], Train Loss: 0.794433, Test Loss: 1.320544, LR: 0.050000\n",
      "Seed 66, Epoch [770/1000], Train Loss: 0.788224, Test Loss: 1.309296, LR: 0.050000\n",
      "Seed 66, Epoch [780/1000], Train Loss: 0.813546, Test Loss: 1.416533, LR: 0.050000\n",
      "Seed 66, Epoch [790/1000], Train Loss: 0.785658, Test Loss: 1.283705, LR: 0.050000\n",
      "Seed 66, Epoch [800/1000], Train Loss: 0.773385, Test Loss: 1.212673, LR: 0.050000\n",
      "Seed 66, Epoch [810/1000], Train Loss: 0.767858, Test Loss: 1.290893, LR: 0.050000\n",
      "Seed 66, Epoch [820/1000], Train Loss: 0.764943, Test Loss: 1.282169, LR: 0.050000\n",
      "Seed 66, Epoch [830/1000], Train Loss: 0.758563, Test Loss: 1.248511, LR: 0.050000\n",
      "Seed 66, Epoch [840/1000], Train Loss: 0.755247, Test Loss: 1.205991, LR: 0.050000\n",
      "Seed 66, Epoch [850/1000], Train Loss: 0.752569, Test Loss: 1.189994, LR: 0.050000\n",
      "Seed 66, Epoch [860/1000], Train Loss: 0.754214, Test Loss: 1.160957, LR: 0.050000\n",
      "Seed 66, Epoch [870/1000], Train Loss: 0.751630, Test Loss: 1.216041, LR: 0.050000\n",
      "Seed 66, Epoch [880/1000], Train Loss: 0.744797, Test Loss: 1.170235, LR: 0.050000\n",
      "Seed 66, Epoch [890/1000], Train Loss: 0.742570, Test Loss: 1.145556, LR: 0.050000\n",
      "Seed 66, Epoch [900/1000], Train Loss: 0.767978, Test Loss: 1.109533, LR: 0.050000\n",
      "Seed 66, Epoch [910/1000], Train Loss: 0.750412, Test Loss: 1.128372, LR: 0.050000\n",
      "Seed 66, Epoch [920/1000], Train Loss: 0.739100, Test Loss: 1.122721, LR: 0.050000\n",
      "Seed 66, Epoch [930/1000], Train Loss: 0.736694, Test Loss: 1.103590, LR: 0.050000\n",
      "Seed 66, Epoch [940/1000], Train Loss: 0.734304, Test Loss: 1.126551, LR: 0.050000\n",
      "Seed 66, Epoch [950/1000], Train Loss: 0.733023, Test Loss: 1.106524, LR: 0.050000\n",
      "Seed 66, Epoch [960/1000], Train Loss: 0.738212, Test Loss: 1.223234, LR: 0.050000\n",
      "Seed 66, Epoch [970/1000], Train Loss: 0.733044, Test Loss: 1.082474, LR: 0.050000\n",
      "Seed 66, Epoch [980/1000], Train Loss: 0.730927, Test Loss: 1.085325, LR: 0.050000\n",
      "Seed 66, Epoch [990/1000], Train Loss: 0.731081, Test Loss: 1.101287, LR: 0.050000\n",
      "Seed 66, Epoch [1000/1000], Train Loss: 0.726810, Test Loss: 1.099777, LR: 0.050000\n",
      "Seed 67, Epoch [10/1000], Train Loss: 2.619728, Test Loss: 2.223066, LR: 0.050000\n",
      "Seed 67, Epoch [20/1000], Train Loss: 2.358796, Test Loss: 2.187194, LR: 0.050000\n",
      "Seed 67, Epoch [30/1000], Train Loss: 2.432178, Test Loss: 2.235899, LR: 0.050000\n",
      "Seed 67, Epoch [40/1000], Train Loss: 2.435446, Test Loss: 2.230594, LR: 0.050000\n",
      "Seed 67, Epoch [50/1000], Train Loss: 2.414593, Test Loss: 2.209253, LR: 0.050000\n",
      "Seed 67, Epoch [60/1000], Train Loss: 2.390976, Test Loss: 2.188145, LR: 0.050000\n",
      "Seed 67, Epoch [70/1000], Train Loss: 2.369545, Test Loss: 2.169226, LR: 0.050000\n",
      "Seed 67, Epoch [80/1000], Train Loss: 2.348618, Test Loss: 2.149543, LR: 0.050000\n",
      "Seed 67, Epoch [90/1000], Train Loss: 2.325739, Test Loss: 2.126549, LR: 0.050000\n",
      "Seed 67, Epoch [100/1000], Train Loss: 2.299398, Test Loss: 2.099124, LR: 0.050000\n",
      "Seed 67, Epoch [110/1000], Train Loss: 2.268930, Test Loss: 2.066808, LR: 0.050000\n",
      "Seed 67, Epoch [120/1000], Train Loss: 2.236753, Test Loss: 2.032827, LR: 0.050000\n",
      "Seed 67, Epoch [130/1000], Train Loss: 2.197678, Test Loss: 1.989659, LR: 0.050000\n",
      "Seed 67, Epoch [140/1000], Train Loss: 2.164341, Test Loss: 1.942186, LR: 0.050000\n",
      "Seed 67, Epoch [150/1000], Train Loss: 2.126220, Test Loss: 1.893020, LR: 0.050000\n",
      "Seed 67, Epoch [160/1000], Train Loss: 2.085372, Test Loss: 1.843631, LR: 0.050000\n",
      "Seed 67, Epoch [170/1000], Train Loss: 2.022854, Test Loss: 1.791832, LR: 0.050000\n",
      "Seed 67, Epoch [180/1000], Train Loss: 1.961495, Test Loss: 1.718107, LR: 0.050000\n",
      "Seed 67, Epoch [190/1000], Train Loss: 1.869263, Test Loss: 1.639611, LR: 0.050000\n",
      "Seed 67, Epoch [200/1000], Train Loss: 1.736753, Test Loss: 1.549274, LR: 0.050000\n",
      "Seed 67, Epoch [210/1000], Train Loss: 1.574363, Test Loss: 1.396053, LR: 0.050000\n",
      "Seed 67, Epoch [220/1000], Train Loss: 1.491843, Test Loss: 1.388174, LR: 0.050000\n",
      "Seed 67, Epoch [230/1000], Train Loss: 1.397517, Test Loss: 1.334949, LR: 0.050000\n",
      "Seed 67, Epoch [240/1000], Train Loss: 1.318516, Test Loss: 1.309270, LR: 0.050000\n",
      "Seed 67, Epoch [250/1000], Train Loss: 1.251600, Test Loss: 1.209688, LR: 0.050000\n",
      "Seed 67, Epoch [260/1000], Train Loss: 1.198579, Test Loss: 1.109601, LR: 0.050000\n",
      "Seed 67, Epoch [270/1000], Train Loss: 1.161198, Test Loss: 1.071665, LR: 0.050000\n",
      "Seed 67, Epoch [280/1000], Train Loss: 1.132329, Test Loss: 1.065651, LR: 0.050000\n",
      "Seed 67, Epoch [290/1000], Train Loss: 1.114160, Test Loss: 1.062219, LR: 0.050000\n",
      "Seed 67, Epoch [300/1000], Train Loss: 1.098911, Test Loss: 1.070749, LR: 0.050000\n",
      "Seed 67, Epoch [310/1000], Train Loss: 1.083038, Test Loss: 1.087277, LR: 0.050000\n",
      "Seed 67, Epoch [320/1000], Train Loss: 1.072509, Test Loss: 1.092454, LR: 0.050000\n",
      "Seed 67, Epoch [330/1000], Train Loss: 1.065860, Test Loss: 1.107300, LR: 0.050000\n",
      "Seed 67, Epoch [340/1000], Train Loss: 1.057503, Test Loss: 1.119250, LR: 0.050000\n",
      "Seed 67, Epoch [350/1000], Train Loss: 1.053173, Test Loss: 1.137726, LR: 0.050000\n",
      "Seed 67, Epoch [360/1000], Train Loss: 1.046750, Test Loss: 1.150129, LR: 0.050000\n",
      "Seed 67, Epoch [370/1000], Train Loss: 1.042511, Test Loss: 1.164863, LR: 0.050000\n",
      "Seed 67, Epoch [380/1000], Train Loss: 1.036278, Test Loss: 1.176488, LR: 0.050000\n",
      "Seed 67, Epoch [390/1000], Train Loss: 1.032434, Test Loss: 1.188247, LR: 0.050000\n",
      "Seed 67, Epoch [400/1000], Train Loss: 1.025267, Test Loss: 1.200167, LR: 0.050000\n",
      "Seed 67, Epoch [410/1000], Train Loss: 1.020283, Test Loss: 1.213018, LR: 0.050000\n",
      "Seed 67, Epoch [420/1000], Train Loss: 1.011416, Test Loss: 1.222791, LR: 0.050000\n",
      "Seed 67, Epoch [430/1000], Train Loss: 1.003886, Test Loss: 1.231675, LR: 0.050000\n",
      "Seed 67, Epoch [440/1000], Train Loss: 0.992340, Test Loss: 1.245938, LR: 0.050000\n",
      "Seed 67, Epoch [450/1000], Train Loss: 0.983743, Test Loss: 1.251194, LR: 0.050000\n",
      "Seed 67, Epoch [460/1000], Train Loss: 0.971252, Test Loss: 1.280971, LR: 0.050000\n",
      "Seed 67, Epoch [470/1000], Train Loss: 0.962348, Test Loss: 1.290542, LR: 0.050000\n",
      "Seed 67, Epoch [480/1000], Train Loss: 0.950806, Test Loss: 1.332647, LR: 0.050000\n",
      "Seed 67, Epoch [490/1000], Train Loss: 0.941825, Test Loss: 1.349530, LR: 0.050000\n",
      "Seed 67, Epoch [500/1000], Train Loss: 0.931815, Test Loss: 1.385708, LR: 0.050000\n",
      "Seed 67, Epoch [510/1000], Train Loss: 0.921627, Test Loss: 1.421327, LR: 0.050000\n",
      "Seed 67, Epoch [520/1000], Train Loss: 0.911753, Test Loss: 1.456782, LR: 0.050000\n",
      "Seed 67, Epoch [530/1000], Train Loss: 0.901691, Test Loss: 1.495856, LR: 0.050000\n",
      "Seed 67, Epoch [540/1000], Train Loss: 0.891777, Test Loss: 1.531424, LR: 0.050000\n",
      "Seed 67, Epoch [550/1000], Train Loss: 0.882220, Test Loss: 1.597417, LR: 0.050000\n",
      "Seed 67, Epoch [560/1000], Train Loss: 0.880037, Test Loss: 1.614825, LR: 0.050000\n",
      "Seed 67, Epoch [570/1000], Train Loss: 0.865826, Test Loss: 1.656747, LR: 0.050000\n",
      "Seed 67, Epoch [580/1000], Train Loss: 0.859393, Test Loss: 1.698802, LR: 0.050000\n",
      "Seed 67, Epoch [590/1000], Train Loss: 0.846191, Test Loss: 1.697947, LR: 0.050000\n",
      "Seed 67, Epoch [600/1000], Train Loss: 0.839608, Test Loss: 1.724760, LR: 0.050000\n",
      "Seed 67, Epoch [610/1000], Train Loss: 0.849776, Test Loss: 1.802402, LR: 0.050000\n",
      "Seed 67, Epoch [620/1000], Train Loss: 0.838587, Test Loss: 1.791791, LR: 0.050000\n",
      "Seed 67, Epoch [630/1000], Train Loss: 0.824780, Test Loss: 1.807104, LR: 0.050000\n",
      "Seed 67, Epoch [640/1000], Train Loss: 0.821876, Test Loss: 1.822066, LR: 0.050000\n",
      "Seed 67, Epoch [650/1000], Train Loss: 0.817279, Test Loss: 1.850157, LR: 0.050000\n",
      "Seed 67, Epoch [660/1000], Train Loss: 0.820084, Test Loss: 1.856535, LR: 0.050000\n",
      "Seed 67, Epoch [670/1000], Train Loss: 0.812168, Test Loss: 1.854559, LR: 0.050000\n",
      "Seed 67, Epoch [680/1000], Train Loss: 0.834100, Test Loss: 1.994983, LR: 0.050000\n",
      "Seed 67, Epoch [690/1000], Train Loss: 0.811061, Test Loss: 1.910591, LR: 0.050000\n",
      "Seed 67, Epoch [700/1000], Train Loss: 0.799652, Test Loss: 1.915930, LR: 0.050000\n",
      "Seed 67, Epoch [710/1000], Train Loss: 0.793055, Test Loss: 1.939806, LR: 0.050000\n",
      "Seed 67, Epoch [720/1000], Train Loss: 0.788287, Test Loss: 1.951692, LR: 0.050000\n",
      "Seed 67, Epoch [730/1000], Train Loss: 0.849212, Test Loss: 1.926805, LR: 0.050000\n",
      "Seed 67, Epoch [740/1000], Train Loss: 0.859969, Test Loss: 2.127415, LR: 0.050000\n",
      "Seed 67, Epoch [750/1000], Train Loss: 0.793008, Test Loss: 1.986029, LR: 0.050000\n",
      "Seed 67, Epoch [760/1000], Train Loss: 0.778992, Test Loss: 2.015578, LR: 0.050000\n",
      "Seed 67, Epoch [770/1000], Train Loss: 0.772141, Test Loss: 1.960734, LR: 0.050000\n",
      "Seed 67, Epoch [780/1000], Train Loss: 0.785757, Test Loss: 2.061865, LR: 0.050000\n",
      "Early stopping at epoch 783 for seed 67\n",
      "Seed 68, Epoch [10/1000], Train Loss: 2.725928, Test Loss: 1.974211, LR: 0.050000\n",
      "Seed 68, Epoch [20/1000], Train Loss: 2.144193, Test Loss: 2.139952, LR: 0.050000\n",
      "Seed 68, Epoch [30/1000], Train Loss: 2.144325, Test Loss: 2.272976, LR: 0.050000\n",
      "Seed 68, Epoch [40/1000], Train Loss: 2.159818, Test Loss: 2.318971, LR: 0.050000\n",
      "Seed 68, Epoch [50/1000], Train Loss: 2.160425, Test Loss: 2.322598, LR: 0.050000\n",
      "Seed 68, Epoch [60/1000], Train Loss: 2.152716, Test Loss: 2.308450, LR: 0.050000\n",
      "Seed 68, Epoch [70/1000], Train Loss: 2.142877, Test Loss: 2.289595, LR: 0.050000\n",
      "Seed 68, Epoch [80/1000], Train Loss: 2.133443, Test Loss: 2.271760, LR: 0.050000\n",
      "Seed 68, Epoch [90/1000], Train Loss: 2.124915, Test Loss: 2.256968, LR: 0.050000\n",
      "Seed 68, Epoch [100/1000], Train Loss: 2.116893, Test Loss: 2.245344, LR: 0.050000\n",
      "Seed 68, Epoch [110/1000], Train Loss: 2.108884, Test Loss: 2.236219, LR: 0.050000\n",
      "Seed 68, Epoch [120/1000], Train Loss: 2.100603, Test Loss: 2.228678, LR: 0.050000\n",
      "Seed 68, Epoch [130/1000], Train Loss: 2.091952, Test Loss: 2.221850, LR: 0.050000\n",
      "Seed 68, Epoch [140/1000], Train Loss: 2.082912, Test Loss: 2.215054, LR: 0.050000\n",
      "Seed 68, Epoch [150/1000], Train Loss: 2.073484, Test Loss: 2.207843, LR: 0.050000\n",
      "Seed 68, Epoch [160/1000], Train Loss: 2.063667, Test Loss: 2.199986, LR: 0.050000\n",
      "Seed 68, Epoch [170/1000], Train Loss: 2.053461, Test Loss: 2.191399, LR: 0.050000\n",
      "Seed 68, Epoch [180/1000], Train Loss: 2.042866, Test Loss: 2.182067, LR: 0.050000\n",
      "Seed 68, Epoch [190/1000], Train Loss: 2.031878, Test Loss: 2.171990, LR: 0.050000\n",
      "Seed 68, Epoch [200/1000], Train Loss: 2.020488, Test Loss: 2.161147, LR: 0.050000\n",
      "Seed 68, Epoch [210/1000], Train Loss: 2.008675, Test Loss: 2.149488, LR: 0.050000\n",
      "Seed 68, Epoch [220/1000], Train Loss: 1.996402, Test Loss: 2.136934, LR: 0.050000\n",
      "Seed 68, Epoch [230/1000], Train Loss: 1.983610, Test Loss: 2.123386, LR: 0.050000\n",
      "Seed 68, Epoch [240/1000], Train Loss: 1.970216, Test Loss: 2.108727, LR: 0.050000\n",
      "Seed 68, Epoch [250/1000], Train Loss: 1.956116, Test Loss: 2.092820, LR: 0.050000\n",
      "Seed 68, Epoch [260/1000], Train Loss: 1.941182, Test Loss: 2.075501, LR: 0.050000\n",
      "Seed 68, Epoch [270/1000], Train Loss: 1.925270, Test Loss: 2.056576, LR: 0.050000\n",
      "Seed 68, Epoch [280/1000], Train Loss: 1.908219, Test Loss: 2.035812, LR: 0.050000\n",
      "Seed 68, Epoch [290/1000], Train Loss: 1.889852, Test Loss: 2.012941, LR: 0.050000\n",
      "Seed 68, Epoch [300/1000], Train Loss: 1.869972, Test Loss: 1.987656, LR: 0.050000\n",
      "Seed 68, Epoch [310/1000], Train Loss: 1.848357, Test Loss: 1.959611, LR: 0.050000\n",
      "Seed 68, Epoch [320/1000], Train Loss: 1.824756, Test Loss: 1.928427, LR: 0.050000\n",
      "Seed 68, Epoch [330/1000], Train Loss: 1.798885, Test Loss: 1.893705, LR: 0.050000\n",
      "Seed 68, Epoch [340/1000], Train Loss: 1.770432, Test Loss: 1.855066, LR: 0.050000\n",
      "Seed 68, Epoch [350/1000], Train Loss: 1.739078, Test Loss: 1.812235, LR: 0.050000\n",
      "Seed 68, Epoch [360/1000], Train Loss: 1.704540, Test Loss: 1.765206, LR: 0.050000\n",
      "Seed 68, Epoch [370/1000], Train Loss: 1.666644, Test Loss: 1.714513, LR: 0.050000\n",
      "Seed 68, Epoch [380/1000], Train Loss: 1.625434, Test Loss: 1.661573, LR: 0.050000\n",
      "Seed 68, Epoch [390/1000], Train Loss: 1.581276, Test Loss: 1.608892, LR: 0.050000\n",
      "Seed 68, Epoch [400/1000], Train Loss: 1.535180, Test Loss: 1.559668, LR: 0.050000\n",
      "Seed 68, Epoch [410/1000], Train Loss: 1.489020, Test Loss: 1.516623, LR: 0.050000\n",
      "Seed 68, Epoch [420/1000], Train Loss: 1.443832, Test Loss: 1.479951, LR: 0.050000\n",
      "Seed 68, Epoch [430/1000], Train Loss: 1.399535, Test Loss: 1.443446, LR: 0.050000\n",
      "Seed 68, Epoch [440/1000], Train Loss: 1.355945, Test Loss: 1.401691, LR: 0.050000\n",
      "Seed 68, Epoch [450/1000], Train Loss: 1.314424, Test Loss: 1.359339, LR: 0.050000\n",
      "Seed 68, Epoch [460/1000], Train Loss: 1.276796, Test Loss: 1.345369, LR: 0.050000\n",
      "Seed 68, Epoch [470/1000], Train Loss: 1.243546, Test Loss: 1.389698, LR: 0.050000\n",
      "Seed 68, Epoch [480/1000], Train Loss: 1.214805, Test Loss: 1.488253, LR: 0.050000\n",
      "Seed 68, Epoch [490/1000], Train Loss: 1.189404, Test Loss: 1.647990, LR: 0.050000\n",
      "Seed 68, Epoch [500/1000], Train Loss: 1.167320, Test Loss: 1.865251, LR: 0.050000\n",
      "Seed 68, Epoch [510/1000], Train Loss: 1.148228, Test Loss: 2.108571, LR: 0.050000\n",
      "Seed 68, Epoch [520/1000], Train Loss: 1.131625, Test Loss: 2.358638, LR: 0.050000\n",
      "Seed 68, Epoch [530/1000], Train Loss: 1.117191, Test Loss: 2.576511, LR: 0.050000\n",
      "Seed 68, Epoch [540/1000], Train Loss: 1.104618, Test Loss: 2.734505, LR: 0.050000\n",
      "Seed 68, Epoch [550/1000], Train Loss: 1.093522, Test Loss: 2.831589, LR: 0.050000\n",
      "Seed 68, Epoch [560/1000], Train Loss: 1.083529, Test Loss: 2.874497, LR: 0.050000\n",
      "Seed 68, Epoch [570/1000], Train Loss: 1.074352, Test Loss: 2.881909, LR: 0.050000\n",
      "Seed 68, Epoch [580/1000], Train Loss: 1.065798, Test Loss: 2.866738, LR: 0.050000\n",
      "Seed 68, Epoch [590/1000], Train Loss: 1.057741, Test Loss: 2.837868, LR: 0.050000\n",
      "Seed 68, Epoch [600/1000], Train Loss: 1.050094, Test Loss: 2.798956, LR: 0.050000\n",
      "Seed 68, Epoch [610/1000], Train Loss: 1.042798, Test Loss: 2.756682, LR: 0.050000\n",
      "Seed 68, Epoch [620/1000], Train Loss: 1.035810, Test Loss: 2.713574, LR: 0.050000\n",
      "Seed 68, Epoch [630/1000], Train Loss: 1.029097, Test Loss: 2.670306, LR: 0.050000\n",
      "Seed 68, Epoch [640/1000], Train Loss: 1.022634, Test Loss: 2.629477, LR: 0.050000\n",
      "Seed 68, Epoch [650/1000], Train Loss: 1.016403, Test Loss: 2.593246, LR: 0.050000\n",
      "Seed 68, Epoch [660/1000], Train Loss: 1.010388, Test Loss: 2.561586, LR: 0.050000\n",
      "Seed 68, Epoch [670/1000], Train Loss: 1.004564, Test Loss: 2.535311, LR: 0.050000\n",
      "Seed 68, Epoch [680/1000], Train Loss: 0.998898, Test Loss: 2.517357, LR: 0.050000\n",
      "Seed 68, Epoch [690/1000], Train Loss: 0.993357, Test Loss: 2.505645, LR: 0.050000\n",
      "Seed 68, Epoch [700/1000], Train Loss: 0.987923, Test Loss: 2.499894, LR: 0.050000\n",
      "Seed 68, Epoch [710/1000], Train Loss: 0.982568, Test Loss: 2.500321, LR: 0.050000\n",
      "Seed 68, Epoch [720/1000], Train Loss: 0.977257, Test Loss: 2.508685, LR: 0.050000\n",
      "Seed 68, Epoch [730/1000], Train Loss: 0.971957, Test Loss: 2.523396, LR: 0.050000\n",
      "Seed 68, Epoch [740/1000], Train Loss: 0.966642, Test Loss: 2.539540, LR: 0.050000\n",
      "Seed 68, Epoch [750/1000], Train Loss: 0.961286, Test Loss: 2.557976, LR: 0.050000\n",
      "Seed 68, Epoch [760/1000], Train Loss: 0.955869, Test Loss: 2.575504, LR: 0.050000\n",
      "Seed 68, Epoch [770/1000], Train Loss: 0.950375, Test Loss: 2.596255, LR: 0.050000\n",
      "Seed 68, Epoch [780/1000], Train Loss: 0.944790, Test Loss: 2.619715, LR: 0.050000\n",
      "Seed 68, Epoch [790/1000], Train Loss: 0.939104, Test Loss: 2.645561, LR: 0.050000\n",
      "Seed 68, Epoch [800/1000], Train Loss: 0.933311, Test Loss: 2.673818, LR: 0.050000\n",
      "Seed 68, Epoch [810/1000], Train Loss: 0.927403, Test Loss: 2.704173, LR: 0.050000\n",
      "Seed 68, Epoch [820/1000], Train Loss: 0.921380, Test Loss: 2.737542, LR: 0.050000\n",
      "Seed 68, Epoch [830/1000], Train Loss: 0.915241, Test Loss: 2.773846, LR: 0.050000\n",
      "Seed 68, Epoch [840/1000], Train Loss: 0.908992, Test Loss: 2.813655, LR: 0.050000\n",
      "Seed 68, Epoch [850/1000], Train Loss: 0.902641, Test Loss: 2.857148, LR: 0.050000\n",
      "Seed 68, Epoch [860/1000], Train Loss: 0.896202, Test Loss: 2.904660, LR: 0.050000\n",
      "Seed 68, Epoch [870/1000], Train Loss: 0.889694, Test Loss: 2.956393, LR: 0.050000\n",
      "Seed 68, Epoch [880/1000], Train Loss: 0.883139, Test Loss: 3.011336, LR: 0.050000\n",
      "Seed 68, Epoch [890/1000], Train Loss: 0.876564, Test Loss: 3.069674, LR: 0.050000\n",
      "Seed 68, Epoch [900/1000], Train Loss: 0.870000, Test Loss: 3.130676, LR: 0.050000\n",
      "Seed 68, Epoch [910/1000], Train Loss: 0.863475, Test Loss: 3.193396, LR: 0.050000\n",
      "Seed 68, Epoch [920/1000], Train Loss: 0.857018, Test Loss: 3.256655, LR: 0.050000\n",
      "Seed 68, Epoch [930/1000], Train Loss: 0.850658, Test Loss: 3.320715, LR: 0.050000\n",
      "Seed 68, Epoch [940/1000], Train Loss: 0.844415, Test Loss: 3.383883, LR: 0.050000\n",
      "Seed 68, Epoch [950/1000], Train Loss: 0.838309, Test Loss: 3.446052, LR: 0.050000\n",
      "Early stopping at epoch 958 for seed 68\n",
      "Seed 69, Epoch [10/1000], Train Loss: 2.913340, Test Loss: 2.476760, LR: 0.050000\n",
      "Seed 69, Epoch [20/1000], Train Loss: 2.359133, Test Loss: 2.310270, LR: 0.050000\n",
      "Seed 69, Epoch [30/1000], Train Loss: 2.392705, Test Loss: 2.364726, LR: 0.050000\n",
      "Seed 69, Epoch [40/1000], Train Loss: 2.384491, Test Loss: 2.398577, LR: 0.050000\n",
      "Seed 69, Epoch [50/1000], Train Loss: 2.331192, Test Loss: 2.324708, LR: 0.050000\n",
      "Seed 69, Epoch [60/1000], Train Loss: 2.258807, Test Loss: 2.291857, LR: 0.050000\n",
      "Seed 69, Epoch [70/1000], Train Loss: 2.195243, Test Loss: 2.214237, LR: 0.050000\n",
      "Seed 69, Epoch [80/1000], Train Loss: 2.125687, Test Loss: 2.098172, LR: 0.050000\n",
      "Seed 69, Epoch [90/1000], Train Loss: 1.827903, Test Loss: 2.017358, LR: 0.050000\n",
      "Seed 69, Epoch [100/1000], Train Loss: 1.523632, Test Loss: 1.666259, LR: 0.050000\n",
      "Seed 69, Epoch [110/1000], Train Loss: 1.428554, Test Loss: 1.558946, LR: 0.050000\n",
      "Seed 69, Epoch [120/1000], Train Loss: 1.310034, Test Loss: 1.363095, LR: 0.050000\n",
      "Seed 69, Epoch [130/1000], Train Loss: 1.274359, Test Loss: 1.280021, LR: 0.050000\n",
      "Seed 69, Epoch [140/1000], Train Loss: 1.243081, Test Loss: 1.278151, LR: 0.050000\n",
      "Seed 69, Epoch [150/1000], Train Loss: 1.209305, Test Loss: 1.304880, LR: 0.050000\n",
      "Seed 69, Epoch [160/1000], Train Loss: 1.191316, Test Loss: 1.347201, LR: 0.050000\n",
      "Seed 69, Epoch [170/1000], Train Loss: 1.177067, Test Loss: 1.329699, LR: 0.050000\n",
      "Seed 69, Epoch [180/1000], Train Loss: 1.177639, Test Loss: 1.337993, LR: 0.050000\n",
      "Seed 69, Epoch [190/1000], Train Loss: 1.164301, Test Loss: 1.321170, LR: 0.050000\n",
      "Seed 69, Epoch [200/1000], Train Loss: 1.158531, Test Loss: 1.347915, LR: 0.050000\n",
      "Seed 69, Epoch [210/1000], Train Loss: 1.154553, Test Loss: 1.368966, LR: 0.050000\n",
      "Seed 69, Epoch [220/1000], Train Loss: 1.150590, Test Loss: 1.386592, LR: 0.050000\n",
      "Seed 69, Epoch [230/1000], Train Loss: 1.146839, Test Loss: 1.402623, LR: 0.050000\n",
      "Seed 69, Epoch [240/1000], Train Loss: 1.143196, Test Loss: 1.421260, LR: 0.050000\n",
      "Seed 69, Epoch [250/1000], Train Loss: 1.139526, Test Loss: 1.440806, LR: 0.050000\n",
      "Seed 69, Epoch [260/1000], Train Loss: 1.135932, Test Loss: 1.457772, LR: 0.050000\n",
      "Seed 69, Epoch [270/1000], Train Loss: 1.132448, Test Loss: 1.475963, LR: 0.050000\n",
      "Seed 69, Epoch [280/1000], Train Loss: 1.129052, Test Loss: 1.492041, LR: 0.050000\n",
      "Seed 69, Epoch [290/1000], Train Loss: 1.125658, Test Loss: 1.507019, LR: 0.050000\n",
      "Seed 69, Epoch [300/1000], Train Loss: 1.122179, Test Loss: 1.521303, LR: 0.050000\n",
      "Seed 69, Epoch [310/1000], Train Loss: 1.118556, Test Loss: 1.534993, LR: 0.050000\n",
      "Seed 69, Epoch [320/1000], Train Loss: 1.114736, Test Loss: 1.548682, LR: 0.050000\n",
      "Seed 69, Epoch [330/1000], Train Loss: 1.110680, Test Loss: 1.562093, LR: 0.050000\n",
      "Seed 69, Epoch [340/1000], Train Loss: 1.106673, Test Loss: 1.578603, LR: 0.050000\n",
      "Seed 69, Epoch [350/1000], Train Loss: 1.151439, Test Loss: 1.567637, LR: 0.050000\n",
      "Seed 69, Epoch [360/1000], Train Loss: 1.119173, Test Loss: 1.584079, LR: 0.050000\n",
      "Seed 69, Epoch [370/1000], Train Loss: 1.101391, Test Loss: 1.606027, LR: 0.050000\n",
      "Seed 69, Epoch [380/1000], Train Loss: 1.095993, Test Loss: 1.593272, LR: 0.050000\n",
      "Seed 69, Epoch [390/1000], Train Loss: 1.090045, Test Loss: 1.606898, LR: 0.050000\n",
      "Seed 69, Epoch [400/1000], Train Loss: 1.102464, Test Loss: 1.631815, LR: 0.050000\n",
      "Seed 69, Epoch [410/1000], Train Loss: 1.115975, Test Loss: 1.612129, LR: 0.050000\n",
      "Seed 69, Epoch [420/1000], Train Loss: 1.082046, Test Loss: 1.630313, LR: 0.050000\n",
      "Seed 69, Epoch [430/1000], Train Loss: 1.079204, Test Loss: 1.623560, LR: 0.050000\n",
      "Seed 69, Epoch [440/1000], Train Loss: 1.091271, Test Loss: 1.608082, LR: 0.050000\n",
      "Seed 69, Epoch [450/1000], Train Loss: 1.079342, Test Loss: 1.604890, LR: 0.050000\n",
      "Seed 69, Epoch [460/1000], Train Loss: 1.101626, Test Loss: 1.612007, LR: 0.050000\n",
      "Seed 69, Epoch [470/1000], Train Loss: 1.088026, Test Loss: 1.630605, LR: 0.050000\n",
      "Seed 69, Epoch [480/1000], Train Loss: 1.073081, Test Loss: 1.617336, LR: 0.050000\n",
      "Seed 69, Epoch [490/1000], Train Loss: 1.072859, Test Loss: 1.630495, LR: 0.050000\n",
      "Seed 69, Epoch [500/1000], Train Loss: 1.067545, Test Loss: 1.633329, LR: 0.050000\n",
      "Seed 69, Epoch [510/1000], Train Loss: 1.214106, Test Loss: 1.649467, LR: 0.050000\n",
      "Seed 69, Epoch [520/1000], Train Loss: 1.141223, Test Loss: 1.642936, LR: 0.050000\n",
      "Seed 69, Epoch [530/1000], Train Loss: 1.092677, Test Loss: 1.621313, LR: 0.050000\n",
      "Seed 69, Epoch [540/1000], Train Loss: 1.072286, Test Loss: 1.600728, LR: 0.050000\n",
      "Seed 69, Epoch [550/1000], Train Loss: 1.069014, Test Loss: 1.624201, LR: 0.050000\n",
      "Seed 69, Epoch [560/1000], Train Loss: 1.065055, Test Loss: 1.631859, LR: 0.050000\n",
      "Seed 69, Epoch [570/1000], Train Loss: 1.062290, Test Loss: 1.633950, LR: 0.050000\n",
      "Seed 69, Epoch [580/1000], Train Loss: 1.121453, Test Loss: 1.670057, LR: 0.050000\n",
      "Seed 69, Epoch [590/1000], Train Loss: 1.071960, Test Loss: 1.619880, LR: 0.050000\n",
      "Seed 69, Epoch [600/1000], Train Loss: 1.063036, Test Loss: 1.636410, LR: 0.050000\n",
      "Seed 69, Epoch [610/1000], Train Loss: 1.065627, Test Loss: 1.624497, LR: 0.050000\n",
      "Seed 69, Epoch [620/1000], Train Loss: 1.060038, Test Loss: 1.631846, LR: 0.050000\n",
      "Seed 69, Epoch [630/1000], Train Loss: 1.055464, Test Loss: 1.639821, LR: 0.050000\n",
      "Early stopping at epoch 633 for seed 69\n",
      "Seed 70, Epoch [10/1000], Train Loss: 2.266144, Test Loss: 2.163092, LR: 0.050000\n",
      "Seed 70, Epoch [20/1000], Train Loss: 2.459108, Test Loss: 2.359120, LR: 0.050000\n",
      "Seed 70, Epoch [30/1000], Train Loss: 2.317233, Test Loss: 2.239624, LR: 0.050000\n",
      "Seed 70, Epoch [40/1000], Train Loss: 2.129927, Test Loss: 2.094535, LR: 0.050000\n",
      "Seed 70, Epoch [50/1000], Train Loss: 1.749296, Test Loss: 1.912075, LR: 0.050000\n",
      "Seed 70, Epoch [60/1000], Train Loss: 1.272666, Test Loss: 1.404490, LR: 0.050000\n",
      "Seed 70, Epoch [70/1000], Train Loss: 1.098028, Test Loss: 0.975114, LR: 0.050000\n",
      "Seed 70, Epoch [80/1000], Train Loss: 1.034335, Test Loss: 1.257603, LR: 0.050000\n",
      "Seed 70, Epoch [90/1000], Train Loss: 0.994810, Test Loss: 1.560185, LR: 0.050000\n",
      "Seed 70, Epoch [100/1000], Train Loss: 0.967957, Test Loss: 1.617031, LR: 0.050000\n",
      "Seed 70, Epoch [110/1000], Train Loss: 0.998689, Test Loss: 1.936203, LR: 0.050000\n",
      "Seed 70, Epoch [120/1000], Train Loss: 0.969034, Test Loss: 1.835349, LR: 0.050000\n",
      "Seed 70, Epoch [130/1000], Train Loss: 0.914372, Test Loss: 1.871303, LR: 0.050000\n",
      "Seed 70, Epoch [140/1000], Train Loss: 0.904152, Test Loss: 1.913349, LR: 0.050000\n",
      "Seed 70, Epoch [150/1000], Train Loss: 0.920660, Test Loss: 1.871784, LR: 0.050000\n",
      "Seed 70, Epoch [160/1000], Train Loss: 0.870795, Test Loss: 1.977211, LR: 0.050000\n",
      "Seed 70, Epoch [170/1000], Train Loss: 1.036154, Test Loss: 1.913339, LR: 0.050000\n",
      "Seed 70, Epoch [180/1000], Train Loss: 0.924220, Test Loss: 1.960923, LR: 0.050000\n",
      "Seed 70, Epoch [190/1000], Train Loss: 1.033382, Test Loss: 2.008297, LR: 0.050000\n",
      "Seed 70, Epoch [200/1000], Train Loss: 0.881734, Test Loss: 1.850636, LR: 0.050000\n",
      "Seed 70, Epoch [210/1000], Train Loss: 0.849077, Test Loss: 1.931903, LR: 0.050000\n",
      "Seed 70, Epoch [220/1000], Train Loss: 0.841546, Test Loss: 2.065037, LR: 0.050000\n",
      "Seed 70, Epoch [230/1000], Train Loss: 0.813813, Test Loss: 2.023366, LR: 0.050000\n",
      "Seed 70, Epoch [240/1000], Train Loss: 0.819873, Test Loss: 2.081600, LR: 0.050000\n",
      "Seed 70, Epoch [250/1000], Train Loss: 0.805842, Test Loss: 2.111705, LR: 0.050000\n",
      "Seed 70, Epoch [260/1000], Train Loss: 0.802308, Test Loss: 2.186905, LR: 0.050000\n",
      "Seed 70, Epoch [270/1000], Train Loss: 0.790266, Test Loss: 2.196254, LR: 0.050000\n",
      "Seed 70, Epoch [280/1000], Train Loss: 0.781833, Test Loss: 2.185067, LR: 0.050000\n",
      "Seed 70, Epoch [290/1000], Train Loss: 0.778211, Test Loss: 2.165105, LR: 0.050000\n",
      "Seed 70, Epoch [300/1000], Train Loss: 0.772597, Test Loss: 2.189448, LR: 0.050000\n",
      "Seed 70, Epoch [310/1000], Train Loss: 0.788148, Test Loss: 2.128621, LR: 0.050000\n",
      "Seed 70, Epoch [320/1000], Train Loss: 0.766276, Test Loss: 2.150315, LR: 0.050000\n",
      "Seed 70, Epoch [330/1000], Train Loss: 0.773813, Test Loss: 2.149939, LR: 0.050000\n",
      "Seed 70, Epoch [340/1000], Train Loss: 0.772838, Test Loss: 2.200193, LR: 0.050000\n",
      "Seed 70, Epoch [350/1000], Train Loss: 0.755575, Test Loss: 2.170166, LR: 0.050000\n",
      "Seed 70, Epoch [360/1000], Train Loss: 0.757883, Test Loss: 2.163978, LR: 0.050000\n",
      "Seed 70, Epoch [370/1000], Train Loss: 0.755525, Test Loss: 2.200037, LR: 0.050000\n",
      "Seed 70, Epoch [380/1000], Train Loss: 0.752515, Test Loss: 2.162227, LR: 0.050000\n",
      "Seed 70, Epoch [390/1000], Train Loss: 0.751690, Test Loss: 2.251861, LR: 0.050000\n",
      "Seed 70, Epoch [400/1000], Train Loss: 0.731682, Test Loss: 2.206196, LR: 0.050000\n",
      "Seed 70, Epoch [410/1000], Train Loss: 0.744625, Test Loss: 2.151608, LR: 0.050000\n",
      "Seed 70, Epoch [420/1000], Train Loss: 0.722563, Test Loss: 2.203018, LR: 0.050000\n",
      "Seed 70, Epoch [430/1000], Train Loss: 0.732595, Test Loss: 2.285524, LR: 0.050000\n",
      "Seed 70, Epoch [440/1000], Train Loss: 0.710849, Test Loss: 2.291443, LR: 0.050000\n",
      "Seed 70, Epoch [450/1000], Train Loss: 0.724933, Test Loss: 2.258033, LR: 0.050000\n",
      "Seed 70, Epoch [460/1000], Train Loss: 0.702202, Test Loss: 2.310214, LR: 0.050000\n",
      "Seed 70, Epoch [470/1000], Train Loss: 0.712343, Test Loss: 2.426031, LR: 0.050000\n",
      "Seed 70, Epoch [480/1000], Train Loss: 0.692636, Test Loss: 2.382669, LR: 0.050000\n",
      "Seed 70, Epoch [490/1000], Train Loss: 0.705674, Test Loss: 2.342280, LR: 0.050000\n",
      "Seed 70, Epoch [500/1000], Train Loss: 0.686218, Test Loss: 2.369785, LR: 0.050000\n",
      "Seed 70, Epoch [510/1000], Train Loss: 0.698873, Test Loss: 2.470320, LR: 0.050000\n",
      "Seed 70, Epoch [520/1000], Train Loss: 0.672543, Test Loss: 2.398732, LR: 0.050000\n",
      "Seed 70, Epoch [530/1000], Train Loss: 0.698153, Test Loss: 2.318917, LR: 0.050000\n",
      "Seed 70, Epoch [540/1000], Train Loss: 0.667232, Test Loss: 2.316929, LR: 0.050000\n",
      "Seed 70, Epoch [550/1000], Train Loss: 0.684426, Test Loss: 2.482952, LR: 0.050000\n",
      "Seed 70, Epoch [560/1000], Train Loss: 0.675884, Test Loss: 2.385158, LR: 0.050000\n",
      "Early stopping at epoch 567 for seed 70\n",
      "Seed 71, Epoch [10/1000], Train Loss: 3.763460, Test Loss: 4.234522, LR: 0.050000\n",
      "Seed 71, Epoch [20/1000], Train Loss: 2.596514, Test Loss: 2.375201, LR: 0.050000\n",
      "Seed 71, Epoch [30/1000], Train Loss: 2.321406, Test Loss: 2.123288, LR: 0.050000\n",
      "Seed 71, Epoch [40/1000], Train Loss: 2.290766, Test Loss: 2.082537, LR: 0.050000\n",
      "Seed 71, Epoch [50/1000], Train Loss: 2.282392, Test Loss: 2.063923, LR: 0.050000\n",
      "Seed 71, Epoch [60/1000], Train Loss: 2.267316, Test Loss: 2.042766, LR: 0.050000\n",
      "Seed 71, Epoch [70/1000], Train Loss: 2.244164, Test Loss: 2.019460, LR: 0.050000\n",
      "Seed 71, Epoch [80/1000], Train Loss: 2.214830, Test Loss: 2.001877, LR: 0.050000\n",
      "Seed 71, Epoch [90/1000], Train Loss: 2.181898, Test Loss: 2.008171, LR: 0.050000\n",
      "Seed 71, Epoch [100/1000], Train Loss: 2.150548, Test Loss: 2.064347, LR: 0.050000\n",
      "Seed 71, Epoch [110/1000], Train Loss: 2.125103, Test Loss: 2.144909, LR: 0.050000\n",
      "Seed 71, Epoch [120/1000], Train Loss: 2.099757, Test Loss: 2.149221, LR: 0.050000\n",
      "Seed 71, Epoch [130/1000], Train Loss: 2.071885, Test Loss: 2.105890, LR: 0.050000\n",
      "Seed 71, Epoch [140/1000], Train Loss: 2.041463, Test Loss: 2.100848, LR: 0.050000\n",
      "Seed 71, Epoch [150/1000], Train Loss: 2.006817, Test Loss: 2.133394, LR: 0.050000\n",
      "Seed 71, Epoch [160/1000], Train Loss: 1.967542, Test Loss: 2.155998, LR: 0.050000\n",
      "Seed 71, Epoch [170/1000], Train Loss: 1.922972, Test Loss: 2.154315, LR: 0.050000\n",
      "Seed 71, Epoch [180/1000], Train Loss: 1.872363, Test Loss: 2.148235, LR: 0.050000\n",
      "Seed 71, Epoch [190/1000], Train Loss: 1.814462, Test Loss: 2.131357, LR: 0.050000\n",
      "Seed 71, Epoch [200/1000], Train Loss: 1.747204, Test Loss: 2.084324, LR: 0.050000\n",
      "Seed 71, Epoch [210/1000], Train Loss: 1.667760, Test Loss: 2.005892, LR: 0.050000\n",
      "Seed 71, Epoch [220/1000], Train Loss: 1.574520, Test Loss: 1.923439, LR: 0.050000\n",
      "Seed 71, Epoch [230/1000], Train Loss: 1.476957, Test Loss: 1.901838, LR: 0.050000\n",
      "Seed 71, Epoch [240/1000], Train Loss: 1.408512, Test Loss: 1.875628, LR: 0.050000\n",
      "Seed 71, Epoch [250/1000], Train Loss: 1.343247, Test Loss: 1.695833, LR: 0.050000\n",
      "Seed 71, Epoch [260/1000], Train Loss: 1.263588, Test Loss: 1.517093, LR: 0.050000\n",
      "Seed 71, Epoch [270/1000], Train Loss: 1.178317, Test Loss: 1.304208, LR: 0.050000\n",
      "Seed 71, Epoch [280/1000], Train Loss: 4.085014, Test Loss: 1.033008, LR: 0.050000\n",
      "Seed 71, Epoch [290/1000], Train Loss: 1.891635, Test Loss: 2.365271, LR: 0.050000\n",
      "Seed 71, Epoch [300/1000], Train Loss: 1.770304, Test Loss: 2.134267, LR: 0.050000\n",
      "Seed 71, Epoch [310/1000], Train Loss: 1.713574, Test Loss: 2.009128, LR: 0.050000\n",
      "Seed 71, Epoch [320/1000], Train Loss: 1.603753, Test Loss: 1.822283, LR: 0.050000\n",
      "Seed 71, Epoch [330/1000], Train Loss: 1.417693, Test Loss: 1.470258, LR: 0.050000\n",
      "Seed 71, Epoch [340/1000], Train Loss: 1.308719, Test Loss: 1.191965, LR: 0.050000\n",
      "Seed 71, Epoch [350/1000], Train Loss: 1.226937, Test Loss: 1.007481, LR: 0.050000\n",
      "Seed 71, Epoch [360/1000], Train Loss: 1.163563, Test Loss: 0.939259, LR: 0.050000\n",
      "Seed 71, Epoch [370/1000], Train Loss: 1.134904, Test Loss: 0.929211, LR: 0.050000\n",
      "Seed 71, Epoch [380/1000], Train Loss: 1.108918, Test Loss: 0.955307, LR: 0.050000\n",
      "Seed 71, Epoch [390/1000], Train Loss: 1.087951, Test Loss: 0.937228, LR: 0.050000\n",
      "Seed 71, Epoch [400/1000], Train Loss: 1.065383, Test Loss: 0.902893, LR: 0.050000\n",
      "Seed 71, Epoch [410/1000], Train Loss: 1.040021, Test Loss: 0.893757, LR: 0.050000\n",
      "Seed 71, Epoch [420/1000], Train Loss: 1.012395, Test Loss: 0.903991, LR: 0.050000\n",
      "Seed 71, Epoch [430/1000], Train Loss: 0.988046, Test Loss: 0.945850, LR: 0.050000\n",
      "Seed 71, Epoch [440/1000], Train Loss: 0.969789, Test Loss: 1.015946, LR: 0.050000\n",
      "Seed 71, Epoch [450/1000], Train Loss: 0.953769, Test Loss: 1.083475, LR: 0.050000\n",
      "Seed 71, Epoch [460/1000], Train Loss: 0.939070, Test Loss: 1.140315, LR: 0.050000\n",
      "Seed 71, Epoch [470/1000], Train Loss: 0.925456, Test Loss: 1.196289, LR: 0.050000\n",
      "Seed 71, Epoch [480/1000], Train Loss: 0.912517, Test Loss: 1.241534, LR: 0.050000\n",
      "Seed 71, Epoch [490/1000], Train Loss: 0.899920, Test Loss: 1.272094, LR: 0.050000\n",
      "Seed 71, Epoch [500/1000], Train Loss: 0.887467, Test Loss: 1.293103, LR: 0.050000\n",
      "Seed 71, Epoch [510/1000], Train Loss: 0.875117, Test Loss: 1.308669, LR: 0.050000\n",
      "Seed 71, Epoch [520/1000], Train Loss: 0.862980, Test Loss: 1.318832, LR: 0.050000\n",
      "Seed 71, Epoch [530/1000], Train Loss: 0.851235, Test Loss: 1.325002, LR: 0.050000\n",
      "Seed 71, Epoch [540/1000], Train Loss: 0.840067, Test Loss: 1.330190, LR: 0.050000\n",
      "Seed 71, Epoch [550/1000], Train Loss: 0.829622, Test Loss: 1.336356, LR: 0.050000\n",
      "Seed 71, Epoch [560/1000], Train Loss: 0.819972, Test Loss: 1.344834, LR: 0.050000\n",
      "Seed 71, Epoch [570/1000], Train Loss: 0.811111, Test Loss: 1.356310, LR: 0.050000\n",
      "Seed 71, Epoch [580/1000], Train Loss: 0.802979, Test Loss: 1.370845, LR: 0.050000\n",
      "Seed 71, Epoch [590/1000], Train Loss: 0.795487, Test Loss: 1.387972, LR: 0.050000\n",
      "Seed 71, Epoch [600/1000], Train Loss: 0.788549, Test Loss: 1.406420, LR: 0.050000\n",
      "Seed 71, Epoch [610/1000], Train Loss: 0.782311, Test Loss: 1.411108, LR: 0.050000\n",
      "Seed 71, Epoch [620/1000], Train Loss: 0.855697, Test Loss: 1.618438, LR: 0.050000\n",
      "Seed 71, Epoch [630/1000], Train Loss: 0.793168, Test Loss: 1.451834, LR: 0.050000\n",
      "Seed 71, Epoch [640/1000], Train Loss: 0.774221, Test Loss: 1.470527, LR: 0.050000\n",
      "Seed 71, Epoch [650/1000], Train Loss: 0.765167, Test Loss: 1.469909, LR: 0.050000\n",
      "Seed 71, Epoch [660/1000], Train Loss: 0.758033, Test Loss: 1.484532, LR: 0.050000\n",
      "Seed 71, Epoch [670/1000], Train Loss: 0.751622, Test Loss: 1.507308, LR: 0.050000\n",
      "Seed 71, Epoch [680/1000], Train Loss: 0.746421, Test Loss: 1.526586, LR: 0.050000\n",
      "Seed 71, Epoch [690/1000], Train Loss: 0.742073, Test Loss: 1.547554, LR: 0.050000\n",
      "Seed 71, Epoch [700/1000], Train Loss: 0.737787, Test Loss: 1.559140, LR: 0.050000\n",
      "Seed 71, Epoch [710/1000], Train Loss: 0.733751, Test Loss: 1.571490, LR: 0.050000\n",
      "Seed 71, Epoch [720/1000], Train Loss: 0.729835, Test Loss: 1.587130, LR: 0.050000\n",
      "Seed 71, Epoch [730/1000], Train Loss: 0.726026, Test Loss: 1.600890, LR: 0.050000\n",
      "Seed 71, Epoch [740/1000], Train Loss: 0.722288, Test Loss: 1.612978, LR: 0.050000\n",
      "Seed 71, Epoch [750/1000], Train Loss: 0.718613, Test Loss: 1.625093, LR: 0.050000\n",
      "Seed 71, Epoch [760/1000], Train Loss: 0.714987, Test Loss: 1.635652, LR: 0.050000\n",
      "Seed 71, Epoch [770/1000], Train Loss: 0.711489, Test Loss: 1.641929, LR: 0.050000\n",
      "Seed 71, Epoch [780/1000], Train Loss: 0.709147, Test Loss: 1.637816, LR: 0.050000\n",
      "Seed 71, Epoch [790/1000], Train Loss: 0.705074, Test Loss: 1.659352, LR: 0.050000\n",
      "Seed 71, Epoch [800/1000], Train Loss: 0.701609, Test Loss: 1.688010, LR: 0.050000\n",
      "Seed 71, Epoch [810/1000], Train Loss: 0.697412, Test Loss: 1.668810, LR: 0.050000\n",
      "Seed 71, Epoch [820/1000], Train Loss: 0.694289, Test Loss: 1.664062, LR: 0.050000\n",
      "Seed 71, Epoch [830/1000], Train Loss: 0.690937, Test Loss: 1.664753, LR: 0.050000\n",
      "Seed 71, Epoch [840/1000], Train Loss: 0.687708, Test Loss: 1.661384, LR: 0.050000\n",
      "Seed 71, Epoch [850/1000], Train Loss: 0.684692, Test Loss: 1.649970, LR: 0.050000\n",
      "Seed 71, Epoch [860/1000], Train Loss: 0.684846, Test Loss: 1.616528, LR: 0.050000\n",
      "Seed 71, Epoch [870/1000], Train Loss: 0.678361, Test Loss: 1.663220, LR: 0.050000\n",
      "Seed 71, Epoch [880/1000], Train Loss: 0.675320, Test Loss: 1.630250, LR: 0.050000\n",
      "Seed 71, Epoch [890/1000], Train Loss: 0.676110, Test Loss: 1.600600, LR: 0.050000\n",
      "Seed 71, Epoch [900/1000], Train Loss: 0.673525, Test Loss: 1.644432, LR: 0.050000\n",
      "Early stopping at epoch 905 for seed 71\n",
      "Seed 72, Epoch [10/1000], Train Loss: 2.230614, Test Loss: 2.057318, LR: 0.050000\n",
      "Seed 72, Epoch [20/1000], Train Loss: 2.351762, Test Loss: 2.225759, LR: 0.050000\n",
      "Seed 72, Epoch [30/1000], Train Loss: 2.487265, Test Loss: 2.325912, LR: 0.050000\n",
      "Seed 72, Epoch [40/1000], Train Loss: 2.460222, Test Loss: 2.303124, LR: 0.050000\n",
      "Seed 72, Epoch [50/1000], Train Loss: 2.383596, Test Loss: 2.248594, LR: 0.050000\n",
      "Seed 72, Epoch [60/1000], Train Loss: 2.317345, Test Loss: 2.199839, LR: 0.050000\n",
      "Seed 72, Epoch [70/1000], Train Loss: 2.284852, Test Loss: 2.165779, LR: 0.050000\n",
      "Seed 72, Epoch [80/1000], Train Loss: 2.243989, Test Loss: 2.146430, LR: 0.050000\n",
      "Seed 72, Epoch [90/1000], Train Loss: 2.192736, Test Loss: 2.126649, LR: 0.050000\n",
      "Seed 72, Epoch [100/1000], Train Loss: 2.131149, Test Loss: 2.094670, LR: 0.050000\n",
      "Seed 72, Epoch [110/1000], Train Loss: 2.055903, Test Loss: 2.049850, LR: 0.050000\n",
      "Seed 72, Epoch [120/1000], Train Loss: 1.960551, Test Loss: 1.984381, LR: 0.050000\n",
      "Seed 72, Epoch [130/1000], Train Loss: 1.829607, Test Loss: 1.866897, LR: 0.050000\n",
      "Seed 72, Epoch [140/1000], Train Loss: 1.645361, Test Loss: 1.716101, LR: 0.050000\n",
      "Seed 72, Epoch [150/1000], Train Loss: 1.405837, Test Loss: 1.452250, LR: 0.050000\n",
      "Seed 72, Epoch [160/1000], Train Loss: 1.151690, Test Loss: 1.183288, LR: 0.050000\n",
      "Seed 72, Epoch [170/1000], Train Loss: 1.142924, Test Loss: 1.293403, LR: 0.050000\n",
      "Seed 72, Epoch [180/1000], Train Loss: 1.115092, Test Loss: 1.295374, LR: 0.050000\n",
      "Seed 72, Epoch [190/1000], Train Loss: 1.093792, Test Loss: 1.380787, LR: 0.050000\n",
      "Seed 72, Epoch [200/1000], Train Loss: 1.073773, Test Loss: 1.583640, LR: 0.050000\n",
      "Seed 72, Epoch [210/1000], Train Loss: 1.052121, Test Loss: 1.853847, LR: 0.050000\n",
      "Seed 72, Epoch [220/1000], Train Loss: 1.034340, Test Loss: 2.160337, LR: 0.050000\n",
      "Seed 72, Epoch [230/1000], Train Loss: 1.351487, Test Loss: 2.002967, LR: 0.050000\n",
      "Seed 72, Epoch [240/1000], Train Loss: 1.192015, Test Loss: 1.612381, LR: 0.050000\n",
      "Seed 72, Epoch [250/1000], Train Loss: 1.063925, Test Loss: 1.826499, LR: 0.050000\n",
      "Seed 72, Epoch [260/1000], Train Loss: 1.036017, Test Loss: 1.742642, LR: 0.050000\n",
      "Seed 72, Epoch [270/1000], Train Loss: 1.006483, Test Loss: 2.034298, LR: 0.050000\n",
      "Seed 72, Epoch [280/1000], Train Loss: 0.986625, Test Loss: 2.604383, LR: 0.050000\n",
      "Seed 72, Epoch [290/1000], Train Loss: 0.973725, Test Loss: 3.347760, LR: 0.050000\n",
      "Seed 72, Epoch [300/1000], Train Loss: 0.968407, Test Loss: 3.594061, LR: 0.050000\n",
      "Seed 72, Epoch [310/1000], Train Loss: 0.994318, Test Loss: 3.054458, LR: 0.050000\n",
      "Seed 72, Epoch [320/1000], Train Loss: 0.962821, Test Loss: 3.525148, LR: 0.050000\n",
      "Seed 72, Epoch [330/1000], Train Loss: 0.939809, Test Loss: 3.664644, LR: 0.050000\n",
      "Seed 72, Epoch [340/1000], Train Loss: 0.930360, Test Loss: 4.256574, LR: 0.050000\n",
      "Seed 72, Epoch [350/1000], Train Loss: 0.938518, Test Loss: 5.307510, LR: 0.050000\n",
      "Seed 72, Epoch [360/1000], Train Loss: 1.162270, Test Loss: 1.948219, LR: 0.050000\n",
      "Seed 72, Epoch [370/1000], Train Loss: 1.040928, Test Loss: 2.143781, LR: 0.050000\n",
      "Seed 72, Epoch [380/1000], Train Loss: 0.968318, Test Loss: 2.590016, LR: 0.050000\n",
      "Seed 72, Epoch [390/1000], Train Loss: 0.929335, Test Loss: 2.576437, LR: 0.050000\n",
      "Seed 72, Epoch [400/1000], Train Loss: 0.907865, Test Loss: 3.382272, LR: 0.050000\n",
      "Seed 72, Epoch [410/1000], Train Loss: 0.901253, Test Loss: 3.836185, LR: 0.050000\n",
      "Seed 72, Epoch [420/1000], Train Loss: 0.893968, Test Loss: 3.879098, LR: 0.050000\n",
      "Seed 72, Epoch [430/1000], Train Loss: 0.888666, Test Loss: 3.935324, LR: 0.050000\n",
      "Seed 72, Epoch [440/1000], Train Loss: 0.884495, Test Loss: 3.843838, LR: 0.050000\n",
      "Seed 72, Epoch [450/1000], Train Loss: 0.880678, Test Loss: 3.703524, LR: 0.050000\n",
      "Seed 72, Epoch [460/1000], Train Loss: 0.876993, Test Loss: 3.567395, LR: 0.050000\n",
      "Seed 72, Epoch [470/1000], Train Loss: 0.873459, Test Loss: 3.412842, LR: 0.050000\n",
      "Seed 72, Epoch [480/1000], Train Loss: 0.870110, Test Loss: 3.269132, LR: 0.050000\n",
      "Seed 72, Epoch [490/1000], Train Loss: 0.866957, Test Loss: 3.139010, LR: 0.050000\n",
      "Seed 72, Epoch [500/1000], Train Loss: 0.863999, Test Loss: 3.024766, LR: 0.050000\n",
      "Seed 72, Epoch [510/1000], Train Loss: 0.861221, Test Loss: 2.927263, LR: 0.050000\n",
      "Seed 72, Epoch [520/1000], Train Loss: 0.858615, Test Loss: 2.838894, LR: 0.050000\n",
      "Seed 72, Epoch [530/1000], Train Loss: 0.862308, Test Loss: 2.672728, LR: 0.050000\n",
      "Seed 72, Epoch [540/1000], Train Loss: 0.859674, Test Loss: 2.579283, LR: 0.050000\n",
      "Seed 72, Epoch [550/1000], Train Loss: 0.856648, Test Loss: 2.590461, LR: 0.050000\n",
      "Seed 72, Epoch [560/1000], Train Loss: 0.850683, Test Loss: 2.591664, LR: 0.050000\n",
      "Seed 72, Epoch [570/1000], Train Loss: 0.848265, Test Loss: 2.596602, LR: 0.050000\n",
      "Seed 72, Epoch [580/1000], Train Loss: 0.861832, Test Loss: 2.615753, LR: 0.050000\n",
      "Seed 72, Epoch [590/1000], Train Loss: 0.842990, Test Loss: 2.505869, LR: 0.050000\n",
      "Seed 72, Epoch [600/1000], Train Loss: 0.841094, Test Loss: 2.411598, LR: 0.050000\n",
      "Seed 72, Epoch [610/1000], Train Loss: 0.842294, Test Loss: 2.502504, LR: 0.050000\n",
      "Seed 72, Epoch [620/1000], Train Loss: 0.845114, Test Loss: 2.361148, LR: 0.050000\n",
      "Seed 72, Epoch [630/1000], Train Loss: 0.851891, Test Loss: 2.479381, LR: 0.050000\n",
      "Seed 72, Epoch [640/1000], Train Loss: 0.835208, Test Loss: 2.432052, LR: 0.050000\n",
      "Seed 72, Epoch [650/1000], Train Loss: 0.831099, Test Loss: 2.338755, LR: 0.050000\n",
      "Seed 72, Epoch [660/1000], Train Loss: 0.827754, Test Loss: 2.383550, LR: 0.050000\n",
      "Seed 72, Epoch [670/1000], Train Loss: 0.856636, Test Loss: 2.525166, LR: 0.050000\n",
      "Seed 72, Epoch [680/1000], Train Loss: 0.832907, Test Loss: 2.308201, LR: 0.050000\n",
      "Seed 72, Epoch [690/1000], Train Loss: 0.823996, Test Loss: 2.276833, LR: 0.050000\n",
      "Seed 72, Epoch [700/1000], Train Loss: 0.820831, Test Loss: 2.353328, LR: 0.050000\n",
      "Seed 72, Epoch [710/1000], Train Loss: 0.824330, Test Loss: 2.387049, LR: 0.050000\n",
      "Seed 72, Epoch [720/1000], Train Loss: 0.842362, Test Loss: 2.227654, LR: 0.050000\n",
      "Early stopping at epoch 726 for seed 72\n",
      "Seed 73, Epoch [10/1000], Train Loss: 4.335617, Test Loss: 3.776067, LR: 0.050000\n",
      "Seed 73, Epoch [20/1000], Train Loss: 2.843309, Test Loss: 2.583054, LR: 0.050000\n",
      "Seed 73, Epoch [30/1000], Train Loss: 2.382553, Test Loss: 2.235602, LR: 0.050000\n",
      "Seed 73, Epoch [40/1000], Train Loss: 2.317334, Test Loss: 2.149318, LR: 0.050000\n",
      "Seed 73, Epoch [50/1000], Train Loss: 2.318149, Test Loss: 2.136442, LR: 0.050000\n",
      "Seed 73, Epoch [60/1000], Train Loss: 2.304560, Test Loss: 2.116290, LR: 0.050000\n",
      "Seed 73, Epoch [70/1000], Train Loss: 2.279252, Test Loss: 2.089986, LR: 0.050000\n",
      "Seed 73, Epoch [80/1000], Train Loss: 2.251458, Test Loss: 2.060503, LR: 0.050000\n",
      "Seed 73, Epoch [90/1000], Train Loss: 2.218366, Test Loss: 2.020262, LR: 0.050000\n",
      "Seed 73, Epoch [100/1000], Train Loss: 2.176705, Test Loss: 1.964489, LR: 0.050000\n",
      "Seed 73, Epoch [110/1000], Train Loss: 2.124949, Test Loss: 1.890914, LR: 0.050000\n",
      "Seed 73, Epoch [120/1000], Train Loss: 2.057751, Test Loss: 1.793458, LR: 0.050000\n",
      "Seed 73, Epoch [130/1000], Train Loss: 1.966533, Test Loss: 1.675006, LR: 0.050000\n",
      "Seed 73, Epoch [140/1000], Train Loss: 1.878286, Test Loss: 1.630041, LR: 0.050000\n",
      "Seed 73, Epoch [150/1000], Train Loss: 1.815179, Test Loss: 1.630295, LR: 0.050000\n",
      "Seed 73, Epoch [160/1000], Train Loss: 1.742985, Test Loss: 1.580110, LR: 0.050000\n",
      "Seed 73, Epoch [170/1000], Train Loss: 1.671231, Test Loss: 1.555912, LR: 0.050000\n",
      "Seed 73, Epoch [180/1000], Train Loss: 1.597347, Test Loss: 1.523141, LR: 0.050000\n",
      "Seed 73, Epoch [190/1000], Train Loss: 1.523797, Test Loss: 1.461998, LR: 0.050000\n",
      "Seed 73, Epoch [200/1000], Train Loss: 1.442496, Test Loss: 1.415252, LR: 0.050000\n",
      "Seed 73, Epoch [210/1000], Train Loss: 1.371257, Test Loss: 1.393475, LR: 0.050000\n",
      "Seed 73, Epoch [220/1000], Train Loss: 1.303939, Test Loss: 1.337085, LR: 0.050000\n",
      "Seed 73, Epoch [230/1000], Train Loss: 1.263611, Test Loss: 1.262990, LR: 0.050000\n",
      "Seed 73, Epoch [240/1000], Train Loss: 1.230974, Test Loss: 1.192131, LR: 0.050000\n",
      "Seed 73, Epoch [250/1000], Train Loss: 1.201367, Test Loss: 1.155693, LR: 0.050000\n",
      "Seed 73, Epoch [260/1000], Train Loss: 1.171999, Test Loss: 1.136916, LR: 0.050000\n",
      "Seed 73, Epoch [270/1000], Train Loss: 1.140787, Test Loss: 1.162814, LR: 0.050000\n",
      "Seed 73, Epoch [280/1000], Train Loss: 1.115794, Test Loss: 1.220661, LR: 0.050000\n",
      "Seed 73, Epoch [290/1000], Train Loss: 1.117636, Test Loss: 1.175773, LR: 0.050000\n",
      "Seed 73, Epoch [300/1000], Train Loss: 1.079625, Test Loss: 1.364423, LR: 0.050000\n",
      "Seed 73, Epoch [310/1000], Train Loss: 1.052755, Test Loss: 1.492405, LR: 0.050000\n",
      "Seed 73, Epoch [320/1000], Train Loss: 1.038411, Test Loss: 1.652410, LR: 0.050000\n",
      "Seed 73, Epoch [330/1000], Train Loss: 1.068158, Test Loss: 1.480462, LR: 0.050000\n",
      "Seed 73, Epoch [340/1000], Train Loss: 1.015388, Test Loss: 1.485684, LR: 0.050000\n",
      "Seed 73, Epoch [350/1000], Train Loss: 1.078195, Test Loss: 1.070185, LR: 0.050000\n",
      "Seed 73, Epoch [360/1000], Train Loss: 1.096624, Test Loss: 1.213229, LR: 0.050000\n",
      "Seed 73, Epoch [370/1000], Train Loss: 1.022956, Test Loss: 1.211084, LR: 0.050000\n",
      "Seed 73, Epoch [380/1000], Train Loss: 0.995833, Test Loss: 1.237812, LR: 0.050000\n",
      "Seed 73, Epoch [390/1000], Train Loss: 0.985178, Test Loss: 1.305864, LR: 0.050000\n",
      "Seed 73, Epoch [400/1000], Train Loss: 0.971271, Test Loss: 1.472681, LR: 0.050000\n",
      "Seed 73, Epoch [410/1000], Train Loss: 0.963343, Test Loss: 1.897136, LR: 0.050000\n",
      "Seed 73, Epoch [420/1000], Train Loss: 1.059903, Test Loss: 1.440246, LR: 0.050000\n",
      "Seed 73, Epoch [430/1000], Train Loss: 0.987614, Test Loss: 1.411245, LR: 0.050000\n",
      "Seed 73, Epoch [440/1000], Train Loss: 0.972868, Test Loss: 1.490943, LR: 0.050000\n",
      "Seed 73, Epoch [450/1000], Train Loss: 0.962362, Test Loss: 1.521690, LR: 0.050000\n",
      "Seed 73, Epoch [460/1000], Train Loss: 0.950492, Test Loss: 1.593297, LR: 0.050000\n",
      "Seed 73, Epoch [470/1000], Train Loss: 0.944125, Test Loss: 1.671592, LR: 0.050000\n",
      "Seed 73, Epoch [480/1000], Train Loss: 0.942480, Test Loss: 1.654887, LR: 0.050000\n",
      "Seed 73, Epoch [490/1000], Train Loss: 0.934117, Test Loss: 1.893846, LR: 0.050000\n",
      "Seed 73, Epoch [500/1000], Train Loss: 0.944731, Test Loss: 1.778841, LR: 0.050000\n",
      "Seed 73, Epoch [510/1000], Train Loss: 0.937675, Test Loss: 2.035224, LR: 0.050000\n",
      "Seed 73, Epoch [520/1000], Train Loss: 0.957292, Test Loss: 2.006551, LR: 0.050000\n",
      "Seed 73, Epoch [530/1000], Train Loss: 0.946831, Test Loss: 1.821635, LR: 0.050000\n",
      "Seed 73, Epoch [540/1000], Train Loss: 1.005107, Test Loss: 1.805229, LR: 0.050000\n",
      "Seed 73, Epoch [550/1000], Train Loss: 0.942420, Test Loss: 1.824547, LR: 0.050000\n",
      "Seed 73, Epoch [560/1000], Train Loss: 0.929483, Test Loss: 1.812477, LR: 0.050000\n",
      "Seed 73, Epoch [570/1000], Train Loss: 0.922047, Test Loss: 1.851952, LR: 0.050000\n",
      "Seed 73, Epoch [580/1000], Train Loss: 0.920592, Test Loss: 2.087872, LR: 0.050000\n",
      "Seed 73, Epoch [590/1000], Train Loss: 0.997470, Test Loss: 1.952141, LR: 0.050000\n",
      "Seed 73, Epoch [600/1000], Train Loss: 0.939685, Test Loss: 1.875149, LR: 0.050000\n",
      "Seed 73, Epoch [610/1000], Train Loss: 0.936953, Test Loss: 1.777454, LR: 0.050000\n",
      "Seed 73, Epoch [620/1000], Train Loss: 0.928197, Test Loss: 1.797260, LR: 0.050000\n",
      "Seed 73, Epoch [630/1000], Train Loss: 0.956631, Test Loss: 1.637991, LR: 0.050000\n",
      "Seed 73, Epoch [640/1000], Train Loss: 0.929021, Test Loss: 1.707476, LR: 0.050000\n",
      "Seed 73, Epoch [650/1000], Train Loss: 0.969884, Test Loss: 1.832779, LR: 0.050000\n",
      "Seed 73, Epoch [660/1000], Train Loss: 0.933255, Test Loss: 1.751693, LR: 0.050000\n",
      "Seed 73, Epoch [670/1000], Train Loss: 0.921637, Test Loss: 1.840289, LR: 0.050000\n",
      "Seed 73, Epoch [680/1000], Train Loss: 0.961777, Test Loss: 1.636175, LR: 0.050000\n",
      "Seed 73, Epoch [690/1000], Train Loss: 0.979894, Test Loss: 1.716298, LR: 0.050000\n",
      "Seed 73, Epoch [700/1000], Train Loss: 0.937066, Test Loss: 1.540921, LR: 0.050000\n",
      "Seed 73, Epoch [710/1000], Train Loss: 0.924896, Test Loss: 1.697250, LR: 0.050000\n",
      "Seed 73, Epoch [720/1000], Train Loss: 0.917155, Test Loss: 1.695020, LR: 0.050000\n",
      "Seed 73, Epoch [730/1000], Train Loss: 1.097281, Test Loss: 1.448283, LR: 0.050000\n",
      "Seed 73, Epoch [740/1000], Train Loss: 0.953907, Test Loss: 1.725616, LR: 0.050000\n",
      "Seed 73, Epoch [750/1000], Train Loss: 0.938073, Test Loss: 1.543335, LR: 0.050000\n",
      "Seed 73, Epoch [760/1000], Train Loss: 0.918292, Test Loss: 1.581525, LR: 0.050000\n",
      "Seed 73, Epoch [770/1000], Train Loss: 0.944782, Test Loss: 1.806933, LR: 0.050000\n",
      "Seed 73, Epoch [780/1000], Train Loss: 0.933002, Test Loss: 1.556471, LR: 0.050000\n",
      "Seed 73, Epoch [790/1000], Train Loss: 0.916198, Test Loss: 1.616414, LR: 0.050000\n",
      "Seed 73, Epoch [800/1000], Train Loss: 0.908966, Test Loss: 1.543867, LR: 0.050000\n",
      "Seed 73, Epoch [810/1000], Train Loss: 0.992874, Test Loss: 1.435594, LR: 0.050000\n",
      "Seed 73, Epoch [820/1000], Train Loss: 0.944874, Test Loss: 1.679976, LR: 0.050000\n",
      "Seed 73, Epoch [830/1000], Train Loss: 0.928977, Test Loss: 1.658528, LR: 0.050000\n",
      "Seed 73, Epoch [840/1000], Train Loss: 0.931469, Test Loss: 1.434206, LR: 0.050000\n",
      "Early stopping at epoch 846 for seed 73\n",
      "Seed 74, Epoch [10/1000], Train Loss: 2.300337, Test Loss: 2.225380, LR: 0.050000\n",
      "Seed 74, Epoch [20/1000], Train Loss: 2.443331, Test Loss: 2.313481, LR: 0.050000\n",
      "Seed 74, Epoch [30/1000], Train Loss: 2.157983, Test Loss: 2.044018, LR: 0.050000\n",
      "Seed 74, Epoch [40/1000], Train Loss: 1.847498, Test Loss: 1.793836, LR: 0.050000\n",
      "Seed 74, Epoch [50/1000], Train Loss: 1.770914, Test Loss: 1.759179, LR: 0.050000\n",
      "Seed 74, Epoch [60/1000], Train Loss: 1.546767, Test Loss: 1.436413, LR: 0.050000\n",
      "Seed 74, Epoch [70/1000], Train Loss: 1.323550, Test Loss: 1.077621, LR: 0.050000\n",
      "Seed 74, Epoch [80/1000], Train Loss: 1.226170, Test Loss: 1.097764, LR: 0.050000\n",
      "Seed 74, Epoch [90/1000], Train Loss: 1.179968, Test Loss: 1.026640, LR: 0.050000\n",
      "Seed 74, Epoch [100/1000], Train Loss: 1.105581, Test Loss: 1.182783, LR: 0.050000\n",
      "Seed 74, Epoch [110/1000], Train Loss: 1.141116, Test Loss: 1.441314, LR: 0.050000\n",
      "Seed 74, Epoch [120/1000], Train Loss: 1.025486, Test Loss: 1.334628, LR: 0.050000\n",
      "Seed 74, Epoch [130/1000], Train Loss: 1.104363, Test Loss: 1.573248, LR: 0.050000\n",
      "Seed 74, Epoch [140/1000], Train Loss: 1.057624, Test Loss: 1.342573, LR: 0.050000\n",
      "Seed 74, Epoch [150/1000], Train Loss: 0.952153, Test Loss: 1.420664, LR: 0.050000\n",
      "Seed 74, Epoch [160/1000], Train Loss: 0.882977, Test Loss: 1.754936, LR: 0.050000\n",
      "Seed 74, Epoch [170/1000], Train Loss: 0.919675, Test Loss: 2.006945, LR: 0.050000\n",
      "Seed 74, Epoch [180/1000], Train Loss: 0.801567, Test Loss: 2.207448, LR: 0.050000\n",
      "Seed 74, Epoch [190/1000], Train Loss: 0.766718, Test Loss: 2.239866, LR: 0.050000\n",
      "Seed 74, Epoch [200/1000], Train Loss: 0.752665, Test Loss: 2.454398, LR: 0.050000\n",
      "Seed 74, Epoch [210/1000], Train Loss: 0.772867, Test Loss: 2.449600, LR: 0.050000\n",
      "Seed 74, Epoch [220/1000], Train Loss: 0.757615, Test Loss: 2.370290, LR: 0.050000\n",
      "Seed 74, Epoch [230/1000], Train Loss: 0.719535, Test Loss: 2.363687, LR: 0.050000\n",
      "Seed 74, Epoch [240/1000], Train Loss: 0.767337, Test Loss: 2.430766, LR: 0.050000\n",
      "Seed 74, Epoch [250/1000], Train Loss: 0.703697, Test Loss: 2.471327, LR: 0.050000\n",
      "Seed 74, Epoch [260/1000], Train Loss: 0.692309, Test Loss: 2.458637, LR: 0.050000\n",
      "Seed 74, Epoch [270/1000], Train Loss: 0.685732, Test Loss: 2.473993, LR: 0.050000\n",
      "Seed 74, Epoch [280/1000], Train Loss: 0.750012, Test Loss: 2.504773, LR: 0.050000\n",
      "Seed 74, Epoch [290/1000], Train Loss: 0.729876, Test Loss: 2.370244, LR: 0.050000\n",
      "Seed 74, Epoch [300/1000], Train Loss: 0.713021, Test Loss: 2.229672, LR: 0.050000\n",
      "Seed 74, Epoch [310/1000], Train Loss: 0.697228, Test Loss: 2.383420, LR: 0.050000\n",
      "Seed 74, Epoch [320/1000], Train Loss: 0.671577, Test Loss: 2.495307, LR: 0.050000\n",
      "Seed 74, Epoch [330/1000], Train Loss: 0.679180, Test Loss: 2.599582, LR: 0.050000\n",
      "Seed 74, Epoch [340/1000], Train Loss: 0.740675, Test Loss: 2.556866, LR: 0.050000\n",
      "Seed 74, Epoch [350/1000], Train Loss: 0.688366, Test Loss: 2.524191, LR: 0.050000\n",
      "Seed 74, Epoch [360/1000], Train Loss: 0.656624, Test Loss: 2.554022, LR: 0.050000\n",
      "Seed 74, Epoch [370/1000], Train Loss: 0.664841, Test Loss: 2.601342, LR: 0.050000\n",
      "Seed 74, Epoch [380/1000], Train Loss: 0.650805, Test Loss: 2.613388, LR: 0.050000\n",
      "Seed 74, Epoch [390/1000], Train Loss: 0.649598, Test Loss: 2.625200, LR: 0.050000\n",
      "Seed 74, Epoch [400/1000], Train Loss: 0.641110, Test Loss: 2.645220, LR: 0.050000\n",
      "Seed 74, Epoch [410/1000], Train Loss: 0.640511, Test Loss: 2.643718, LR: 0.050000\n",
      "Seed 74, Epoch [420/1000], Train Loss: 0.640744, Test Loss: 2.668906, LR: 0.050000\n",
      "Seed 74, Epoch [430/1000], Train Loss: 0.653403, Test Loss: 2.621607, LR: 0.050000\n",
      "Seed 74, Epoch [440/1000], Train Loss: 0.678177, Test Loss: 2.598992, LR: 0.050000\n",
      "Seed 74, Epoch [450/1000], Train Loss: 0.639932, Test Loss: 2.659818, LR: 0.050000\n",
      "Seed 74, Epoch [460/1000], Train Loss: 0.644754, Test Loss: 2.684823, LR: 0.050000\n",
      "Seed 74, Epoch [470/1000], Train Loss: 0.636104, Test Loss: 2.688048, LR: 0.050000\n",
      "Seed 74, Epoch [480/1000], Train Loss: 0.702060, Test Loss: 2.672106, LR: 0.050000\n",
      "Seed 74, Epoch [490/1000], Train Loss: 0.673317, Test Loss: 2.654305, LR: 0.050000\n",
      "Seed 74, Epoch [500/1000], Train Loss: 0.643934, Test Loss: 2.676877, LR: 0.050000\n",
      "Seed 74, Epoch [510/1000], Train Loss: 0.636020, Test Loss: 2.698616, LR: 0.050000\n",
      "Seed 74, Epoch [520/1000], Train Loss: 0.775007, Test Loss: 2.670659, LR: 0.050000\n",
      "Seed 74, Epoch [530/1000], Train Loss: 0.682116, Test Loss: 2.648501, LR: 0.050000\n",
      "Seed 74, Epoch [540/1000], Train Loss: 0.657509, Test Loss: 2.675214, LR: 0.050000\n",
      "Seed 74, Epoch [550/1000], Train Loss: 0.629712, Test Loss: 2.695336, LR: 0.050000\n",
      "Seed 74, Epoch [560/1000], Train Loss: 0.634879, Test Loss: 2.661197, LR: 0.050000\n",
      "Seed 74, Epoch [570/1000], Train Loss: 0.640804, Test Loss: 2.667320, LR: 0.050000\n",
      "Early stopping at epoch 572 for seed 74\n",
      "Seed 75, Epoch [10/1000], Train Loss: 4.783315, Test Loss: 4.402927, LR: 0.050000\n",
      "Seed 75, Epoch [20/1000], Train Loss: 2.958360, Test Loss: 2.902769, LR: 0.050000\n",
      "Seed 75, Epoch [30/1000], Train Loss: 2.636807, Test Loss: 2.522542, LR: 0.050000\n",
      "Seed 75, Epoch [40/1000], Train Loss: 2.515584, Test Loss: 2.363553, LR: 0.050000\n",
      "Seed 75, Epoch [50/1000], Train Loss: 2.448236, Test Loss: 2.267683, LR: 0.050000\n",
      "Seed 75, Epoch [60/1000], Train Loss: 2.396337, Test Loss: 2.192272, LR: 0.050000\n",
      "Seed 75, Epoch [70/1000], Train Loss: 2.349896, Test Loss: 2.123714, LR: 0.050000\n",
      "Seed 75, Epoch [80/1000], Train Loss: 2.301314, Test Loss: 2.055404, LR: 0.050000\n",
      "Seed 75, Epoch [90/1000], Train Loss: 2.241204, Test Loss: 1.974468, LR: 0.050000\n",
      "Seed 75, Epoch [100/1000], Train Loss: 2.168451, Test Loss: 1.887004, LR: 0.050000\n",
      "Seed 75, Epoch [110/1000], Train Loss: 2.074212, Test Loss: 1.761751, LR: 0.050000\n",
      "Seed 75, Epoch [120/1000], Train Loss: 1.944119, Test Loss: 1.565145, LR: 0.050000\n",
      "Seed 75, Epoch [130/1000], Train Loss: 1.780503, Test Loss: 1.324238, LR: 0.050000\n",
      "Seed 75, Epoch [140/1000], Train Loss: 1.709512, Test Loss: 2.035881, LR: 0.050000\n",
      "Seed 75, Epoch [150/1000], Train Loss: 1.632106, Test Loss: 1.915112, LR: 0.050000\n",
      "Seed 75, Epoch [160/1000], Train Loss: 1.563475, Test Loss: 1.914798, LR: 0.050000\n",
      "Seed 75, Epoch [170/1000], Train Loss: 1.482330, Test Loss: 2.161439, LR: 0.050000\n",
      "Seed 75, Epoch [180/1000], Train Loss: 1.395449, Test Loss: 2.184327, LR: 0.050000\n",
      "Seed 75, Epoch [190/1000], Train Loss: 1.317422, Test Loss: 1.589232, LR: 0.050000\n",
      "Seed 75, Epoch [200/1000], Train Loss: 1.234006, Test Loss: 1.283977, LR: 0.050000\n",
      "Seed 75, Epoch [210/1000], Train Loss: 1.188979, Test Loss: 1.253438, LR: 0.050000\n",
      "Seed 75, Epoch [220/1000], Train Loss: 1.154528, Test Loss: 1.163219, LR: 0.050000\n",
      "Seed 75, Epoch [230/1000], Train Loss: 1.128700, Test Loss: 1.139024, LR: 0.050000\n",
      "Seed 75, Epoch [240/1000], Train Loss: 1.103224, Test Loss: 1.125205, LR: 0.050000\n",
      "Seed 75, Epoch [250/1000], Train Loss: 1.089336, Test Loss: 1.407973, LR: 0.050000\n",
      "Seed 75, Epoch [260/1000], Train Loss: 1.071985, Test Loss: 1.331911, LR: 0.050000\n",
      "Seed 75, Epoch [270/1000], Train Loss: 1.043755, Test Loss: 1.171277, LR: 0.050000\n",
      "Seed 75, Epoch [280/1000], Train Loss: 1.018684, Test Loss: 1.029434, LR: 0.050000\n",
      "Seed 75, Epoch [290/1000], Train Loss: 0.995587, Test Loss: 0.952938, LR: 0.050000\n",
      "Seed 75, Epoch [300/1000], Train Loss: 0.975605, Test Loss: 0.966600, LR: 0.050000\n",
      "Seed 75, Epoch [310/1000], Train Loss: 0.959136, Test Loss: 0.928352, LR: 0.050000\n",
      "Seed 75, Epoch [320/1000], Train Loss: 1.035690, Test Loss: 0.987418, LR: 0.050000\n",
      "Seed 75, Epoch [330/1000], Train Loss: 0.939105, Test Loss: 0.956626, LR: 0.050000\n",
      "Seed 75, Epoch [340/1000], Train Loss: 0.901780, Test Loss: 0.910800, LR: 0.050000\n",
      "Seed 75, Epoch [350/1000], Train Loss: 0.885157, Test Loss: 0.914085, LR: 0.050000\n",
      "Seed 75, Epoch [360/1000], Train Loss: 0.871894, Test Loss: 0.921040, LR: 0.050000\n",
      "Seed 75, Epoch [370/1000], Train Loss: 0.859186, Test Loss: 0.930707, LR: 0.050000\n",
      "Seed 75, Epoch [380/1000], Train Loss: 0.904801, Test Loss: 1.120919, LR: 0.050000\n",
      "Seed 75, Epoch [390/1000], Train Loss: 0.853829, Test Loss: 0.977165, LR: 0.050000\n",
      "Seed 75, Epoch [400/1000], Train Loss: 0.851792, Test Loss: 0.984046, LR: 0.050000\n",
      "Seed 75, Epoch [410/1000], Train Loss: 0.819690, Test Loss: 0.970753, LR: 0.050000\n",
      "Seed 75, Epoch [420/1000], Train Loss: 0.856640, Test Loss: 1.059604, LR: 0.050000\n",
      "Seed 75, Epoch [430/1000], Train Loss: 0.811622, Test Loss: 1.030976, LR: 0.050000\n",
      "Seed 75, Epoch [440/1000], Train Loss: 0.799411, Test Loss: 0.975651, LR: 0.050000\n",
      "Seed 75, Epoch [450/1000], Train Loss: 0.805206, Test Loss: 1.045171, LR: 0.050000\n",
      "Seed 75, Epoch [460/1000], Train Loss: 0.836901, Test Loss: 1.192343, LR: 0.050000\n",
      "Seed 75, Epoch [470/1000], Train Loss: 0.812194, Test Loss: 0.921818, LR: 0.050000\n",
      "Seed 75, Epoch [480/1000], Train Loss: 0.784517, Test Loss: 0.983803, LR: 0.050000\n",
      "Seed 75, Epoch [490/1000], Train Loss: 0.807599, Test Loss: 1.073947, LR: 0.050000\n",
      "Seed 75, Epoch [500/1000], Train Loss: 0.795925, Test Loss: 0.931178, LR: 0.050000\n",
      "Seed 75, Epoch [510/1000], Train Loss: 0.808975, Test Loss: 0.926045, LR: 0.050000\n",
      "Seed 75, Epoch [520/1000], Train Loss: 0.796517, Test Loss: 0.932069, LR: 0.050000\n",
      "Seed 75, Epoch [530/1000], Train Loss: 0.780817, Test Loss: 0.963948, LR: 0.050000\n",
      "Seed 75, Epoch [540/1000], Train Loss: 0.778976, Test Loss: 0.926724, LR: 0.050000\n",
      "Seed 75, Epoch [550/1000], Train Loss: 0.785779, Test Loss: 0.911722, LR: 0.050000\n",
      "Seed 75, Epoch [560/1000], Train Loss: 0.794878, Test Loss: 0.956164, LR: 0.050000\n",
      "Seed 75, Epoch [570/1000], Train Loss: 0.862228, Test Loss: 0.916060, LR: 0.050000\n",
      "Seed 75, Epoch [580/1000], Train Loss: 0.798548, Test Loss: 0.852785, LR: 0.050000\n",
      "Seed 75, Epoch [590/1000], Train Loss: 0.776254, Test Loss: 0.821420, LR: 0.050000\n",
      "Seed 75, Epoch [600/1000], Train Loss: 0.764961, Test Loss: 0.818986, LR: 0.050000\n",
      "Seed 75, Epoch [610/1000], Train Loss: 0.775775, Test Loss: 0.814872, LR: 0.050000\n",
      "Seed 75, Epoch [620/1000], Train Loss: 0.783279, Test Loss: 0.830961, LR: 0.050000\n",
      "Seed 75, Epoch [630/1000], Train Loss: 0.764276, Test Loss: 0.837986, LR: 0.050000\n",
      "Seed 75, Epoch [640/1000], Train Loss: 0.752120, Test Loss: 0.807837, LR: 0.050000\n",
      "Seed 75, Epoch [650/1000], Train Loss: 1.109817, Test Loss: 0.855837, LR: 0.050000\n",
      "Seed 75, Epoch [660/1000], Train Loss: 0.817792, Test Loss: 0.880487, LR: 0.050000\n",
      "Seed 75, Epoch [670/1000], Train Loss: 0.807643, Test Loss: 0.854442, LR: 0.050000\n",
      "Seed 75, Epoch [680/1000], Train Loss: 0.784691, Test Loss: 0.771567, LR: 0.050000\n",
      "Seed 75, Epoch [690/1000], Train Loss: 0.758427, Test Loss: 0.756748, LR: 0.050000\n",
      "Seed 75, Epoch [700/1000], Train Loss: 0.890817, Test Loss: 0.853773, LR: 0.050000\n",
      "Seed 75, Epoch [710/1000], Train Loss: 0.814259, Test Loss: 0.791189, LR: 0.050000\n",
      "Seed 75, Epoch [720/1000], Train Loss: 0.784431, Test Loss: 0.732333, LR: 0.050000\n",
      "Seed 75, Epoch [730/1000], Train Loss: 0.759753, Test Loss: 0.745738, LR: 0.050000\n",
      "Seed 75, Epoch [740/1000], Train Loss: 0.788586, Test Loss: 0.743456, LR: 0.050000\n",
      "Seed 75, Epoch [750/1000], Train Loss: 0.795946, Test Loss: 0.757078, LR: 0.050000\n",
      "Seed 75, Epoch [760/1000], Train Loss: 0.761481, Test Loss: 0.725304, LR: 0.050000\n",
      "Seed 75, Epoch [770/1000], Train Loss: 0.776232, Test Loss: 0.731971, LR: 0.050000\n",
      "Seed 75, Epoch [780/1000], Train Loss: 0.762920, Test Loss: 0.722536, LR: 0.050000\n",
      "Seed 75, Epoch [790/1000], Train Loss: 0.763457, Test Loss: 0.735669, LR: 0.050000\n",
      "Seed 75, Epoch [800/1000], Train Loss: 0.819755, Test Loss: 0.727026, LR: 0.050000\n",
      "Seed 75, Epoch [810/1000], Train Loss: 0.785758, Test Loss: 0.740336, LR: 0.050000\n",
      "Seed 75, Epoch [820/1000], Train Loss: 0.776240, Test Loss: 0.719090, LR: 0.050000\n",
      "Seed 75, Epoch [830/1000], Train Loss: 0.803164, Test Loss: 0.753834, LR: 0.050000\n",
      "Seed 75, Epoch [840/1000], Train Loss: 0.758494, Test Loss: 0.712676, LR: 0.050000\n",
      "Seed 75, Epoch [850/1000], Train Loss: 0.912072, Test Loss: 0.843974, LR: 0.050000\n",
      "Seed 75, Epoch [860/1000], Train Loss: 0.988373, Test Loss: 0.825083, LR: 0.050000\n",
      "Seed 75, Epoch [870/1000], Train Loss: 0.801610, Test Loss: 0.775836, LR: 0.050000\n",
      "Seed 75, Epoch [880/1000], Train Loss: 0.778783, Test Loss: 0.728069, LR: 0.050000\n",
      "Seed 75, Epoch [890/1000], Train Loss: 0.766780, Test Loss: 0.706938, LR: 0.050000\n",
      "Seed 75, Epoch [900/1000], Train Loss: 0.875598, Test Loss: 0.890777, LR: 0.050000\n",
      "Seed 75, Epoch [910/1000], Train Loss: 0.847110, Test Loss: 0.843667, LR: 0.050000\n",
      "Seed 75, Epoch [920/1000], Train Loss: 0.821899, Test Loss: 0.804404, LR: 0.050000\n",
      "Seed 75, Epoch [930/1000], Train Loss: 0.763763, Test Loss: 0.811596, LR: 0.050000\n",
      "Seed 75, Epoch [940/1000], Train Loss: 0.876152, Test Loss: 0.816617, LR: 0.050000\n",
      "Seed 75, Epoch [950/1000], Train Loss: 0.774853, Test Loss: 0.719959, LR: 0.050000\n",
      "Seed 75, Epoch [960/1000], Train Loss: 0.753328, Test Loss: 0.712484, LR: 0.050000\n",
      "Seed 75, Epoch [970/1000], Train Loss: 0.735775, Test Loss: 0.711681, LR: 0.050000\n",
      "Seed 75, Epoch [980/1000], Train Loss: 0.987118, Test Loss: 0.724114, LR: 0.050000\n",
      "Seed 75, Epoch [990/1000], Train Loss: 0.894584, Test Loss: 0.744539, LR: 0.050000\n",
      "Seed 75, Epoch [1000/1000], Train Loss: 0.791010, Test Loss: 0.800695, LR: 0.050000\n",
      "Seed 76, Epoch [10/1000], Train Loss: 2.311875, Test Loss: 2.209390, LR: 0.050000\n",
      "Seed 76, Epoch [20/1000], Train Loss: 2.532326, Test Loss: 2.370396, LR: 0.050000\n",
      "Seed 76, Epoch [30/1000], Train Loss: 2.418180, Test Loss: 2.248185, LR: 0.050000\n",
      "Seed 76, Epoch [40/1000], Train Loss: 2.320814, Test Loss: 2.110948, LR: 0.050000\n",
      "Seed 76, Epoch [50/1000], Train Loss: 2.206413, Test Loss: 2.088502, LR: 0.050000\n",
      "Seed 76, Epoch [60/1000], Train Loss: 2.050311, Test Loss: 2.017879, LR: 0.050000\n",
      "Seed 76, Epoch [70/1000], Train Loss: 1.845705, Test Loss: 1.872528, LR: 0.050000\n",
      "Seed 76, Epoch [80/1000], Train Loss: 1.523700, Test Loss: 1.483881, LR: 0.050000\n",
      "Seed 76, Epoch [90/1000], Train Loss: 1.327553, Test Loss: 1.252017, LR: 0.050000\n",
      "Seed 76, Epoch [100/1000], Train Loss: 1.301234, Test Loss: 1.240768, LR: 0.050000\n",
      "Seed 76, Epoch [110/1000], Train Loss: 1.196903, Test Loss: 1.095270, LR: 0.050000\n",
      "Seed 76, Epoch [120/1000], Train Loss: 1.144658, Test Loss: 1.005306, LR: 0.050000\n",
      "Seed 76, Epoch [130/1000], Train Loss: 1.089986, Test Loss: 0.985880, LR: 0.050000\n",
      "Seed 76, Epoch [140/1000], Train Loss: 1.022965, Test Loss: 0.959732, LR: 0.050000\n",
      "Seed 76, Epoch [150/1000], Train Loss: 0.998352, Test Loss: 0.990757, LR: 0.050000\n",
      "Seed 76, Epoch [160/1000], Train Loss: 0.913693, Test Loss: 1.163291, LR: 0.050000\n",
      "Seed 76, Epoch [170/1000], Train Loss: 0.869848, Test Loss: 1.302824, LR: 0.050000\n",
      "Seed 76, Epoch [180/1000], Train Loss: 0.905508, Test Loss: 1.513982, LR: 0.050000\n",
      "Seed 76, Epoch [190/1000], Train Loss: 0.850904, Test Loss: 1.512682, LR: 0.050000\n",
      "Seed 76, Epoch [200/1000], Train Loss: 0.827602, Test Loss: 1.699804, LR: 0.050000\n",
      "Seed 76, Epoch [210/1000], Train Loss: 0.815955, Test Loss: 1.827214, LR: 0.050000\n",
      "Seed 76, Epoch [220/1000], Train Loss: 0.798118, Test Loss: 1.884217, LR: 0.050000\n",
      "Seed 76, Epoch [230/1000], Train Loss: 0.823203, Test Loss: 1.647224, LR: 0.050000\n",
      "Seed 76, Epoch [240/1000], Train Loss: 0.800547, Test Loss: 1.698439, LR: 0.050000\n",
      "Seed 76, Epoch [250/1000], Train Loss: 0.823996, Test Loss: 2.057273, LR: 0.050000\n",
      "Seed 76, Epoch [260/1000], Train Loss: 0.765011, Test Loss: 1.914999, LR: 0.050000\n",
      "Seed 76, Epoch [270/1000], Train Loss: 0.813927, Test Loss: 1.836689, LR: 0.050000\n",
      "Seed 76, Epoch [280/1000], Train Loss: 0.804922, Test Loss: 1.822836, LR: 0.050000\n",
      "Seed 76, Epoch [290/1000], Train Loss: 0.786130, Test Loss: 2.241471, LR: 0.050000\n",
      "Seed 76, Epoch [300/1000], Train Loss: 2.098359, Test Loss: 2.903236, LR: 0.050000\n",
      "Seed 76, Epoch [310/1000], Train Loss: 1.058539, Test Loss: 1.953764, LR: 0.050000\n",
      "Seed 76, Epoch [320/1000], Train Loss: 0.966680, Test Loss: 1.636616, LR: 0.050000\n",
      "Seed 76, Epoch [330/1000], Train Loss: 0.792366, Test Loss: 1.442299, LR: 0.050000\n",
      "Seed 76, Epoch [340/1000], Train Loss: 0.739002, Test Loss: 1.520313, LR: 0.050000\n",
      "Seed 76, Epoch [350/1000], Train Loss: 0.721751, Test Loss: 1.750119, LR: 0.050000\n",
      "Seed 76, Epoch [360/1000], Train Loss: 0.713858, Test Loss: 1.702542, LR: 0.050000\n",
      "Seed 76, Epoch [370/1000], Train Loss: 0.734336, Test Loss: 1.903171, LR: 0.050000\n",
      "Seed 76, Epoch [380/1000], Train Loss: 0.732163, Test Loss: 1.758874, LR: 0.050000\n",
      "Seed 76, Epoch [390/1000], Train Loss: 0.717374, Test Loss: 1.611451, LR: 0.050000\n",
      "Seed 76, Epoch [400/1000], Train Loss: 0.758697, Test Loss: 1.542912, LR: 0.050000\n",
      "Seed 76, Epoch [410/1000], Train Loss: 0.697473, Test Loss: 1.533222, LR: 0.050000\n",
      "Seed 76, Epoch [420/1000], Train Loss: 0.723370, Test Loss: 1.633560, LR: 0.050000\n",
      "Seed 76, Epoch [430/1000], Train Loss: 0.735326, Test Loss: 1.588150, LR: 0.050000\n",
      "Seed 76, Epoch [440/1000], Train Loss: 0.708422, Test Loss: 1.507721, LR: 0.050000\n",
      "Seed 76, Epoch [450/1000], Train Loss: 0.755261, Test Loss: 1.436965, LR: 0.050000\n",
      "Seed 76, Epoch [460/1000], Train Loss: 0.697664, Test Loss: 1.452447, LR: 0.050000\n",
      "Seed 76, Epoch [470/1000], Train Loss: 0.724136, Test Loss: 1.386673, LR: 0.050000\n",
      "Seed 76, Epoch [480/1000], Train Loss: 0.737284, Test Loss: 1.510791, LR: 0.050000\n",
      "Seed 76, Epoch [490/1000], Train Loss: 0.767748, Test Loss: 1.628579, LR: 0.050000\n",
      "Seed 76, Epoch [500/1000], Train Loss: 0.719183, Test Loss: 1.497904, LR: 0.050000\n",
      "Seed 76, Epoch [510/1000], Train Loss: 0.719050, Test Loss: 1.376188, LR: 0.050000\n",
      "Seed 76, Epoch [520/1000], Train Loss: 0.714360, Test Loss: 1.348157, LR: 0.050000\n",
      "Seed 76, Epoch [530/1000], Train Loss: 0.827783, Test Loss: 1.288109, LR: 0.050000\n",
      "Seed 76, Epoch [540/1000], Train Loss: 0.709827, Test Loss: 1.397324, LR: 0.050000\n",
      "Seed 76, Epoch [550/1000], Train Loss: 0.730901, Test Loss: 1.442364, LR: 0.050000\n",
      "Seed 76, Epoch [560/1000], Train Loss: 0.763871, Test Loss: 1.270846, LR: 0.050000\n",
      "Seed 76, Epoch [570/1000], Train Loss: 0.845754, Test Loss: 1.246836, LR: 0.050000\n",
      "Seed 76, Epoch [580/1000], Train Loss: 0.760659, Test Loss: 1.174331, LR: 0.050000\n",
      "Seed 76, Epoch [590/1000], Train Loss: 0.701616, Test Loss: 1.186013, LR: 0.050000\n",
      "Seed 76, Epoch [600/1000], Train Loss: 0.835475, Test Loss: 1.536821, LR: 0.050000\n",
      "Seed 76, Epoch [610/1000], Train Loss: 0.871426, Test Loss: 1.433657, LR: 0.050000\n",
      "Seed 76, Epoch [620/1000], Train Loss: 0.803011, Test Loss: 1.299929, LR: 0.050000\n",
      "Seed 76, Epoch [630/1000], Train Loss: 0.750380, Test Loss: 1.123723, LR: 0.050000\n",
      "Seed 76, Epoch [640/1000], Train Loss: 0.688448, Test Loss: 1.207449, LR: 0.050000\n",
      "Early stopping at epoch 644 for seed 76\n",
      "Seed 77, Epoch [10/1000], Train Loss: 3.421122, Test Loss: 3.128565, LR: 0.050000\n",
      "Seed 77, Epoch [20/1000], Train Loss: 2.324508, Test Loss: 2.188348, LR: 0.050000\n",
      "Seed 77, Epoch [30/1000], Train Loss: 2.351577, Test Loss: 2.211887, LR: 0.050000\n",
      "Seed 77, Epoch [40/1000], Train Loss: 2.372945, Test Loss: 2.228326, LR: 0.050000\n",
      "Seed 77, Epoch [50/1000], Train Loss: 2.372988, Test Loss: 2.224605, LR: 0.050000\n",
      "Seed 77, Epoch [60/1000], Train Loss: 2.359097, Test Loss: 2.207669, LR: 0.050000\n",
      "Seed 77, Epoch [70/1000], Train Loss: 2.337235, Test Loss: 2.182910, LR: 0.050000\n",
      "Seed 77, Epoch [80/1000], Train Loss: 2.310604, Test Loss: 2.152616, LR: 0.050000\n",
      "Seed 77, Epoch [90/1000], Train Loss: 2.281298, Test Loss: 2.117657, LR: 0.050000\n",
      "Seed 77, Epoch [100/1000], Train Loss: 2.251252, Test Loss: 2.078743, LR: 0.050000\n",
      "Seed 77, Epoch [110/1000], Train Loss: 2.222275, Test Loss: 2.037213, LR: 0.050000\n",
      "Seed 77, Epoch [120/1000], Train Loss: 2.195494, Test Loss: 1.995398, LR: 0.050000\n",
      "Seed 77, Epoch [130/1000], Train Loss: 2.170559, Test Loss: 1.956352, LR: 0.050000\n",
      "Seed 77, Epoch [140/1000], Train Loss: 2.146293, Test Loss: 1.921975, LR: 0.050000\n",
      "Seed 77, Epoch [150/1000], Train Loss: 2.169596, Test Loss: 1.922130, LR: 0.050000\n",
      "Seed 77, Epoch [160/1000], Train Loss: 2.131471, Test Loss: 1.903895, LR: 0.050000\n",
      "Seed 77, Epoch [170/1000], Train Loss: 2.104915, Test Loss: 1.885620, LR: 0.050000\n",
      "Seed 77, Epoch [180/1000], Train Loss: 2.078506, Test Loss: 1.836105, LR: 0.050000\n",
      "Seed 77, Epoch [190/1000], Train Loss: 2.033289, Test Loss: 1.791169, LR: 0.050000\n",
      "Seed 77, Epoch [200/1000], Train Loss: 2.010431, Test Loss: 1.760596, LR: 0.050000\n",
      "Seed 77, Epoch [210/1000], Train Loss: 1.968511, Test Loss: 1.719141, LR: 0.050000\n",
      "Seed 77, Epoch [220/1000], Train Loss: 1.921915, Test Loss: 1.675712, LR: 0.050000\n",
      "Seed 77, Epoch [230/1000], Train Loss: 1.862590, Test Loss: 1.624934, LR: 0.050000\n",
      "Seed 77, Epoch [240/1000], Train Loss: 1.806548, Test Loss: 1.569396, LR: 0.050000\n",
      "Seed 77, Epoch [250/1000], Train Loss: 1.745963, Test Loss: 1.507892, LR: 0.050000\n",
      "Seed 77, Epoch [260/1000], Train Loss: 1.671129, Test Loss: 1.442001, LR: 0.050000\n",
      "Seed 77, Epoch [270/1000], Train Loss: 1.563996, Test Loss: 1.350816, LR: 0.050000\n",
      "Seed 77, Epoch [280/1000], Train Loss: 1.413844, Test Loss: 1.211424, LR: 0.050000\n",
      "Seed 77, Epoch [290/1000], Train Loss: 1.348507, Test Loss: 1.074868, LR: 0.050000\n",
      "Seed 77, Epoch [300/1000], Train Loss: 1.297234, Test Loss: 1.120396, LR: 0.050000\n",
      "Seed 77, Epoch [310/1000], Train Loss: 1.256726, Test Loss: 1.074872, LR: 0.050000\n",
      "Seed 77, Epoch [320/1000], Train Loss: 1.221073, Test Loss: 1.063468, LR: 0.050000\n",
      "Seed 77, Epoch [330/1000], Train Loss: 1.195474, Test Loss: 1.034907, LR: 0.050000\n",
      "Seed 77, Epoch [340/1000], Train Loss: 1.176197, Test Loss: 1.010534, LR: 0.050000\n",
      "Seed 77, Epoch [350/1000], Train Loss: 1.159241, Test Loss: 0.979366, LR: 0.050000\n",
      "Seed 77, Epoch [360/1000], Train Loss: 2.192953, Test Loss: 2.110534, LR: 0.050000\n",
      "Seed 77, Epoch [370/1000], Train Loss: 1.707895, Test Loss: 1.640235, LR: 0.050000\n",
      "Seed 77, Epoch [380/1000], Train Loss: 1.683936, Test Loss: 1.585360, LR: 0.050000\n",
      "Seed 77, Epoch [390/1000], Train Loss: 1.474325, Test Loss: 1.450083, LR: 0.050000\n",
      "Seed 77, Epoch [400/1000], Train Loss: 1.299428, Test Loss: 1.192459, LR: 0.050000\n",
      "Seed 77, Epoch [410/1000], Train Loss: 1.152271, Test Loss: 0.927531, LR: 0.050000\n",
      "Seed 77, Epoch [420/1000], Train Loss: 1.126196, Test Loss: 0.916693, LR: 0.050000\n",
      "Seed 77, Epoch [430/1000], Train Loss: 1.104459, Test Loss: 0.902171, LR: 0.050000\n",
      "Seed 77, Epoch [440/1000], Train Loss: 1.080677, Test Loss: 0.877321, LR: 0.050000\n",
      "Seed 77, Epoch [450/1000], Train Loss: 1.060816, Test Loss: 0.868982, LR: 0.050000\n",
      "Seed 77, Epoch [460/1000], Train Loss: 1.040802, Test Loss: 0.852583, LR: 0.050000\n",
      "Seed 77, Epoch [470/1000], Train Loss: 1.023519, Test Loss: 0.879213, LR: 0.050000\n",
      "Seed 77, Epoch [480/1000], Train Loss: 1.009338, Test Loss: 0.933209, LR: 0.050000\n",
      "Seed 77, Epoch [490/1000], Train Loss: 0.997801, Test Loss: 0.983443, LR: 0.050000\n",
      "Seed 77, Epoch [500/1000], Train Loss: 0.987833, Test Loss: 1.016280, LR: 0.050000\n",
      "Seed 77, Epoch [510/1000], Train Loss: 0.978810, Test Loss: 1.023515, LR: 0.050000\n",
      "Seed 77, Epoch [520/1000], Train Loss: 0.970512, Test Loss: 1.008577, LR: 0.050000\n",
      "Seed 77, Epoch [530/1000], Train Loss: 0.962745, Test Loss: 0.988191, LR: 0.050000\n",
      "Seed 77, Epoch [540/1000], Train Loss: 0.955289, Test Loss: 0.972639, LR: 0.050000\n",
      "Seed 77, Epoch [550/1000], Train Loss: 0.947947, Test Loss: 0.962698, LR: 0.050000\n",
      "Seed 77, Epoch [560/1000], Train Loss: 0.940526, Test Loss: 0.960640, LR: 0.050000\n",
      "Seed 77, Epoch [570/1000], Train Loss: 0.932868, Test Loss: 0.967117, LR: 0.050000\n",
      "Seed 77, Epoch [580/1000], Train Loss: 0.924851, Test Loss: 0.983050, LR: 0.050000\n",
      "Seed 77, Epoch [590/1000], Train Loss: 0.916429, Test Loss: 1.009478, LR: 0.050000\n",
      "Seed 77, Epoch [600/1000], Train Loss: 0.907645, Test Loss: 1.049474, LR: 0.050000\n",
      "Seed 77, Epoch [610/1000], Train Loss: 0.898645, Test Loss: 1.097678, LR: 0.050000\n",
      "Seed 77, Epoch [620/1000], Train Loss: 0.889617, Test Loss: 1.154751, LR: 0.050000\n",
      "Seed 77, Epoch [630/1000], Train Loss: 0.881235, Test Loss: 1.177306, LR: 0.050000\n",
      "Seed 77, Epoch [640/1000], Train Loss: 0.958251, Test Loss: 1.274145, LR: 0.050000\n",
      "Seed 77, Epoch [650/1000], Train Loss: 0.894951, Test Loss: 0.936091, LR: 0.050000\n",
      "Seed 77, Epoch [660/1000], Train Loss: 0.867100, Test Loss: 1.200453, LR: 0.050000\n",
      "Seed 77, Epoch [670/1000], Train Loss: 0.854537, Test Loss: 1.247972, LR: 0.050000\n",
      "Seed 77, Epoch [680/1000], Train Loss: 0.846638, Test Loss: 1.295261, LR: 0.050000\n",
      "Seed 77, Epoch [690/1000], Train Loss: 0.839086, Test Loss: 1.342823, LR: 0.050000\n",
      "Seed 77, Epoch [700/1000], Train Loss: 0.832086, Test Loss: 1.234660, LR: 0.050000\n",
      "Seed 77, Epoch [710/1000], Train Loss: 0.824808, Test Loss: 1.238208, LR: 0.050000\n",
      "Seed 77, Epoch [720/1000], Train Loss: 0.817657, Test Loss: 1.174259, LR: 0.050000\n",
      "Seed 77, Epoch [730/1000], Train Loss: 0.813003, Test Loss: 1.080796, LR: 0.050000\n",
      "Seed 77, Epoch [740/1000], Train Loss: 0.828031, Test Loss: 1.224608, LR: 0.050000\n",
      "Seed 77, Epoch [750/1000], Train Loss: 0.805245, Test Loss: 1.045761, LR: 0.050000\n",
      "Seed 77, Epoch [760/1000], Train Loss: 0.792772, Test Loss: 0.953954, LR: 0.050000\n",
      "Seed 77, Epoch [770/1000], Train Loss: 0.786094, Test Loss: 0.987038, LR: 0.050000\n",
      "Seed 77, Epoch [780/1000], Train Loss: 0.857035, Test Loss: 0.728623, LR: 0.050000\n",
      "Seed 77, Epoch [790/1000], Train Loss: 0.803280, Test Loss: 0.885705, LR: 0.050000\n",
      "Seed 77, Epoch [800/1000], Train Loss: 0.773321, Test Loss: 0.826360, LR: 0.050000\n",
      "Seed 77, Epoch [810/1000], Train Loss: 0.762334, Test Loss: 0.903325, LR: 0.050000\n",
      "Seed 77, Epoch [820/1000], Train Loss: 0.765425, Test Loss: 0.774862, LR: 0.050000\n",
      "Seed 77, Epoch [830/1000], Train Loss: 0.755374, Test Loss: 0.838270, LR: 0.050000\n",
      "Seed 77, Epoch [840/1000], Train Loss: 0.747798, Test Loss: 0.807082, LR: 0.050000\n",
      "Seed 77, Epoch [850/1000], Train Loss: 0.743037, Test Loss: 0.843389, LR: 0.050000\n",
      "Seed 77, Epoch [860/1000], Train Loss: 0.737958, Test Loss: 0.813341, LR: 0.050000\n",
      "Seed 77, Epoch [870/1000], Train Loss: 0.786425, Test Loss: 0.790116, LR: 0.050000\n",
      "Seed 77, Epoch [880/1000], Train Loss: 0.739358, Test Loss: 0.845520, LR: 0.050000\n",
      "Seed 77, Epoch [890/1000], Train Loss: 0.730016, Test Loss: 0.785627, LR: 0.050000\n",
      "Seed 77, Epoch [900/1000], Train Loss: 0.725825, Test Loss: 0.767989, LR: 0.050000\n",
      "Seed 77, Epoch [910/1000], Train Loss: 0.743170, Test Loss: 0.865849, LR: 0.050000\n",
      "Seed 77, Epoch [920/1000], Train Loss: 0.724386, Test Loss: 0.876802, LR: 0.050000\n",
      "Seed 77, Epoch [930/1000], Train Loss: 0.715763, Test Loss: 0.808881, LR: 0.050000\n",
      "Seed 77, Epoch [940/1000], Train Loss: 0.728012, Test Loss: 0.723666, LR: 0.050000\n",
      "Seed 77, Epoch [950/1000], Train Loss: 0.708834, Test Loss: 0.769290, LR: 0.050000\n",
      "Seed 77, Epoch [960/1000], Train Loss: 0.704708, Test Loss: 0.757975, LR: 0.050000\n",
      "Seed 77, Epoch [970/1000], Train Loss: 0.701838, Test Loss: 0.805331, LR: 0.050000\n",
      "Seed 77, Epoch [980/1000], Train Loss: 0.699147, Test Loss: 0.748607, LR: 0.050000\n",
      "Seed 77, Epoch [990/1000], Train Loss: 0.696874, Test Loss: 0.747596, LR: 0.050000\n",
      "Seed 77, Epoch [1000/1000], Train Loss: 0.697797, Test Loss: 0.803394, LR: 0.050000\n",
      "Seed 78, Epoch [10/1000], Train Loss: 3.258462, Test Loss: 2.925193, LR: 0.050000\n",
      "Seed 78, Epoch [20/1000], Train Loss: 2.514539, Test Loss: 2.373377, LR: 0.050000\n",
      "Seed 78, Epoch [30/1000], Train Loss: 2.478856, Test Loss: 2.338274, LR: 0.050000\n",
      "Seed 78, Epoch [40/1000], Train Loss: 2.456694, Test Loss: 2.309003, LR: 0.050000\n",
      "Seed 78, Epoch [50/1000], Train Loss: 2.450577, Test Loss: 2.289704, LR: 0.050000\n",
      "Seed 78, Epoch [60/1000], Train Loss: 2.422718, Test Loss: 2.267413, LR: 0.050000\n",
      "Seed 78, Epoch [70/1000], Train Loss: 2.389074, Test Loss: 2.233372, LR: 0.050000\n",
      "Seed 78, Epoch [80/1000], Train Loss: 2.339071, Test Loss: 2.177301, LR: 0.050000\n",
      "Seed 78, Epoch [90/1000], Train Loss: 2.265854, Test Loss: 2.088411, LR: 0.050000\n",
      "Seed 78, Epoch [100/1000], Train Loss: 2.153489, Test Loss: 1.945193, LR: 0.050000\n",
      "Seed 78, Epoch [110/1000], Train Loss: 1.969471, Test Loss: 1.699634, LR: 0.050000\n",
      "Seed 78, Epoch [120/1000], Train Loss: 1.634684, Test Loss: 1.267330, LR: 0.050000\n",
      "Seed 78, Epoch [130/1000], Train Loss: 1.550498, Test Loss: 1.175857, LR: 0.050000\n",
      "Seed 78, Epoch [140/1000], Train Loss: 1.444542, Test Loss: 1.208241, LR: 0.050000\n",
      "Seed 78, Epoch [150/1000], Train Loss: 1.377022, Test Loss: 1.414442, LR: 0.050000\n",
      "Seed 78, Epoch [160/1000], Train Loss: 1.403940, Test Loss: 1.132970, LR: 0.050000\n",
      "Seed 78, Epoch [170/1000], Train Loss: 1.550396, Test Loss: 1.661318, LR: 0.050000\n",
      "Seed 78, Epoch [180/1000], Train Loss: 1.856918, Test Loss: 1.726460, LR: 0.050000\n",
      "Seed 78, Epoch [190/1000], Train Loss: 1.822828, Test Loss: 1.744143, LR: 0.050000\n",
      "Seed 78, Epoch [200/1000], Train Loss: 1.697459, Test Loss: 1.635964, LR: 0.050000\n",
      "Seed 78, Epoch [210/1000], Train Loss: 1.566757, Test Loss: 1.503222, LR: 0.050000\n",
      "Seed 78, Epoch [220/1000], Train Loss: 1.461416, Test Loss: 1.394880, LR: 0.050000\n",
      "Seed 78, Epoch [230/1000], Train Loss: 1.371331, Test Loss: 1.253668, LR: 0.050000\n",
      "Seed 78, Epoch [240/1000], Train Loss: 1.325520, Test Loss: 1.148504, LR: 0.050000\n",
      "Seed 78, Epoch [250/1000], Train Loss: 1.323053, Test Loss: 1.104680, LR: 0.050000\n",
      "Seed 78, Epoch [260/1000], Train Loss: 1.318747, Test Loss: 1.121162, LR: 0.050000\n",
      "Seed 78, Epoch [270/1000], Train Loss: 1.315075, Test Loss: 1.148425, LR: 0.050000\n",
      "Seed 78, Epoch [280/1000], Train Loss: 1.313509, Test Loss: 1.152643, LR: 0.050000\n",
      "Seed 78, Epoch [290/1000], Train Loss: 1.311661, Test Loss: 1.147077, LR: 0.050000\n",
      "Seed 78, Epoch [300/1000], Train Loss: 1.310189, Test Loss: 1.145906, LR: 0.050000\n",
      "Seed 78, Epoch [310/1000], Train Loss: 1.308887, Test Loss: 1.148836, LR: 0.050000\n",
      "Seed 78, Epoch [320/1000], Train Loss: 1.307703, Test Loss: 1.152427, LR: 0.050000\n",
      "Seed 78, Epoch [330/1000], Train Loss: 1.306640, Test Loss: 1.154566, LR: 0.050000\n",
      "Seed 78, Epoch [340/1000], Train Loss: 1.305666, Test Loss: 1.155988, LR: 0.050000\n",
      "Seed 78, Epoch [350/1000], Train Loss: 1.304776, Test Loss: 1.157629, LR: 0.050000\n",
      "Seed 78, Epoch [360/1000], Train Loss: 1.303957, Test Loss: 1.159517, LR: 0.050000\n",
      "Seed 78, Epoch [370/1000], Train Loss: 1.303200, Test Loss: 1.161366, LR: 0.050000\n",
      "Seed 78, Epoch [380/1000], Train Loss: 1.302497, Test Loss: 1.163084, LR: 0.050000\n",
      "Seed 78, Epoch [390/1000], Train Loss: 1.301842, Test Loss: 1.164778, LR: 0.050000\n",
      "Seed 78, Epoch [400/1000], Train Loss: 1.301231, Test Loss: 1.166486, LR: 0.050000\n",
      "Seed 78, Epoch [410/1000], Train Loss: 1.300658, Test Loss: 1.168170, LR: 0.050000\n",
      "Seed 78, Epoch [420/1000], Train Loss: 1.300119, Test Loss: 1.169818, LR: 0.050000\n",
      "Seed 78, Epoch [430/1000], Train Loss: 1.299613, Test Loss: 1.171451, LR: 0.050000\n",
      "Seed 78, Epoch [440/1000], Train Loss: 1.299136, Test Loss: 1.173084, LR: 0.050000\n",
      "Seed 78, Epoch [450/1000], Train Loss: 1.298687, Test Loss: 1.174710, LR: 0.050000\n",
      "Seed 78, Epoch [460/1000], Train Loss: 1.298262, Test Loss: 1.176332, LR: 0.050000\n",
      "Seed 78, Epoch [470/1000], Train Loss: 1.297861, Test Loss: 1.177954, LR: 0.050000\n",
      "Seed 78, Epoch [480/1000], Train Loss: 1.297481, Test Loss: 1.179570, LR: 0.050000\n",
      "Seed 78, Epoch [490/1000], Train Loss: 1.297122, Test Loss: 1.181182, LR: 0.050000\n",
      "Seed 78, Epoch [500/1000], Train Loss: 1.296780, Test Loss: 1.182783, LR: 0.050000\n",
      "Seed 78, Epoch [510/1000], Train Loss: 1.296456, Test Loss: 1.184374, LR: 0.050000\n",
      "Seed 78, Epoch [520/1000], Train Loss: 1.296147, Test Loss: 1.185949, LR: 0.050000\n",
      "Seed 78, Epoch [530/1000], Train Loss: 1.295851, Test Loss: 1.187507, LR: 0.050000\n",
      "Seed 78, Epoch [540/1000], Train Loss: 1.295566, Test Loss: 1.189041, LR: 0.050000\n",
      "Seed 78, Epoch [550/1000], Train Loss: 1.295291, Test Loss: 1.190549, LR: 0.050000\n",
      "Seed 78, Epoch [560/1000], Train Loss: 1.295021, Test Loss: 1.192023, LR: 0.050000\n",
      "Seed 78, Epoch [570/1000], Train Loss: 1.294753, Test Loss: 1.193453, LR: 0.050000\n",
      "Seed 78, Epoch [580/1000], Train Loss: 1.294478, Test Loss: 1.194829, LR: 0.050000\n",
      "Seed 78, Epoch [590/1000], Train Loss: 1.294184, Test Loss: 1.196125, LR: 0.050000\n",
      "Seed 78, Epoch [600/1000], Train Loss: 1.293842, Test Loss: 1.197292, LR: 0.050000\n",
      "Seed 78, Epoch [610/1000], Train Loss: 1.293382, Test Loss: 1.198217, LR: 0.050000\n",
      "Seed 78, Epoch [620/1000], Train Loss: 1.292568, Test Loss: 1.198533, LR: 0.050000\n",
      "Seed 78, Epoch [630/1000], Train Loss: 1.290042, Test Loss: 1.196266, LR: 0.050000\n",
      "Seed 78, Epoch [640/1000], Train Loss: 1.261808, Test Loss: 1.175091, LR: 0.050000\n",
      "Seed 78, Epoch [650/1000], Train Loss: 1.409202, Test Loss: 1.273023, LR: 0.050000\n",
      "Seed 78, Epoch [660/1000], Train Loss: 1.484258, Test Loss: 1.873622, LR: 0.050000\n",
      "Early stopping at epoch 661 for seed 78\n",
      "Seed 79, Epoch [10/1000], Train Loss: 2.176174, Test Loss: 2.188076, LR: 0.050000\n",
      "Seed 79, Epoch [20/1000], Train Loss: 2.518446, Test Loss: 2.558495, LR: 0.050000\n",
      "Seed 79, Epoch [30/1000], Train Loss: 2.287235, Test Loss: 2.408276, LR: 0.050000\n",
      "Seed 79, Epoch [40/1000], Train Loss: 2.116873, Test Loss: 2.245675, LR: 0.050000\n",
      "Seed 79, Epoch [50/1000], Train Loss: 1.763399, Test Loss: 2.110840, LR: 0.050000\n",
      "Seed 79, Epoch [60/1000], Train Loss: 1.634677, Test Loss: 1.925663, LR: 0.050000\n",
      "Seed 79, Epoch [70/1000], Train Loss: 1.332781, Test Loss: 1.894882, LR: 0.050000\n",
      "Seed 79, Epoch [80/1000], Train Loss: 1.397128, Test Loss: 1.861091, LR: 0.050000\n",
      "Seed 79, Epoch [90/1000], Train Loss: 1.170806, Test Loss: 1.844851, LR: 0.050000\n",
      "Seed 79, Epoch [100/1000], Train Loss: 1.095082, Test Loss: 1.805835, LR: 0.050000\n",
      "Seed 79, Epoch [110/1000], Train Loss: 1.030907, Test Loss: 1.882563, LR: 0.050000\n",
      "Seed 79, Epoch [120/1000], Train Loss: 0.980650, Test Loss: 1.989383, LR: 0.050000\n",
      "Seed 79, Epoch [130/1000], Train Loss: 0.938223, Test Loss: 2.049026, LR: 0.050000\n",
      "Seed 79, Epoch [140/1000], Train Loss: 0.911816, Test Loss: 2.119993, LR: 0.050000\n",
      "Seed 79, Epoch [150/1000], Train Loss: 0.901679, Test Loss: 2.118339, LR: 0.050000\n",
      "Seed 79, Epoch [160/1000], Train Loss: 0.912509, Test Loss: 2.190078, LR: 0.050000\n",
      "Seed 79, Epoch [170/1000], Train Loss: 0.885889, Test Loss: 2.222445, LR: 0.050000\n",
      "Seed 79, Epoch [180/1000], Train Loss: 0.862121, Test Loss: 2.252171, LR: 0.050000\n",
      "Seed 79, Epoch [190/1000], Train Loss: 0.871749, Test Loss: 2.337180, LR: 0.050000\n",
      "Seed 79, Epoch [200/1000], Train Loss: 0.851352, Test Loss: 2.332417, LR: 0.050000\n",
      "Seed 79, Epoch [210/1000], Train Loss: 0.830994, Test Loss: 2.347198, LR: 0.050000\n",
      "Seed 79, Epoch [220/1000], Train Loss: 0.881991, Test Loss: 2.374223, LR: 0.050000\n",
      "Seed 79, Epoch [230/1000], Train Loss: 0.864484, Test Loss: 2.368828, LR: 0.050000\n",
      "Seed 79, Epoch [240/1000], Train Loss: 0.827557, Test Loss: 2.383060, LR: 0.050000\n",
      "Seed 79, Epoch [250/1000], Train Loss: 0.870835, Test Loss: 2.388495, LR: 0.050000\n",
      "Seed 79, Epoch [260/1000], Train Loss: 0.836679, Test Loss: 2.355751, LR: 0.050000\n",
      "Seed 79, Epoch [270/1000], Train Loss: 0.800056, Test Loss: 2.349333, LR: 0.050000\n",
      "Seed 79, Epoch [280/1000], Train Loss: 0.775434, Test Loss: 2.392529, LR: 0.050000\n",
      "Seed 79, Epoch [290/1000], Train Loss: 0.768851, Test Loss: 2.374325, LR: 0.050000\n",
      "Seed 79, Epoch [300/1000], Train Loss: 0.755305, Test Loss: 2.352967, LR: 0.050000\n",
      "Seed 79, Epoch [310/1000], Train Loss: 0.751443, Test Loss: 2.316076, LR: 0.050000\n",
      "Seed 79, Epoch [320/1000], Train Loss: 0.738116, Test Loss: 2.327787, LR: 0.050000\n",
      "Seed 79, Epoch [330/1000], Train Loss: 0.737475, Test Loss: 2.265296, LR: 0.050000\n",
      "Seed 79, Epoch [340/1000], Train Loss: 0.753095, Test Loss: 2.187322, LR: 0.050000\n",
      "Seed 79, Epoch [350/1000], Train Loss: 0.769644, Test Loss: 2.136467, LR: 0.050000\n",
      "Seed 79, Epoch [360/1000], Train Loss: 0.695786, Test Loss: 2.114286, LR: 0.050000\n",
      "Seed 79, Epoch [370/1000], Train Loss: 0.752853, Test Loss: 2.000715, LR: 0.050000\n",
      "Seed 79, Epoch [380/1000], Train Loss: 0.706321, Test Loss: 1.958351, LR: 0.050000\n",
      "Seed 79, Epoch [390/1000], Train Loss: 0.766713, Test Loss: 1.865281, LR: 0.050000\n",
      "Seed 79, Epoch [400/1000], Train Loss: 0.679221, Test Loss: 1.865066, LR: 0.050000\n",
      "Seed 79, Epoch [410/1000], Train Loss: 0.678619, Test Loss: 1.711887, LR: 0.050000\n",
      "Seed 79, Epoch [420/1000], Train Loss: 0.693956, Test Loss: 1.554974, LR: 0.050000\n",
      "Seed 79, Epoch [430/1000], Train Loss: 0.665850, Test Loss: 1.514598, LR: 0.050000\n",
      "Seed 79, Epoch [440/1000], Train Loss: 0.709570, Test Loss: 1.428010, LR: 0.050000\n",
      "Seed 79, Epoch [450/1000], Train Loss: 0.651821, Test Loss: 1.338707, LR: 0.050000\n",
      "Seed 79, Epoch [460/1000], Train Loss: 0.637599, Test Loss: 1.218691, LR: 0.050000\n",
      "Seed 79, Epoch [470/1000], Train Loss: 0.636402, Test Loss: 1.026510, LR: 0.050000\n",
      "Seed 79, Epoch [480/1000], Train Loss: 0.625856, Test Loss: 0.930232, LR: 0.050000\n",
      "Seed 79, Epoch [490/1000], Train Loss: 0.622042, Test Loss: 0.833903, LR: 0.050000\n",
      "Seed 79, Epoch [500/1000], Train Loss: 0.647059, Test Loss: 0.756401, LR: 0.050000\n",
      "Seed 79, Epoch [510/1000], Train Loss: 0.623017, Test Loss: 0.682128, LR: 0.050000\n",
      "Seed 79, Epoch [520/1000], Train Loss: 0.627352, Test Loss: 0.694542, LR: 0.050000\n",
      "Seed 79, Epoch [530/1000], Train Loss: 0.607251, Test Loss: 0.779782, LR: 0.050000\n",
      "Seed 79, Epoch [540/1000], Train Loss: 0.613186, Test Loss: 0.827331, LR: 0.050000\n",
      "Seed 79, Epoch [550/1000], Train Loss: 0.618879, Test Loss: 0.902385, LR: 0.050000\n",
      "Seed 79, Epoch [560/1000], Train Loss: 0.603823, Test Loss: 1.183837, LR: 0.050000\n",
      "Seed 79, Epoch [570/1000], Train Loss: 0.593638, Test Loss: 1.784751, LR: 0.050000\n",
      "Seed 79, Epoch [580/1000], Train Loss: 0.645187, Test Loss: 2.562507, LR: 0.050000\n",
      "Seed 79, Epoch [590/1000], Train Loss: 0.603405, Test Loss: 3.053557, LR: 0.050000\n",
      "Seed 79, Epoch [600/1000], Train Loss: 0.594483, Test Loss: 3.994351, LR: 0.050000\n",
      "Seed 79, Epoch [610/1000], Train Loss: 0.570120, Test Loss: 5.078944, LR: 0.050000\n",
      "Seed 79, Epoch [620/1000], Train Loss: 0.736611, Test Loss: 4.798717, LR: 0.050000\n",
      "Seed 79, Epoch [630/1000], Train Loss: 0.629786, Test Loss: 6.042808, LR: 0.050000\n",
      "Seed 79, Epoch [640/1000], Train Loss: 0.585894, Test Loss: 11.106384, LR: 0.050000\n",
      "Seed 79, Epoch [650/1000], Train Loss: 0.561461, Test Loss: 10.520706, LR: 0.050000\n",
      "Seed 79, Epoch [660/1000], Train Loss: 0.552285, Test Loss: 11.658308, LR: 0.050000\n",
      "Seed 79, Epoch [670/1000], Train Loss: 0.588092, Test Loss: 9.610408, LR: 0.050000\n",
      "Seed 79, Epoch [680/1000], Train Loss: 0.560795, Test Loss: 10.555327, LR: 0.050000\n",
      "Seed 79, Epoch [690/1000], Train Loss: 0.583905, Test Loss: 11.606809, LR: 0.050000\n",
      "Seed 79, Epoch [700/1000], Train Loss: 0.561197, Test Loss: 15.623323, LR: 0.050000\n",
      "Seed 79, Epoch [710/1000], Train Loss: 0.560431, Test Loss: 16.427130, LR: 0.050000\n",
      "Seed 79, Epoch [720/1000], Train Loss: 0.578359, Test Loss: 15.852224, LR: 0.050000\n",
      "Seed 79, Epoch [730/1000], Train Loss: 0.542138, Test Loss: 24.209641, LR: 0.050000\n",
      "Seed 79, Epoch [740/1000], Train Loss: 0.539986, Test Loss: 25.110100, LR: 0.050000\n",
      "Seed 79, Epoch [750/1000], Train Loss: 0.554669, Test Loss: 23.898737, LR: 0.050000\n",
      "Seed 79, Epoch [760/1000], Train Loss: 0.569449, Test Loss: 23.959661, LR: 0.050000\n",
      "Seed 79, Epoch [770/1000], Train Loss: 0.546791, Test Loss: 30.990700, LR: 0.050000\n",
      "Seed 79, Epoch [780/1000], Train Loss: 0.556920, Test Loss: 29.572966, LR: 0.050000\n",
      "Seed 79, Epoch [790/1000], Train Loss: 0.538508, Test Loss: 30.251823, LR: 0.050000\n",
      "Seed 79, Epoch [800/1000], Train Loss: 0.541195, Test Loss: 33.725761, LR: 0.050000\n",
      "Seed 79, Epoch [810/1000], Train Loss: 0.551799, Test Loss: 35.323212, LR: 0.050000\n",
      "Seed 79, Epoch [820/1000], Train Loss: 0.545439, Test Loss: 39.329834, LR: 0.050000\n",
      "Seed 79, Epoch [830/1000], Train Loss: 0.543140, Test Loss: 38.624283, LR: 0.050000\n",
      "Seed 79, Epoch [840/1000], Train Loss: 0.542665, Test Loss: 44.392429, LR: 0.050000\n",
      "Seed 79, Epoch [850/1000], Train Loss: 0.540052, Test Loss: 43.638741, LR: 0.050000\n",
      "Seed 79, Epoch [860/1000], Train Loss: 0.527219, Test Loss: 51.692402, LR: 0.050000\n",
      "Seed 79, Epoch [870/1000], Train Loss: 0.652916, Test Loss: 49.929398, LR: 0.050000\n",
      "Seed 79, Epoch [880/1000], Train Loss: 0.565612, Test Loss: 49.827652, LR: 0.050000\n",
      "Seed 79, Epoch [890/1000], Train Loss: 0.540797, Test Loss: 59.087746, LR: 0.050000\n",
      "Seed 79, Epoch [900/1000], Train Loss: 0.530240, Test Loss: 63.424568, LR: 0.050000\n",
      "Seed 79, Epoch [910/1000], Train Loss: 0.604791, Test Loss: 68.824081, LR: 0.050000\n",
      "Seed 79, Epoch [920/1000], Train Loss: 0.611685, Test Loss: 65.182045, LR: 0.050000\n",
      "Seed 79, Epoch [930/1000], Train Loss: 0.557478, Test Loss: 64.964134, LR: 0.050000\n",
      "Seed 79, Epoch [940/1000], Train Loss: 0.526627, Test Loss: 82.035019, LR: 0.050000\n",
      "Seed 79, Epoch [950/1000], Train Loss: 0.533592, Test Loss: 75.479515, LR: 0.050000\n",
      "Seed 79, Epoch [960/1000], Train Loss: 0.566135, Test Loss: 80.772652, LR: 0.050000\n",
      "Seed 79, Epoch [970/1000], Train Loss: 0.534239, Test Loss: 81.417931, LR: 0.050000\n",
      "Seed 79, Epoch [980/1000], Train Loss: 0.539978, Test Loss: 82.188248, LR: 0.050000\n",
      "Seed 79, Epoch [990/1000], Train Loss: 0.532910, Test Loss: 87.009544, LR: 0.050000\n",
      "Seed 79, Epoch [1000/1000], Train Loss: 0.527014, Test Loss: 89.500702, LR: 0.050000\n",
      "Seed 80, Epoch [10/1000], Train Loss: 4.161529, Test Loss: 3.630834, LR: 0.050000\n",
      "Seed 80, Epoch [20/1000], Train Loss: 2.914549, Test Loss: 2.823797, LR: 0.050000\n",
      "Seed 80, Epoch [30/1000], Train Loss: 2.627501, Test Loss: 2.558268, LR: 0.050000\n",
      "Seed 80, Epoch [40/1000], Train Loss: 2.490538, Test Loss: 2.423734, LR: 0.050000\n",
      "Seed 80, Epoch [50/1000], Train Loss: 2.428339, Test Loss: 2.354876, LR: 0.050000\n",
      "Seed 80, Epoch [60/1000], Train Loss: 2.408721, Test Loss: 2.330685, LR: 0.050000\n",
      "Seed 80, Epoch [70/1000], Train Loss: 2.434060, Test Loss: 2.360106, LR: 0.050000\n",
      "Seed 80, Epoch [80/1000], Train Loss: 2.396508, Test Loss: 2.324835, LR: 0.050000\n",
      "Seed 80, Epoch [90/1000], Train Loss: 2.377619, Test Loss: 2.308760, LR: 0.050000\n",
      "Seed 80, Epoch [100/1000], Train Loss: 2.363655, Test Loss: 2.297637, LR: 0.050000\n",
      "Seed 80, Epoch [110/1000], Train Loss: 2.344137, Test Loss: 2.284952, LR: 0.050000\n",
      "Seed 80, Epoch [120/1000], Train Loss: 2.325153, Test Loss: 2.271234, LR: 0.050000\n",
      "Seed 80, Epoch [130/1000], Train Loss: 2.304183, Test Loss: 2.255282, LR: 0.050000\n",
      "Seed 80, Epoch [140/1000], Train Loss: 2.281340, Test Loss: 2.237440, LR: 0.050000\n",
      "Seed 80, Epoch [150/1000], Train Loss: 2.256674, Test Loss: 2.217465, LR: 0.050000\n",
      "Seed 80, Epoch [160/1000], Train Loss: 2.229809, Test Loss: 2.194630, LR: 0.050000\n",
      "Seed 80, Epoch [170/1000], Train Loss: 2.200402, Test Loss: 2.168116, LR: 0.050000\n",
      "Seed 80, Epoch [180/1000], Train Loss: 2.168072, Test Loss: 2.136903, LR: 0.050000\n",
      "Seed 80, Epoch [190/1000], Train Loss: 2.132160, Test Loss: 2.099492, LR: 0.050000\n",
      "Seed 80, Epoch [200/1000], Train Loss: 2.091515, Test Loss: 2.053482, LR: 0.050000\n",
      "Seed 80, Epoch [210/1000], Train Loss: 2.044631, Test Loss: 1.995042, LR: 0.050000\n",
      "Seed 80, Epoch [220/1000], Train Loss: 1.989244, Test Loss: 1.918914, LR: 0.050000\n",
      "Seed 80, Epoch [230/1000], Train Loss: 1.923087, Test Loss: 1.820585, LR: 0.050000\n",
      "Seed 80, Epoch [240/1000], Train Loss: 1.849089, Test Loss: 1.704372, LR: 0.050000\n",
      "Seed 80, Epoch [250/1000], Train Loss: 1.775640, Test Loss: 1.598665, LR: 0.050000\n",
      "Seed 80, Epoch [260/1000], Train Loss: 1.701939, Test Loss: 1.533033, LR: 0.050000\n",
      "Seed 80, Epoch [270/1000], Train Loss: 1.637017, Test Loss: 1.497943, LR: 0.050000\n",
      "Seed 80, Epoch [280/1000], Train Loss: 1.597103, Test Loss: 1.483043, LR: 0.050000\n",
      "Seed 80, Epoch [290/1000], Train Loss: 1.567896, Test Loss: 1.479432, LR: 0.050000\n",
      "Seed 80, Epoch [300/1000], Train Loss: 1.535674, Test Loss: 1.489321, LR: 0.050000\n",
      "Seed 80, Epoch [310/1000], Train Loss: 1.504267, Test Loss: 1.516859, LR: 0.050000\n",
      "Seed 80, Epoch [320/1000], Train Loss: 1.470686, Test Loss: 1.532599, LR: 0.050000\n",
      "Seed 80, Epoch [330/1000], Train Loss: 1.518091, Test Loss: 1.384215, LR: 0.050000\n",
      "Seed 80, Epoch [340/1000], Train Loss: 1.456951, Test Loss: 1.295870, LR: 0.050000\n",
      "Seed 80, Epoch [350/1000], Train Loss: 1.397872, Test Loss: 1.358299, LR: 0.050000\n",
      "Seed 80, Epoch [360/1000], Train Loss: 1.352890, Test Loss: 1.518826, LR: 0.050000\n",
      "Seed 80, Epoch [370/1000], Train Loss: 1.322180, Test Loss: 1.558097, LR: 0.050000\n",
      "Seed 80, Epoch [380/1000], Train Loss: 1.293335, Test Loss: 1.468286, LR: 0.050000\n",
      "Seed 80, Epoch [390/1000], Train Loss: 1.272736, Test Loss: 1.648145, LR: 0.050000\n",
      "Seed 80, Epoch [400/1000], Train Loss: 1.258332, Test Loss: 1.490218, LR: 0.050000\n",
      "Seed 80, Epoch [410/1000], Train Loss: 1.234199, Test Loss: 1.451150, LR: 0.050000\n",
      "Seed 80, Epoch [420/1000], Train Loss: 1.216169, Test Loss: 1.468895, LR: 0.050000\n",
      "Seed 80, Epoch [430/1000], Train Loss: 1.199207, Test Loss: 1.396618, LR: 0.050000\n",
      "Seed 80, Epoch [440/1000], Train Loss: 1.198391, Test Loss: 1.358407, LR: 0.050000\n",
      "Seed 80, Epoch [450/1000], Train Loss: 1.167658, Test Loss: 1.312436, LR: 0.050000\n",
      "Seed 80, Epoch [460/1000], Train Loss: 1.181976, Test Loss: 1.192789, LR: 0.050000\n",
      "Seed 80, Epoch [470/1000], Train Loss: 1.153721, Test Loss: 1.296253, LR: 0.050000\n",
      "Seed 80, Epoch [480/1000], Train Loss: 1.125329, Test Loss: 1.256660, LR: 0.050000\n",
      "Seed 80, Epoch [490/1000], Train Loss: 2.450821, Test Loss: 4.343497, LR: 0.050000\n",
      "Seed 80, Epoch [500/1000], Train Loss: 1.466499, Test Loss: 1.360726, LR: 0.050000\n",
      "Seed 80, Epoch [510/1000], Train Loss: 1.439695, Test Loss: 1.322785, LR: 0.050000\n",
      "Seed 80, Epoch [520/1000], Train Loss: 1.326162, Test Loss: 1.169190, LR: 0.050000\n",
      "Seed 80, Epoch [530/1000], Train Loss: 1.219800, Test Loss: 0.989572, LR: 0.050000\n",
      "Seed 80, Epoch [540/1000], Train Loss: 1.131663, Test Loss: 1.036895, LR: 0.050000\n",
      "Seed 80, Epoch [550/1000], Train Loss: 1.112314, Test Loss: 1.107461, LR: 0.050000\n",
      "Seed 80, Epoch [560/1000], Train Loss: 1.084412, Test Loss: 1.188786, LR: 0.050000\n",
      "Seed 80, Epoch [570/1000], Train Loss: 1.407385, Test Loss: 1.000289, LR: 0.050000\n",
      "Seed 80, Epoch [580/1000], Train Loss: 1.339503, Test Loss: 1.119547, LR: 0.050000\n",
      "Seed 80, Epoch [590/1000], Train Loss: 1.271145, Test Loss: 1.045196, LR: 0.050000\n",
      "Seed 80, Epoch [600/1000], Train Loss: 1.111581, Test Loss: 0.937060, LR: 0.050000\n",
      "Seed 80, Epoch [610/1000], Train Loss: 1.092686, Test Loss: 1.014577, LR: 0.050000\n",
      "Seed 80, Epoch [620/1000], Train Loss: 1.072108, Test Loss: 1.070624, LR: 0.050000\n",
      "Seed 80, Epoch [630/1000], Train Loss: 1.059175, Test Loss: 1.129002, LR: 0.050000\n",
      "Seed 80, Epoch [640/1000], Train Loss: 1.044802, Test Loss: 1.201442, LR: 0.050000\n",
      "Seed 80, Epoch [650/1000], Train Loss: 1.316118, Test Loss: 1.327519, LR: 0.050000\n",
      "Seed 80, Epoch [660/1000], Train Loss: 1.226554, Test Loss: 1.164486, LR: 0.050000\n",
      "Seed 80, Epoch [670/1000], Train Loss: 1.097736, Test Loss: 0.984813, LR: 0.050000\n",
      "Seed 80, Epoch [680/1000], Train Loss: 1.055816, Test Loss: 1.258658, LR: 0.050000\n",
      "Seed 80, Epoch [690/1000], Train Loss: 1.038739, Test Loss: 1.163166, LR: 0.050000\n",
      "Seed 80, Epoch [700/1000], Train Loss: 1.018753, Test Loss: 1.185660, LR: 0.050000\n",
      "Seed 80, Epoch [710/1000], Train Loss: 1.007429, Test Loss: 1.410409, LR: 0.050000\n",
      "Seed 80, Epoch [720/1000], Train Loss: 1.133778, Test Loss: 1.666791, LR: 0.050000\n",
      "Seed 80, Epoch [730/1000], Train Loss: 1.104153, Test Loss: 1.449944, LR: 0.050000\n",
      "Seed 80, Epoch [740/1000], Train Loss: 1.028026, Test Loss: 1.143556, LR: 0.050000\n",
      "Seed 80, Epoch [750/1000], Train Loss: 1.002259, Test Loss: 1.331151, LR: 0.050000\n",
      "Seed 80, Epoch [760/1000], Train Loss: 0.984049, Test Loss: 1.425722, LR: 0.050000\n",
      "Seed 80, Epoch [770/1000], Train Loss: 0.972821, Test Loss: 1.509794, LR: 0.050000\n",
      "Seed 80, Epoch [780/1000], Train Loss: 1.014798, Test Loss: 2.017683, LR: 0.050000\n",
      "Seed 80, Epoch [790/1000], Train Loss: 1.168171, Test Loss: 1.739832, LR: 0.050000\n",
      "Seed 80, Epoch [800/1000], Train Loss: 1.039839, Test Loss: 1.454559, LR: 0.050000\n",
      "Seed 80, Epoch [810/1000], Train Loss: 0.989693, Test Loss: 1.508641, LR: 0.050000\n",
      "Seed 80, Epoch [820/1000], Train Loss: 0.969986, Test Loss: 1.611951, LR: 0.050000\n",
      "Seed 80, Epoch [830/1000], Train Loss: 0.955470, Test Loss: 1.686674, LR: 0.050000\n",
      "Seed 80, Epoch [840/1000], Train Loss: 0.947491, Test Loss: 1.804438, LR: 0.050000\n",
      "Seed 80, Epoch [850/1000], Train Loss: 1.148711, Test Loss: 2.278828, LR: 0.050000\n",
      "Seed 80, Epoch [860/1000], Train Loss: 1.156252, Test Loss: 1.846987, LR: 0.050000\n",
      "Seed 80, Epoch [870/1000], Train Loss: 0.987934, Test Loss: 1.871462, LR: 0.050000\n",
      "Seed 80, Epoch [880/1000], Train Loss: 0.971053, Test Loss: 1.766446, LR: 0.050000\n",
      "Seed 80, Epoch [890/1000], Train Loss: 0.954194, Test Loss: 1.828546, LR: 0.050000\n",
      "Seed 80, Epoch [900/1000], Train Loss: 0.942526, Test Loss: 1.875715, LR: 0.050000\n",
      "Seed 80, Epoch [910/1000], Train Loss: 0.938780, Test Loss: 1.991938, LR: 0.050000\n",
      "Seed 80, Epoch [920/1000], Train Loss: 1.047548, Test Loss: 2.224290, LR: 0.050000\n",
      "Seed 80, Epoch [930/1000], Train Loss: 1.009127, Test Loss: 2.096385, LR: 0.050000\n",
      "Seed 80, Epoch [940/1000], Train Loss: 0.999922, Test Loss: 1.727040, LR: 0.050000\n",
      "Seed 80, Epoch [950/1000], Train Loss: 0.945109, Test Loss: 1.923314, LR: 0.050000\n",
      "Seed 80, Epoch [960/1000], Train Loss: 0.936990, Test Loss: 1.904040, LR: 0.050000\n",
      "Seed 80, Epoch [970/1000], Train Loss: 0.963835, Test Loss: 1.787906, LR: 0.050000\n",
      "Seed 80, Epoch [980/1000], Train Loss: 1.108792, Test Loss: 2.003323, LR: 0.050000\n",
      "Seed 80, Epoch [990/1000], Train Loss: 1.087163, Test Loss: 1.966646, LR: 0.050000\n",
      "Seed 80, Epoch [1000/1000], Train Loss: 0.973694, Test Loss: 1.846629, LR: 0.050000\n",
      "Seed 81, Epoch [10/1000], Train Loss: 3.394145, Test Loss: 2.803523, LR: 0.050000\n",
      "Seed 81, Epoch [20/1000], Train Loss: 2.422458, Test Loss: 2.324262, LR: 0.050000\n",
      "Seed 81, Epoch [30/1000], Train Loss: 2.411111, Test Loss: 2.307126, LR: 0.050000\n",
      "Seed 81, Epoch [40/1000], Train Loss: 2.431410, Test Loss: 2.319864, LR: 0.050000\n",
      "Seed 81, Epoch [50/1000], Train Loss: 2.435648, Test Loss: 2.323132, LR: 0.050000\n",
      "Seed 81, Epoch [60/1000], Train Loss: 2.427134, Test Loss: 2.318632, LR: 0.050000\n",
      "Seed 81, Epoch [70/1000], Train Loss: 2.412584, Test Loss: 2.311606, LR: 0.050000\n",
      "Seed 81, Epoch [80/1000], Train Loss: 2.406744, Test Loss: 2.314368, LR: 0.050000\n",
      "Seed 81, Epoch [90/1000], Train Loss: 2.387615, Test Loss: 2.302433, LR: 0.050000\n",
      "Seed 81, Epoch [100/1000], Train Loss: 2.359436, Test Loss: 2.288944, LR: 0.050000\n",
      "Seed 81, Epoch [110/1000], Train Loss: 2.346648, Test Loss: 2.279394, LR: 0.050000\n",
      "Seed 81, Epoch [120/1000], Train Loss: 2.323986, Test Loss: 2.265022, LR: 0.050000\n",
      "Seed 81, Epoch [130/1000], Train Loss: 2.294335, Test Loss: 2.251473, LR: 0.050000\n",
      "Seed 81, Epoch [140/1000], Train Loss: 2.264426, Test Loss: 2.239430, LR: 0.050000\n",
      "Seed 81, Epoch [150/1000], Train Loss: 2.231139, Test Loss: 2.225279, LR: 0.050000\n",
      "Seed 81, Epoch [160/1000], Train Loss: 2.192348, Test Loss: 2.207871, LR: 0.050000\n",
      "Seed 81, Epoch [170/1000], Train Loss: 2.146312, Test Loss: 2.187485, LR: 0.050000\n",
      "Seed 81, Epoch [180/1000], Train Loss: 2.091399, Test Loss: 2.162320, LR: 0.050000\n",
      "Seed 81, Epoch [190/1000], Train Loss: 2.027836, Test Loss: 2.130667, LR: 0.050000\n",
      "Seed 81, Epoch [200/1000], Train Loss: 1.961734, Test Loss: 2.095064, LR: 0.050000\n",
      "Seed 81, Epoch [210/1000], Train Loss: 1.902661, Test Loss: 2.062996, LR: 0.050000\n",
      "Seed 81, Epoch [220/1000], Train Loss: 1.842275, Test Loss: 2.041373, LR: 0.050000\n",
      "Seed 81, Epoch [230/1000], Train Loss: 1.776139, Test Loss: 2.020038, LR: 0.050000\n",
      "Seed 81, Epoch [240/1000], Train Loss: 1.698434, Test Loss: 1.984993, LR: 0.050000\n",
      "Seed 81, Epoch [250/1000], Train Loss: 1.602137, Test Loss: 1.934886, LR: 0.050000\n",
      "Seed 81, Epoch [260/1000], Train Loss: 1.525075, Test Loss: 1.869376, LR: 0.050000\n",
      "Seed 81, Epoch [270/1000], Train Loss: 1.495501, Test Loss: 1.826551, LR: 0.050000\n",
      "Seed 81, Epoch [280/1000], Train Loss: 1.474463, Test Loss: 1.810976, LR: 0.050000\n",
      "Seed 81, Epoch [290/1000], Train Loss: 1.458800, Test Loss: 1.791677, LR: 0.050000\n",
      "Seed 81, Epoch [300/1000], Train Loss: 1.441189, Test Loss: 1.767041, LR: 0.050000\n",
      "Seed 81, Epoch [310/1000], Train Loss: 1.423115, Test Loss: 1.748413, LR: 0.050000\n",
      "Seed 81, Epoch [320/1000], Train Loss: 1.403933, Test Loss: 1.732300, LR: 0.050000\n",
      "Seed 81, Epoch [330/1000], Train Loss: 1.383689, Test Loss: 1.717291, LR: 0.050000\n",
      "Seed 81, Epoch [340/1000], Train Loss: 1.362256, Test Loss: 1.704024, LR: 0.050000\n",
      "Seed 81, Epoch [350/1000], Train Loss: 1.339702, Test Loss: 1.693919, LR: 0.050000\n",
      "Seed 81, Epoch [360/1000], Train Loss: 1.316198, Test Loss: 1.686255, LR: 0.050000\n",
      "Seed 81, Epoch [370/1000], Train Loss: 1.291965, Test Loss: 1.681123, LR: 0.050000\n",
      "Seed 81, Epoch [380/1000], Train Loss: 1.267390, Test Loss: 1.679284, LR: 0.050000\n",
      "Seed 81, Epoch [390/1000], Train Loss: 1.243071, Test Loss: 1.681633, LR: 0.050000\n",
      "Seed 81, Epoch [400/1000], Train Loss: 1.626528, Test Loss: 1.671506, LR: 0.050000\n",
      "Seed 81, Epoch [410/1000], Train Loss: 1.316305, Test Loss: 1.739513, LR: 0.050000\n",
      "Seed 81, Epoch [420/1000], Train Loss: 1.249036, Test Loss: 1.696625, LR: 0.050000\n",
      "Seed 81, Epoch [430/1000], Train Loss: 1.195758, Test Loss: 1.655656, LR: 0.050000\n",
      "Seed 81, Epoch [440/1000], Train Loss: 1.153080, Test Loss: 1.712451, LR: 0.050000\n",
      "Seed 81, Epoch [450/1000], Train Loss: 1.131133, Test Loss: 1.722143, LR: 0.050000\n",
      "Seed 81, Epoch [460/1000], Train Loss: 1.106668, Test Loss: 1.736376, LR: 0.050000\n",
      "Seed 81, Epoch [470/1000], Train Loss: 1.079962, Test Loss: 1.771115, LR: 0.050000\n",
      "Seed 81, Epoch [480/1000], Train Loss: 1.053386, Test Loss: 1.766769, LR: 0.050000\n",
      "Seed 81, Epoch [490/1000], Train Loss: 1.077455, Test Loss: 1.693304, LR: 0.050000\n",
      "Seed 81, Epoch [500/1000], Train Loss: 1.026957, Test Loss: 1.673267, LR: 0.050000\n",
      "Seed 81, Epoch [510/1000], Train Loss: 0.980026, Test Loss: 1.918648, LR: 0.050000\n",
      "Seed 81, Epoch [520/1000], Train Loss: 0.969334, Test Loss: 1.896444, LR: 0.050000\n",
      "Seed 81, Epoch [530/1000], Train Loss: 0.904788, Test Loss: 2.095156, LR: 0.050000\n",
      "Seed 81, Epoch [540/1000], Train Loss: 0.947453, Test Loss: 2.085398, LR: 0.050000\n",
      "Seed 81, Epoch [550/1000], Train Loss: 0.867311, Test Loss: 2.313872, LR: 0.050000\n",
      "Seed 81, Epoch [560/1000], Train Loss: 0.853067, Test Loss: 2.546642, LR: 0.050000\n",
      "Seed 81, Epoch [570/1000], Train Loss: 0.845908, Test Loss: 2.568970, LR: 0.050000\n",
      "Seed 81, Epoch [580/1000], Train Loss: 0.824144, Test Loss: 2.771997, LR: 0.050000\n",
      "Seed 81, Epoch [590/1000], Train Loss: 0.881880, Test Loss: 2.971768, LR: 0.050000\n",
      "Seed 81, Epoch [600/1000], Train Loss: 0.799835, Test Loss: 2.499992, LR: 0.050000\n",
      "Seed 81, Epoch [610/1000], Train Loss: 0.802239, Test Loss: 2.821878, LR: 0.050000\n",
      "Seed 81, Epoch [620/1000], Train Loss: 0.777291, Test Loss: 2.999591, LR: 0.050000\n",
      "Seed 81, Epoch [630/1000], Train Loss: 0.756795, Test Loss: 2.932388, LR: 0.050000\n",
      "Seed 81, Epoch [640/1000], Train Loss: 0.856542, Test Loss: 2.253965, LR: 0.050000\n",
      "Seed 81, Epoch [650/1000], Train Loss: 0.813921, Test Loss: 2.066546, LR: 0.050000\n",
      "Seed 81, Epoch [660/1000], Train Loss: 0.769830, Test Loss: 2.492104, LR: 0.050000\n",
      "Seed 81, Epoch [670/1000], Train Loss: 0.737002, Test Loss: 2.739897, LR: 0.050000\n",
      "Seed 81, Epoch [680/1000], Train Loss: 0.713528, Test Loss: 2.631602, LR: 0.050000\n",
      "Seed 81, Epoch [690/1000], Train Loss: 0.707676, Test Loss: 2.567314, LR: 0.050000\n",
      "Seed 81, Epoch [700/1000], Train Loss: 0.698613, Test Loss: 2.604199, LR: 0.050000\n",
      "Seed 81, Epoch [710/1000], Train Loss: 0.692157, Test Loss: 2.563620, LR: 0.050000\n",
      "Seed 81, Epoch [720/1000], Train Loss: 0.686856, Test Loss: 2.544498, LR: 0.050000\n",
      "Seed 81, Epoch [730/1000], Train Loss: 0.736078, Test Loss: 2.406048, LR: 0.050000\n",
      "Seed 81, Epoch [740/1000], Train Loss: 0.683701, Test Loss: 2.388749, LR: 0.050000\n",
      "Seed 81, Epoch [750/1000], Train Loss: 0.678787, Test Loss: 2.421938, LR: 0.050000\n",
      "Seed 81, Epoch [760/1000], Train Loss: 0.673744, Test Loss: 2.366659, LR: 0.050000\n",
      "Seed 81, Epoch [770/1000], Train Loss: 0.671875, Test Loss: 2.352763, LR: 0.050000\n",
      "Seed 81, Epoch [780/1000], Train Loss: 0.672876, Test Loss: 2.327896, LR: 0.050000\n",
      "Seed 81, Epoch [790/1000], Train Loss: 0.657940, Test Loss: 2.337963, LR: 0.050000\n",
      "Seed 81, Epoch [800/1000], Train Loss: 0.664382, Test Loss: 2.153901, LR: 0.050000\n",
      "Seed 81, Epoch [810/1000], Train Loss: 0.681600, Test Loss: 2.123151, LR: 0.050000\n",
      "Seed 81, Epoch [820/1000], Train Loss: 0.654893, Test Loss: 2.230131, LR: 0.050000\n",
      "Seed 81, Epoch [830/1000], Train Loss: 0.665105, Test Loss: 2.260688, LR: 0.050000\n",
      "Seed 81, Epoch [840/1000], Train Loss: 0.647238, Test Loss: 2.218404, LR: 0.050000\n",
      "Seed 81, Epoch [850/1000], Train Loss: 0.641029, Test Loss: 2.220700, LR: 0.050000\n",
      "Seed 81, Epoch [860/1000], Train Loss: 0.637551, Test Loss: 2.198412, LR: 0.050000\n",
      "Seed 81, Epoch [870/1000], Train Loss: 0.787382, Test Loss: 2.115323, LR: 0.050000\n",
      "Seed 81, Epoch [880/1000], Train Loss: 0.661196, Test Loss: 2.124212, LR: 0.050000\n",
      "Seed 81, Epoch [890/1000], Train Loss: 0.645618, Test Loss: 2.152810, LR: 0.050000\n",
      "Seed 81, Epoch [900/1000], Train Loss: 1.098591, Test Loss: 2.317678, LR: 0.050000\n",
      "Early stopping at epoch 901 for seed 81\n",
      "Seed 82, Epoch [10/1000], Train Loss: 2.415366, Test Loss: 2.124551, LR: 0.050000\n",
      "Seed 82, Epoch [20/1000], Train Loss: 2.402784, Test Loss: 2.274747, LR: 0.050000\n",
      "Seed 82, Epoch [30/1000], Train Loss: 2.468878, Test Loss: 2.352517, LR: 0.050000\n",
      "Seed 82, Epoch [40/1000], Train Loss: 2.471164, Test Loss: 2.346232, LR: 0.050000\n",
      "Seed 82, Epoch [50/1000], Train Loss: 2.492216, Test Loss: 2.389839, LR: 0.050000\n",
      "Seed 82, Epoch [60/1000], Train Loss: 2.490292, Test Loss: 2.352748, LR: 0.050000\n",
      "Seed 82, Epoch [70/1000], Train Loss: 2.458529, Test Loss: 2.324162, LR: 0.050000\n",
      "Seed 82, Epoch [80/1000], Train Loss: 2.432170, Test Loss: 2.306984, LR: 0.050000\n",
      "Seed 82, Epoch [90/1000], Train Loss: 2.426366, Test Loss: 2.302623, LR: 0.050000\n",
      "Seed 82, Epoch [100/1000], Train Loss: 2.420011, Test Loss: 2.294853, LR: 0.050000\n",
      "Seed 82, Epoch [110/1000], Train Loss: 2.412698, Test Loss: 2.291880, LR: 0.050000\n",
      "Seed 82, Epoch [120/1000], Train Loss: 2.408839, Test Loss: 2.288706, LR: 0.050000\n",
      "Seed 82, Epoch [130/1000], Train Loss: 2.405818, Test Loss: 2.285486, LR: 0.050000\n",
      "Seed 82, Epoch [140/1000], Train Loss: 2.401397, Test Loss: 2.283096, LR: 0.050000\n",
      "Seed 82, Epoch [150/1000], Train Loss: 2.398433, Test Loss: 2.278431, LR: 0.050000\n",
      "Seed 82, Epoch [160/1000], Train Loss: 2.393695, Test Loss: 2.274700, LR: 0.050000\n",
      "Seed 82, Epoch [170/1000], Train Loss: 2.390104, Test Loss: 2.270888, LR: 0.050000\n",
      "Seed 82, Epoch [180/1000], Train Loss: 2.385392, Test Loss: 2.268976, LR: 0.050000\n",
      "Seed 82, Epoch [190/1000], Train Loss: 2.381104, Test Loss: 2.263224, LR: 0.050000\n",
      "Seed 82, Epoch [200/1000], Train Loss: 2.377170, Test Loss: 2.259059, LR: 0.050000\n",
      "Seed 82, Epoch [210/1000], Train Loss: 2.372234, Test Loss: 2.254478, LR: 0.050000\n",
      "Seed 82, Epoch [220/1000], Train Loss: 2.367488, Test Loss: 2.249897, LR: 0.050000\n",
      "Seed 82, Epoch [230/1000], Train Loss: 2.362683, Test Loss: 2.243957, LR: 0.050000\n",
      "Seed 82, Epoch [240/1000], Train Loss: 2.357698, Test Loss: 2.241168, LR: 0.050000\n",
      "Seed 82, Epoch [250/1000], Train Loss: 2.352587, Test Loss: 2.234096, LR: 0.050000\n",
      "Seed 82, Epoch [260/1000], Train Loss: 2.347303, Test Loss: 2.228816, LR: 0.050000\n",
      "Seed 82, Epoch [270/1000], Train Loss: 2.341880, Test Loss: 2.221895, LR: 0.050000\n",
      "Seed 82, Epoch [280/1000], Train Loss: 2.336406, Test Loss: 2.216788, LR: 0.050000\n",
      "Seed 82, Epoch [290/1000], Train Loss: 2.331200, Test Loss: 2.209664, LR: 0.050000\n",
      "Seed 82, Epoch [300/1000], Train Loss: 2.324596, Test Loss: 2.204414, LR: 0.050000\n",
      "Seed 82, Epoch [310/1000], Train Loss: 2.319154, Test Loss: 2.198715, LR: 0.050000\n",
      "Seed 82, Epoch [320/1000], Train Loss: 2.312189, Test Loss: 2.189800, LR: 0.050000\n",
      "Seed 82, Epoch [330/1000], Train Loss: 2.306380, Test Loss: 2.185043, LR: 0.050000\n",
      "Seed 82, Epoch [340/1000], Train Loss: 2.298819, Test Loss: 2.176146, LR: 0.050000\n",
      "Seed 82, Epoch [350/1000], Train Loss: 2.291641, Test Loss: 2.167804, LR: 0.050000\n",
      "Seed 82, Epoch [360/1000], Train Loss: 2.284261, Test Loss: 2.161368, LR: 0.050000\n",
      "Seed 82, Epoch [370/1000], Train Loss: 2.275901, Test Loss: 2.152610, LR: 0.050000\n",
      "Seed 82, Epoch [380/1000], Train Loss: 2.268322, Test Loss: 2.145384, LR: 0.050000\n",
      "Seed 82, Epoch [390/1000], Train Loss: 2.258347, Test Loss: 2.135512, LR: 0.050000\n",
      "Seed 82, Epoch [400/1000], Train Loss: 2.248595, Test Loss: 2.126961, LR: 0.050000\n",
      "Seed 82, Epoch [410/1000], Train Loss: 2.238075, Test Loss: 2.118223, LR: 0.050000\n",
      "Seed 82, Epoch [420/1000], Train Loss: 2.227905, Test Loss: 2.112257, LR: 0.050000\n",
      "Seed 82, Epoch [430/1000], Train Loss: 2.215340, Test Loss: 2.100310, LR: 0.050000\n",
      "Seed 82, Epoch [440/1000], Train Loss: 2.204099, Test Loss: 2.094127, LR: 0.050000\n",
      "Seed 82, Epoch [450/1000], Train Loss: 2.191918, Test Loss: 2.082076, LR: 0.050000\n",
      "Seed 82, Epoch [460/1000], Train Loss: 2.178562, Test Loss: 2.072719, LR: 0.050000\n",
      "Seed 82, Epoch [470/1000], Train Loss: 2.166167, Test Loss: 2.062389, LR: 0.050000\n",
      "Seed 82, Epoch [480/1000], Train Loss: 2.154026, Test Loss: 2.051675, LR: 0.050000\n",
      "Seed 82, Epoch [490/1000], Train Loss: 2.142045, Test Loss: 2.044809, LR: 0.050000\n",
      "Seed 82, Epoch [500/1000], Train Loss: 2.129978, Test Loss: 2.031510, LR: 0.050000\n",
      "Seed 82, Epoch [510/1000], Train Loss: 2.118126, Test Loss: 2.021502, LR: 0.050000\n",
      "Seed 82, Epoch [520/1000], Train Loss: 2.106287, Test Loss: 2.011667, LR: 0.050000\n",
      "Seed 82, Epoch [530/1000], Train Loss: 2.094841, Test Loss: 2.004585, LR: 0.050000\n",
      "Seed 82, Epoch [540/1000], Train Loss: 2.081922, Test Loss: 1.994049, LR: 0.050000\n",
      "Seed 82, Epoch [550/1000], Train Loss: 2.069416, Test Loss: 1.980221, LR: 0.050000\n",
      "Seed 82, Epoch [560/1000], Train Loss: 2.056542, Test Loss: 1.972888, LR: 0.050000\n",
      "Seed 82, Epoch [570/1000], Train Loss: 2.043252, Test Loss: 1.959601, LR: 0.050000\n",
      "Seed 82, Epoch [580/1000], Train Loss: 2.030134, Test Loss: 1.951022, LR: 0.050000\n",
      "Seed 82, Epoch [590/1000], Train Loss: 2.016059, Test Loss: 1.940476, LR: 0.050000\n",
      "Seed 82, Epoch [600/1000], Train Loss: 2.000596, Test Loss: 1.927487, LR: 0.050000\n",
      "Seed 82, Epoch [610/1000], Train Loss: 1.985003, Test Loss: 1.912592, LR: 0.050000\n",
      "Seed 82, Epoch [620/1000], Train Loss: 1.967503, Test Loss: 1.900114, LR: 0.050000\n",
      "Seed 82, Epoch [630/1000], Train Loss: 1.950641, Test Loss: 1.888419, LR: 0.050000\n",
      "Seed 82, Epoch [640/1000], Train Loss: 1.929900, Test Loss: 1.873817, LR: 0.050000\n",
      "Seed 82, Epoch [650/1000], Train Loss: 1.909839, Test Loss: 1.856866, LR: 0.050000\n",
      "Seed 82, Epoch [660/1000], Train Loss: 1.885976, Test Loss: 1.839488, LR: 0.050000\n",
      "Seed 82, Epoch [670/1000], Train Loss: 1.858983, Test Loss: 1.818927, LR: 0.050000\n",
      "Seed 82, Epoch [680/1000], Train Loss: 1.828096, Test Loss: 1.793992, LR: 0.050000\n",
      "Seed 82, Epoch [690/1000], Train Loss: 1.796003, Test Loss: 1.771215, LR: 0.050000\n",
      "Seed 82, Epoch [700/1000], Train Loss: 1.760727, Test Loss: 1.739209, LR: 0.050000\n",
      "Seed 82, Epoch [710/1000], Train Loss: 1.718960, Test Loss: 1.701889, LR: 0.050000\n",
      "Seed 82, Epoch [720/1000], Train Loss: 1.676257, Test Loss: 1.668407, LR: 0.050000\n",
      "Seed 82, Epoch [730/1000], Train Loss: 1.640344, Test Loss: 1.637177, LR: 0.050000\n",
      "Seed 82, Epoch [740/1000], Train Loss: 1.615693, Test Loss: 1.610993, LR: 0.050000\n",
      "Seed 82, Epoch [750/1000], Train Loss: 1.597363, Test Loss: 1.607412, LR: 0.050000\n",
      "Seed 82, Epoch [760/1000], Train Loss: 1.579346, Test Loss: 1.615374, LR: 0.050000\n",
      "Seed 82, Epoch [770/1000], Train Loss: 1.561473, Test Loss: 1.614809, LR: 0.050000\n",
      "Seed 82, Epoch [780/1000], Train Loss: 1.542624, Test Loss: 1.610991, LR: 0.050000\n",
      "Seed 82, Epoch [790/1000], Train Loss: 1.525280, Test Loss: 1.607723, LR: 0.050000\n",
      "Seed 82, Epoch [800/1000], Train Loss: 1.507476, Test Loss: 1.597551, LR: 0.050000\n",
      "Seed 82, Epoch [810/1000], Train Loss: 1.490120, Test Loss: 1.588177, LR: 0.050000\n",
      "Seed 82, Epoch [820/1000], Train Loss: 1.472525, Test Loss: 1.570264, LR: 0.050000\n",
      "Seed 82, Epoch [830/1000], Train Loss: 1.455297, Test Loss: 1.549694, LR: 0.050000\n",
      "Seed 82, Epoch [840/1000], Train Loss: 1.436139, Test Loss: 1.524730, LR: 0.050000\n",
      "Seed 82, Epoch [850/1000], Train Loss: 1.417224, Test Loss: 1.496247, LR: 0.050000\n",
      "Seed 82, Epoch [860/1000], Train Loss: 1.396558, Test Loss: 1.463169, LR: 0.050000\n",
      "Seed 82, Epoch [870/1000], Train Loss: 1.374689, Test Loss: 1.425623, LR: 0.050000\n",
      "Seed 82, Epoch [880/1000], Train Loss: 1.351281, Test Loss: 1.381804, LR: 0.050000\n",
      "Seed 82, Epoch [890/1000], Train Loss: 1.326816, Test Loss: 1.333379, LR: 0.050000\n",
      "Seed 82, Epoch [900/1000], Train Loss: 1.300065, Test Loss: 1.290867, LR: 0.050000\n",
      "Seed 82, Epoch [910/1000], Train Loss: 1.273574, Test Loss: 1.258357, LR: 0.050000\n",
      "Seed 82, Epoch [920/1000], Train Loss: 1.246030, Test Loss: 1.237420, LR: 0.050000\n",
      "Seed 82, Epoch [930/1000], Train Loss: 1.219918, Test Loss: 1.231126, LR: 0.050000\n",
      "Seed 82, Epoch [940/1000], Train Loss: 1.197563, Test Loss: 1.236599, LR: 0.050000\n",
      "Seed 82, Epoch [950/1000], Train Loss: 1.177437, Test Loss: 1.251104, LR: 0.050000\n",
      "Seed 82, Epoch [960/1000], Train Loss: 1.162148, Test Loss: 1.274593, LR: 0.050000\n",
      "Seed 82, Epoch [970/1000], Train Loss: 1.148817, Test Loss: 1.301037, LR: 0.050000\n",
      "Seed 82, Epoch [980/1000], Train Loss: 1.138492, Test Loss: 1.330512, LR: 0.050000\n",
      "Seed 82, Epoch [990/1000], Train Loss: 1.129770, Test Loss: 1.353450, LR: 0.050000\n",
      "Seed 82, Epoch [1000/1000], Train Loss: 1.122822, Test Loss: 1.379788, LR: 0.050000\n",
      "Seed 83, Epoch [10/1000], Train Loss: 2.439811, Test Loss: 2.261756, LR: 0.050000\n",
      "Seed 83, Epoch [20/1000], Train Loss: 2.403881, Test Loss: 2.311728, LR: 0.050000\n",
      "Seed 83, Epoch [30/1000], Train Loss: 2.445360, Test Loss: 2.347388, LR: 0.050000\n",
      "Seed 83, Epoch [40/1000], Train Loss: 2.428433, Test Loss: 2.341335, LR: 0.050000\n",
      "Seed 83, Epoch [50/1000], Train Loss: 2.391221, Test Loss: 2.316305, LR: 0.050000\n",
      "Seed 83, Epoch [60/1000], Train Loss: 2.348180, Test Loss: 2.281395, LR: 0.050000\n",
      "Seed 83, Epoch [70/1000], Train Loss: 2.293467, Test Loss: 2.234317, LR: 0.050000\n",
      "Seed 83, Epoch [80/1000], Train Loss: 2.226443, Test Loss: 2.180591, LR: 0.050000\n",
      "Seed 83, Epoch [90/1000], Train Loss: 2.154377, Test Loss: 2.133515, LR: 0.050000\n",
      "Seed 83, Epoch [100/1000], Train Loss: 2.073447, Test Loss: 2.101234, LR: 0.050000\n",
      "Seed 83, Epoch [110/1000], Train Loss: 1.978147, Test Loss: 2.075128, LR: 0.050000\n",
      "Seed 83, Epoch [120/1000], Train Loss: 1.877467, Test Loss: 2.028046, LR: 0.050000\n",
      "Seed 83, Epoch [130/1000], Train Loss: 1.805328, Test Loss: 1.943100, LR: 0.050000\n",
      "Seed 83, Epoch [140/1000], Train Loss: 1.728585, Test Loss: 1.837073, LR: 0.050000\n",
      "Seed 83, Epoch [150/1000], Train Loss: 1.626732, Test Loss: 1.654201, LR: 0.050000\n",
      "Seed 83, Epoch [160/1000], Train Loss: 1.532362, Test Loss: 1.443343, LR: 0.050000\n",
      "Seed 83, Epoch [170/1000], Train Loss: 1.436753, Test Loss: 1.320144, LR: 0.050000\n",
      "Seed 83, Epoch [180/1000], Train Loss: 1.393849, Test Loss: 1.210402, LR: 0.050000\n",
      "Seed 83, Epoch [190/1000], Train Loss: 1.355708, Test Loss: 1.214876, LR: 0.050000\n",
      "Seed 83, Epoch [200/1000], Train Loss: 1.327433, Test Loss: 1.191550, LR: 0.050000\n",
      "Seed 83, Epoch [210/1000], Train Loss: 1.294431, Test Loss: 1.136565, LR: 0.050000\n",
      "Seed 83, Epoch [220/1000], Train Loss: 1.255887, Test Loss: 1.097411, LR: 0.050000\n",
      "Seed 83, Epoch [230/1000], Train Loss: 1.208293, Test Loss: 1.071254, LR: 0.050000\n",
      "Seed 83, Epoch [240/1000], Train Loss: 1.154835, Test Loss: 1.108403, LR: 0.050000\n",
      "Seed 83, Epoch [250/1000], Train Loss: 1.102790, Test Loss: 1.303453, LR: 0.050000\n",
      "Seed 83, Epoch [260/1000], Train Loss: 1.095545, Test Loss: 2.004469, LR: 0.050000\n",
      "Seed 83, Epoch [270/1000], Train Loss: 1.056547, Test Loss: 1.595073, LR: 0.050000\n",
      "Seed 83, Epoch [280/1000], Train Loss: 1.049447, Test Loss: 1.716383, LR: 0.050000\n",
      "Seed 83, Epoch [290/1000], Train Loss: 1.027524, Test Loss: 1.721867, LR: 0.050000\n",
      "Seed 83, Epoch [300/1000], Train Loss: 1.312116, Test Loss: 2.628047, LR: 0.050000\n",
      "Seed 83, Epoch [310/1000], Train Loss: 1.245247, Test Loss: 1.156148, LR: 0.050000\n",
      "Seed 83, Epoch [320/1000], Train Loss: 1.121123, Test Loss: 1.325060, LR: 0.050000\n",
      "Seed 83, Epoch [330/1000], Train Loss: 1.041441, Test Loss: 1.377163, LR: 0.050000\n",
      "Seed 83, Epoch [340/1000], Train Loss: 1.010120, Test Loss: 1.446581, LR: 0.050000\n",
      "Seed 83, Epoch [350/1000], Train Loss: 0.986282, Test Loss: 1.381320, LR: 0.050000\n",
      "Seed 83, Epoch [360/1000], Train Loss: 0.971225, Test Loss: 1.605636, LR: 0.050000\n",
      "Seed 83, Epoch [370/1000], Train Loss: 0.962331, Test Loss: 1.730788, LR: 0.050000\n",
      "Seed 83, Epoch [380/1000], Train Loss: 0.954519, Test Loss: 1.770775, LR: 0.050000\n",
      "Seed 83, Epoch [390/1000], Train Loss: 0.948450, Test Loss: 1.798027, LR: 0.050000\n",
      "Seed 83, Epoch [400/1000], Train Loss: 0.942704, Test Loss: 1.848760, LR: 0.050000\n",
      "Seed 83, Epoch [410/1000], Train Loss: 0.938373, Test Loss: 1.880168, LR: 0.050000\n",
      "Seed 83, Epoch [420/1000], Train Loss: 0.934128, Test Loss: 1.949982, LR: 0.050000\n",
      "Seed 83, Epoch [430/1000], Train Loss: 0.929874, Test Loss: 1.973315, LR: 0.050000\n",
      "Seed 83, Epoch [440/1000], Train Loss: 0.926462, Test Loss: 1.960293, LR: 0.050000\n",
      "Seed 83, Epoch [450/1000], Train Loss: 0.923110, Test Loss: 2.033392, LR: 0.050000\n",
      "Seed 83, Epoch [460/1000], Train Loss: 0.920734, Test Loss: 2.013245, LR: 0.050000\n",
      "Seed 83, Epoch [470/1000], Train Loss: 0.917735, Test Loss: 2.041675, LR: 0.050000\n",
      "Seed 83, Epoch [480/1000], Train Loss: 0.915624, Test Loss: 2.068252, LR: 0.050000\n",
      "Seed 83, Epoch [490/1000], Train Loss: 0.913407, Test Loss: 2.086267, LR: 0.050000\n",
      "Seed 83, Epoch [500/1000], Train Loss: 0.911387, Test Loss: 2.142655, LR: 0.050000\n",
      "Seed 83, Epoch [510/1000], Train Loss: 0.909722, Test Loss: 2.153971, LR: 0.050000\n",
      "Seed 83, Epoch [520/1000], Train Loss: 0.908735, Test Loss: 2.082962, LR: 0.050000\n",
      "Seed 83, Epoch [530/1000], Train Loss: 0.906392, Test Loss: 2.053975, LR: 0.050000\n",
      "Seed 83, Epoch [540/1000], Train Loss: 0.984758, Test Loss: 1.951906, LR: 0.050000\n",
      "Seed 83, Epoch [550/1000], Train Loss: 0.961484, Test Loss: 1.576575, LR: 0.050000\n",
      "Seed 83, Epoch [560/1000], Train Loss: 0.922932, Test Loss: 1.649743, LR: 0.050000\n",
      "Seed 83, Epoch [570/1000], Train Loss: 0.916895, Test Loss: 1.911840, LR: 0.050000\n",
      "Seed 83, Epoch [580/1000], Train Loss: 0.906264, Test Loss: 2.097119, LR: 0.050000\n",
      "Seed 83, Epoch [590/1000], Train Loss: 0.902984, Test Loss: 2.062926, LR: 0.050000\n",
      "Seed 83, Epoch [600/1000], Train Loss: 0.900601, Test Loss: 2.088752, LR: 0.050000\n",
      "Seed 83, Epoch [610/1000], Train Loss: 0.899824, Test Loss: 2.111964, LR: 0.050000\n",
      "Seed 83, Epoch [620/1000], Train Loss: 0.898261, Test Loss: 2.131005, LR: 0.050000\n",
      "Seed 83, Epoch [630/1000], Train Loss: 0.898232, Test Loss: 2.261300, LR: 0.050000\n",
      "Seed 83, Epoch [640/1000], Train Loss: 0.898632, Test Loss: 2.108351, LR: 0.050000\n",
      "Seed 83, Epoch [650/1000], Train Loss: 0.895691, Test Loss: 2.148680, LR: 0.050000\n",
      "Seed 83, Epoch [660/1000], Train Loss: 0.897034, Test Loss: 2.320271, LR: 0.050000\n",
      "Seed 83, Epoch [670/1000], Train Loss: 0.956331, Test Loss: 1.846026, LR: 0.050000\n",
      "Seed 83, Epoch [680/1000], Train Loss: 0.904805, Test Loss: 1.934740, LR: 0.050000\n",
      "Seed 83, Epoch [690/1000], Train Loss: 0.903729, Test Loss: 2.095105, LR: 0.050000\n",
      "Seed 83, Epoch [700/1000], Train Loss: 0.899511, Test Loss: 2.161287, LR: 0.050000\n",
      "Seed 83, Epoch [710/1000], Train Loss: 0.897854, Test Loss: 2.112959, LR: 0.050000\n",
      "Seed 83, Epoch [720/1000], Train Loss: 0.937054, Test Loss: 1.831029, LR: 0.050000\n",
      "Seed 83, Epoch [730/1000], Train Loss: 0.931747, Test Loss: 2.166593, LR: 0.050000\n",
      "Seed 83, Epoch [740/1000], Train Loss: 0.903316, Test Loss: 2.046921, LR: 0.050000\n",
      "Seed 83, Epoch [750/1000], Train Loss: 0.900840, Test Loss: 1.899708, LR: 0.050000\n",
      "Seed 83, Epoch [760/1000], Train Loss: 0.925944, Test Loss: 1.794523, LR: 0.050000\n",
      "Seed 83, Epoch [770/1000], Train Loss: 0.913940, Test Loss: 1.870701, LR: 0.050000\n",
      "Seed 83, Epoch [780/1000], Train Loss: 0.913482, Test Loss: 2.046080, LR: 0.050000\n",
      "Seed 83, Epoch [790/1000], Train Loss: 0.983950, Test Loss: 1.593839, LR: 0.050000\n",
      "Seed 83, Epoch [800/1000], Train Loss: 0.906521, Test Loss: 1.785105, LR: 0.050000\n",
      "Early stopping at epoch 803 for seed 83\n",
      "Seed 84, Epoch [10/1000], Train Loss: 2.152730, Test Loss: 2.091470, LR: 0.050000\n",
      "Seed 84, Epoch [20/1000], Train Loss: 2.272626, Test Loss: 2.138623, LR: 0.050000\n",
      "Seed 84, Epoch [30/1000], Train Loss: 2.016901, Test Loss: 1.867856, LR: 0.050000\n",
      "Seed 84, Epoch [40/1000], Train Loss: 1.578580, Test Loss: 1.517684, LR: 0.050000\n",
      "Seed 84, Epoch [50/1000], Train Loss: 1.246886, Test Loss: 1.169762, LR: 0.050000\n",
      "Seed 84, Epoch [60/1000], Train Loss: 1.172051, Test Loss: 1.093496, LR: 0.050000\n",
      "Seed 84, Epoch [70/1000], Train Loss: 1.106039, Test Loss: 1.185149, LR: 0.050000\n",
      "Seed 84, Epoch [80/1000], Train Loss: 1.046589, Test Loss: 1.504779, LR: 0.050000\n",
      "Seed 84, Epoch [90/1000], Train Loss: 1.006870, Test Loss: 1.905607, LR: 0.050000\n",
      "Seed 84, Epoch [100/1000], Train Loss: 1.007546, Test Loss: 2.235901, LR: 0.050000\n",
      "Seed 84, Epoch [110/1000], Train Loss: 0.984604, Test Loss: 2.165679, LR: 0.050000\n",
      "Seed 84, Epoch [120/1000], Train Loss: 0.978220, Test Loss: 2.186126, LR: 0.050000\n",
      "Seed 84, Epoch [130/1000], Train Loss: 0.979062, Test Loss: 2.193127, LR: 0.050000\n",
      "Seed 84, Epoch [140/1000], Train Loss: 0.959175, Test Loss: 2.369347, LR: 0.050000\n",
      "Seed 84, Epoch [150/1000], Train Loss: 1.001401, Test Loss: 2.295824, LR: 0.050000\n",
      "Seed 84, Epoch [160/1000], Train Loss: 0.994468, Test Loss: 1.831832, LR: 0.050000\n",
      "Seed 84, Epoch [170/1000], Train Loss: 0.990686, Test Loss: 1.996961, LR: 0.050000\n",
      "Seed 84, Epoch [180/1000], Train Loss: 0.943832, Test Loss: 1.988299, LR: 0.050000\n",
      "Seed 84, Epoch [190/1000], Train Loss: 0.921645, Test Loss: 2.129306, LR: 0.050000\n",
      "Seed 84, Epoch [200/1000], Train Loss: 0.900904, Test Loss: 2.259733, LR: 0.050000\n",
      "Seed 84, Epoch [210/1000], Train Loss: 0.894744, Test Loss: 2.397324, LR: 0.050000\n",
      "Seed 84, Epoch [220/1000], Train Loss: 0.890697, Test Loss: 2.567760, LR: 0.050000\n",
      "Seed 84, Epoch [230/1000], Train Loss: 0.907197, Test Loss: 2.427008, LR: 0.050000\n",
      "Seed 84, Epoch [240/1000], Train Loss: 0.884605, Test Loss: 2.440953, LR: 0.050000\n",
      "Seed 84, Epoch [250/1000], Train Loss: 0.923282, Test Loss: 2.544241, LR: 0.050000\n",
      "Seed 84, Epoch [260/1000], Train Loss: 0.911735, Test Loss: 2.082048, LR: 0.050000\n",
      "Seed 84, Epoch [270/1000], Train Loss: 0.940405, Test Loss: 2.038682, LR: 0.050000\n",
      "Seed 84, Epoch [280/1000], Train Loss: 0.885257, Test Loss: 2.136956, LR: 0.050000\n",
      "Seed 84, Epoch [290/1000], Train Loss: 0.865907, Test Loss: 2.246673, LR: 0.050000\n",
      "Seed 84, Epoch [300/1000], Train Loss: 0.871246, Test Loss: 2.268201, LR: 0.050000\n",
      "Seed 84, Epoch [310/1000], Train Loss: 0.852378, Test Loss: 2.409773, LR: 0.050000\n",
      "Seed 84, Epoch [320/1000], Train Loss: 0.863723, Test Loss: 2.460823, LR: 0.050000\n",
      "Seed 84, Epoch [330/1000], Train Loss: 0.924989, Test Loss: 2.530726, LR: 0.050000\n",
      "Seed 84, Epoch [340/1000], Train Loss: 0.964893, Test Loss: 2.081091, LR: 0.050000\n",
      "Seed 84, Epoch [350/1000], Train Loss: 0.864107, Test Loss: 1.697720, LR: 0.050000\n",
      "Seed 84, Epoch [360/1000], Train Loss: 0.852615, Test Loss: 1.971221, LR: 0.050000\n",
      "Seed 84, Epoch [370/1000], Train Loss: 0.840295, Test Loss: 2.171239, LR: 0.050000\n",
      "Seed 84, Epoch [380/1000], Train Loss: 0.841303, Test Loss: 2.066486, LR: 0.050000\n",
      "Seed 84, Epoch [390/1000], Train Loss: 0.986956, Test Loss: 2.077761, LR: 0.050000\n",
      "Seed 84, Epoch [400/1000], Train Loss: 0.845805, Test Loss: 1.835986, LR: 0.050000\n",
      "Seed 84, Epoch [410/1000], Train Loss: 0.845854, Test Loss: 2.147406, LR: 0.050000\n",
      "Seed 84, Epoch [420/1000], Train Loss: 0.820439, Test Loss: 2.109285, LR: 0.050000\n",
      "Seed 84, Epoch [430/1000], Train Loss: 0.815982, Test Loss: 2.396364, LR: 0.050000\n",
      "Seed 84, Epoch [440/1000], Train Loss: 0.851594, Test Loss: 2.042228, LR: 0.050000\n",
      "Seed 84, Epoch [450/1000], Train Loss: 0.858597, Test Loss: 2.120454, LR: 0.050000\n",
      "Seed 84, Epoch [460/1000], Train Loss: 0.814963, Test Loss: 2.110693, LR: 0.050000\n",
      "Seed 84, Epoch [470/1000], Train Loss: 0.825203, Test Loss: 1.951681, LR: 0.050000\n",
      "Seed 84, Epoch [480/1000], Train Loss: 0.791230, Test Loss: 2.166010, LR: 0.050000\n",
      "Seed 84, Epoch [490/1000], Train Loss: 1.023537, Test Loss: 2.109086, LR: 0.050000\n",
      "Seed 84, Epoch [500/1000], Train Loss: 0.908576, Test Loss: 1.285665, LR: 0.050000\n",
      "Seed 84, Epoch [510/1000], Train Loss: 0.868018, Test Loss: 1.629085, LR: 0.050000\n",
      "Seed 84, Epoch [520/1000], Train Loss: 0.827674, Test Loss: 1.762509, LR: 0.050000\n",
      "Seed 84, Epoch [530/1000], Train Loss: 0.789691, Test Loss: 1.829188, LR: 0.050000\n",
      "Seed 84, Epoch [540/1000], Train Loss: 0.797421, Test Loss: 2.326067, LR: 0.050000\n",
      "Seed 84, Epoch [550/1000], Train Loss: 0.905514, Test Loss: 1.606991, LR: 0.050000\n",
      "Early stopping at epoch 558 for seed 84\n",
      "Seed 85, Epoch [10/1000], Train Loss: 3.771023, Test Loss: 3.051969, LR: 0.050000\n",
      "Seed 85, Epoch [20/1000], Train Loss: 2.519843, Test Loss: 2.233654, LR: 0.050000\n",
      "Seed 85, Epoch [30/1000], Train Loss: 2.428644, Test Loss: 2.252109, LR: 0.050000\n",
      "Seed 85, Epoch [40/1000], Train Loss: 2.305977, Test Loss: 2.239401, LR: 0.050000\n",
      "Seed 85, Epoch [50/1000], Train Loss: 2.186688, Test Loss: 2.193713, LR: 0.050000\n",
      "Seed 85, Epoch [60/1000], Train Loss: 2.031026, Test Loss: 2.110923, LR: 0.050000\n",
      "Seed 85, Epoch [70/1000], Train Loss: 1.856449, Test Loss: 1.975978, LR: 0.050000\n",
      "Seed 85, Epoch [80/1000], Train Loss: 1.828206, Test Loss: 1.896458, LR: 0.050000\n",
      "Seed 85, Epoch [90/1000], Train Loss: 1.756268, Test Loss: 1.815256, LR: 0.050000\n",
      "Seed 85, Epoch [100/1000], Train Loss: 1.700474, Test Loss: 1.747108, LR: 0.050000\n",
      "Seed 85, Epoch [110/1000], Train Loss: 1.669523, Test Loss: 1.722040, LR: 0.050000\n",
      "Seed 85, Epoch [120/1000], Train Loss: 1.628962, Test Loss: 1.641440, LR: 0.050000\n",
      "Seed 85, Epoch [130/1000], Train Loss: 1.636283, Test Loss: 1.644589, LR: 0.050000\n",
      "Seed 85, Epoch [140/1000], Train Loss: 1.571648, Test Loss: 1.577613, LR: 0.050000\n",
      "Seed 85, Epoch [150/1000], Train Loss: 1.557303, Test Loss: 1.586094, LR: 0.050000\n",
      "Seed 85, Epoch [160/1000], Train Loss: 1.543962, Test Loss: 1.570600, LR: 0.050000\n",
      "Seed 85, Epoch [170/1000], Train Loss: 1.531830, Test Loss: 1.565982, LR: 0.050000\n",
      "Seed 85, Epoch [180/1000], Train Loss: 1.515843, Test Loss: 1.567097, LR: 0.050000\n",
      "Seed 85, Epoch [190/1000], Train Loss: 1.493812, Test Loss: 1.563134, LR: 0.050000\n",
      "Seed 85, Epoch [200/1000], Train Loss: 1.466488, Test Loss: 1.545206, LR: 0.050000\n",
      "Seed 85, Epoch [210/1000], Train Loss: 1.432716, Test Loss: 1.508948, LR: 0.050000\n",
      "Seed 85, Epoch [220/1000], Train Loss: 1.393864, Test Loss: 1.453900, LR: 0.050000\n",
      "Seed 85, Epoch [230/1000], Train Loss: 1.349624, Test Loss: 1.383741, LR: 0.050000\n",
      "Seed 85, Epoch [240/1000], Train Loss: 1.319570, Test Loss: 1.314221, LR: 0.050000\n",
      "Seed 85, Epoch [250/1000], Train Loss: 1.254790, Test Loss: 1.292562, LR: 0.050000\n",
      "Seed 85, Epoch [260/1000], Train Loss: 1.246567, Test Loss: 1.310560, LR: 0.050000\n",
      "Seed 85, Epoch [270/1000], Train Loss: 1.179476, Test Loss: 1.186712, LR: 0.050000\n",
      "Seed 85, Epoch [280/1000], Train Loss: 1.135870, Test Loss: 1.214546, LR: 0.050000\n",
      "Seed 85, Epoch [290/1000], Train Loss: 1.094745, Test Loss: 1.205953, LR: 0.050000\n",
      "Seed 85, Epoch [300/1000], Train Loss: 1.039604, Test Loss: 1.165372, LR: 0.050000\n",
      "Seed 85, Epoch [310/1000], Train Loss: 1.045567, Test Loss: 1.214326, LR: 0.050000\n",
      "Seed 85, Epoch [320/1000], Train Loss: 1.004168, Test Loss: 1.236413, LR: 0.050000\n",
      "Seed 85, Epoch [330/1000], Train Loss: 0.950199, Test Loss: 1.434224, LR: 0.050000\n",
      "Seed 85, Epoch [340/1000], Train Loss: 0.930684, Test Loss: 1.289293, LR: 0.050000\n",
      "Seed 85, Epoch [350/1000], Train Loss: 0.906280, Test Loss: 1.360861, LR: 0.050000\n",
      "Seed 85, Epoch [360/1000], Train Loss: 0.888680, Test Loss: 1.409850, LR: 0.050000\n",
      "Seed 85, Epoch [370/1000], Train Loss: 0.876623, Test Loss: 1.431965, LR: 0.050000\n",
      "Seed 85, Epoch [380/1000], Train Loss: 0.865399, Test Loss: 1.496766, LR: 0.050000\n",
      "Seed 85, Epoch [390/1000], Train Loss: 0.890359, Test Loss: 1.532224, LR: 0.050000\n",
      "Seed 85, Epoch [400/1000], Train Loss: 0.854268, Test Loss: 1.568419, LR: 0.050000\n",
      "Seed 85, Epoch [410/1000], Train Loss: 0.849758, Test Loss: 1.630413, LR: 0.050000\n",
      "Seed 85, Epoch [420/1000], Train Loss: 0.891012, Test Loss: 1.686029, LR: 0.050000\n",
      "Seed 85, Epoch [430/1000], Train Loss: 0.843629, Test Loss: 1.587226, LR: 0.050000\n",
      "Seed 85, Epoch [440/1000], Train Loss: 0.837787, Test Loss: 1.620118, LR: 0.050000\n",
      "Seed 85, Epoch [450/1000], Train Loss: 0.814496, Test Loss: 1.590765, LR: 0.050000\n",
      "Seed 85, Epoch [460/1000], Train Loss: 0.807880, Test Loss: 1.607162, LR: 0.050000\n",
      "Seed 85, Epoch [470/1000], Train Loss: 0.976141, Test Loss: 1.803058, LR: 0.050000\n",
      "Seed 85, Epoch [480/1000], Train Loss: 0.900480, Test Loss: 1.629907, LR: 0.050000\n",
      "Seed 85, Epoch [490/1000], Train Loss: 0.822931, Test Loss: 1.589408, LR: 0.050000\n",
      "Seed 85, Epoch [500/1000], Train Loss: 0.810764, Test Loss: 1.618713, LR: 0.050000\n",
      "Seed 85, Epoch [510/1000], Train Loss: 0.800469, Test Loss: 1.690082, LR: 0.050000\n",
      "Seed 85, Epoch [520/1000], Train Loss: 0.818395, Test Loss: 1.687377, LR: 0.050000\n",
      "Seed 85, Epoch [530/1000], Train Loss: 0.858528, Test Loss: 1.628762, LR: 0.050000\n",
      "Seed 85, Epoch [540/1000], Train Loss: 0.890363, Test Loss: 1.683129, LR: 0.050000\n",
      "Seed 85, Epoch [550/1000], Train Loss: 0.818549, Test Loss: 1.622878, LR: 0.050000\n",
      "Seed 85, Epoch [560/1000], Train Loss: 0.786736, Test Loss: 1.587836, LR: 0.050000\n",
      "Seed 85, Epoch [570/1000], Train Loss: 0.805509, Test Loss: 1.706145, LR: 0.050000\n",
      "Seed 85, Epoch [580/1000], Train Loss: 0.851470, Test Loss: 1.783065, LR: 0.050000\n",
      "Seed 85, Epoch [590/1000], Train Loss: 0.780266, Test Loss: 1.648488, LR: 0.050000\n",
      "Seed 85, Epoch [600/1000], Train Loss: 0.772543, Test Loss: 1.634292, LR: 0.050000\n",
      "Seed 85, Epoch [610/1000], Train Loss: 0.746678, Test Loss: 1.569950, LR: 0.050000\n",
      "Seed 85, Epoch [620/1000], Train Loss: 1.320943, Test Loss: 2.073895, LR: 0.050000\n",
      "Seed 85, Epoch [630/1000], Train Loss: 0.873276, Test Loss: 1.503675, LR: 0.050000\n",
      "Seed 85, Epoch [640/1000], Train Loss: 0.846221, Test Loss: 1.498161, LR: 0.050000\n",
      "Seed 85, Epoch [650/1000], Train Loss: 0.770516, Test Loss: 1.468662, LR: 0.050000\n",
      "Seed 85, Epoch [660/1000], Train Loss: 1.702887, Test Loss: 2.405713, LR: 0.050000\n",
      "Seed 85, Epoch [670/1000], Train Loss: 1.204096, Test Loss: 1.320190, LR: 0.050000\n",
      "Seed 85, Epoch [680/1000], Train Loss: 0.985292, Test Loss: 1.324541, LR: 0.050000\n",
      "Seed 85, Epoch [690/1000], Train Loss: 0.879605, Test Loss: 1.308387, LR: 0.050000\n",
      "Seed 85, Epoch [700/1000], Train Loss: 0.787688, Test Loss: 1.295090, LR: 0.050000\n",
      "Seed 85, Epoch [710/1000], Train Loss: 0.840413, Test Loss: 1.357565, LR: 0.050000\n",
      "Seed 85, Epoch [720/1000], Train Loss: 1.261491, Test Loss: 1.767830, LR: 0.050000\n",
      "Seed 85, Epoch [730/1000], Train Loss: 0.906031, Test Loss: 1.225008, LR: 0.050000\n",
      "Seed 85, Epoch [740/1000], Train Loss: 0.814614, Test Loss: 1.364973, LR: 0.050000\n",
      "Seed 85, Epoch [750/1000], Train Loss: 0.757440, Test Loss: 1.318551, LR: 0.050000\n",
      "Seed 85, Epoch [760/1000], Train Loss: 0.738747, Test Loss: 1.257548, LR: 0.050000\n",
      "Seed 85, Epoch [770/1000], Train Loss: 0.836147, Test Loss: 1.357676, LR: 0.050000\n",
      "Seed 85, Epoch [780/1000], Train Loss: 0.772375, Test Loss: 1.188643, LR: 0.050000\n",
      "Early stopping at epoch 785 for seed 85\n",
      "Seed 86, Epoch [10/1000], Train Loss: 2.229474, Test Loss: 2.117529, LR: 0.050000\n",
      "Seed 86, Epoch [20/1000], Train Loss: 2.232003, Test Loss: 2.016544, LR: 0.050000\n",
      "Seed 86, Epoch [30/1000], Train Loss: 2.297818, Test Loss: 2.032035, LR: 0.050000\n",
      "Seed 86, Epoch [40/1000], Train Loss: 2.314128, Test Loss: 2.040223, LR: 0.050000\n",
      "Seed 86, Epoch [50/1000], Train Loss: 2.306293, Test Loss: 2.041584, LR: 0.050000\n",
      "Seed 86, Epoch [60/1000], Train Loss: 2.287927, Test Loss: 2.039130, LR: 0.050000\n",
      "Seed 86, Epoch [70/1000], Train Loss: 2.265103, Test Loss: 2.033911, LR: 0.050000\n",
      "Seed 86, Epoch [80/1000], Train Loss: 2.239805, Test Loss: 2.026468, LR: 0.050000\n",
      "Seed 86, Epoch [90/1000], Train Loss: 2.211997, Test Loss: 2.016965, LR: 0.050000\n",
      "Seed 86, Epoch [100/1000], Train Loss: 2.181741, Test Loss: 2.005647, LR: 0.050000\n",
      "Seed 86, Epoch [110/1000], Train Loss: 2.149859, Test Loss: 1.993390, LR: 0.050000\n",
      "Seed 86, Epoch [120/1000], Train Loss: 2.117121, Test Loss: 1.981502, LR: 0.050000\n",
      "Seed 86, Epoch [130/1000], Train Loss: 2.080559, Test Loss: 1.966732, LR: 0.050000\n",
      "Seed 86, Epoch [140/1000], Train Loss: 2.043794, Test Loss: 1.964486, LR: 0.050000\n",
      "Seed 86, Epoch [150/1000], Train Loss: 2.004838, Test Loss: 1.952787, LR: 0.050000\n",
      "Seed 86, Epoch [160/1000], Train Loss: 1.967078, Test Loss: 1.954314, LR: 0.050000\n",
      "Seed 86, Epoch [170/1000], Train Loss: 1.912536, Test Loss: 1.941033, LR: 0.050000\n",
      "Seed 86, Epoch [180/1000], Train Loss: 1.862337, Test Loss: 1.935033, LR: 0.050000\n",
      "Seed 86, Epoch [190/1000], Train Loss: 1.817814, Test Loss: 1.932427, LR: 0.050000\n",
      "Seed 86, Epoch [200/1000], Train Loss: 1.783555, Test Loss: 1.932197, LR: 0.050000\n",
      "Seed 86, Epoch [210/1000], Train Loss: 1.756598, Test Loss: 1.926236, LR: 0.050000\n",
      "Seed 86, Epoch [220/1000], Train Loss: 1.728230, Test Loss: 1.915621, LR: 0.050000\n",
      "Seed 86, Epoch [230/1000], Train Loss: 1.701878, Test Loss: 1.901808, LR: 0.050000\n",
      "Seed 86, Epoch [240/1000], Train Loss: 1.674743, Test Loss: 1.884576, LR: 0.050000\n",
      "Seed 86, Epoch [250/1000], Train Loss: 1.646473, Test Loss: 1.867432, LR: 0.050000\n",
      "Seed 86, Epoch [260/1000], Train Loss: 1.643428, Test Loss: 1.891541, LR: 0.050000\n",
      "Seed 86, Epoch [270/1000], Train Loss: 1.643543, Test Loss: 1.867497, LR: 0.050000\n",
      "Seed 86, Epoch [280/1000], Train Loss: 1.591143, Test Loss: 1.835830, LR: 0.050000\n",
      "Seed 86, Epoch [290/1000], Train Loss: 1.552968, Test Loss: 1.828837, LR: 0.050000\n",
      "Seed 86, Epoch [300/1000], Train Loss: 1.573357, Test Loss: 1.824180, LR: 0.050000\n",
      "Seed 86, Epoch [310/1000], Train Loss: 1.512715, Test Loss: 1.768219, LR: 0.050000\n",
      "Seed 86, Epoch [320/1000], Train Loss: 1.464764, Test Loss: 1.778107, LR: 0.050000\n",
      "Seed 86, Epoch [330/1000], Train Loss: 1.439957, Test Loss: 1.703614, LR: 0.050000\n",
      "Seed 86, Epoch [340/1000], Train Loss: 1.409283, Test Loss: 1.743529, LR: 0.050000\n",
      "Seed 86, Epoch [350/1000], Train Loss: 1.380933, Test Loss: 1.796424, LR: 0.050000\n",
      "Seed 86, Epoch [360/1000], Train Loss: 1.407521, Test Loss: 1.800237, LR: 0.050000\n",
      "Seed 86, Epoch [370/1000], Train Loss: 1.289434, Test Loss: 1.757989, LR: 0.050000\n",
      "Seed 86, Epoch [380/1000], Train Loss: 1.258958, Test Loss: 1.836717, LR: 0.050000\n",
      "Seed 86, Epoch [390/1000], Train Loss: 1.225083, Test Loss: 2.279313, LR: 0.050000\n",
      "Seed 86, Epoch [400/1000], Train Loss: 1.227133, Test Loss: 1.930419, LR: 0.050000\n",
      "Seed 86, Epoch [410/1000], Train Loss: 1.184094, Test Loss: 2.217701, LR: 0.050000\n",
      "Seed 86, Epoch [420/1000], Train Loss: 1.197263, Test Loss: 2.143152, LR: 0.050000\n",
      "Seed 86, Epoch [430/1000], Train Loss: 1.142348, Test Loss: 2.479047, LR: 0.050000\n",
      "Seed 86, Epoch [440/1000], Train Loss: 1.115236, Test Loss: 2.708143, LR: 0.050000\n",
      "Seed 86, Epoch [450/1000], Train Loss: 1.096699, Test Loss: 3.028941, LR: 0.050000\n",
      "Seed 86, Epoch [460/1000], Train Loss: 1.078992, Test Loss: 3.041555, LR: 0.050000\n",
      "Seed 86, Epoch [470/1000], Train Loss: 1.074713, Test Loss: 3.126853, LR: 0.050000\n",
      "Seed 86, Epoch [480/1000], Train Loss: 1.059724, Test Loss: 3.073072, LR: 0.050000\n",
      "Seed 86, Epoch [490/1000], Train Loss: 1.047964, Test Loss: 2.828429, LR: 0.050000\n",
      "Seed 86, Epoch [500/1000], Train Loss: 1.039413, Test Loss: 2.892906, LR: 0.050000\n",
      "Seed 86, Epoch [510/1000], Train Loss: 1.034232, Test Loss: 2.872380, LR: 0.050000\n",
      "Seed 86, Epoch [520/1000], Train Loss: 1.032695, Test Loss: 2.541655, LR: 0.050000\n",
      "Seed 86, Epoch [530/1000], Train Loss: 1.022407, Test Loss: 2.438864, LR: 0.050000\n",
      "Seed 86, Epoch [540/1000], Train Loss: 1.006645, Test Loss: 2.445670, LR: 0.050000\n",
      "Seed 86, Epoch [550/1000], Train Loss: 1.002613, Test Loss: 2.329011, LR: 0.050000\n",
      "Seed 86, Epoch [560/1000], Train Loss: 1.002205, Test Loss: 2.185775, LR: 0.050000\n",
      "Seed 86, Epoch [570/1000], Train Loss: 0.998734, Test Loss: 2.079811, LR: 0.050000\n",
      "Seed 86, Epoch [580/1000], Train Loss: 0.995078, Test Loss: 1.861410, LR: 0.050000\n",
      "Seed 86, Epoch [590/1000], Train Loss: 0.989445, Test Loss: 1.764530, LR: 0.050000\n",
      "Seed 86, Epoch [600/1000], Train Loss: 0.982182, Test Loss: 1.711914, LR: 0.050000\n",
      "Seed 86, Epoch [610/1000], Train Loss: 0.978823, Test Loss: 1.596074, LR: 0.050000\n",
      "Seed 86, Epoch [620/1000], Train Loss: 0.971380, Test Loss: 1.662548, LR: 0.050000\n",
      "Seed 86, Epoch [630/1000], Train Loss: 0.970358, Test Loss: 1.542016, LR: 0.050000\n",
      "Seed 86, Epoch [640/1000], Train Loss: 0.964328, Test Loss: 1.536343, LR: 0.050000\n",
      "Seed 86, Epoch [650/1000], Train Loss: 0.956917, Test Loss: 1.412189, LR: 0.050000\n",
      "Seed 86, Epoch [660/1000], Train Loss: 0.950006, Test Loss: 1.425605, LR: 0.050000\n",
      "Seed 86, Epoch [670/1000], Train Loss: 0.947834, Test Loss: 1.319993, LR: 0.050000\n",
      "Seed 86, Epoch [680/1000], Train Loss: 0.944611, Test Loss: 1.257318, LR: 0.050000\n",
      "Seed 86, Epoch [690/1000], Train Loss: 0.944652, Test Loss: 1.229089, LR: 0.050000\n",
      "Seed 86, Epoch [700/1000], Train Loss: 0.937929, Test Loss: 1.202091, LR: 0.050000\n",
      "Seed 86, Epoch [710/1000], Train Loss: 0.931584, Test Loss: 1.196326, LR: 0.050000\n",
      "Seed 86, Epoch [720/1000], Train Loss: 0.927081, Test Loss: 1.185244, LR: 0.050000\n",
      "Seed 86, Epoch [730/1000], Train Loss: 0.924791, Test Loss: 1.167837, LR: 0.050000\n",
      "Seed 86, Epoch [740/1000], Train Loss: 0.922159, Test Loss: 1.161238, LR: 0.050000\n",
      "Seed 86, Epoch [750/1000], Train Loss: 0.917836, Test Loss: 1.151467, LR: 0.050000\n",
      "Seed 86, Epoch [760/1000], Train Loss: 0.912352, Test Loss: 1.159792, LR: 0.050000\n",
      "Seed 86, Epoch [770/1000], Train Loss: 0.910461, Test Loss: 1.157453, LR: 0.050000\n",
      "Seed 86, Epoch [780/1000], Train Loss: 0.906705, Test Loss: 1.167172, LR: 0.050000\n",
      "Seed 86, Epoch [790/1000], Train Loss: 0.903365, Test Loss: 1.181964, LR: 0.050000\n",
      "Seed 86, Epoch [800/1000], Train Loss: 0.898801, Test Loss: 1.191546, LR: 0.050000\n",
      "Seed 86, Epoch [810/1000], Train Loss: 0.897793, Test Loss: 1.209318, LR: 0.050000\n",
      "Seed 86, Epoch [820/1000], Train Loss: 0.893019, Test Loss: 1.221498, LR: 0.050000\n",
      "Seed 86, Epoch [830/1000], Train Loss: 0.890118, Test Loss: 1.232036, LR: 0.050000\n",
      "Seed 86, Epoch [840/1000], Train Loss: 0.887092, Test Loss: 1.251108, LR: 0.050000\n",
      "Seed 86, Epoch [850/1000], Train Loss: 0.884062, Test Loss: 1.264234, LR: 0.050000\n",
      "Seed 86, Epoch [860/1000], Train Loss: 0.881658, Test Loss: 1.281315, LR: 0.050000\n",
      "Seed 86, Epoch [870/1000], Train Loss: 0.879412, Test Loss: 1.297485, LR: 0.050000\n",
      "Seed 86, Epoch [880/1000], Train Loss: 0.879922, Test Loss: 1.310039, LR: 0.050000\n",
      "Seed 86, Epoch [890/1000], Train Loss: 0.874667, Test Loss: 1.327864, LR: 0.050000\n",
      "Seed 86, Epoch [900/1000], Train Loss: 0.872289, Test Loss: 1.336699, LR: 0.050000\n",
      "Seed 86, Epoch [910/1000], Train Loss: 0.869101, Test Loss: 1.354328, LR: 0.050000\n",
      "Seed 86, Epoch [920/1000], Train Loss: 0.869893, Test Loss: 1.369645, LR: 0.050000\n",
      "Seed 86, Epoch [930/1000], Train Loss: 0.866874, Test Loss: 1.378473, LR: 0.050000\n",
      "Seed 86, Epoch [940/1000], Train Loss: 0.862082, Test Loss: 1.386347, LR: 0.050000\n",
      "Seed 86, Epoch [950/1000], Train Loss: 0.869566, Test Loss: 1.413836, LR: 0.050000\n",
      "Seed 86, Epoch [960/1000], Train Loss: 0.870778, Test Loss: 1.471003, LR: 0.050000\n",
      "Seed 86, Epoch [970/1000], Train Loss: 0.864184, Test Loss: 1.417243, LR: 0.050000\n",
      "Seed 86, Epoch [980/1000], Train Loss: 0.861994, Test Loss: 1.430957, LR: 0.050000\n",
      "Seed 86, Epoch [990/1000], Train Loss: 0.867844, Test Loss: 1.446108, LR: 0.050000\n",
      "Seed 86, Epoch [1000/1000], Train Loss: 0.858979, Test Loss: 1.475369, LR: 0.050000\n",
      "Seed 87, Epoch [10/1000], Train Loss: 4.303110, Test Loss: 3.682609, LR: 0.050000\n",
      "Seed 87, Epoch [20/1000], Train Loss: 2.789032, Test Loss: 2.368778, LR: 0.050000\n",
      "Seed 87, Epoch [30/1000], Train Loss: 2.328768, Test Loss: 2.155251, LR: 0.050000\n",
      "Seed 87, Epoch [40/1000], Train Loss: 2.332529, Test Loss: 2.152031, LR: 0.050000\n",
      "Seed 87, Epoch [50/1000], Train Loss: 2.378539, Test Loss: 2.277582, LR: 0.050000\n",
      "Seed 87, Epoch [60/1000], Train Loss: 2.268955, Test Loss: 2.174765, LR: 0.050000\n",
      "Seed 87, Epoch [70/1000], Train Loss: 2.239729, Test Loss: 2.144018, LR: 0.050000\n",
      "Seed 87, Epoch [80/1000], Train Loss: 2.279860, Test Loss: 2.192598, LR: 0.050000\n",
      "Seed 87, Epoch [90/1000], Train Loss: 2.213374, Test Loss: 2.128781, LR: 0.050000\n",
      "Seed 87, Epoch [100/1000], Train Loss: 2.200760, Test Loss: 2.118490, LR: 0.050000\n",
      "Seed 87, Epoch [110/1000], Train Loss: 2.179263, Test Loss: 2.107057, LR: 0.050000\n",
      "Seed 87, Epoch [120/1000], Train Loss: 2.156922, Test Loss: 2.095994, LR: 0.050000\n",
      "Seed 87, Epoch [130/1000], Train Loss: 2.133681, Test Loss: 2.083358, LR: 0.050000\n",
      "Seed 87, Epoch [140/1000], Train Loss: 2.107490, Test Loss: 2.067670, LR: 0.050000\n",
      "Seed 87, Epoch [150/1000], Train Loss: 2.078035, Test Loss: 2.050225, LR: 0.050000\n",
      "Seed 87, Epoch [160/1000], Train Loss: 2.044740, Test Loss: 2.031462, LR: 0.050000\n",
      "Seed 87, Epoch [170/1000], Train Loss: 2.006739, Test Loss: 2.010924, LR: 0.050000\n",
      "Seed 87, Epoch [180/1000], Train Loss: 1.962979, Test Loss: 1.987953, LR: 0.050000\n",
      "Seed 87, Epoch [190/1000], Train Loss: 1.912441, Test Loss: 1.962345, LR: 0.050000\n",
      "Seed 87, Epoch [200/1000], Train Loss: 1.854145, Test Loss: 1.933585, LR: 0.050000\n",
      "Seed 87, Epoch [210/1000], Train Loss: 1.788535, Test Loss: 1.901069, LR: 0.050000\n",
      "Seed 87, Epoch [220/1000], Train Loss: 1.720714, Test Loss: 1.864795, LR: 0.050000\n",
      "Seed 87, Epoch [230/1000], Train Loss: 1.669507, Test Loss: 1.826668, LR: 0.050000\n",
      "Seed 87, Epoch [240/1000], Train Loss: 1.634727, Test Loss: 1.790657, LR: 0.050000\n",
      "Seed 87, Epoch [250/1000], Train Loss: 1.607554, Test Loss: 1.795593, LR: 0.050000\n",
      "Seed 87, Epoch [260/1000], Train Loss: 1.625344, Test Loss: 1.760528, LR: 0.050000\n",
      "Seed 87, Epoch [270/1000], Train Loss: 1.595528, Test Loss: 1.737921, LR: 0.050000\n",
      "Seed 87, Epoch [280/1000], Train Loss: 1.584428, Test Loss: 1.728808, LR: 0.050000\n",
      "Seed 87, Epoch [290/1000], Train Loss: 1.574124, Test Loss: 1.716667, LR: 0.050000\n",
      "Seed 87, Epoch [300/1000], Train Loss: 1.567851, Test Loss: 1.708280, LR: 0.050000\n",
      "Seed 87, Epoch [310/1000], Train Loss: 1.554611, Test Loss: 1.693965, LR: 0.050000\n",
      "Seed 87, Epoch [320/1000], Train Loss: 1.540807, Test Loss: 1.677489, LR: 0.050000\n",
      "Seed 87, Epoch [330/1000], Train Loss: 1.519343, Test Loss: 1.658365, LR: 0.050000\n",
      "Seed 87, Epoch [340/1000], Train Loss: 1.500284, Test Loss: 1.635314, LR: 0.050000\n",
      "Seed 87, Epoch [350/1000], Train Loss: 1.482175, Test Loss: 1.611687, LR: 0.050000\n",
      "Seed 87, Epoch [360/1000], Train Loss: 1.459367, Test Loss: 1.586364, LR: 0.050000\n",
      "Seed 87, Epoch [370/1000], Train Loss: 1.438251, Test Loss: 1.563995, LR: 0.050000\n",
      "Seed 87, Epoch [380/1000], Train Loss: 1.415797, Test Loss: 1.535354, LR: 0.050000\n",
      "Seed 87, Epoch [390/1000], Train Loss: 1.394149, Test Loss: 1.511914, LR: 0.050000\n",
      "Seed 87, Epoch [400/1000], Train Loss: 1.369907, Test Loss: 1.480760, LR: 0.050000\n",
      "Seed 87, Epoch [410/1000], Train Loss: 1.346837, Test Loss: 1.454735, LR: 0.050000\n",
      "Seed 87, Epoch [420/1000], Train Loss: 1.420197, Test Loss: 1.424541, LR: 0.050000\n",
      "Seed 87, Epoch [430/1000], Train Loss: 1.300694, Test Loss: 1.411706, LR: 0.050000\n",
      "Seed 87, Epoch [440/1000], Train Loss: 1.313387, Test Loss: 1.395863, LR: 0.050000\n",
      "Seed 87, Epoch [450/1000], Train Loss: 1.265087, Test Loss: 1.344143, LR: 0.050000\n",
      "Seed 87, Epoch [460/1000], Train Loss: 1.251584, Test Loss: 1.311110, LR: 0.050000\n",
      "Seed 87, Epoch [470/1000], Train Loss: 1.207304, Test Loss: 1.266878, LR: 0.050000\n",
      "Seed 87, Epoch [480/1000], Train Loss: 1.183553, Test Loss: 1.244670, LR: 0.050000\n",
      "Seed 87, Epoch [490/1000], Train Loss: 1.146491, Test Loss: 1.187028, LR: 0.050000\n",
      "Seed 87, Epoch [500/1000], Train Loss: 1.123541, Test Loss: 1.140906, LR: 0.050000\n",
      "Seed 87, Epoch [510/1000], Train Loss: 1.094396, Test Loss: 1.122903, LR: 0.050000\n",
      "Seed 87, Epoch [520/1000], Train Loss: 1.078710, Test Loss: 1.156273, LR: 0.050000\n",
      "Seed 87, Epoch [530/1000], Train Loss: 1.081538, Test Loss: 1.147513, LR: 0.050000\n",
      "Seed 87, Epoch [540/1000], Train Loss: 1.046298, Test Loss: 1.149553, LR: 0.050000\n",
      "Seed 87, Epoch [550/1000], Train Loss: 1.014456, Test Loss: 1.132851, LR: 0.050000\n",
      "Seed 87, Epoch [560/1000], Train Loss: 0.995755, Test Loss: 1.089092, LR: 0.050000\n",
      "Seed 87, Epoch [570/1000], Train Loss: 0.976683, Test Loss: 1.156901, LR: 0.050000\n",
      "Seed 87, Epoch [580/1000], Train Loss: 0.965762, Test Loss: 1.165608, LR: 0.050000\n",
      "Seed 87, Epoch [590/1000], Train Loss: 0.947051, Test Loss: 1.179328, LR: 0.050000\n",
      "Seed 87, Epoch [600/1000], Train Loss: 0.937513, Test Loss: 1.198022, LR: 0.050000\n",
      "Seed 87, Epoch [610/1000], Train Loss: 0.922510, Test Loss: 1.243456, LR: 0.050000\n",
      "Seed 87, Epoch [620/1000], Train Loss: 0.920725, Test Loss: 1.317355, LR: 0.050000\n",
      "Seed 87, Epoch [630/1000], Train Loss: 0.935345, Test Loss: 1.378378, LR: 0.050000\n",
      "Seed 87, Epoch [640/1000], Train Loss: 0.911954, Test Loss: 1.327131, LR: 0.050000\n",
      "Seed 87, Epoch [650/1000], Train Loss: 0.896203, Test Loss: 1.367860, LR: 0.050000\n",
      "Seed 87, Epoch [660/1000], Train Loss: 0.886205, Test Loss: 1.392841, LR: 0.050000\n",
      "Seed 87, Epoch [670/1000], Train Loss: 0.876285, Test Loss: 1.392696, LR: 0.050000\n",
      "Seed 87, Epoch [680/1000], Train Loss: 1.107863, Test Loss: 1.523068, LR: 0.050000\n",
      "Seed 87, Epoch [690/1000], Train Loss: 0.915512, Test Loss: 1.713439, LR: 0.050000\n",
      "Seed 87, Epoch [700/1000], Train Loss: 0.884459, Test Loss: 1.486420, LR: 0.050000\n",
      "Seed 87, Epoch [710/1000], Train Loss: 0.872424, Test Loss: 1.574579, LR: 0.050000\n",
      "Seed 87, Epoch [720/1000], Train Loss: 0.865011, Test Loss: 1.560135, LR: 0.050000\n",
      "Seed 87, Epoch [730/1000], Train Loss: 0.890286, Test Loss: 1.639894, LR: 0.050000\n",
      "Seed 87, Epoch [740/1000], Train Loss: 0.856557, Test Loss: 1.665090, LR: 0.050000\n",
      "Seed 87, Epoch [750/1000], Train Loss: 0.889542, Test Loss: 1.775597, LR: 0.050000\n",
      "Seed 87, Epoch [760/1000], Train Loss: 0.869887, Test Loss: 1.765265, LR: 0.050000\n",
      "Seed 87, Epoch [770/1000], Train Loss: 0.869405, Test Loss: 1.672039, LR: 0.050000\n",
      "Seed 87, Epoch [780/1000], Train Loss: 0.862061, Test Loss: 1.804617, LR: 0.050000\n",
      "Seed 87, Epoch [790/1000], Train Loss: 0.862371, Test Loss: 1.714391, LR: 0.050000\n",
      "Seed 87, Epoch [800/1000], Train Loss: 0.918633, Test Loss: 1.967825, LR: 0.050000\n",
      "Seed 87, Epoch [810/1000], Train Loss: 0.859324, Test Loss: 1.812617, LR: 0.050000\n",
      "Seed 87, Epoch [820/1000], Train Loss: 0.851179, Test Loss: 1.954252, LR: 0.050000\n",
      "Seed 87, Epoch [830/1000], Train Loss: 0.854887, Test Loss: 1.940448, LR: 0.050000\n",
      "Seed 87, Epoch [840/1000], Train Loss: 1.197387, Test Loss: 1.926147, LR: 0.050000\n",
      "Seed 87, Epoch [850/1000], Train Loss: 0.915435, Test Loss: 2.192178, LR: 0.050000\n",
      "Seed 87, Epoch [860/1000], Train Loss: 0.886018, Test Loss: 1.943244, LR: 0.050000\n",
      "Seed 87, Epoch [870/1000], Train Loss: 0.855823, Test Loss: 1.979293, LR: 0.050000\n",
      "Seed 87, Epoch [880/1000], Train Loss: 0.834309, Test Loss: 1.928694, LR: 0.050000\n",
      "Seed 87, Epoch [890/1000], Train Loss: 0.858486, Test Loss: 1.876060, LR: 0.050000\n",
      "Seed 87, Epoch [900/1000], Train Loss: 0.844853, Test Loss: 2.041525, LR: 0.050000\n",
      "Seed 87, Epoch [910/1000], Train Loss: 0.923713, Test Loss: 1.880053, LR: 0.050000\n",
      "Seed 87, Epoch [920/1000], Train Loss: 0.893458, Test Loss: 2.249567, LR: 0.050000\n",
      "Seed 87, Epoch [930/1000], Train Loss: 0.864207, Test Loss: 1.939093, LR: 0.050000\n",
      "Seed 87, Epoch [940/1000], Train Loss: 0.848796, Test Loss: 2.028262, LR: 0.050000\n",
      "Seed 87, Epoch [950/1000], Train Loss: 0.867390, Test Loss: 2.142178, LR: 0.050000\n",
      "Seed 87, Epoch [960/1000], Train Loss: 0.831030, Test Loss: 2.026538, LR: 0.050000\n",
      "Seed 87, Epoch [970/1000], Train Loss: 0.904623, Test Loss: 2.314206, LR: 0.050000\n",
      "Seed 87, Epoch [980/1000], Train Loss: 0.853857, Test Loss: 2.150449, LR: 0.050000\n",
      "Seed 87, Epoch [990/1000], Train Loss: 0.988225, Test Loss: 2.002807, LR: 0.050000\n",
      "Seed 87, Epoch [1000/1000], Train Loss: 0.844296, Test Loss: 2.132135, LR: 0.050000\n",
      "Seed 88, Epoch [10/1000], Train Loss: 2.541958, Test Loss: 2.184112, LR: 0.050000\n",
      "Seed 88, Epoch [20/1000], Train Loss: 2.262957, Test Loss: 2.252666, LR: 0.050000\n",
      "Seed 88, Epoch [30/1000], Train Loss: 2.357775, Test Loss: 2.355899, LR: 0.050000\n",
      "Seed 88, Epoch [40/1000], Train Loss: 2.395534, Test Loss: 2.392995, LR: 0.050000\n",
      "Seed 88, Epoch [50/1000], Train Loss: 2.402545, Test Loss: 2.401350, LR: 0.050000\n",
      "Seed 88, Epoch [60/1000], Train Loss: 2.396184, Test Loss: 2.398129, LR: 0.050000\n",
      "Seed 88, Epoch [70/1000], Train Loss: 2.384497, Test Loss: 2.391194, LR: 0.050000\n",
      "Seed 88, Epoch [80/1000], Train Loss: 2.370500, Test Loss: 2.383895, LR: 0.050000\n",
      "Seed 88, Epoch [90/1000], Train Loss: 2.354673, Test Loss: 2.377572, LR: 0.050000\n",
      "Seed 88, Epoch [100/1000], Train Loss: 2.336043, Test Loss: 2.372746, LR: 0.050000\n",
      "Seed 88, Epoch [110/1000], Train Loss: 2.312729, Test Loss: 2.369602, LR: 0.050000\n",
      "Seed 88, Epoch [120/1000], Train Loss: 2.283492, Test Loss: 2.368085, LR: 0.050000\n",
      "Seed 88, Epoch [130/1000], Train Loss: 2.251638, Test Loss: 2.367960, LR: 0.050000\n",
      "Seed 88, Epoch [140/1000], Train Loss: 2.224721, Test Loss: 2.369240, LR: 0.050000\n",
      "Seed 88, Epoch [150/1000], Train Loss: 2.204486, Test Loss: 2.372472, LR: 0.050000\n",
      "Seed 88, Epoch [160/1000], Train Loss: 2.186905, Test Loss: 2.377980, LR: 0.050000\n",
      "Seed 88, Epoch [170/1000], Train Loss: 2.170045, Test Loss: 2.384980, LR: 0.050000\n",
      "Seed 88, Epoch [180/1000], Train Loss: 2.154009, Test Loss: 2.391900, LR: 0.050000\n",
      "Seed 88, Epoch [190/1000], Train Loss: 2.159724, Test Loss: 2.379667, LR: 0.050000\n",
      "Seed 88, Epoch [200/1000], Train Loss: 2.129754, Test Loss: 2.410020, LR: 0.050000\n",
      "Seed 88, Epoch [210/1000], Train Loss: 2.127964, Test Loss: 2.386179, LR: 0.050000\n",
      "Seed 88, Epoch [220/1000], Train Loss: 2.096624, Test Loss: 2.412072, LR: 0.050000\n",
      "Seed 88, Epoch [230/1000], Train Loss: 2.081624, Test Loss: 2.413042, LR: 0.050000\n",
      "Seed 88, Epoch [240/1000], Train Loss: 2.081850, Test Loss: 2.384657, LR: 0.050000\n",
      "Seed 88, Epoch [250/1000], Train Loss: 2.065107, Test Loss: 2.381618, LR: 0.050000\n",
      "Seed 88, Epoch [260/1000], Train Loss: 2.032502, Test Loss: 2.377047, LR: 0.050000\n",
      "Seed 88, Epoch [270/1000], Train Loss: 2.027999, Test Loss: 2.370938, LR: 0.050000\n",
      "Seed 88, Epoch [280/1000], Train Loss: 2.006831, Test Loss: 2.362319, LR: 0.050000\n",
      "Seed 88, Epoch [290/1000], Train Loss: 1.982711, Test Loss: 2.349866, LR: 0.050000\n",
      "Seed 88, Epoch [300/1000], Train Loss: 1.943297, Test Loss: 2.330285, LR: 0.050000\n",
      "Seed 88, Epoch [310/1000], Train Loss: 1.918430, Test Loss: 2.297225, LR: 0.050000\n",
      "Seed 88, Epoch [320/1000], Train Loss: 1.857009, Test Loss: 2.235695, LR: 0.050000\n",
      "Seed 88, Epoch [330/1000], Train Loss: 1.829578, Test Loss: 2.213932, LR: 0.050000\n",
      "Seed 88, Epoch [340/1000], Train Loss: 1.764865, Test Loss: 2.184486, LR: 0.050000\n",
      "Seed 88, Epoch [350/1000], Train Loss: 1.738677, Test Loss: 2.160922, LR: 0.050000\n",
      "Seed 88, Epoch [360/1000], Train Loss: 1.780175, Test Loss: 2.118957, LR: 0.050000\n",
      "Seed 88, Epoch [370/1000], Train Loss: 1.765457, Test Loss: 2.279347, LR: 0.050000\n",
      "Seed 88, Epoch [380/1000], Train Loss: 1.636415, Test Loss: 2.089667, LR: 0.050000\n",
      "Seed 88, Epoch [390/1000], Train Loss: 1.577619, Test Loss: 2.107408, LR: 0.050000\n",
      "Seed 88, Epoch [400/1000], Train Loss: 1.541123, Test Loss: 2.060414, LR: 0.050000\n",
      "Seed 88, Epoch [410/1000], Train Loss: 1.504194, Test Loss: 2.014651, LR: 0.050000\n",
      "Seed 88, Epoch [420/1000], Train Loss: 1.548051, Test Loss: 1.979444, LR: 0.050000\n",
      "Seed 88, Epoch [430/1000], Train Loss: 1.522354, Test Loss: 2.268725, LR: 0.050000\n",
      "Seed 88, Epoch [440/1000], Train Loss: 1.467781, Test Loss: 1.846861, LR: 0.050000\n",
      "Seed 88, Epoch [450/1000], Train Loss: 1.413331, Test Loss: 1.897596, LR: 0.050000\n",
      "Seed 88, Epoch [460/1000], Train Loss: 1.363911, Test Loss: 1.859489, LR: 0.050000\n",
      "Seed 88, Epoch [470/1000], Train Loss: 1.328690, Test Loss: 1.780401, LR: 0.050000\n",
      "Seed 88, Epoch [480/1000], Train Loss: 1.295590, Test Loss: 1.775705, LR: 0.050000\n",
      "Seed 88, Epoch [490/1000], Train Loss: 1.264509, Test Loss: 1.776848, LR: 0.050000\n",
      "Seed 88, Epoch [500/1000], Train Loss: 1.231666, Test Loss: 1.774412, LR: 0.050000\n",
      "Seed 88, Epoch [510/1000], Train Loss: 1.197911, Test Loss: 1.772281, LR: 0.050000\n",
      "Seed 88, Epoch [520/1000], Train Loss: 1.162954, Test Loss: 1.783836, LR: 0.050000\n",
      "Seed 88, Epoch [530/1000], Train Loss: 1.127886, Test Loss: 1.814130, LR: 0.050000\n",
      "Seed 88, Epoch [540/1000], Train Loss: 1.095306, Test Loss: 1.859012, LR: 0.050000\n",
      "Seed 88, Epoch [550/1000], Train Loss: 1.067779, Test Loss: 1.905614, LR: 0.050000\n",
      "Seed 88, Epoch [560/1000], Train Loss: 1.044309, Test Loss: 1.940954, LR: 0.050000\n",
      "Seed 88, Epoch [570/1000], Train Loss: 1.023403, Test Loss: 1.957386, LR: 0.050000\n",
      "Seed 88, Epoch [580/1000], Train Loss: 1.006132, Test Loss: 1.963567, LR: 0.050000\n",
      "Seed 88, Epoch [590/1000], Train Loss: 0.992895, Test Loss: 1.960376, LR: 0.050000\n",
      "Seed 88, Epoch [600/1000], Train Loss: 0.983024, Test Loss: 1.946034, LR: 0.050000\n",
      "Seed 88, Epoch [610/1000], Train Loss: 0.975804, Test Loss: 1.925485, LR: 0.050000\n",
      "Seed 88, Epoch [620/1000], Train Loss: 0.970286, Test Loss: 1.906344, LR: 0.050000\n",
      "Seed 88, Epoch [630/1000], Train Loss: 0.965653, Test Loss: 1.891894, LR: 0.050000\n",
      "Seed 88, Epoch [640/1000], Train Loss: 0.961448, Test Loss: 1.882366, LR: 0.050000\n",
      "Seed 88, Epoch [650/1000], Train Loss: 0.957453, Test Loss: 1.877526, LR: 0.050000\n",
      "Seed 88, Epoch [660/1000], Train Loss: 0.953574, Test Loss: 1.876104, LR: 0.050000\n",
      "Seed 88, Epoch [670/1000], Train Loss: 0.949766, Test Loss: 1.876360, LR: 0.050000\n",
      "Seed 88, Epoch [680/1000], Train Loss: 0.946001, Test Loss: 1.877331, LR: 0.050000\n",
      "Seed 88, Epoch [690/1000], Train Loss: 0.942267, Test Loss: 1.878792, LR: 0.050000\n",
      "Seed 88, Epoch [700/1000], Train Loss: 0.938560, Test Loss: 1.880564, LR: 0.050000\n",
      "Seed 88, Epoch [710/1000], Train Loss: 0.934877, Test Loss: 1.882420, LR: 0.050000\n",
      "Seed 88, Epoch [720/1000], Train Loss: 0.931221, Test Loss: 1.884334, LR: 0.050000\n",
      "Seed 88, Epoch [730/1000], Train Loss: 0.927598, Test Loss: 1.886406, LR: 0.050000\n",
      "Seed 88, Epoch [740/1000], Train Loss: 0.924016, Test Loss: 1.888437, LR: 0.050000\n",
      "Seed 88, Epoch [750/1000], Train Loss: 0.920484, Test Loss: 1.890443, LR: 0.050000\n",
      "Seed 88, Epoch [760/1000], Train Loss: 0.917013, Test Loss: 1.892365, LR: 0.050000\n",
      "Seed 88, Epoch [770/1000], Train Loss: 0.913614, Test Loss: 1.894108, LR: 0.050000\n",
      "Seed 88, Epoch [780/1000], Train Loss: 0.910298, Test Loss: 1.895678, LR: 0.050000\n",
      "Seed 88, Epoch [790/1000], Train Loss: 0.907072, Test Loss: 1.897036, LR: 0.050000\n",
      "Seed 88, Epoch [800/1000], Train Loss: 0.903945, Test Loss: 1.898126, LR: 0.050000\n",
      "Seed 88, Epoch [810/1000], Train Loss: 0.900921, Test Loss: 1.898883, LR: 0.050000\n",
      "Seed 88, Epoch [820/1000], Train Loss: 0.898004, Test Loss: 1.899259, LR: 0.050000\n",
      "Seed 88, Epoch [830/1000], Train Loss: 0.895194, Test Loss: 1.899468, LR: 0.050000\n",
      "Seed 88, Epoch [840/1000], Train Loss: 0.892489, Test Loss: 1.898710, LR: 0.050000\n",
      "Seed 88, Epoch [850/1000], Train Loss: 0.889887, Test Loss: 1.898655, LR: 0.050000\n",
      "Seed 88, Epoch [860/1000], Train Loss: 0.887391, Test Loss: 1.898425, LR: 0.050000\n",
      "Seed 88, Epoch [870/1000], Train Loss: 0.884990, Test Loss: 1.893561, LR: 0.050000\n",
      "Seed 88, Epoch [880/1000], Train Loss: 0.882629, Test Loss: 1.886868, LR: 0.050000\n",
      "Seed 88, Epoch [890/1000], Train Loss: 0.880428, Test Loss: 1.891205, LR: 0.050000\n",
      "Seed 88, Epoch [900/1000], Train Loss: 0.878214, Test Loss: 1.887735, LR: 0.050000\n",
      "Seed 88, Epoch [910/1000], Train Loss: 0.876065, Test Loss: 1.884599, LR: 0.050000\n",
      "Seed 88, Epoch [920/1000], Train Loss: 0.874353, Test Loss: 1.858238, LR: 0.050000\n",
      "Seed 88, Epoch [930/1000], Train Loss: 0.918232, Test Loss: 1.802807, LR: 0.050000\n",
      "Seed 88, Epoch [940/1000], Train Loss: 0.875981, Test Loss: 1.820590, LR: 0.050000\n",
      "Seed 88, Epoch [950/1000], Train Loss: 0.870511, Test Loss: 1.800314, LR: 0.050000\n",
      "Seed 88, Epoch [960/1000], Train Loss: 0.866461, Test Loss: 1.841045, LR: 0.050000\n",
      "Seed 88, Epoch [970/1000], Train Loss: 0.864425, Test Loss: 1.850590, LR: 0.050000\n",
      "Seed 88, Epoch [980/1000], Train Loss: 0.862504, Test Loss: 1.839882, LR: 0.050000\n",
      "Seed 88, Epoch [990/1000], Train Loss: 0.860457, Test Loss: 1.825399, LR: 0.050000\n",
      "Seed 88, Epoch [1000/1000], Train Loss: 0.858573, Test Loss: 1.816368, LR: 0.050000\n",
      "Seed 89, Epoch [10/1000], Train Loss: 2.068147, Test Loss: 1.910506, LR: 0.050000\n",
      "Seed 89, Epoch [20/1000], Train Loss: 2.341037, Test Loss: 2.066847, LR: 0.050000\n",
      "Seed 89, Epoch [30/1000], Train Loss: 2.202518, Test Loss: 1.967589, LR: 0.050000\n",
      "Seed 89, Epoch [40/1000], Train Loss: 2.096746, Test Loss: 1.971194, LR: 0.050000\n",
      "Seed 89, Epoch [50/1000], Train Loss: 2.035855, Test Loss: 1.927918, LR: 0.050000\n",
      "Seed 89, Epoch [60/1000], Train Loss: 1.907189, Test Loss: 1.807243, LR: 0.050000\n",
      "Seed 89, Epoch [70/1000], Train Loss: 1.849719, Test Loss: 1.788322, LR: 0.050000\n",
      "Seed 89, Epoch [80/1000], Train Loss: 1.645982, Test Loss: 1.646005, LR: 0.050000\n",
      "Seed 89, Epoch [90/1000], Train Loss: 1.639112, Test Loss: 1.633566, LR: 0.050000\n",
      "Seed 89, Epoch [100/1000], Train Loss: 1.378816, Test Loss: 1.187298, LR: 0.050000\n",
      "Seed 89, Epoch [110/1000], Train Loss: 1.162767, Test Loss: 0.970550, LR: 0.050000\n",
      "Seed 89, Epoch [120/1000], Train Loss: 1.074913, Test Loss: 0.819814, LR: 0.050000\n",
      "Seed 89, Epoch [130/1000], Train Loss: 1.015591, Test Loss: 0.976190, LR: 0.050000\n",
      "Seed 89, Epoch [140/1000], Train Loss: 1.219256, Test Loss: 2.135617, LR: 0.050000\n",
      "Seed 89, Epoch [150/1000], Train Loss: 2.314663, Test Loss: 2.759071, LR: 0.050000\n",
      "Seed 89, Epoch [160/1000], Train Loss: 2.019314, Test Loss: 2.353830, LR: 0.050000\n",
      "Seed 89, Epoch [170/1000], Train Loss: 1.830791, Test Loss: 2.107729, LR: 0.050000\n",
      "Seed 89, Epoch [180/1000], Train Loss: 1.626118, Test Loss: 1.974406, LR: 0.050000\n",
      "Seed 89, Epoch [190/1000], Train Loss: 1.526209, Test Loss: 1.858025, LR: 0.050000\n",
      "Seed 89, Epoch [200/1000], Train Loss: 1.477438, Test Loss: 1.756114, LR: 0.050000\n",
      "Seed 89, Epoch [210/1000], Train Loss: 1.424317, Test Loss: 1.659832, LR: 0.050000\n",
      "Seed 89, Epoch [220/1000], Train Loss: 1.359989, Test Loss: 1.555557, LR: 0.050000\n",
      "Seed 89, Epoch [230/1000], Train Loss: 1.258899, Test Loss: 1.414364, LR: 0.050000\n",
      "Seed 89, Epoch [240/1000], Train Loss: 1.186927, Test Loss: 1.357750, LR: 0.050000\n",
      "Seed 89, Epoch [250/1000], Train Loss: 1.154079, Test Loss: 1.333600, LR: 0.050000\n",
      "Seed 89, Epoch [260/1000], Train Loss: 1.098999, Test Loss: 1.383004, LR: 0.050000\n",
      "Seed 89, Epoch [270/1000], Train Loss: 1.025908, Test Loss: 1.452892, LR: 0.050000\n",
      "Seed 89, Epoch [280/1000], Train Loss: 0.985830, Test Loss: 1.571992, LR: 0.050000\n",
      "Seed 89, Epoch [290/1000], Train Loss: 0.962352, Test Loss: 1.703966, LR: 0.050000\n",
      "Seed 89, Epoch [300/1000], Train Loss: 0.946355, Test Loss: 1.790659, LR: 0.050000\n",
      "Seed 89, Epoch [310/1000], Train Loss: 0.931125, Test Loss: 1.873503, LR: 0.050000\n",
      "Seed 89, Epoch [320/1000], Train Loss: 0.915134, Test Loss: 1.841377, LR: 0.050000\n",
      "Seed 89, Epoch [330/1000], Train Loss: 0.895566, Test Loss: 1.806304, LR: 0.050000\n",
      "Seed 89, Epoch [340/1000], Train Loss: 0.886319, Test Loss: 1.512318, LR: 0.050000\n",
      "Seed 89, Epoch [350/1000], Train Loss: 0.911896, Test Loss: 1.537225, LR: 0.050000\n",
      "Seed 89, Epoch [360/1000], Train Loss: 0.846219, Test Loss: 1.538830, LR: 0.050000\n",
      "Seed 89, Epoch [370/1000], Train Loss: 0.817402, Test Loss: 1.539515, LR: 0.050000\n",
      "Seed 89, Epoch [380/1000], Train Loss: 0.839563, Test Loss: 1.284575, LR: 0.050000\n",
      "Seed 89, Epoch [390/1000], Train Loss: 0.821632, Test Loss: 1.513287, LR: 0.050000\n",
      "Seed 89, Epoch [400/1000], Train Loss: 0.782443, Test Loss: 1.422529, LR: 0.050000\n",
      "Seed 89, Epoch [410/1000], Train Loss: 0.766698, Test Loss: 1.300884, LR: 0.050000\n",
      "Seed 89, Epoch [420/1000], Train Loss: 0.756161, Test Loss: 1.268917, LR: 0.050000\n",
      "Seed 89, Epoch [430/1000], Train Loss: 0.788945, Test Loss: 1.198233, LR: 0.050000\n",
      "Seed 89, Epoch [440/1000], Train Loss: 0.743522, Test Loss: 1.249076, LR: 0.050000\n",
      "Seed 89, Epoch [450/1000], Train Loss: 0.739875, Test Loss: 1.250617, LR: 0.050000\n",
      "Seed 89, Epoch [460/1000], Train Loss: 0.755247, Test Loss: 1.163422, LR: 0.050000\n",
      "Seed 89, Epoch [470/1000], Train Loss: 0.735085, Test Loss: 1.152489, LR: 0.050000\n",
      "Seed 89, Epoch [480/1000], Train Loss: 0.724251, Test Loss: 1.201213, LR: 0.050000\n",
      "Seed 89, Epoch [490/1000], Train Loss: 0.730439, Test Loss: 1.172486, LR: 0.050000\n",
      "Seed 89, Epoch [500/1000], Train Loss: 0.711488, Test Loss: 1.182125, LR: 0.050000\n",
      "Seed 89, Epoch [510/1000], Train Loss: 0.704961, Test Loss: 1.160342, LR: 0.050000\n",
      "Seed 89, Epoch [520/1000], Train Loss: 0.779280, Test Loss: 1.275718, LR: 0.050000\n",
      "Seed 89, Epoch [530/1000], Train Loss: 0.707036, Test Loss: 1.183721, LR: 0.050000\n",
      "Seed 89, Epoch [540/1000], Train Loss: 0.706158, Test Loss: 1.148856, LR: 0.050000\n",
      "Seed 89, Epoch [550/1000], Train Loss: 0.687326, Test Loss: 1.115557, LR: 0.050000\n",
      "Seed 89, Epoch [560/1000], Train Loss: 0.685392, Test Loss: 1.130349, LR: 0.050000\n",
      "Seed 89, Epoch [570/1000], Train Loss: 0.700105, Test Loss: 1.119300, LR: 0.050000\n",
      "Seed 89, Epoch [580/1000], Train Loss: 0.678787, Test Loss: 1.123075, LR: 0.050000\n",
      "Seed 89, Epoch [590/1000], Train Loss: 0.685507, Test Loss: 1.147516, LR: 0.050000\n",
      "Seed 89, Epoch [600/1000], Train Loss: 0.682652, Test Loss: 1.118008, LR: 0.050000\n",
      "Seed 89, Epoch [610/1000], Train Loss: 0.677149, Test Loss: 1.152185, LR: 0.050000\n",
      "Early stopping at epoch 620 for seed 89\n",
      "Seed 90, Epoch [10/1000], Train Loss: 2.558152, Test Loss: 2.359171, LR: 0.050000\n",
      "Seed 90, Epoch [20/1000], Train Loss: 2.394811, Test Loss: 2.269493, LR: 0.050000\n",
      "Seed 90, Epoch [30/1000], Train Loss: 2.506068, Test Loss: 2.372276, LR: 0.050000\n",
      "Seed 90, Epoch [40/1000], Train Loss: 2.537375, Test Loss: 2.398993, LR: 0.050000\n",
      "Seed 90, Epoch [50/1000], Train Loss: 2.529910, Test Loss: 2.390771, LR: 0.050000\n",
      "Seed 90, Epoch [60/1000], Train Loss: 2.514466, Test Loss: 2.376994, LR: 0.050000\n",
      "Seed 90, Epoch [70/1000], Train Loss: 2.502622, Test Loss: 2.367586, LR: 0.050000\n",
      "Seed 90, Epoch [80/1000], Train Loss: 2.495178, Test Loss: 2.362376, LR: 0.050000\n",
      "Seed 90, Epoch [90/1000], Train Loss: 2.490044, Test Loss: 2.358983, LR: 0.050000\n",
      "Seed 90, Epoch [100/1000], Train Loss: 2.485512, Test Loss: 2.355765, LR: 0.050000\n",
      "Seed 90, Epoch [110/1000], Train Loss: 2.480801, Test Loss: 2.352116, LR: 0.050000\n",
      "Seed 90, Epoch [120/1000], Train Loss: 2.475695, Test Loss: 2.347982, LR: 0.050000\n",
      "Seed 90, Epoch [130/1000], Train Loss: 2.470168, Test Loss: 2.343452, LR: 0.050000\n",
      "Seed 90, Epoch [140/1000], Train Loss: 2.464206, Test Loss: 2.338593, LR: 0.050000\n",
      "Seed 90, Epoch [150/1000], Train Loss: 2.457891, Test Loss: 2.333519, LR: 0.050000\n",
      "Seed 90, Epoch [160/1000], Train Loss: 2.451563, Test Loss: 2.328530, LR: 0.050000\n",
      "Seed 90, Epoch [170/1000], Train Loss: 2.444707, Test Loss: 2.323206, LR: 0.050000\n",
      "Seed 90, Epoch [180/1000], Train Loss: 2.437265, Test Loss: 2.317506, LR: 0.050000\n",
      "Seed 90, Epoch [190/1000], Train Loss: 2.429169, Test Loss: 2.311383, LR: 0.050000\n",
      "Seed 90, Epoch [200/1000], Train Loss: 2.420343, Test Loss: 2.304789, LR: 0.050000\n",
      "Seed 90, Epoch [210/1000], Train Loss: 2.410697, Test Loss: 2.297669, LR: 0.050000\n",
      "Seed 90, Epoch [220/1000], Train Loss: 2.400134, Test Loss: 2.289962, LR: 0.050000\n",
      "Seed 90, Epoch [230/1000], Train Loss: 2.388548, Test Loss: 2.281600, LR: 0.050000\n",
      "Seed 90, Epoch [240/1000], Train Loss: 2.376896, Test Loss: 2.273762, LR: 0.050000\n",
      "Seed 90, Epoch [250/1000], Train Loss: 2.362205, Test Loss: 2.262434, LR: 0.050000\n",
      "Seed 90, Epoch [260/1000], Train Loss: 2.347461, Test Loss: 2.252410, LR: 0.050000\n",
      "Seed 90, Epoch [270/1000], Train Loss: 2.330752, Test Loss: 2.239861, LR: 0.050000\n",
      "Seed 90, Epoch [280/1000], Train Loss: 2.312423, Test Loss: 2.226876, LR: 0.050000\n",
      "Seed 90, Epoch [290/1000], Train Loss: 2.291134, Test Loss: 2.212594, LR: 0.050000\n",
      "Seed 90, Epoch [300/1000], Train Loss: 2.268824, Test Loss: 2.197153, LR: 0.050000\n",
      "Seed 90, Epoch [310/1000], Train Loss: 2.246794, Test Loss: 2.180368, LR: 0.050000\n",
      "Seed 90, Epoch [320/1000], Train Loss: 2.220925, Test Loss: 2.161706, LR: 0.050000\n",
      "Seed 90, Epoch [330/1000], Train Loss: 2.192111, Test Loss: 2.140885, LR: 0.050000\n",
      "Seed 90, Epoch [340/1000], Train Loss: 2.159713, Test Loss: 2.117578, LR: 0.050000\n",
      "Seed 90, Epoch [350/1000], Train Loss: 2.122784, Test Loss: 2.091599, LR: 0.050000\n",
      "Seed 90, Epoch [360/1000], Train Loss: 2.080150, Test Loss: 2.063026, LR: 0.050000\n",
      "Seed 90, Epoch [370/1000], Train Loss: 2.030420, Test Loss: 2.030220, LR: 0.050000\n",
      "Seed 90, Epoch [380/1000], Train Loss: 1.971234, Test Loss: 1.990028, LR: 0.050000\n",
      "Seed 90, Epoch [390/1000], Train Loss: 1.899885, Test Loss: 1.942057, LR: 0.050000\n",
      "Seed 90, Epoch [400/1000], Train Loss: 1.813971, Test Loss: 1.885254, LR: 0.050000\n",
      "Seed 90, Epoch [410/1000], Train Loss: 1.714038, Test Loss: 1.816530, LR: 0.050000\n",
      "Seed 90, Epoch [420/1000], Train Loss: 1.609401, Test Loss: 1.738872, LR: 0.050000\n",
      "Seed 90, Epoch [430/1000], Train Loss: 1.517529, Test Loss: 1.653337, LR: 0.050000\n",
      "Seed 90, Epoch [440/1000], Train Loss: 1.469361, Test Loss: 1.569439, LR: 0.050000\n",
      "Seed 90, Epoch [450/1000], Train Loss: 1.455248, Test Loss: 1.523311, LR: 0.050000\n",
      "Seed 90, Epoch [460/1000], Train Loss: 1.435750, Test Loss: 1.494169, LR: 0.050000\n",
      "Seed 90, Epoch [470/1000], Train Loss: 1.424613, Test Loss: 1.460470, LR: 0.050000\n",
      "Seed 90, Epoch [480/1000], Train Loss: 1.414261, Test Loss: 1.427366, LR: 0.050000\n",
      "Seed 90, Epoch [490/1000], Train Loss: 1.405240, Test Loss: 1.401719, LR: 0.050000\n",
      "Seed 90, Epoch [500/1000], Train Loss: 1.396755, Test Loss: 1.381983, LR: 0.050000\n",
      "Seed 90, Epoch [510/1000], Train Loss: 1.388941, Test Loss: 1.361742, LR: 0.050000\n",
      "Seed 90, Epoch [520/1000], Train Loss: 1.381582, Test Loss: 1.340514, LR: 0.050000\n",
      "Seed 90, Epoch [530/1000], Train Loss: 1.374574, Test Loss: 1.320640, LR: 0.050000\n",
      "Seed 90, Epoch [540/1000], Train Loss: 1.367836, Test Loss: 1.301804, LR: 0.050000\n",
      "Seed 90, Epoch [550/1000], Train Loss: 1.361286, Test Loss: 1.283473, LR: 0.050000\n",
      "Seed 90, Epoch [560/1000], Train Loss: 1.354859, Test Loss: 1.265704, LR: 0.050000\n",
      "Seed 90, Epoch [570/1000], Train Loss: 1.348618, Test Loss: 1.248847, LR: 0.050000\n",
      "Seed 90, Epoch [580/1000], Train Loss: 1.342637, Test Loss: 1.233269, LR: 0.050000\n",
      "Seed 90, Epoch [590/1000], Train Loss: 1.336891, Test Loss: 1.218545, LR: 0.050000\n",
      "Seed 90, Epoch [600/1000], Train Loss: 1.331347, Test Loss: 1.204512, LR: 0.050000\n",
      "Seed 90, Epoch [610/1000], Train Loss: 1.325968, Test Loss: 1.191290, LR: 0.050000\n",
      "Seed 90, Epoch [620/1000], Train Loss: 1.320714, Test Loss: 1.178745, LR: 0.050000\n",
      "Seed 90, Epoch [630/1000], Train Loss: 1.315547, Test Loss: 1.166762, LR: 0.050000\n",
      "Seed 90, Epoch [640/1000], Train Loss: 1.311078, Test Loss: 2.311408, LR: 0.050000\n",
      "Seed 90, Epoch [650/1000], Train Loss: 1.537802, Test Loss: 1.319351, LR: 0.050000\n",
      "Seed 90, Epoch [660/1000], Train Loss: 1.505763, Test Loss: 1.412258, LR: 0.050000\n",
      "Seed 90, Epoch [670/1000], Train Loss: 1.425240, Test Loss: 1.289448, LR: 0.050000\n",
      "Seed 90, Epoch [680/1000], Train Loss: 1.356197, Test Loss: 1.268530, LR: 0.050000\n",
      "Seed 90, Epoch [690/1000], Train Loss: 1.594565, Test Loss: 1.442492, LR: 0.050000\n",
      "Seed 90, Epoch [700/1000], Train Loss: 1.323884, Test Loss: 1.211726, LR: 0.050000\n",
      "Seed 90, Epoch [710/1000], Train Loss: 1.324952, Test Loss: 1.151552, LR: 0.050000\n",
      "Seed 90, Epoch [720/1000], Train Loss: 1.384213, Test Loss: 1.245257, LR: 0.050000\n",
      "Seed 90, Epoch [730/1000], Train Loss: 1.280411, Test Loss: 1.137260, LR: 0.050000\n",
      "Seed 90, Epoch [740/1000], Train Loss: 1.261090, Test Loss: 1.096835, LR: 0.050000\n",
      "Seed 90, Epoch [750/1000], Train Loss: 1.275386, Test Loss: 1.137789, LR: 0.050000\n",
      "Seed 90, Epoch [760/1000], Train Loss: 1.242406, Test Loss: 1.101961, LR: 0.050000\n",
      "Seed 90, Epoch [770/1000], Train Loss: 1.222482, Test Loss: 1.089879, LR: 0.050000\n",
      "Seed 90, Epoch [780/1000], Train Loss: 1.208524, Test Loss: 1.064333, LR: 0.050000\n",
      "Seed 90, Epoch [790/1000], Train Loss: 1.198455, Test Loss: 1.061395, LR: 0.050000\n",
      "Seed 90, Epoch [800/1000], Train Loss: 1.191408, Test Loss: 1.040809, LR: 0.050000\n",
      "Seed 90, Epoch [810/1000], Train Loss: 1.185690, Test Loss: 1.032426, LR: 0.050000\n",
      "Seed 90, Epoch [820/1000], Train Loss: 1.180635, Test Loss: 1.027767, LR: 0.050000\n",
      "Seed 90, Epoch [830/1000], Train Loss: 1.175842, Test Loss: 1.021462, LR: 0.050000\n",
      "Seed 90, Epoch [840/1000], Train Loss: 1.171073, Test Loss: 1.016227, LR: 0.050000\n",
      "Seed 90, Epoch [850/1000], Train Loss: 1.166189, Test Loss: 1.007868, LR: 0.050000\n",
      "Seed 90, Epoch [860/1000], Train Loss: 1.161045, Test Loss: 0.997988, LR: 0.050000\n",
      "Seed 90, Epoch [870/1000], Train Loss: 1.155445, Test Loss: 0.985635, LR: 0.050000\n",
      "Seed 90, Epoch [880/1000], Train Loss: 1.149138, Test Loss: 0.969623, LR: 0.050000\n",
      "Seed 90, Epoch [890/1000], Train Loss: 1.141812, Test Loss: 0.949667, LR: 0.050000\n",
      "Seed 90, Epoch [900/1000], Train Loss: 1.133014, Test Loss: 0.926638, LR: 0.050000\n",
      "Seed 90, Epoch [910/1000], Train Loss: 1.121992, Test Loss: 0.904005, LR: 0.050000\n",
      "Seed 90, Epoch [920/1000], Train Loss: 1.107837, Test Loss: 0.889150, LR: 0.050000\n",
      "Seed 90, Epoch [930/1000], Train Loss: 1.091146, Test Loss: 0.890092, LR: 0.050000\n",
      "Seed 90, Epoch [940/1000], Train Loss: 1.074049, Test Loss: 0.904511, LR: 0.050000\n",
      "Seed 90, Epoch [950/1000], Train Loss: 1.056705, Test Loss: 0.923585, LR: 0.050000\n",
      "Seed 90, Epoch [960/1000], Train Loss: 1.038354, Test Loss: 0.947186, LR: 0.050000\n",
      "Seed 90, Epoch [970/1000], Train Loss: 1.019365, Test Loss: 0.974508, LR: 0.050000\n",
      "Seed 90, Epoch [980/1000], Train Loss: 1.001253, Test Loss: 1.003346, LR: 0.050000\n",
      "Seed 90, Epoch [990/1000], Train Loss: 0.985318, Test Loss: 1.032883, LR: 0.050000\n",
      "Seed 90, Epoch [1000/1000], Train Loss: 0.972082, Test Loss: 1.060493, LR: 0.050000\n",
      "Seed 91, Epoch [10/1000], Train Loss: 2.265402, Test Loss: 1.845287, LR: 0.050000\n",
      "Seed 91, Epoch [20/1000], Train Loss: 2.956853, Test Loss: 2.423293, LR: 0.050000\n",
      "Seed 91, Epoch [30/1000], Train Loss: 3.045851, Test Loss: 2.606493, LR: 0.050000\n",
      "Seed 91, Epoch [40/1000], Train Loss: 2.880780, Test Loss: 2.599048, LR: 0.050000\n",
      "Seed 91, Epoch [50/1000], Train Loss: 2.630977, Test Loss: 2.537547, LR: 0.050000\n",
      "Seed 91, Epoch [60/1000], Train Loss: 2.501937, Test Loss: 2.478585, LR: 0.050000\n",
      "Seed 91, Epoch [70/1000], Train Loss: 2.436127, Test Loss: 2.427988, LR: 0.050000\n",
      "Seed 91, Epoch [80/1000], Train Loss: 2.401513, Test Loss: 2.385842, LR: 0.050000\n",
      "Seed 91, Epoch [90/1000], Train Loss: 2.374490, Test Loss: 2.351583, LR: 0.050000\n",
      "Seed 91, Epoch [100/1000], Train Loss: 2.353631, Test Loss: 2.324011, LR: 0.050000\n",
      "Seed 91, Epoch [110/1000], Train Loss: 2.336187, Test Loss: 2.300657, LR: 0.050000\n",
      "Seed 91, Epoch [120/1000], Train Loss: 2.319985, Test Loss: 2.279131, LR: 0.050000\n",
      "Seed 91, Epoch [130/1000], Train Loss: 2.303158, Test Loss: 2.257047, LR: 0.050000\n",
      "Seed 91, Epoch [140/1000], Train Loss: 2.284032, Test Loss: 2.231848, LR: 0.050000\n",
      "Seed 91, Epoch [150/1000], Train Loss: 2.261247, Test Loss: 2.200522, LR: 0.050000\n",
      "Seed 91, Epoch [160/1000], Train Loss: 2.234426, Test Loss: 2.160220, LR: 0.050000\n",
      "Seed 91, Epoch [170/1000], Train Loss: 2.205295, Test Loss: 2.110837, LR: 0.050000\n",
      "Seed 91, Epoch [180/1000], Train Loss: 2.177253, Test Loss: 2.058021, LR: 0.050000\n",
      "Seed 91, Epoch [190/1000], Train Loss: 2.151115, Test Loss: 2.009314, LR: 0.050000\n",
      "Seed 91, Epoch [200/1000], Train Loss: 2.125296, Test Loss: 1.967218, LR: 0.050000\n",
      "Seed 91, Epoch [210/1000], Train Loss: 2.098910, Test Loss: 1.929650, LR: 0.050000\n",
      "Seed 91, Epoch [220/1000], Train Loss: 2.071600, Test Loss: 1.893249, LR: 0.050000\n",
      "Seed 91, Epoch [230/1000], Train Loss: 2.043142, Test Loss: 1.855870, LR: 0.050000\n",
      "Seed 91, Epoch [240/1000], Train Loss: 2.013420, Test Loss: 1.817102, LR: 0.050000\n",
      "Seed 91, Epoch [250/1000], Train Loss: 1.982051, Test Loss: 1.777876, LR: 0.050000\n",
      "Seed 91, Epoch [260/1000], Train Loss: 1.948892, Test Loss: 1.738926, LR: 0.050000\n",
      "Seed 91, Epoch [270/1000], Train Loss: 1.913994, Test Loss: 1.700080, LR: 0.050000\n",
      "Seed 91, Epoch [280/1000], Train Loss: 1.877447, Test Loss: 1.661641, LR: 0.050000\n",
      "Seed 91, Epoch [290/1000], Train Loss: 1.839077, Test Loss: 1.623719, LR: 0.050000\n",
      "Seed 91, Epoch [300/1000], Train Loss: 1.799705, Test Loss: 1.588194, LR: 0.050000\n",
      "Seed 91, Epoch [310/1000], Train Loss: 1.777841, Test Loss: 1.611178, LR: 0.050000\n",
      "Seed 91, Epoch [320/1000], Train Loss: 1.746247, Test Loss: 1.569725, LR: 0.050000\n",
      "Seed 91, Epoch [330/1000], Train Loss: 1.695086, Test Loss: 1.526863, LR: 0.050000\n",
      "Seed 91, Epoch [340/1000], Train Loss: 1.702902, Test Loss: 1.560349, LR: 0.050000\n",
      "Seed 91, Epoch [350/1000], Train Loss: 1.634763, Test Loss: 1.506103, LR: 0.050000\n",
      "Seed 91, Epoch [360/1000], Train Loss: 1.606376, Test Loss: 1.529332, LR: 0.050000\n",
      "Seed 91, Epoch [370/1000], Train Loss: 1.606233, Test Loss: 1.499429, LR: 0.050000\n",
      "Seed 91, Epoch [380/1000], Train Loss: 1.546952, Test Loss: 1.480637, LR: 0.050000\n",
      "Seed 91, Epoch [390/1000], Train Loss: 1.644173, Test Loss: 1.727849, LR: 0.050000\n",
      "Seed 91, Epoch [400/1000], Train Loss: 1.525938, Test Loss: 1.475869, LR: 0.050000\n",
      "Seed 91, Epoch [410/1000], Train Loss: 1.483446, Test Loss: 1.625162, LR: 0.050000\n",
      "Seed 91, Epoch [420/1000], Train Loss: 1.465464, Test Loss: 1.473321, LR: 0.050000\n",
      "Seed 91, Epoch [430/1000], Train Loss: 1.467242, Test Loss: 1.443984, LR: 0.050000\n",
      "Seed 91, Epoch [440/1000], Train Loss: 1.420918, Test Loss: 1.687521, LR: 0.050000\n",
      "Seed 91, Epoch [450/1000], Train Loss: 1.398695, Test Loss: 1.422454, LR: 0.050000\n",
      "Seed 91, Epoch [460/1000], Train Loss: 1.369958, Test Loss: 1.596052, LR: 0.050000\n",
      "Seed 91, Epoch [470/1000], Train Loss: 1.362120, Test Loss: 1.753194, LR: 0.050000\n",
      "Seed 91, Epoch [480/1000], Train Loss: 1.343738, Test Loss: 1.364918, LR: 0.050000\n",
      "Seed 91, Epoch [490/1000], Train Loss: 1.326353, Test Loss: 1.436040, LR: 0.050000\n",
      "Seed 91, Epoch [500/1000], Train Loss: 1.311378, Test Loss: 1.428836, LR: 0.050000\n",
      "Seed 91, Epoch [510/1000], Train Loss: 1.346783, Test Loss: 1.372319, LR: 0.050000\n",
      "Seed 91, Epoch [520/1000], Train Loss: 1.295249, Test Loss: 1.412789, LR: 0.050000\n",
      "Seed 91, Epoch [530/1000], Train Loss: 1.278705, Test Loss: 1.363626, LR: 0.050000\n",
      "Seed 91, Epoch [540/1000], Train Loss: 1.281806, Test Loss: 1.330592, LR: 0.050000\n",
      "Seed 91, Epoch [550/1000], Train Loss: 1.259443, Test Loss: 1.348833, LR: 0.050000\n",
      "Seed 91, Epoch [560/1000], Train Loss: 1.247857, Test Loss: 1.310916, LR: 0.050000\n",
      "Seed 91, Epoch [570/1000], Train Loss: 1.238916, Test Loss: 1.262765, LR: 0.050000\n",
      "Seed 91, Epoch [580/1000], Train Loss: 1.228672, Test Loss: 1.270579, LR: 0.050000\n",
      "Seed 91, Epoch [590/1000], Train Loss: 1.219655, Test Loss: 1.238046, LR: 0.050000\n",
      "Seed 91, Epoch [600/1000], Train Loss: 1.210696, Test Loss: 1.219019, LR: 0.050000\n",
      "Seed 91, Epoch [610/1000], Train Loss: 1.202354, Test Loss: 1.200585, LR: 0.050000\n",
      "Seed 91, Epoch [620/1000], Train Loss: 1.193488, Test Loss: 1.182042, LR: 0.050000\n",
      "Seed 91, Epoch [630/1000], Train Loss: 1.186315, Test Loss: 1.163508, LR: 0.050000\n",
      "Seed 91, Epoch [640/1000], Train Loss: 1.178026, Test Loss: 1.148578, LR: 0.050000\n",
      "Seed 91, Epoch [650/1000], Train Loss: 1.171573, Test Loss: 1.131223, LR: 0.050000\n",
      "Seed 91, Epoch [660/1000], Train Loss: 1.163453, Test Loss: 1.114580, LR: 0.050000\n",
      "Seed 91, Epoch [670/1000], Train Loss: 1.156626, Test Loss: 1.097106, LR: 0.050000\n",
      "Seed 91, Epoch [680/1000], Train Loss: 1.150117, Test Loss: 1.084544, LR: 0.050000\n",
      "Seed 91, Epoch [690/1000], Train Loss: 1.143698, Test Loss: 1.065147, LR: 0.050000\n",
      "Seed 91, Epoch [700/1000], Train Loss: 1.137315, Test Loss: 1.050761, LR: 0.050000\n",
      "Seed 91, Epoch [710/1000], Train Loss: 1.131622, Test Loss: 1.033994, LR: 0.050000\n",
      "Seed 91, Epoch [720/1000], Train Loss: 1.124844, Test Loss: 1.018517, LR: 0.050000\n",
      "Seed 91, Epoch [730/1000], Train Loss: 1.119915, Test Loss: 1.004544, LR: 0.050000\n",
      "Seed 91, Epoch [740/1000], Train Loss: 1.113108, Test Loss: 0.985671, LR: 0.050000\n",
      "Seed 91, Epoch [750/1000], Train Loss: 1.108559, Test Loss: 0.976590, LR: 0.050000\n",
      "Seed 91, Epoch [760/1000], Train Loss: 1.102329, Test Loss: 0.958001, LR: 0.050000\n",
      "Seed 91, Epoch [770/1000], Train Loss: 1.097796, Test Loss: 0.946244, LR: 0.050000\n",
      "Seed 91, Epoch [780/1000], Train Loss: 1.091780, Test Loss: 0.931519, LR: 0.050000\n",
      "Seed 91, Epoch [790/1000], Train Loss: 1.087169, Test Loss: 0.920020, LR: 0.050000\n",
      "Seed 91, Epoch [800/1000], Train Loss: 1.082971, Test Loss: 0.909150, LR: 0.050000\n",
      "Seed 91, Epoch [810/1000], Train Loss: 1.078190, Test Loss: 0.897193, LR: 0.050000\n",
      "Seed 91, Epoch [820/1000], Train Loss: 1.073084, Test Loss: 0.884937, LR: 0.050000\n",
      "Seed 91, Epoch [830/1000], Train Loss: 1.068092, Test Loss: 0.874875, LR: 0.050000\n",
      "Seed 91, Epoch [840/1000], Train Loss: 1.063573, Test Loss: 0.864636, LR: 0.050000\n",
      "Seed 91, Epoch [850/1000], Train Loss: 1.058676, Test Loss: 0.855526, LR: 0.050000\n",
      "Seed 91, Epoch [860/1000], Train Loss: 1.054395, Test Loss: 0.846838, LR: 0.050000\n",
      "Seed 91, Epoch [870/1000], Train Loss: 1.049321, Test Loss: 0.838600, LR: 0.050000\n",
      "Seed 91, Epoch [880/1000], Train Loss: 1.044567, Test Loss: 0.831334, LR: 0.050000\n",
      "Seed 91, Epoch [890/1000], Train Loss: 1.158972, Test Loss: 0.887878, LR: 0.050000\n",
      "Seed 91, Epoch [900/1000], Train Loss: 1.038237, Test Loss: 0.832624, LR: 0.050000\n",
      "Seed 91, Epoch [910/1000], Train Loss: 1.031756, Test Loss: 0.817198, LR: 0.050000\n",
      "Seed 91, Epoch [920/1000], Train Loss: 1.025148, Test Loss: 0.811521, LR: 0.050000\n",
      "Seed 91, Epoch [930/1000], Train Loss: 1.037862, Test Loss: 0.852940, LR: 0.050000\n",
      "Seed 91, Epoch [940/1000], Train Loss: 1.022337, Test Loss: 0.808710, LR: 0.050000\n",
      "Seed 91, Epoch [950/1000], Train Loss: 1.013892, Test Loss: 0.811796, LR: 0.050000\n",
      "Seed 91, Epoch [960/1000], Train Loss: 1.005397, Test Loss: 0.806907, LR: 0.050000\n",
      "Seed 91, Epoch [970/1000], Train Loss: 1.074028, Test Loss: 0.843555, LR: 0.050000\n",
      "Seed 91, Epoch [980/1000], Train Loss: 1.017771, Test Loss: 0.807009, LR: 0.050000\n",
      "Seed 91, Epoch [990/1000], Train Loss: 0.996969, Test Loss: 0.841201, LR: 0.050000\n",
      "Seed 91, Epoch [1000/1000], Train Loss: 0.986927, Test Loss: 0.819279, LR: 0.050000\n",
      "Seed 92, Epoch [10/1000], Train Loss: 2.404162, Test Loss: 2.288338, LR: 0.050000\n",
      "Seed 92, Epoch [20/1000], Train Loss: 2.543774, Test Loss: 2.364656, LR: 0.050000\n",
      "Seed 92, Epoch [30/1000], Train Loss: 2.550746, Test Loss: 2.351082, LR: 0.050000\n",
      "Seed 92, Epoch [40/1000], Train Loss: 2.456975, Test Loss: 2.274233, LR: 0.050000\n",
      "Seed 92, Epoch [50/1000], Train Loss: 2.370187, Test Loss: 2.185027, LR: 0.050000\n",
      "Seed 92, Epoch [60/1000], Train Loss: 2.244924, Test Loss: 2.019175, LR: 0.050000\n",
      "Seed 92, Epoch [70/1000], Train Loss: 1.991884, Test Loss: 1.653104, LR: 0.050000\n",
      "Seed 92, Epoch [80/1000], Train Loss: 1.738047, Test Loss: 1.393289, LR: 0.050000\n",
      "Seed 92, Epoch [90/1000], Train Loss: 1.498249, Test Loss: 1.277104, LR: 0.050000\n",
      "Seed 92, Epoch [100/1000], Train Loss: 1.438972, Test Loss: 1.226243, LR: 0.050000\n",
      "Seed 92, Epoch [110/1000], Train Loss: 1.357244, Test Loss: 1.297655, LR: 0.050000\n",
      "Seed 92, Epoch [120/1000], Train Loss: 1.315314, Test Loss: 1.392936, LR: 0.050000\n",
      "Seed 92, Epoch [130/1000], Train Loss: 1.280507, Test Loss: 1.338533, LR: 0.050000\n",
      "Seed 92, Epoch [140/1000], Train Loss: 1.257951, Test Loss: 1.358701, LR: 0.050000\n",
      "Seed 92, Epoch [150/1000], Train Loss: 1.235226, Test Loss: 1.334444, LR: 0.050000\n",
      "Seed 92, Epoch [160/1000], Train Loss: 1.215487, Test Loss: 1.247000, LR: 0.050000\n",
      "Seed 92, Epoch [170/1000], Train Loss: 1.192976, Test Loss: 1.133518, LR: 0.050000\n",
      "Seed 92, Epoch [180/1000], Train Loss: 1.167778, Test Loss: 1.071727, LR: 0.050000\n",
      "Seed 92, Epoch [190/1000], Train Loss: 1.212918, Test Loss: 0.982213, LR: 0.050000\n",
      "Seed 92, Epoch [200/1000], Train Loss: 1.141777, Test Loss: 0.966659, LR: 0.050000\n",
      "Seed 92, Epoch [210/1000], Train Loss: 1.099112, Test Loss: 0.940907, LR: 0.050000\n",
      "Seed 92, Epoch [220/1000], Train Loss: 1.068461, Test Loss: 0.959246, LR: 0.050000\n",
      "Seed 92, Epoch [230/1000], Train Loss: 1.043037, Test Loss: 1.120631, LR: 0.050000\n",
      "Seed 92, Epoch [240/1000], Train Loss: 1.018499, Test Loss: 1.210743, LR: 0.050000\n",
      "Seed 92, Epoch [250/1000], Train Loss: 1.030287, Test Loss: 1.253113, LR: 0.050000\n",
      "Seed 92, Epoch [260/1000], Train Loss: 1.014051, Test Loss: 1.166474, LR: 0.050000\n",
      "Seed 92, Epoch [270/1000], Train Loss: 0.978228, Test Loss: 1.256653, LR: 0.050000\n",
      "Seed 92, Epoch [280/1000], Train Loss: 0.955601, Test Loss: 1.269474, LR: 0.050000\n",
      "Seed 92, Epoch [290/1000], Train Loss: 0.971161, Test Loss: 1.409717, LR: 0.050000\n",
      "Seed 92, Epoch [300/1000], Train Loss: 0.920050, Test Loss: 1.254692, LR: 0.050000\n",
      "Seed 92, Epoch [310/1000], Train Loss: 0.931886, Test Loss: 1.456617, LR: 0.050000\n",
      "Seed 92, Epoch [320/1000], Train Loss: 0.936631, Test Loss: 1.203241, LR: 0.050000\n",
      "Seed 92, Epoch [330/1000], Train Loss: 0.900440, Test Loss: 1.411228, LR: 0.050000\n",
      "Seed 92, Epoch [340/1000], Train Loss: 0.948651, Test Loss: 1.657801, LR: 0.050000\n",
      "Seed 92, Epoch [350/1000], Train Loss: 0.886058, Test Loss: 1.543149, LR: 0.050000\n",
      "Seed 92, Epoch [360/1000], Train Loss: 0.871673, Test Loss: 1.210646, LR: 0.050000\n",
      "Seed 92, Epoch [370/1000], Train Loss: 0.844477, Test Loss: 1.251601, LR: 0.050000\n",
      "Seed 92, Epoch [380/1000], Train Loss: 0.832509, Test Loss: 1.319265, LR: 0.050000\n",
      "Seed 92, Epoch [390/1000], Train Loss: 0.848940, Test Loss: 1.544562, LR: 0.050000\n",
      "Seed 92, Epoch [400/1000], Train Loss: 0.834766, Test Loss: 1.277881, LR: 0.050000\n",
      "Seed 92, Epoch [410/1000], Train Loss: 0.931729, Test Loss: 1.247646, LR: 0.050000\n",
      "Seed 92, Epoch [420/1000], Train Loss: 0.824168, Test Loss: 1.190990, LR: 0.050000\n",
      "Seed 92, Epoch [430/1000], Train Loss: 0.865315, Test Loss: 1.072558, LR: 0.050000\n",
      "Seed 92, Epoch [440/1000], Train Loss: 0.815832, Test Loss: 1.096676, LR: 0.050000\n",
      "Seed 92, Epoch [450/1000], Train Loss: 0.834881, Test Loss: 1.340750, LR: 0.050000\n",
      "Seed 92, Epoch [460/1000], Train Loss: 0.868456, Test Loss: 0.812470, LR: 0.050000\n",
      "Seed 92, Epoch [470/1000], Train Loss: 0.918526, Test Loss: 1.634628, LR: 0.050000\n",
      "Seed 92, Epoch [480/1000], Train Loss: 0.906054, Test Loss: 1.007700, LR: 0.050000\n",
      "Seed 92, Epoch [490/1000], Train Loss: 0.827680, Test Loss: 0.943007, LR: 0.050000\n",
      "Seed 92, Epoch [500/1000], Train Loss: 0.794501, Test Loss: 1.032743, LR: 0.050000\n",
      "Seed 92, Epoch [510/1000], Train Loss: 0.779834, Test Loss: 1.012813, LR: 0.050000\n",
      "Seed 92, Epoch [520/1000], Train Loss: 0.795518, Test Loss: 1.189531, LR: 0.050000\n",
      "Seed 92, Epoch [530/1000], Train Loss: 0.765281, Test Loss: 1.083626, LR: 0.050000\n",
      "Seed 92, Epoch [540/1000], Train Loss: 0.753840, Test Loss: 1.017292, LR: 0.050000\n",
      "Seed 92, Epoch [550/1000], Train Loss: 1.131062, Test Loss: 2.098051, LR: 0.050000\n",
      "Seed 92, Epoch [560/1000], Train Loss: 0.961190, Test Loss: 0.884043, LR: 0.050000\n",
      "Seed 92, Epoch [570/1000], Train Loss: 0.841284, Test Loss: 1.181697, LR: 0.050000\n",
      "Seed 92, Epoch [580/1000], Train Loss: 0.756432, Test Loss: 1.068070, LR: 0.050000\n",
      "Seed 92, Epoch [590/1000], Train Loss: 0.748792, Test Loss: 0.971233, LR: 0.050000\n",
      "Seed 92, Epoch [600/1000], Train Loss: 0.734430, Test Loss: 0.965110, LR: 0.050000\n",
      "Seed 92, Epoch [610/1000], Train Loss: 0.762623, Test Loss: 1.160520, LR: 0.050000\n",
      "Seed 92, Epoch [620/1000], Train Loss: 0.731083, Test Loss: 1.040289, LR: 0.050000\n",
      "Seed 92, Epoch [630/1000], Train Loss: 0.718409, Test Loss: 0.874718, LR: 0.050000\n",
      "Seed 92, Epoch [640/1000], Train Loss: 0.800004, Test Loss: 1.446838, LR: 0.050000\n",
      "Seed 92, Epoch [650/1000], Train Loss: 0.793139, Test Loss: 1.610533, LR: 0.050000\n",
      "Seed 92, Epoch [660/1000], Train Loss: 0.731551, Test Loss: 1.000315, LR: 0.050000\n",
      "Seed 92, Epoch [670/1000], Train Loss: 0.714941, Test Loss: 0.797536, LR: 0.050000\n",
      "Seed 92, Epoch [680/1000], Train Loss: 0.704460, Test Loss: 0.811993, LR: 0.050000\n",
      "Seed 92, Epoch [690/1000], Train Loss: 0.692152, Test Loss: 0.842011, LR: 0.050000\n",
      "Seed 92, Epoch [700/1000], Train Loss: 0.719152, Test Loss: 0.765665, LR: 0.050000\n",
      "Seed 92, Epoch [710/1000], Train Loss: 0.698759, Test Loss: 0.771949, LR: 0.050000\n",
      "Seed 92, Epoch [720/1000], Train Loss: 0.762900, Test Loss: 0.750599, LR: 0.050000\n",
      "Seed 92, Epoch [730/1000], Train Loss: 0.724867, Test Loss: 0.950134, LR: 0.050000\n",
      "Seed 92, Epoch [740/1000], Train Loss: 0.759970, Test Loss: 0.732092, LR: 0.050000\n",
      "Seed 92, Epoch [750/1000], Train Loss: 0.780593, Test Loss: 1.112996, LR: 0.050000\n",
      "Seed 92, Epoch [760/1000], Train Loss: 0.711624, Test Loss: 0.956111, LR: 0.050000\n",
      "Seed 92, Epoch [770/1000], Train Loss: 0.952949, Test Loss: 0.689830, LR: 0.050000\n",
      "Seed 92, Epoch [780/1000], Train Loss: 0.703060, Test Loss: 0.984481, LR: 0.050000\n",
      "Seed 92, Epoch [790/1000], Train Loss: 0.716172, Test Loss: 0.912810, LR: 0.050000\n",
      "Seed 92, Epoch [800/1000], Train Loss: 0.739440, Test Loss: 0.772584, LR: 0.050000\n",
      "Seed 92, Epoch [810/1000], Train Loss: 0.704245, Test Loss: 0.724343, LR: 0.050000\n",
      "Seed 92, Epoch [820/1000], Train Loss: 0.679913, Test Loss: 0.784246, LR: 0.050000\n",
      "Seed 92, Epoch [830/1000], Train Loss: 0.970512, Test Loss: 1.225285, LR: 0.050000\n",
      "Seed 92, Epoch [840/1000], Train Loss: 0.777976, Test Loss: 1.079749, LR: 0.050000\n",
      "Seed 92, Epoch [850/1000], Train Loss: 0.816666, Test Loss: 0.780478, LR: 0.050000\n",
      "Seed 92, Epoch [860/1000], Train Loss: 0.735803, Test Loss: 0.900988, LR: 0.050000\n",
      "Seed 92, Epoch [870/1000], Train Loss: 0.681247, Test Loss: 0.791854, LR: 0.050000\n",
      "Seed 92, Epoch [880/1000], Train Loss: 0.701023, Test Loss: 0.819265, LR: 0.050000\n",
      "Seed 92, Epoch [890/1000], Train Loss: 1.215939, Test Loss: 0.683654, LR: 0.050000\n",
      "Seed 92, Epoch [900/1000], Train Loss: 0.727358, Test Loss: 0.724079, LR: 0.050000\n",
      "Seed 92, Epoch [910/1000], Train Loss: 0.699026, Test Loss: 0.885606, LR: 0.050000\n",
      "Seed 92, Epoch [920/1000], Train Loss: 0.774855, Test Loss: 0.751046, LR: 0.050000\n",
      "Seed 92, Epoch [930/1000], Train Loss: 0.715263, Test Loss: 0.752803, LR: 0.050000\n",
      "Seed 92, Epoch [940/1000], Train Loss: 0.694846, Test Loss: 0.770576, LR: 0.050000\n",
      "Seed 92, Epoch [950/1000], Train Loss: 0.829554, Test Loss: 1.298316, LR: 0.050000\n",
      "Seed 92, Epoch [960/1000], Train Loss: 0.818571, Test Loss: 1.159260, LR: 0.050000\n",
      "Seed 92, Epoch [970/1000], Train Loss: 0.732914, Test Loss: 0.805318, LR: 0.050000\n",
      "Seed 92, Epoch [980/1000], Train Loss: 0.765360, Test Loss: 1.103554, LR: 0.050000\n",
      "Seed 92, Epoch [990/1000], Train Loss: 1.095397, Test Loss: 1.516164, LR: 0.050000\n",
      "Seed 92, Epoch [1000/1000], Train Loss: 1.042116, Test Loss: 1.019407, LR: 0.050000\n",
      "Seed 93, Epoch [10/1000], Train Loss: 3.917500, Test Loss: 3.198395, LR: 0.050000\n",
      "Seed 93, Epoch [20/1000], Train Loss: 2.470063, Test Loss: 2.346574, LR: 0.050000\n",
      "Seed 93, Epoch [30/1000], Train Loss: 2.385049, Test Loss: 2.309383, LR: 0.050000\n",
      "Seed 93, Epoch [40/1000], Train Loss: 2.401992, Test Loss: 2.312024, LR: 0.050000\n",
      "Seed 93, Epoch [50/1000], Train Loss: 2.329974, Test Loss: 2.277647, LR: 0.050000\n",
      "Seed 93, Epoch [60/1000], Train Loss: 2.263988, Test Loss: 2.253196, LR: 0.050000\n",
      "Seed 93, Epoch [70/1000], Train Loss: 2.171234, Test Loss: 2.231836, LR: 0.050000\n",
      "Seed 93, Epoch [80/1000], Train Loss: 2.064089, Test Loss: 2.210934, LR: 0.050000\n",
      "Seed 93, Epoch [90/1000], Train Loss: 2.026831, Test Loss: 2.144343, LR: 0.050000\n",
      "Seed 93, Epoch [100/1000], Train Loss: 1.922911, Test Loss: 2.072788, LR: 0.050000\n",
      "Seed 93, Epoch [110/1000], Train Loss: 1.728303, Test Loss: 1.953096, LR: 0.050000\n",
      "Seed 93, Epoch [120/1000], Train Loss: 1.605293, Test Loss: 1.803301, LR: 0.050000\n",
      "Seed 93, Epoch [130/1000], Train Loss: 1.535846, Test Loss: 1.690963, LR: 0.050000\n",
      "Seed 93, Epoch [140/1000], Train Loss: 1.458864, Test Loss: 1.487556, LR: 0.050000\n",
      "Seed 93, Epoch [150/1000], Train Loss: 1.373103, Test Loss: 1.211933, LR: 0.050000\n",
      "Seed 93, Epoch [160/1000], Train Loss: 1.293698, Test Loss: 1.021621, LR: 0.050000\n",
      "Seed 93, Epoch [170/1000], Train Loss: 1.235231, Test Loss: 1.049505, LR: 0.050000\n",
      "Seed 93, Epoch [180/1000], Train Loss: 1.195877, Test Loss: 1.096215, LR: 0.050000\n",
      "Seed 93, Epoch [190/1000], Train Loss: 1.168557, Test Loss: 1.046098, LR: 0.050000\n",
      "Seed 93, Epoch [200/1000], Train Loss: 1.141836, Test Loss: 0.987049, LR: 0.050000\n",
      "Seed 93, Epoch [210/1000], Train Loss: 1.125381, Test Loss: 1.023266, LR: 0.050000\n",
      "Seed 93, Epoch [220/1000], Train Loss: 1.117511, Test Loss: 1.019422, LR: 0.050000\n",
      "Seed 93, Epoch [230/1000], Train Loss: 1.106671, Test Loss: 0.954562, LR: 0.050000\n",
      "Seed 93, Epoch [240/1000], Train Loss: 1.098780, Test Loss: 1.046775, LR: 0.050000\n",
      "Seed 93, Epoch [250/1000], Train Loss: 1.094041, Test Loss: 1.014045, LR: 0.050000\n",
      "Seed 93, Epoch [260/1000], Train Loss: 1.088308, Test Loss: 0.987250, LR: 0.050000\n",
      "Seed 93, Epoch [270/1000], Train Loss: 1.093777, Test Loss: 0.956688, LR: 0.050000\n",
      "Seed 93, Epoch [280/1000], Train Loss: 1.089960, Test Loss: 0.900421, LR: 0.050000\n",
      "Seed 93, Epoch [290/1000], Train Loss: 1.074887, Test Loss: 1.007101, LR: 0.050000\n",
      "Seed 93, Epoch [300/1000], Train Loss: 1.070802, Test Loss: 1.009395, LR: 0.050000\n",
      "Seed 93, Epoch [310/1000], Train Loss: 1.065340, Test Loss: 0.952966, LR: 0.050000\n",
      "Seed 93, Epoch [320/1000], Train Loss: 1.061834, Test Loss: 1.032049, LR: 0.050000\n",
      "Seed 93, Epoch [330/1000], Train Loss: 1.055438, Test Loss: 0.891501, LR: 0.050000\n",
      "Seed 93, Epoch [340/1000], Train Loss: 1.060147, Test Loss: 1.188492, LR: 0.050000\n",
      "Seed 93, Epoch [350/1000], Train Loss: 1.037297, Test Loss: 1.110426, LR: 0.050000\n",
      "Seed 93, Epoch [360/1000], Train Loss: 1.030100, Test Loss: 1.141091, LR: 0.050000\n",
      "Seed 93, Epoch [370/1000], Train Loss: 1.054833, Test Loss: 0.955415, LR: 0.050000\n",
      "Seed 93, Epoch [380/1000], Train Loss: 1.018003, Test Loss: 1.251696, LR: 0.050000\n",
      "Seed 93, Epoch [390/1000], Train Loss: 0.999836, Test Loss: 1.391023, LR: 0.050000\n",
      "Seed 93, Epoch [400/1000], Train Loss: 1.042625, Test Loss: 1.202098, LR: 0.050000\n",
      "Seed 93, Epoch [410/1000], Train Loss: 0.983327, Test Loss: 1.740172, LR: 0.050000\n",
      "Seed 93, Epoch [420/1000], Train Loss: 0.986855, Test Loss: 1.574334, LR: 0.050000\n",
      "Seed 93, Epoch [430/1000], Train Loss: 1.066032, Test Loss: 1.244664, LR: 0.050000\n",
      "Seed 93, Epoch [440/1000], Train Loss: 0.967580, Test Loss: 1.382874, LR: 0.050000\n",
      "Seed 93, Epoch [450/1000], Train Loss: 0.964845, Test Loss: 2.364840, LR: 0.050000\n",
      "Seed 93, Epoch [460/1000], Train Loss: 0.954415, Test Loss: 2.364750, LR: 0.050000\n",
      "Seed 93, Epoch [470/1000], Train Loss: 0.972735, Test Loss: 1.817907, LR: 0.050000\n",
      "Seed 93, Epoch [480/1000], Train Loss: 0.938244, Test Loss: 2.231217, LR: 0.050000\n",
      "Seed 93, Epoch [490/1000], Train Loss: 0.933939, Test Loss: 3.012927, LR: 0.050000\n",
      "Seed 93, Epoch [500/1000], Train Loss: 0.921006, Test Loss: 2.002630, LR: 0.050000\n",
      "Seed 93, Epoch [510/1000], Train Loss: 0.896946, Test Loss: 2.977430, LR: 0.050000\n",
      "Seed 93, Epoch [520/1000], Train Loss: 0.927936, Test Loss: 2.536386, LR: 0.050000\n",
      "Seed 93, Epoch [530/1000], Train Loss: 0.919214, Test Loss: 2.993177, LR: 0.050000\n",
      "Seed 93, Epoch [540/1000], Train Loss: 0.895541, Test Loss: 3.073634, LR: 0.050000\n",
      "Seed 93, Epoch [550/1000], Train Loss: 0.861493, Test Loss: 3.536340, LR: 0.050000\n",
      "Seed 93, Epoch [560/1000], Train Loss: 0.874872, Test Loss: 3.269683, LR: 0.050000\n",
      "Seed 93, Epoch [570/1000], Train Loss: 0.832208, Test Loss: 3.510477, LR: 0.050000\n",
      "Seed 93, Epoch [580/1000], Train Loss: 1.084178, Test Loss: 2.465925, LR: 0.050000\n",
      "Seed 93, Epoch [590/1000], Train Loss: 0.938561, Test Loss: 2.340728, LR: 0.050000\n",
      "Seed 93, Epoch [600/1000], Train Loss: 0.851096, Test Loss: 2.957911, LR: 0.050000\n",
      "Seed 93, Epoch [610/1000], Train Loss: 0.822658, Test Loss: 3.028268, LR: 0.050000\n",
      "Seed 93, Epoch [620/1000], Train Loss: 0.811195, Test Loss: 2.960766, LR: 0.050000\n",
      "Seed 93, Epoch [630/1000], Train Loss: 0.799817, Test Loss: 2.918569, LR: 0.050000\n",
      "Seed 93, Epoch [640/1000], Train Loss: 0.808909, Test Loss: 2.779440, LR: 0.050000\n",
      "Seed 93, Epoch [650/1000], Train Loss: 0.797805, Test Loss: 2.859075, LR: 0.050000\n",
      "Seed 93, Epoch [660/1000], Train Loss: 0.783945, Test Loss: 2.574469, LR: 0.050000\n",
      "Seed 93, Epoch [670/1000], Train Loss: 0.791540, Test Loss: 2.349198, LR: 0.050000\n",
      "Seed 93, Epoch [680/1000], Train Loss: 0.784484, Test Loss: 2.417922, LR: 0.050000\n",
      "Seed 93, Epoch [690/1000], Train Loss: 0.775137, Test Loss: 2.311668, LR: 0.050000\n",
      "Seed 93, Epoch [700/1000], Train Loss: 0.748480, Test Loss: 2.257945, LR: 0.050000\n",
      "Seed 93, Epoch [710/1000], Train Loss: 0.733182, Test Loss: 2.274970, LR: 0.050000\n",
      "Seed 93, Epoch [720/1000], Train Loss: 0.851381, Test Loss: 2.035983, LR: 0.050000\n",
      "Seed 93, Epoch [730/1000], Train Loss: 0.830986, Test Loss: 1.914627, LR: 0.050000\n",
      "Seed 93, Epoch [740/1000], Train Loss: 0.750040, Test Loss: 2.009899, LR: 0.050000\n",
      "Seed 93, Epoch [750/1000], Train Loss: 0.723637, Test Loss: 1.980721, LR: 0.050000\n",
      "Seed 93, Epoch [760/1000], Train Loss: 0.708567, Test Loss: 1.915900, LR: 0.050000\n",
      "Seed 93, Epoch [770/1000], Train Loss: 0.741409, Test Loss: 1.941908, LR: 0.050000\n",
      "Seed 93, Epoch [780/1000], Train Loss: 0.728669, Test Loss: 1.824021, LR: 0.050000\n",
      "Seed 93, Epoch [790/1000], Train Loss: 0.704930, Test Loss: 1.804111, LR: 0.050000\n",
      "Seed 93, Epoch [800/1000], Train Loss: 0.676124, Test Loss: 1.756272, LR: 0.050000\n",
      "Seed 93, Epoch [810/1000], Train Loss: 0.768300, Test Loss: 1.894177, LR: 0.050000\n",
      "Seed 93, Epoch [820/1000], Train Loss: 0.687359, Test Loss: 1.700454, LR: 0.050000\n",
      "Early stopping at epoch 825 for seed 93\n",
      "Seed 94, Epoch [10/1000], Train Loss: 3.118855, Test Loss: 2.739890, LR: 0.050000\n",
      "Seed 94, Epoch [20/1000], Train Loss: 2.322699, Test Loss: 2.181918, LR: 0.050000\n",
      "Seed 94, Epoch [30/1000], Train Loss: 2.293759, Test Loss: 2.169012, LR: 0.050000\n",
      "Seed 94, Epoch [40/1000], Train Loss: 2.319257, Test Loss: 2.194162, LR: 0.050000\n",
      "Seed 94, Epoch [50/1000], Train Loss: 2.318744, Test Loss: 2.190562, LR: 0.050000\n",
      "Seed 94, Epoch [60/1000], Train Loss: 2.299724, Test Loss: 2.170772, LR: 0.050000\n",
      "Seed 94, Epoch [70/1000], Train Loss: 2.276822, Test Loss: 2.149948, LR: 0.050000\n",
      "Seed 94, Epoch [80/1000], Train Loss: 2.246880, Test Loss: 2.125965, LR: 0.050000\n",
      "Seed 94, Epoch [90/1000], Train Loss: 2.201174, Test Loss: 2.089392, LR: 0.050000\n",
      "Seed 94, Epoch [100/1000], Train Loss: 2.142214, Test Loss: 2.034903, LR: 0.050000\n",
      "Seed 94, Epoch [110/1000], Train Loss: 2.078999, Test Loss: 1.979058, LR: 0.050000\n",
      "Seed 94, Epoch [120/1000], Train Loss: 2.013878, Test Loss: 1.928076, LR: 0.050000\n",
      "Seed 94, Epoch [130/1000], Train Loss: 1.935578, Test Loss: 1.836886, LR: 0.050000\n",
      "Seed 94, Epoch [140/1000], Train Loss: 1.829185, Test Loss: 1.675357, LR: 0.050000\n",
      "Seed 94, Epoch [150/1000], Train Loss: 1.688315, Test Loss: 1.568187, LR: 0.050000\n",
      "Seed 94, Epoch [160/1000], Train Loss: 1.510026, Test Loss: 1.430092, LR: 0.050000\n",
      "Seed 94, Epoch [170/1000], Train Loss: 1.386958, Test Loss: 1.416537, LR: 0.050000\n",
      "Seed 94, Epoch [180/1000], Train Loss: 1.355542, Test Loss: 1.332488, LR: 0.050000\n",
      "Seed 94, Epoch [190/1000], Train Loss: 1.319022, Test Loss: 1.175295, LR: 0.050000\n",
      "Seed 94, Epoch [200/1000], Train Loss: 1.286895, Test Loss: 1.124741, LR: 0.050000\n",
      "Seed 94, Epoch [210/1000], Train Loss: 1.257431, Test Loss: 1.073385, LR: 0.050000\n",
      "Seed 94, Epoch [220/1000], Train Loss: 1.229294, Test Loss: 1.012417, LR: 0.050000\n",
      "Seed 94, Epoch [230/1000], Train Loss: 1.203652, Test Loss: 0.969671, LR: 0.050000\n",
      "Seed 94, Epoch [240/1000], Train Loss: 1.182498, Test Loss: 0.940065, LR: 0.050000\n",
      "Seed 94, Epoch [250/1000], Train Loss: 1.165931, Test Loss: 0.912684, LR: 0.050000\n",
      "Seed 94, Epoch [260/1000], Train Loss: 1.152539, Test Loss: 0.889585, LR: 0.050000\n",
      "Seed 94, Epoch [270/1000], Train Loss: 1.141826, Test Loss: 0.866960, LR: 0.050000\n",
      "Seed 94, Epoch [280/1000], Train Loss: 1.133289, Test Loss: 0.848086, LR: 0.050000\n",
      "Seed 94, Epoch [290/1000], Train Loss: 1.126339, Test Loss: 0.832957, LR: 0.050000\n",
      "Seed 94, Epoch [300/1000], Train Loss: 1.120357, Test Loss: 0.820429, LR: 0.050000\n",
      "Seed 94, Epoch [310/1000], Train Loss: 1.114779, Test Loss: 0.810696, LR: 0.050000\n",
      "Seed 94, Epoch [320/1000], Train Loss: 1.109221, Test Loss: 0.801638, LR: 0.050000\n",
      "Seed 94, Epoch [330/1000], Train Loss: 1.103615, Test Loss: 0.792421, LR: 0.050000\n",
      "Seed 94, Epoch [340/1000], Train Loss: 1.098173, Test Loss: 0.783206, LR: 0.050000\n",
      "Seed 94, Epoch [350/1000], Train Loss: 1.093237, Test Loss: 0.774052, LR: 0.050000\n",
      "Seed 94, Epoch [360/1000], Train Loss: 1.088923, Test Loss: 0.764596, LR: 0.050000\n",
      "Seed 94, Epoch [370/1000], Train Loss: 2.750428, Test Loss: 2.518690, LR: 0.050000\n",
      "Seed 94, Epoch [380/1000], Train Loss: 2.081942, Test Loss: 2.050177, LR: 0.050000\n",
      "Seed 94, Epoch [390/1000], Train Loss: 2.191268, Test Loss: 2.122474, LR: 0.050000\n",
      "Seed 94, Epoch [400/1000], Train Loss: 2.171742, Test Loss: 2.090987, LR: 0.050000\n",
      "Seed 94, Epoch [410/1000], Train Loss: 2.072850, Test Loss: 2.037561, LR: 0.050000\n",
      "Seed 94, Epoch [420/1000], Train Loss: 2.007822, Test Loss: 1.989000, LR: 0.050000\n",
      "Seed 94, Epoch [430/1000], Train Loss: 1.932658, Test Loss: 1.938114, LR: 0.050000\n",
      "Seed 94, Epoch [440/1000], Train Loss: 1.762852, Test Loss: 1.777091, LR: 0.050000\n",
      "Seed 94, Epoch [450/1000], Train Loss: 1.639186, Test Loss: 1.667541, LR: 0.050000\n",
      "Seed 94, Epoch [460/1000], Train Loss: 1.478671, Test Loss: 1.573713, LR: 0.050000\n",
      "Seed 94, Epoch [470/1000], Train Loss: 1.364106, Test Loss: 1.443165, LR: 0.050000\n",
      "Seed 94, Epoch [480/1000], Train Loss: 1.267448, Test Loss: 1.190244, LR: 0.050000\n",
      "Seed 94, Epoch [490/1000], Train Loss: 1.178006, Test Loss: 0.933788, LR: 0.050000\n",
      "Seed 94, Epoch [500/1000], Train Loss: 1.137092, Test Loss: 0.801254, LR: 0.050000\n",
      "Seed 94, Epoch [510/1000], Train Loss: 1.101300, Test Loss: 0.765286, LR: 0.050000\n",
      "Seed 94, Epoch [520/1000], Train Loss: 1.078616, Test Loss: 0.734318, LR: 0.050000\n",
      "Seed 94, Epoch [530/1000], Train Loss: 1.064650, Test Loss: 0.736380, LR: 0.050000\n",
      "Seed 94, Epoch [540/1000], Train Loss: 1.051469, Test Loss: 0.769012, LR: 0.050000\n",
      "Seed 94, Epoch [550/1000], Train Loss: 1.036095, Test Loss: 0.815925, LR: 0.050000\n",
      "Seed 94, Epoch [560/1000], Train Loss: 1.018677, Test Loss: 0.903149, LR: 0.050000\n",
      "Seed 94, Epoch [570/1000], Train Loss: 1.000628, Test Loss: 1.037711, LR: 0.050000\n",
      "Seed 94, Epoch [580/1000], Train Loss: 0.983726, Test Loss: 1.232475, LR: 0.050000\n",
      "Seed 94, Epoch [590/1000], Train Loss: 0.968557, Test Loss: 1.476125, LR: 0.050000\n",
      "Seed 94, Epoch [600/1000], Train Loss: 0.954753, Test Loss: 1.744129, LR: 0.050000\n",
      "Seed 94, Epoch [610/1000], Train Loss: 0.942229, Test Loss: 2.006430, LR: 0.050000\n",
      "Seed 94, Epoch [620/1000], Train Loss: 0.930973, Test Loss: 2.220993, LR: 0.050000\n",
      "Seed 94, Epoch [630/1000], Train Loss: 0.926161, Test Loss: 2.685277, LR: 0.050000\n",
      "Seed 94, Epoch [640/1000], Train Loss: 1.064315, Test Loss: 0.940104, LR: 0.050000\n",
      "Seed 94, Epoch [650/1000], Train Loss: 1.008141, Test Loss: 0.833203, LR: 0.050000\n",
      "Seed 94, Epoch [660/1000], Train Loss: 0.931951, Test Loss: 0.966475, LR: 0.050000\n",
      "Seed 94, Epoch [670/1000], Train Loss: 0.910054, Test Loss: 1.101471, LR: 0.050000\n",
      "Seed 94, Epoch [680/1000], Train Loss: 0.894517, Test Loss: 1.318463, LR: 0.050000\n",
      "Seed 94, Epoch [690/1000], Train Loss: 0.879485, Test Loss: 1.642453, LR: 0.050000\n",
      "Seed 94, Epoch [700/1000], Train Loss: 0.868125, Test Loss: 1.855547, LR: 0.050000\n",
      "Seed 94, Epoch [710/1000], Train Loss: 0.858642, Test Loss: 1.965583, LR: 0.050000\n",
      "Seed 94, Epoch [720/1000], Train Loss: 0.849631, Test Loss: 1.987294, LR: 0.050000\n",
      "Seed 94, Epoch [730/1000], Train Loss: 0.841448, Test Loss: 1.951666, LR: 0.050000\n",
      "Seed 94, Epoch [740/1000], Train Loss: 0.833867, Test Loss: 1.894661, LR: 0.050000\n",
      "Seed 94, Epoch [750/1000], Train Loss: 0.827101, Test Loss: 1.848499, LR: 0.050000\n",
      "Seed 94, Epoch [760/1000], Train Loss: 0.859607, Test Loss: 2.101668, LR: 0.050000\n",
      "Seed 94, Epoch [770/1000], Train Loss: 0.831672, Test Loss: 1.184707, LR: 0.050000\n",
      "Seed 94, Epoch [780/1000], Train Loss: 0.823359, Test Loss: 1.351225, LR: 0.050000\n",
      "Seed 94, Epoch [790/1000], Train Loss: 0.812198, Test Loss: 1.383578, LR: 0.050000\n",
      "Seed 94, Epoch [800/1000], Train Loss: 0.804473, Test Loss: 1.458459, LR: 0.050000\n",
      "Seed 94, Epoch [810/1000], Train Loss: 0.803904, Test Loss: 1.675466, LR: 0.050000\n",
      "Seed 94, Epoch [820/1000], Train Loss: 0.842497, Test Loss: 1.089743, LR: 0.050000\n",
      "Seed 94, Epoch [830/1000], Train Loss: 0.804058, Test Loss: 1.057660, LR: 0.050000\n",
      "Seed 94, Epoch [840/1000], Train Loss: 0.796055, Test Loss: 1.311027, LR: 0.050000\n",
      "Seed 94, Epoch [850/1000], Train Loss: 0.788381, Test Loss: 1.326694, LR: 0.050000\n",
      "Seed 94, Epoch [860/1000], Train Loss: 0.785195, Test Loss: 1.272756, LR: 0.050000\n",
      "Seed 94, Epoch [870/1000], Train Loss: 0.884165, Test Loss: 0.983103, LR: 0.050000\n",
      "Seed 94, Epoch [880/1000], Train Loss: 0.796845, Test Loss: 1.016970, LR: 0.050000\n",
      "Seed 94, Epoch [890/1000], Train Loss: 0.778344, Test Loss: 1.106635, LR: 0.050000\n",
      "Seed 94, Epoch [900/1000], Train Loss: 0.773396, Test Loss: 1.135288, LR: 0.050000\n",
      "Seed 94, Epoch [910/1000], Train Loss: 0.771106, Test Loss: 1.119745, LR: 0.050000\n",
      "Seed 94, Epoch [920/1000], Train Loss: 0.769295, Test Loss: 1.129962, LR: 0.050000\n",
      "Seed 94, Epoch [930/1000], Train Loss: 0.774991, Test Loss: 0.784665, LR: 0.050000\n",
      "Seed 94, Epoch [940/1000], Train Loss: 0.784759, Test Loss: 0.942750, LR: 0.050000\n",
      "Seed 94, Epoch [950/1000], Train Loss: 0.772687, Test Loss: 0.844618, LR: 0.050000\n",
      "Seed 94, Epoch [960/1000], Train Loss: 0.763318, Test Loss: 0.854630, LR: 0.050000\n",
      "Seed 94, Epoch [970/1000], Train Loss: 0.758282, Test Loss: 0.936602, LR: 0.050000\n",
      "Seed 94, Epoch [980/1000], Train Loss: 0.757457, Test Loss: 0.875596, LR: 0.050000\n",
      "Seed 94, Epoch [990/1000], Train Loss: 0.752666, Test Loss: 0.871631, LR: 0.050000\n",
      "Seed 94, Epoch [1000/1000], Train Loss: 0.751092, Test Loss: 0.855857, LR: 0.050000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAGGCAYAAAB/gCblAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOy9d5hdVdn+/9n19Ok9nXSkBkSkV1EEEaRo8JUmoOKrgF0sIAoioAhSVJSiVBF5EQuiAtKrlBh6yiSZTG+n77Z+f6xZe/aZkkwgCN/rN7dXLplz9tl17ac/96MJIQTTmMY0pjGNaYxAf6dPYBrTmMY0pvHuwrRimMY0pjGNaVRgWjFMYxrTmMY0KjCtGKYxjWlMYxoVmFYM05jGNKYxjQpMK4ZpTGMa05hGBaYVwzSmMY1pTKMC04phGtOYxjSmUYFpxTCNaUxjGtOowLRieIdx/fXXo2la+C8ej9PS0sL+++/PhRdeSHd395ve98qVKzn33HNZs2bN1jvhrYyOjg7OPfdcnnvuuSlt/8wzz3DGGWew/fbbk8lkaG5u5qCDDuKf//znlH4/9n6bpsnMmTM56aST2LBhw1u4kqlj7ty5nHjiieHfDzzwAJqm8cADD2zRfh599FHOPfdcBgcHx3233377sd9++72l83y3IPq8ov8aGhre1L7OPffczW6n1snm3p0777yTT3ziEyxYsIBEIsHcuXM5/vjjee2117b43N5NMN/pE5iGxHXXXceSJUtwXZfu7m4efvhhLrroIi655BJuu+02DjrooC3e58qVKznvvPPYb7/9mDt37tY/6a2Ajo4OzjvvPObOnctOO+202e1vueUWnnzySU4++WR23HFH8vk811xzDQceeCA33HADn/rUp6Z0XHW/i8Ui//rXv7jwwgt58MEHefHFF0mlUm/xqrYMy5Yt47HHHmPbbbfdot89+uijnHfeeZx44onU1NRUfHfVVVdtxTN853H00UfzpS99qeIzy7LeobMZxUUXXURLSwvnnHMO22yzDevWreOCCy5g2bJlPP7447znPe95p0/xTWFaMbxLsN1227HrrruGf3/sYx/jrLPOYq+99uKoo47itddeo7m5+R08w3cHvvrVr3LJJZdUfHbooYeybNkyvve9701ZMUTv9/7774/v+5x//vncddddHH/88RP+plAokEwm39oFTICqqip23333rbrPLVUy73Y0Nzdv9Xu0NfDHP/6Rpqamis8OOOAA5s6dy09+8hOuvfbad+jM3hqmQ0nvYsyePZtLL72UbDbLz3/+8/Dzp59+mo9//OPMnTs3dF8/8YlPsHbt2nCb66+/nmOOOQaQgk+539dffz0A9913H0cccQQzZ84kHo+zYMECTj/9dHp7ezd7XkEQ8P3vf5/FixeTSCSoqalhhx124Kc//WnFdq+99hrLly+nqamJWCzG0qVLufLKK8PvH3jgAd773vcCcNJJJ4XnuClXf+xLCGAYBrvssgvr1q3b7LlPBiV01D088cQTSafTvPjii3zgAx8gk8lw4IEHAuA4Dt///vdZsmQJsViMxsZGTjrpJHp6eir26bouX/3qV2lpaSGZTLLXXnvx5JNPjjv2ZKGkJ554gsMPP5z6+nri8Tjz58/nzDPPBODcc8/lK1/5CgDz5s0L753ax0ShpP7+fj73uc8xY8YMbNtmm2224ZxzzqFcLldsp2kan//85/nNb37D0qVLSSaT7Ljjjtxzzz0V2/X09HDaaacxa9as8D7sueee/P3vf5/aTd+KaG9v55Of/GTFWrv00ksJgmCzv3388cfZc889icfjtLW18Y1vfAPXdad03InWY1tbGzNnznxL6/GdxrTH8C7HoYceimEY/Otf/wo/W7NmDYsXL+bjH/84dXV1bNy4kauvvpr3vve9rFy5koaGBj784Q9zwQUX8M1vfpMrr7ySZcuWATB//nwA3njjDd7//vfz6U9/murqatasWcOPf/xj9tprL1588cVNuuk/+tGPOPfcc/nWt77FPvvsg+u6vPzyyxWx7pUrV7LHHnuEyq2lpYV7772XL3zhC/T29vLd736XZcuWcd1113HSSSfxrW99iw9/+MMAzJw5c4vuked5PPTQQ2/JbX/99dcBaGxsDD9zHIePfOQjnH766Xz961/H8zyCIOCII47goYce4qtf/Sp77LEHa9eu5bvf/S777bcfTz/9NIlEAoBTTz2VG2+8kS9/+cscfPDBrFixgqOOOopsNrvZ87n33ns5/PDDWbp0KT/+8Y+ZPXs2a9as4W9/+xsAn/70p+nv7+eKK67gzjvvpLW1FZjcUyiVSuy///688cYbnHfeeeywww489NBDXHjhhTz33HP86U9/qtj+T3/6E0899RTf+973SKfT/OhHP+LII4/klVdeYZtttgHgf/7nf3j22Wf5wQ9+wKJFixgcHOTZZ5+lr69vC+/+5iGEwPO8is8Mw0DTNHp6ethjjz1wHIfzzz+fuXPncs899/DlL3+ZN954Y5NhtZUrV3LggQcyd+5crr/+epLJJFdddRU333zzmz7XVatWsXbtWj760Y++6X284xDTeEdx3XXXCUA89dRTk27T3Nwsli5dOun3nueJXC4nUqmU+OlPfxp+/rvf/U4A4v7779/kOQRBIFzXFWvXrhWA+L//+79Nbn/YYYeJnXbaaZPbHHLIIWLmzJliaGio4vPPf/7zIh6Pi/7+fiGEEE899ZQAxHXXXbfJ/W0K55xzjgDEXXfdtdlt1f1+/PHHheu6IpvNinvuuUc0NjaKTCYjOjs7hRBCnHDCCQIQv/71ryt+f8sttwhA/P73v6/4XF3HVVddJYQQ4qWXXhKAOOussyq2u+mmmwQgTjjhhPCz+++/f9xzmj9/vpg/f74oFouTXsvFF18sALF69epx3+27775i3333Df++5pprBCBuv/32iu0uuugiAYi//e1v4WeAaG5uFsPDw+FnnZ2dQtd1ceGFF4afpdNpceaZZ056flsLwIT/fvnLXwohhPj6178uAPHEE09U/O6zn/2s0DRNvPLKKxX7+u53vxv+fdxxx4lEIhE+dyHk+7RkyZJJ7+2m4Lqu2G+//URVVZVob2/f8ot9l2A6lPT/AMSYkRm5XI6vfe1rLFiwANM0MU2TdDpNPp/npZdemtI+u7u7+cxnPsOsWbMwTRPLspgzZw7AZvex22678fzzz/O5z32Oe++9l+Hh4YrvS6US//jHPzjyyCNJJpN4nhf+O/TQQymVSjz++ONbcAcmx7XXXssPfvADvvSlL3HEEUdM+Xe77747lmWRyWQ47LDDaGlp4S9/+cu4PM7HPvaxir/vueceampqOPzwwyuua6eddqKlpSUM5dx///0A4/IVxx57LKa5aUf91Vdf5Y033uCUU04hHo9P+Zo2hX/+85+kUimOPvrois9VddQ//vGPis/3339/MplM+HdzczNNTU0V4crddtuN66+/nu9///s8/vjjUw6/RO+b53nj1vdEOPbYY3nqqacq/imL/J///Cfbbrstu+2227hrE0JssmLt/vvv58ADD6x47oZhcNxxx03pWqIQQnDKKafw0EMPceONNzJr1qwt3se7BdOhpHc58vk8fX19bL/99uFny5cv5x//+Aff/va3ee9730tVVRWapnHooYdSLBY3u88gCPjABz5AR0cH3/72t9l+++1JpVIEQcDuu+++2X184xvfIJVK8dvf/pZrrrkGwzDYZ599uOiii9h1113p6+vD8zyuuOIKrrjiign3MZVcxuZw3XXXcfrpp3Paaadx8cUXb9Fvb7zxRpYuXYppmjQ3N4ehmCiSySRVVVUVn3V1dTE4OIht2xPuV12XCqe0tLRUfG+aJvX19Zs8N5Wr2NKQ2qbQ19dHS0sLmqZVfN7U1IRpmuPCPxOdYywWq1gbt912G9///ve59tpr+fa3v006nebII4/kRz/60bjrVlizZg3z5s2r+Oz+++/fbGltY2NjRXHG2GubqOqura0t/H4yqPsyFpOd/2QQQvDpT3+a3/72t9xwww1bZKS8GzGtGN7l+NOf/oTv++GLMzQ0xD333MN3v/tdvv71r4fblctl+vv7p7TPFStW8Pzzz3P99ddzwgknhJ+rOPvmYJomZ599NmeffTaDg4P8/e9/55vf/CaHHHII69ato7a2FsMw+J//+R/OOOOMCfcxVjhsKa677jo+/elPc8IJJ3DNNdeME3ibw9KlSycVNAoT7bOhoYH6+nr++te/TvgbZWUrwdrZ2cmMGTPC7z3P22wMXuU51q9fv8nttgT19fU88cQTCCEqrqu7uxvP895UT0BDQwOXXXYZl112Ge3t7dx99918/etfp7u7e9L709bWxlNPPVXx2eLFi7f42FHU19ezcePGcZ93dHSE57mp33Z2do77fKLPJoNSCtdddx2/+tWv+OQnPznl375bMa0Y3sVob2/ny1/+MtXV1Zx++umAFFZCCGKxWMW21157Lb7vV3ymthnrASjBMHYf0cqnqaKmpoajjz6aDRs2cOaZZ7JmzRq23XZb9t9/f/7973+zww47TGpdb+ocN4Xrr7+eT3/603zyk5/k2muv3WKl8FZw2GGHceutt+L7Pu973/sm3U4p8ptuuolddtkl/Pz2228fl0Qdi0WLFjF//nx+/etfc/bZZ497Tgpbcu8OPPBAbr/9du666y6OPPLI8PMbb7wx/P6tYPbs2Xz+85/nH//4B4888sik29m2vVmFvKU48MADufDCC3n22WfDIguQ16ZpGvvvv/+kv91///25++676erqCsNJvu9z2223TenYQghOPfVUrrvuOn7+859z0kknvbWLeZdgWjG8S7BixYow5trd3c1DDz3Eddddh2EY/OEPfwityKqqKvbZZx8uvvhiGhoamDt3Lg8++CC/+tWvxjU5bbfddgD84he/IJPJEI/HmTdvHkuWLGH+/Pl8/etfRwhBXV0df/zjH7nvvvumdK6HH3542AfQ2NjI2rVrueyyy5gzZw4LFy4E4Kc//Sl77bUXe++9N5/97GeZO3cu2WyW119/nT/+8Y9h3Hf+/PkkEgluuukmli5dSjqdpq2tLQwDjMXvfvc7TjnlFHbaaSdOP/30ceWfO++886SCdGvg4x//ODfddBOHHnooX/ziF9ltt92wLIv169dz//33c8QRR3DkkUeydOlSPvnJT3LZZZdhWRYHHXQQK1as4JJLLhkXnpoIV155JYcffji77747Z511FrNnz6a9vZ17772Xm266CSAML/70pz/lhBNOwLIsFi9eXJEbUPjUpz7FlVdeyQknnMCaNWvYfvvtefjhh7ngggs49NBDt7iBcmhoiP3335/ly5ezZMkSMpkMTz31FH/961856qijtmhfbxVnnXUWN954Ix/+8If53ve+x5w5c/jTn/7EVVddxWc/+1kWLVo06W+/9a1vcffdd3PAAQfwne98h2QyyZVXXkk+n5/Ssb/whS/wq1/9ipNPPpntt9++IncWi8XYeeed3/L1vSN4p7Le05BQVTLqn23boqmpSey7777iggsuEN3d3eN+s379evGxj31M1NbWikwmIz74wQ+KFStWiDlz5lRUuwghxGWXXSbmzZsnDMOoqP5ZuXKlOPjgg0UmkxG1tbXimGOOEe3t7eOqNibCpZdeKvbYYw/R0NAgbNsWs2fPFqeccopYs2ZNxXarV68WJ598spgxY4awLEs0NjaKPfbYQ3z/+9+v2O6WW24RS5YsEZZlbfb4qlposn+bqyKZShWYOk4qlZrwO9d1xSWXXCJ23HFHEY/HRTqdFkuWLBGnn366eO2118LtyuWy+NKXviSamppEPB4Xu+++u3jsscfGPaeJqpKEEOKxxx4TH/rQh0R1dbWIxWJi/vz546qcvvGNb4i2tjah63rFPsZWJQkhRF9fn/jMZz4jWltbhWmaYs6cOeIb3/iGKJVKFdsB4owzzhh33dHzLpVK4jOf+YzYYYcdRFVVlUgkEmLx4sXiu9/9rsjn85u4s1uOyc4nirVr14rly5eL+vp6YVmWWLx4sbj44ouF7/vj9jV2fT3yyCNi9913F7FYTLS0tIivfOUr4he/+MWU1tOcOXMmXYtz5sx5E1f77oAmxBRKAqYxjWlMYxr/v8F0ueo0pjGNaUyjAtOKYRrTmMY0plGBacUwjWlMYxrTqMC0YpjGNKYxjWlUYFoxTGMa05jGNCowrRimMY1pTGMaFZhucENyB3V0dJDJZP6rXbTTmMY0pvF2QQhBNpulra0NXd8yH2BaMSA5Vf5fZkKcxjSmMY3JsG7dui0mZJxWDIwSn61bt26zXoMQgqGhIRzHobGxMdy20FHATJnY1ZIXyPO8kI66rq5u3H6CIMDzPAzDwDAMQHK05PN5giAI6S2EEHR0dOA4DiC5Ztra2sadY+AFlLpKmOnRc1C/d10X3/fDATKu61IqldB1nVQqRbm/jO/66JZOUAow6gx61vewfs169Cqd6upqLMsiFouNJ4Tr7KPYX6SxsZHu/m5KutyvVtRosppIz03jl33ya/KYVSYdAx0MZgepilehazq6rdOQbkCzNbRajZqaGordRYpXFqm7rI7hhcM8/M2HKYoisViM2tpaauI1+J0+Ii5INCaosqpIJ9I4psPw0DAGBh1rOyj5JWbNmEXbrDZKxRK9g70ETkBVqor8QJ74jDg4kEllcGMuDEIxKFLSSvR39pMsJKmfWY/VZLFmzRoMw2BRyyLy5Txd2S5836ch1UDGzuCYDn1r+4i3xrFsC8/zyHZmCfSAuta6ihdzcHCQZ555hkceeYRLL72U+vp6XnnlFTZu3Eh3dzd1dXWYpkl1dTW2bZNIJHAch2KxiGVZ2LZNR0cHuVwOz/Ooq6tjxowZ49aEEIJ169YRuAE1Wg2ZtgxG3KhYg6VSiUKhEFJAJBKJkHupoaEhnH89dn1H4bou2WwWTdOora0d/9Ko7bIuzpCDXWVjVf335jUXi0W6u7vRNI0ZM2ZgGAZ+0afUVyLRnEC3tn5EXQhBX18fpVKJ1tbW8B3/b2J4eJhZs2ZNSJGyOUwrBkZJ5YaGhvB9P5xLMBmGhoYwTZN4PB7y8tiODQHEqyR/vuM4DA8Po+v6hMqms7OTUqlEQ0MD6XQakIJ2aGgIoOI3uq7T29tLb28vVVVVFceNwjEcvKxHPBlnODfM0NAQyWSS7u5u8vk88+fPp76+nlwuRzabJR6PY1kWnflOhjqHcGwHp8+hpqWGn/3yZ/z617/m4IMP5pRTTsGyLOLxOFVVVcyYMQPHcejs7GSoMETciNPf10/nhk5EWhBPxEmaSdKpNOl4Gi2loQ/omAkTp8uh7JTpc/owfRM/5pPUk5QGSvgFn1mzZpGyUmxcsJEqqkhsSFDMFyEhuWeEEJREiUQsga7rxIhhxS1SdgrDNHCSDgRgJSwKwwWEIUjZKdKpNAJB2SlTzBfRdI1SvkQmk8HWbFxcYqkY1XY1wwzjOA6WaaHlNNp2bKOvr0+SFBrQXNeMntbp6+vDSlpojoZmaKRSKRKxBKnaFMViET/nMzAwQKlUqnieqVSK9evXs8suu1BVVUVfXx/PPPMM2223HYlEgiAIcF2XjRs3MmPGDKqqqhgcHMT3feLxOHV1dcRiMbq6uujt7cVxHDRNm5CDyXVdcrkcdskmZaewq0YFe7lcZnBwEMuyaG5uplAoYNs21dXV5PN5yuUymUyGdDqNXbLRDI1Y1fh1Vy6XQ8WwSR6oKnDSDu6wS0yPYab/O+KnqqoK3/dD46qqqgqRFhScArHY23ce+XweXdexLCt8x98JvJnw+HTyOYIgCBBCbHZOrGILVQsNwLANAicIh45YloWmaaFnMBZqdGZ0uIlpmmEsMLrvdDodDuQpFovjZvSG+8xYoIM76IYsrGoWcBAE4e/Gnb8JIhB4joev+wTlIOSj7+uRsxV83w89GiC8T5qmoZkaTtlBExo6Or7v4wkPx3fwyh6aqaHp8nziZhwfn6JTRNd0XN/F8R30QEd40rvR4zreNh5CF1gFi6ZcEwk7gWmaUjGUS/i2j0Dgl3yELygXy5iYaIYGAWRqMwRBQG44R2AEiLKgKlEFJviej9AEvuOj27p83h64gYtt2BiGQTqdphwr4zou2Y5sSGI4kB1AeIJkQs5qKPtlkqkkuq9jWAZ+ycd1XVKpFKlMCtdxKZfKFaRshmGw/fbb09bWxl577QVIFtZEIoFhGGQymVBBdHR0UC6XQ0NAPcNUKkVLSwupVIpSqcTatWsnXLfK4i/7ZfxSJfuuWoO+71NdXY2maTiOQywWCwVZb2+vFPqmRuBO/F7Yth2usc0N67GrbcyUSXmgjFfcNMvs1kR1dTUA2WxWrltdQ7d1/LK/mV++eaghS6VS6W07xtuFacUQgdKsm1MMY19SAN3WEUIgPBHuSwngiQS5muI1VmlMpHQ0TQvDOY7jTLrQNF3DrrblCzfyfgZBEJ6v2mdUabmui2mZYAAeCEsgXMGsNplz6evvAzE6RU4JOHWvbNtGj+lhWEzzNKncdCg4BYJCAIb0ejRdI2km0dEJRIBhGOjoFLwCOjq6r1MsFtE0Db1OpzxD3re2njZ8z8eyLAzDwPM8ypTx8Qk0KdTLpbI8tikVUzKexIybFPNFikERoQkMYZBKpjBtk3wxT1CW5+bjo7kagR7gez6Z5IhgNgIc3SG7MUttda28/4FD4Aek4qlQgMar4lhY2Ekbv+zjeR7JpDy+bdi4ZZeBgYGKZ5XJZJgzZw4HHHAAAHfeeWe4FhzHYcaMGZimie/7bNiwIbzfSkmDHCQ0d+5cdF0nn8+zZs2acdPQ4vE4hmEQGAHFXBERjH6v63q4DoMgCMNAxWKR+vr6MATR19dHvpxHeGLCaWuapoVrbCpC0K61pffY54xTVm8XkskklmURBEE4c9uIGW+rYlCh2y2hlH+3YFoxRKCs9TerGAACJ9jkdgpbohhAeg0zZ86kpqZmUo8BwEyZGDGDICu9F9/3w2Mpa07TtAqPRdd1dEtHCzSEIQi0gNlNswHoH+hH+KMCoVwuV5yzZVnSUg58TMNEC6SQEAiKbpHADdCEJleaLq1l27QRmkDoAl3oFNyCVBy+Fl6bkTIozZZCpmZDDfigoYWeiic8AgI0S8Mv+7iOiygJDMsI72MylcTzPfo6+rBSFsIVZGIZEqkEtmWjBRpe2cPTPCwsMOX9SMakEEkmkziWQ7lYxhl0qKmpobquGitmYWt2eF/LQRlLs8BA3sNA4DgOmZqMFLZCxnvHPuu6ujr23XdfGhsbyeVy/P73vw+vTwhBc3Mzti09mFgsFj6z6NpIpVLMnTsX27bxPG8cXbSmyRAXllSeQblybUfXWyaTobGxkaamJjRNo76+PgwN5Usy96UMn7HY1FofC03TsOttdFun3FuueGfeLkTDXMPDwwghMGIGwheTekJvFbFYDE3T8H1/ymNP3y2YzjFEsKWKwXVdgiAIrWHdkq6pmTIrtpvoZZkolASTKwZdl0lglQdxXTfcx7h911gUs0VwIbCDivONXoPjOOFnuq2jCx0E+KbPzCaZLM1ms5SKJQzbCBd5oVAIrSHLsuT5CLkfC4t4LM7Q8BBFo0jgBwhfoBkaGtKbSJpJsmSlMtFNHBx8fAzXoJAvAGCmTUpzS/AIZNZnsHSLUr6EGZchNaELgpK0+IUuwIHSUAm7zqZIEQ2NZCJJqVRiuH8YliKT6/mA2XNnE+QCGZYrljGTJjHkPfICDzw52SudTtOhdyCyAlwwdKkA826eWCFGLBajXC5T9It4rkffUB9JPYlRNhgaGqKlpYWGpgaKnTL8NzAwUJEINE2TVCrFkUceyb333ssDDzzAIYccgu/7DA0NYRhGmFMql8vh/VfxfIVMJsM222xDuVzGNM1xVrtpmgQEFJwCueEcMW00T6D2mcvliMViGIZRsV6TyaTMbcTiOH0O5MGMjxcb0f1MNZ4u0gKnz6G8sUysLva2JIGjUKFIx3Ho7+8nmUhS9sqIYRG+s1sbuq7jOA5DQ0NbPc+gPOi3A9OKIQKlGMZOQhsLVUmkEloqlqjb+oQeg+M440YqRl14pVw29xsVnioWi+Tz+XGDecLzsw2slAUd4Ccqq5EUxiog3dYxjBELygioq64jHotTKpcY6B8glU6FCjMaTggH25sQ+AG2bRMzY2G4x/M8AjeQIR7PR7M1klYSTdMou2VZIaTlcXUXy7NwCiPnk9ApzJdKIrUuRdyIy7BX2sSyLEqlEnEtTtkpU91QjVW00PIaRtlAN+W9tC1plTqOw3DPMFV1VeTX5kHIEEs5X8Ytu2jVGqIslYsrXPyyz3BxmMHBQTRLQ9QIusvdMlSoCYoUIYtUdiNxeV/4WCkLD0/mLnydVatWIQJBoiqBpmv09PSMm3UdBAGnn346Rx55JPF4nHw+jxAiDKmpyqH+/v4wX6XmgE8ENd5VPaNoCEozNdZ3r0fvHxXAyqssFAphFZ36PJqjAln5phU00MYnNNV+AAqFwtQTnkLmt8jKUChvcxuRWsPd3d3y8L6AvHyWb9fxgkAaIW+HEK+pqZlwlvdbxbRiiGCqHgOMDkaPKhHd1vHyHiIQaLqGaZpS2AqB53kVFr6u66FycV03VAimaYaJ47G/URgaGkLTtEkVA4BdY8MG8PM+dv14L0QpBtd1ZazfkOEkURb4gY8W12hqbKJ9fTvD2WFs0w7LRaurqyvCIvF4nFgyhjPkYNkWNckaspkslmbhelLQ6paOV/LQYhpxPU4qkUITGumEjNHbug3d4OTlOWqGRnmhtFzj6+PERAxXuMyeMZt4Ks7AwAC5jTkszSLTmCFRSpBvzyOGZIjA1mySsSRV1VWktTRWYGHEDKkoBhwS1Qm6O7spDhZpmNGAqZlSQMQ1uge6KYgCTU1NJJNJAi+QAmzkf5o2kog1I/kaTyb3BQJTN7ET8v4GfoBTchCawLKtUUUagRCCBQsWhH8rYayscPW8PM8LPQfbtsftKyqclWBX5yeEgECej27poSBR5cwwei1qXSjFoNZg4AYEIiAgCNdvVCCp9RUtopgKhJDhHFXI8N9sMg28ABEIDPvtsbyVMo/mc7YGhBAUCoVQwbW2tm61fcO0YqiAbdthTHdzaGhoqLCmgHBxBW6AEZP/3dbWNun+VMwz+r2mabS2tk76cjU2NoauvuM4k85TNu2RmvMimLpJbW1tWO6pBIuyNHp7e2WytMbEcR3SmTTx6jgf+eBH6OzvZNGiRbQ1tKEndJLJZIXA0DSNxsZGfN9HDAlSiRTVyWpa57ciXEFuTQ6/6EvL2xNYGQsREyyoWcBwcZjqZDVVs6rQdI1sOUs8Ib0v0zTR5+kEqQA9r7OjtiP2e23SzWnKuqzySVYlqcvU0dDcgDPkoHfq4EJrUytoUFNVw7yaeQTDAYEb4A67WHUW5c4yidYEpmFSl6yjtrqWGDESVgKr1uL1Va/T3NpMfX29TPbio6MjNIGOjmEbuCVXJrQtQ4Zq/ADLtAhEAAGY1qhRYGomgRagG3qF8I0iHo9XCGNl8cdiMZkD0vVw1rcyXJSwiRZNRPeh1lNUOSjvTdNHz0FVFUXXs23bocJQBk5gBvi+T8DEx1cx9TcDERPSI/kvKgchBNhSOYy9J/8vQEUCuru7aWpq2qoeybRiiKCmpmZK83iBCYW2Zo2UhpZHFcOmHpYqoRuLyYQ9yJc0mUyGrn9DQ8Ok59e2TRvFjUW0osbixYsrz1XTwhCYalrzSz6lnpGmH1vn4gsvRniCeHOcYkcRM2li18pzE0JUNLvNnj2b5lQzbs5FC2TJqG7p6KZO4AaYMRMEtM1oI5vLYqQMZsRnyBLWmjhGwsDO2VCW+66pqcGcbeIt8LCft0mtScFe4Bd8Mq0ZmpqaWD24mv6+fuqH6slUZcCG8lAZY9CQSlEDAwNigCYFgJEyZAjI0aitrmW4MEx/T79sEEPD8z3QIJlIhtcmEDiug2ZomLqJ7uthaMz3/dHSXSFzKEEQ4LleKGgNU4bofN8Pq8Sigk95h8p7NAwjVAbRMKMS8r4vK5+UNaqEc/Q3ShEojyCqkAI/wNBH1+VEazTq0fq+L89BQzYlGvqEx38rwlzTZUVZ4MkqM8w3V38/VUSvSxU1aG93HOttQDIp16laN1sL01VJWxGaJmuj364qB4Xq6mqCIGB4eHiT+ZCwfLUg496bgx6TIQZVwmelLQI3wC/5BHbAYM8guWyOdevWsWHDhnGli5otK3ICLyA/mCdfyIMlPSj10olAhLkYx3HI5/MU80U2bNjAQHEAv+yHJYxmwsSfL//beF0KV8/xGOwdpFQq0TPQQy6XY/2q9QQiIB/kcQIHJ+fg5qXlHHgBruYyNDxEtpwlKAZYGQs/71NVVSUroQplCq7MZwRuUBHnNgwj/DvwZRjF93wZLhxT3hyIAF2T9zDwZW7A932pHHSDIAhCgTQWqiz11VdfZXBwUFroI9VJSghHzymao/I8L3wWSjgIISrCkqr73fM9fHdqJZoqVKTOIdpwOdnx1bHfzMRgpRyEEDL2/zYjDL1pwNtcGDWV/qg3g7dLeU57DG8BAwMD5PN56urqQs2t2zpeobIssaenJ2yNj8YZJ6KrAPmyDQ4O4rouzc3N445bKBQYGBjAtm2Gh4c3SUNgpAz0nE6pr4RWLa1K5SkoKgOI0HZY0nMwUgaarbF6/Wq6n++mbZs2st1Z2sw2sAgTpOq6VSNUyk1hYNC7vpeNgxsxfZMFdQtkDgEQrsCIG+T786xat4pELEGD3sD6/vWYmonu6mg9GrWzazFsg/JiGTYTLwleevUleku91NbX0ja3jVg8xkDnAIU3CsSqY6Rr0uTLebKFLN3ZbjL1GfxBn75CH6XBEjPnzSTtp2WiUZPX75Qd+tb3MVQeYlbdLMrDZSmQg9HkrWmaUpgGUvgHQYChjRQgMBrTR5NJXiETEqBJga8beijk1X2PrgN1DJVnGhwcDEOVSqD4vh96Giq/Y1lWWBmnwkdRryEIAkzTDAW3+p0QQuYaDH3075HtozktdV7qGIE+ItjEqNJQ3ymvRCk+FX7aUmi6Ju+XH4QhnrcDuq5X3F9d08cVe2wtqEookM9sSwnt3gm8+8/wv4hCoUB7eztdXV1T2l659OMa3fxKi0cJ/7Flq67r0tHRQU9PT8XnmqYxPDxMsVicsGtalTk6jhN2ck6Enp4e2tvb8WyPNWvW8OK/X6yoigmCgIGBAVavXs3atWt56aWXeOzfj/HoE4/y2muv8dvf/pbt99iekz97MqtWr+LVta/ywgsvhIJnzZo1bNiwAdd16e7uZsWKFby6+lUZRvFH6rcDl3wpDz74wmfj+o10Z7splov09fXR3dNN98ZucrkcnT2ddPZ2MtAxQH9/Px09HRTny+Yge5VNYahAsVzEK8t7kslkZCdz2aerq4tkKglJQAff8SkNlzAwEJrA9V28sodjOjKWbcmeDQR4RQ/P8RguDYf7jlq9KjmvIT0BocnvRCDCkIxSDL7voyE9hNB6RwofQzdCK3Ws16DrOjU1NWiaRrFYDGkuokJeCXj1twotjc1HRa159XeYcxipvhl7fOWVjLX0VUgp+hu1jaJ7UP89Njy2Oeyzzz7cfPPN4z7XDEkxorzPtwOapoXXFYiR636bnBT1HAHe9773ceedd749B9qKmFYMY6Css6lgbEcxjDa6RUM3k/UzhNUeY44Z7Zoe288AhFxJ6neTdZsq4SZMWakTFIKKc1BJR9d1ZUWNELJc0/fxHZ+mpiYAevp6MD0ToQlKxRIjRjK5XA7HccI4uOM4FF3ZXWsbNjE7hi988uU8gSsFqlfy8ANJRWEJKxTYtm2j6zqFoICbc6UyDXz8pSNhrX6L+HAcDalwysUy6XRaCnhfkB3K0tHVIQVytYEIBK7jopVHhLRtyEY1zZHKuyzLSHVdJ67F8V2fwdxgpaAXo8/DtEbCMiOeRKBJr0JHWujqXqJFBKc2UuUmglBwKgExtn9F13VisVhIYTEwMBBa+VGhH43lCyEqBPeJJ56Ipml85jOfCT9Tv//iF79IPB7n1FNPlfkWf1QJVJSkTmBkqPLsME8REaDq2pUymip7wD333ENnZycf//jHJ/xeN/RR5eC/PcpB5XLQmFApbk2oZ/iNb3yDr3/9629LWGlrYloxRBBaEFN8aBNRXqjqhql0QCtXHabe6AajjS3V1dVhSeVEiJbfJmoTEICbcysEgjpOmIgbqSX3yz5tbW0AFIoFyrkyhmUQEODm3NEk60jsWQkNF5dAC4gZMRJmAj/wJTXGSN5FNbsZtkHCSuALGaKxTHlNRU16BF7Ok9ZtDfgzpHJIb0hjY+P6LsWhIlVVVRhxAw2N/HCeklui7JShWj6HwJEcSQYGpiV5porFImZGNjoZukEsGSOux8GHquoqWTSgSlPH9GtouhaGHFTZZuAFYdhE3b8gCGRZK6PxfRVeUkI2WnmkYBhGWIKs+hbUv+jvNiV8Z82axW233UapVAqFealU4tZbb2X27Nnh70UgKowRtVYmo7wIvQ6NcZb12F4blWTflKC9/PLLOemkkzYZVtENeT/HeuBbE+oeBCJ4W/Ma6h598IMfZGhoiHvvvfdtO9bWwLRiiGBL+hhgcvIwPaZXUA9EFcPYl+XNKAa1T1XbPhmiis6O22gxDVEQOKXx/QzKstR1aakFTkAqlQq7Nfv6+7CERaAHFIYLxGPximsK6cN1SdgWs2LYho0f+JT8kmwk0zTwpNDWLR3DNDCRpZ4IWX5XEiVcz8UddtF0WboYLJL3MrM+Q0yTzXP54XxIVIcBKTuFj4/ru5SdMkZKVtQIV2CWTQxbciwF5YCyVsZMmbhDLqn6FJqvkSIlcy8q9C+oSEhqmoZlW6ECMAwjtGiVQFGCOxBBqAiioR8Vw57MANF1XSq7ET4o1Simwk/REM5knu1OO+3ErFmzuOOOO0IlcOeddzJr1ix23nlneS3GaHL8oosuYptttiGTyfDe976XO+64I9yX7/uccsopzJs3j0QiweLFi7n8istDwQ/SS/noRz/KJZdcQmtrK42NjZx55pnjenyi6O3t5e9//zsf+chHKj7/8Y9/zPbbb08qlWLWrFl87nOfo1AqoOkaA/0DJBIJ/vrXv1b85s477ySVSpHL5QDYsGEDxx13HLW1tdTX13PEEUewZs2acHt1vhdeeCFtbW0sWbIEXde55dZb2G333chkMrS0tLB8+fKwR0Dh7rvvZuHChSQSCfbff39uuOEGNE1jcHAw3ObRRx9ln332IZFIMGvWLL7whS+ELKvq2X/oQx/illtumfDevFswrRgiiCqGqbiVUYs76g1MxLSq9j1ZOGkyzqTJuGdUAll9P9FLGL0eXdcxUyYiEBT7R0m9onQZYahAB8/1QBCyivYO9mIGUmoWy0WsQJ53NIwVKjlcTMMkpsfCWv5CqSCt8GBUuGmmJhWDCND8kXupQUEU8HNSEBqWQbBUCqHUhhQxYnjCk9U1ZZ9MJoOv+eASKrZCviDDSbpM+iWMBMKVXcteWQrceFMc4QliVkw2vQ078h6ahBZxSDgngDwYjoFRNLAdG7NsQgFEXiCGBCIrJD9VXmCWTLS8hshKpaQVNEReEAwHsomuoKEXdfl5Tnbeqs9t16bGqkEv6gxvHK4IbUWTx6q0daJcxQknnMCNN96I53l4nsevf/1rTjrppHAbw5SVVueddx7XXXcdP/vZz3jxxRf53//9X0488UQeeOCBcN3MnDmT22+/nZUrV/Kd73yHc751DrfdfhueO1qJdP/99/PGG29w//33c/3113PTTTfx29/+NgwzjsXDDz9MMplk6dKl48798ssvZ8WKFdxwww3885//5Ktf/SqaoVFTW8OhHzqUm357U8Vvbr75Zo444gjS6TSFQoH999+fdDrNv/71Lx5++GHS6TQf/OAHKwysf/zjH7z00kvcd9993HPPPbK4IPA579zzeO7fz3HXXXexevVqTjzxxPA3a9as4eijj+ajH/0ozz33HKeffjrnnHNOxbm8+OKLHHLIIRx11FG88MIL3HbbbTz88MN8/vOfD68PYNddd+Whhx4ad1/eTZiuSoog6tZOtUJB8eWMzTMoplXNkvuIx+MUCgXK5XIo1GHznEkqUTm2wiPKZtnV1UWpVAoZOcdejyqZtGwLoQtZedMkO2CjHdBheaMuwmaoxsZGVq9eTedAJ4u3WYwvfDzNA0da+PF4vEIBep5HKSihmzoxPUbciuP4Dvlinlg6BmIk8YeBZmlYWDJv4Pok0gnphVmS3M72bPS4TrCtFC7JtUmMwED3pVdTGJLdyYWBAiI3Qq7neGBCVUsVXo8UjAk9gXDks3CKjvRuEgZWxsIdcrEyFk6vgzPgUIqXwmRkIAL0QA4dIi1J/CwmHzBjjvxvLDb1m4n2MW/kfwDlvjJGYrSfQIWVlNeg1k10fZx44ol861vfYs2aNWiaxiOPPMINN9zAgw8+GK4L13X52c9+xl//+ld23313TNNk1qxZPProo/z85z9nv/32w7IszjvvvHC/8+bN45FHHuH3d/6eo485OlRKtbW1/OxnP8MwDJYsWcKhhx7Kgw8+yMknnxyuq+j5rVmzhubm5nFhpDPPPLPiWOeffz6f/exnueqqq8CA5Z9Yzoknn0g+lyeVTjE8PMyf/vQnfv/73wNw6623ous61157bfjuXnfdddTU1PDAAw/wgQ98AJDEg9dee21Fv9CnP/1pfMdH0zXmL5jP5Zdfzm677RZyP11zzTUsXryYiy++GIDFixezYsUKfvCDH4T7uPjii1m+fHl4HQsXLuTyyy9n33335eqrr8a2bXzfp7W1lfb29ooelXcbphVDBGH8VZWwTeGhqZBOdOFHmVYVMVgsFptQwE+mGFStuLIUJ1IM6XSaWCxGNptFCEEul6ugyYiGLFT1SqAH+MLHGXKIN4wO/Il2vgZ6ICt7yn7YQNc30IcVtzAxqW+pJ27GycQzYe+DuhZd14mn4ui2TiqWYlbrLAqlAjE3hh+M1P8zUnViCWzLpqG+gSAe4Mdkwtsv+vhFH1ES6BmdYIlUDIn2BBoaCT1Ba2sraTNNdVM1whPkNuRI1aZwe10KboFiqYgW10h6SWJmjJpUDWbMpKG6gbrqOuntNdg4WQfDNEgn04hh2ZnteZ70YtDetkqVqcKyLLS4rFRSisC27VAJw3hvs6GhgQ9/+MPcfPPN+L7PIYccQm1tbYX1/vKrL1Mqlfjwhz9c8VvHcdhpp53Cv6+55hquvfZa1q5dG1ZL7bjDjgBheOs973lPxfpsbW3lxRdfrEiAw+h6LBaLFcaRwv33388FF1zAypUrQzbaUqlEPi/Dhod95DBM0+T/7vo/PrH8E/z+978nk8mEAv+ZZ57h9ddfHzexrFQq8cYbb4R/b7/99uOaSP/973/z3e9+l+effz7M7wC0t7ez7bbb8sorr/De97634je77bZbxd/q+DfdNOrVKFmyevVqlixZgmmapNPpcD5KtEz93YRpxTAGUQt4KkilUmEliYJq1IkyrVZXV0/Y6WzbNrW1tRNyIm1qiLemaaHQ1nWdnp4estlsOHAFCOmaleLKZDJyQle8Gj/rSw4jWw9HDyaTSTIZOeAmaSWJ6THe//73E4/H2WuvvahrqSPhJqitrsXQDLQhLbw+VUJrWRZVVVWYMRMra9FW24Zda5Nflyc/KGOthm5g6AZWzMJKWtRV1+GaLqlWOXTGLbs46xy08kjD0zyBiAn0ks4iexHaPI2q2VW4wy6GbzB73myKdhGryqLX6cV3JANpbX0tieEEMTvG3Ma5MubvyuE+uq1jZSzMhEmT34SW1vDzPmaVybryuorKHy2pgQxhy2qnsis9J9/DNm1Jk2HJSijN0HBcB9/xw+SvokpxSo7cxtRCwa4s6rFUGaGnmDDQNdl7Eg0lqcFN0Q7k6Lo9+eSTwxDGZZddNi65rP7/nj/eQ3NLc1jBpjrrAW6//XbOOussLr30Ut7//veTyWS4+OKLeeLxJ2TDHuN7H9R6VPQd6jpUDkut27HzKdauXcuhhx7KZz7zGc4//3zq6up4+OGHOeWUU0KjKRaL8bGPfYxbbr2F4449jptvupnjjjuuojx3l112qRDMCiokCox7X/P5PB/4wAc4+KCD+dUvf0VTSxMbN26sCEFNFEEYKycUIeIXvvCFccdXiX/DMBgcHCSZTL5rlQJMK4ZxmKih7M1Aj+lT4plX1UUT7mOKbmYymQzpCwqFQrjwY7FYBblWdI50qVTCHXSJN8crRpmqRjev4FHuK/PNr38zbDISQlDqLElqiKRJU7kJMvLFamtrq5hr7JekW+4WXOwGW4atdJv6qnoSdQn8os+O2+9IoUMmWBPpBMmMVEyO4zAwNIDu68RjcVzLJVgcYLxgEF8XpzS7FPJReQUPYQsG84O4gy62JdldfU32UIiiwE7JIgGBwHd93IILiZFSyxobLzciVA3wh/3REFzgy1kSGqBkiZAeoetIYRUYMnFuxA1ZxquBkTDwipJjybRNhC3DUhjIhLYJwpShxsAJ8A0fwzYqrG6v7NHV1cXQ+iEWLlxIPB6fkHpCDfMZWwkUFWof/vCHKxSCEIJt37MtsViM1atXs+dee4aecrTn4aGHHmKPPfbgc5/7XHg8ZXnrmi4T7FCRWI8iWnUX7XPYeeed6ezsZGBgIGzOfPrpp/E8j0svvTS8/7fffvu4tf7JT36SD3zgA6xcuZL7H7if753/vfC7ZcuWcdttt9HU1DRlahuAl19+md7eXn540Q9pbmhGaIJnn322YpslS5bw5z//ueKzp59+uuLvZcuW8Z///KeCEHEirFixgmXLlk35/N4JvDsDXP8PIspsCYTUGNGJWbBlfRJTOaailVDVQ6qTeVPQNA27xsZ3/EnHK6qh8UFpVLl5nodneeT6c3T3dVP2ynRv6GZ4eLgiCe26Lo5w0OM6xVyRro4ueod7KXklWT/vSctaIPsrnLJDX1cfHRs68DyP/v5+8kGecqGMcEYE2ntG8hivWiCg0F9goDhAX3cfueEcfUN9dK7rZGBwgGQ8STKZJFvK4us+uaEcWFAqlxjMDdK5upP169YzPDyMmTQx4iN043qAW3LDPIii1IhahpomO3MNXVYgOa4jE+GeH9I5qOa2sFR1JBwokH0HlmmF1qOivohWHYEU+Con1dXVFQr5iZrIJiplNQyDl156iZdeein0LtRvymXZA3L2WWfzla9+hRtuuEE2QL74IldddRU33HADQgjmz5/P008/zb333surr77Kt7/9bZ566qmQIiSaz5ooyazCKGMb8HbccUcaGxt55JFHws/mz5+P53lcccUVrFq1it/85jdcc8014/a577770tzczP+c+D/MnTOX9+3yvvA+HH/88TQ0NHDEEUfw0EMPsXr1ah588EG++MUvsn79+nH7Upg9eza2bfOzn/2MtWvXcs8993DBBRdUbHP66afz8ssv87WvfY1XX32V22+/neuvv77imXzta1/jscce44wzzuC5557jtdde4+677+Z///d/K/b1r3/9iwMPPPBd3cswrRi2ArLZLO3t7RXucZRpVWFoaIj29naGhoYqfq9KE8dWIAkh6OrqYt26dRMuIjUTuLe3N/QSSqXSJktYy+WyjN9qHkbcwB2UlS3d3d2sX78+FFKarslkbd6hp6eHRx55hPb2dtq72unq66LQX8AzPGxsRCApgEHGjzds2EBfXx9W2sJzPFa9vooVr6+ga7ALAkLFQCCt61w+R393P33dfbz22mt0d3czlB+iUC5IGm4Ngh3l9fvP+6xZv4bnX3yeVWtX0d3fjSgL+of76erqorOrE1OXyU7TNlk/tJ72jnY6eztZ3bmaNV1rKOaLuDlXlhHGdfSETvdwNxt7N9LV3xWWz6qqnrHKXdM0TCMiFIUkzUMjrLs3LXNU4Psi5FwKgiAckKSqqNSzHNtXoKzpgYGBsApJzelQjY2q8mes8BVCUFVVFVrO0fyZ2tf3zvse3/z6N7n44ovZdttt+eAHP8jdd9/NzJkzcV2XT3/60xx11FEcd9xxvO9976Ovr6/Ce1CDl6IluFGo64yuXVW6e8IJJ1SEfHbaaSd+/OMfc9FFF7Hddttx0003ceGFF47bp6ZpfOITn+D5559n+fHLZaWbK72gZDLJv/71L2bPns1RRx3F0qVLOfnkkykWi5v0IBobG7n++uv53e9+xw4778Cll17KD3/4w/A+gkyG33HHHdx5553ssMMOXH311WFVksrT7bDDDjz44IO89tpr7L333uy88858+9vfrvDaN2zYwGOPPcb//M//vKsVgybezna/KWDDhg187Wtf4y9/+QvFYpFFixbxq1/9il122QWQD+a8887jF7/4BQMDA7zvfe/jyiuv5D3veU+4j3K5zJe//GVuueUWisUiBx54IFdddVVFaGNTGB4eDqejeZ4XJnGn6o4qXnTLskLGUSEExQ0y7m1VyRhsLpejt7d3XIhnYGCAoaEhMpkM9fX1Fftet24dvu/T0tIyYcJu/fr1eJ5Hc3MzQ0NDlEolqqurQ6GyYcMGPM+jtraW4eFh8vk8sVhM5jxS1RS7igx5Q3QOdJJOp+nr6yOXy9HY2Ehci9O+up1Djz4U3/e5+eabse0YxcFq4kEbIuOx7VwLLR5QCkohd0+5XKa1tZWW+hYK7QVe73qdruEuMiJDc7qZquYq6prreO2N1yi6RRpjjQx0DpBNZEnUJMjn8wwNDDEjPoNZM2dRXV+N8aJB7NAYXp3HI1c+Ir2NBmkpb7dgO17Z+ApdL3dhxS0WL1xM3fw6urq6WPWfVYisoHFGI3q1znD3MNVGNXbSJtGaoHVGK0F/wLrX11EqlgiMAKPBYO6cudIKR8NO2HIu9ghUxZbruTieg/AFliFnPhuGEc4WKJVKiEAqCSsu743wJHWGZkhhquLnQsjZCdF4veM4rFy5Es/zmD17NqlUKsxHKKUFjPud8lQqGtMY9TDDZkZNQ/NlFZqmj2duVdVP0X1Er191J08GpRSiVUkqgd7V1cWyZct4+umnmTt37qT72BwUbcbWousWgbw2T0hFvynOpx/84Adcc801rFu3bsr7/8pXvsLg4CA/+9nPKsrd3yxKpRKrV69m3rx54+RDVK5tSWgN3mGPYWBggD333BPLsvjLX/7CypUrufTSSysqa370ox/x4x//mJ/97Gc89dRTtLS0cPDBB1eETM4880z+8Ic/cOutt/Lwww+Ty+U47LDD3lTIJtqQNFWMHfUJo0yrE1FjKKtPYbLKJNh8o5taDEoh1NfXV+QsVPw32qWsjqXbOmbSxBlywuob13XDf0bcwPXcMMn91FNd/OEPghtuDbjrbpebfu3y7fMCXnhGVljkcrmKJj4PDythkbJSoEHeyVMoFXDL8jrLThnHc9BiUoAJd7QBzAs8yn6ZUkGGn4LFAUIXmP0m1qCFqZl4JQ9hCAr5AlWpKgzbwHd9ssNZkskkTU1NzJwxk2QiSWG4IOPrhqDklrADGzfnksvlMFMmMVv2M0RnGhuaEdIyR6Gsb9OQVrriTvI9+ax1YySkZBqSJ2nEA4la7VHGUkVtMXaQi2VZFZ3Q0d8qD2Gi0OTYZx7tdLcsi0QiURFaUuEylScY24SnwmEV18/4zu1o6Extp/ahoPiVWlpauOaaa1i1atVbspwrGFm9N8fqWrlD+U/1j0Tv31VXXcVTTz0VhrouvvhiTjjhhC3afVNTE+effz7w9jGubg28o4rhoosuYtasWVx33XXstttuzJ07lwMPPJD58+cD8sZddtllnHPOORx11FFst9123HDDDRQKhZB8a2hoiF/96ldceumlHHTQQey888789re/5cUXX+Tvf//7Fp/TlnY/QyUN8th+hmgHtCrnjLItqs/hzSmGaFd1IpEgk8lUhBTGWjvq73BqV7UFAdiBXUHT4PsyZq5pGk0NkjPpz3/uI5s10HWf3mxAY0ZnXafg1pssVjw/KqDUMcpOGStjkdDlUBwv8Cg5Jcm3Lwh5hgzTwLAMDNeouO+OcPACD7fkElgBYpE8t+r2anRNx/Bkp3WukCNlp7ASFsKXrK+FbEEqyoZ6qTw9iOkxin6RolbEMiy8gsdw/zBaTJMDcSw9FOpqUpuGNjFVgj4iaM0Ra31kVoGmaeHITx097IR2yk4FpYTiTYoK+7ECXtO00IPM5XKh0A0bFkfWnJrlEH3Gk9Fiq2OGeQedMGwWzl0YQXTAz1jlMBE1hjKMlCczWcOoOvePfOQj7LnnnuPCTVuKrakclGLUNb2Chwrgtdde44gjjmDbbbfl/PPP50tf+hLnnnvuFu3/K1/5Ci0tLW9Kzvw38Y4qhrvvvptdd92VY445hqamJnbeeWd++ctfht+vXr2azs7OsE4ZpCDcd999efTRRwFZO+y6bsU2bW1tbLfdduE2Y6Hi7NF/Cm/2gU3ImxTTxzFERi18BaUYolQDY/c7FcUw0QsxtkwxSuImhJD0FEkdy7cqKCCUoNEsjcYGWepXKHTjeQaW5dIzBGhQV+UzOJTkkQcCHMcNrVl1TmbSJBFLENfj+JpP0ZP1+EoxoEuBaiQMbGGHijMIAgJDUkuUSrIKSewkr6GqvYpABBiBAS4UvAK2sElUJTA0g3wuTy4r60trGmrCkACe/P8yZVzPxRAGzpBDqVwinpad0HpMHxV4Izz9QRBIryXybNS0LyWEVbI5/N7U0HQNQ5PcS6GFPeJ8RBPHyvJXn0cFebQcenBwsELIhiRwkeepoEplYWKrP9yHaYQcUFFvV2HsTIfwHkTIAqPbquOppsqxx1NQnkPUg323KAf0ypJgdY4/+clP6OjooFQqhcn4Nzuuc1oxbAKrVq3i6quvZuHChdx777185jOf4Qtf+AI33ngjAJ2dncD4EtLm5ubwu87OzrAXYLJtxuLCCy8M+wqqq6uZNWtW+N2bfWATEeWFCehJeJOixxxryY/dfmz4SWGsFyKEYHh4mI6OjnEWIFQyaYbHSkgSO4qjPDxhCaKpkUlJj0EqBhNdD/CFoD/nM6vBZ11XCt8LaF8jX0glJB1HhoniqTi2ZiMQFJ2iTECPzMVWCVk7aWNrdhhmUo124YzlcgCS6ofM6gy+8DE0g6AUUPJLGLohK7N00AMdU5fNgXbCxtNlDX3SSpKMJQkI6C33Etdlz8pg5yCJmgS60MNqLNWTAJKJ1HXdcWEZ5RVYloWma/jeaMmopmmhx6XotpUnouu6vAdilGPKNM1QgEcNBF3XaWpqora2lkwmM7ofUTleNWqpR9fVWKtf7TfMJQg5kjRauRQNAY3dx9gw0USeAIyGYDb1PqnzDzm63mJ+YGsph/A8Ij+PXvvWQNRgezcqh3dUMQRBwLJly7jgggvYeeedOf300zn11FO5+uqrK7abqLFkc4toU9t84xvfYGhoKPwXTR5tTcWgGVrI8rmp7WDycFK02mSiUJOmaRX71DQtpMPO5/MTJs7GEvfpho6W0jBcA8uwQuEmhAAdqqukYnacjbiuTRDo6HpA97CHJkx0XWN4oJ7AqRmNv6vQmuvIITpmGsM0KDlyqpkaL6mh4QsfOyO9haAgR18ahuQ6qq6vJl2dxnd8xA4jVvQbKXwhZw/rri7pufFJxpKkqlJUparCMI5uSmI63dDJ5XM01UolJ+KCpJ2kvqae2kQt6GAbNgQjlUWBFOIq1KII8SrCPfroOguQXpCqxBFChOygmtDCLmpNG6XwBsLkLFQKn2j5an19PfPnzyeTyYRKV61PpVgmW+9jk8fRctbwmIhw8JA6dtQzUQK8IhGrDjVGVka9mGhOa7L3KRrWiiqbNy3Ut4JyUN5gSLEeUdhbC9FQ4rsR72iDW2trK9tuu23FZ0uXLg25T1paWgDpFUSreLq7u0MvoqWlRTZERZpl1DZ77LHHhMeNxWKhMB2LtxJKSiaTxGKxipd0bALatm1SqdS47RQ98kTCX81emGyRV1dXU1VVFV5TOp2mv7+fXC4XdleqwS7KSlWlj2EXaBwszyLpJitoQTRNo6V5VDEUCklc16JUijM0FCOBwawG6B6MUZseTWJXVVVhWZbsfq3yaatvgxQMm8OyY3ZEWWpIIZzJZChmilRVVxFriTE0NCQVhR6EQ3K8hR4mJlaXRbwcJ1mdJJ1K07iokWQsidgoiG0TwyyYJGOjVOQtM1roKnVJmg4zxQ7b70BVpgrRK8KSS78op+hpukZRL0qBKwyEJSTPElL4K1qTMJE8wqJqWRaO58jyZIvRKWYxAz/wwzi+Zsj96Jo+mosYEd6qO1g9a7UPGFVAY4WJShRvqnpGWf3R9aZ+5/s+vvDRAq1C4ahwULSpLrp/RYgoxPhZyWrqm9pfVFlMhLHCUXk+Y6uhpoqK+dE+YGz5CExN1ypCq+p5REuM3yre7PX9N/COegx77rknr7zySsVnr776atiJO2/ePFpaWrjvvvvC7x3H4cEHHwyF/i677IJlWRXbbNy4kRUrVkyqGDYFwzBCLpotgXL5o5QUMEKo545aLrqu09jYKOcNR7ZLp9M0NjaO43kBGRZrbW2dVJnF43ESiUS4YJWwV3mJWCwWljnatk0mk6G1tTWsXlKCpX5mPc01zdRW1ZJOp0kkEqTTaZbtMp/3LDqW+vrlZLMZNm5sob19NrlcFe09BnFbUFttMXeOiSnMkB4jmUxKoZc0sWKSHqOuqk6GeTyBZVrYpo1hGcTsGKmaFEk9SU11DbNmzWLWrFnUNdXJMInwcHAQC+R93FHfkTkz51BfXY9VtjBSku+osbGRZCKJU3IYHh6mXC5TVVNFdboaz5PdxI3VjVTVVGGnbXwxMk1NQCKWIG2mpRA0ZW7A0OX0NgJCAagEl6ZroWJTljeMCtUwVGQZYU4lCALZBQ1hglM9A6UU1LqIeg2+L2k+1q9fH+4XKq35TVncSqkoqBxA1KIPBX2kzHUs1Ybav+fJgUuqEmvssaL5g80phiiiMyjGJby3AGpEqKJF39L9KKWvwmFRL2hrhZTerUoB3mGP4ayzzmKPPfbgggsu4Nhjj+XJJ5/kF7/4Bb/4xS8AeePOPPNMLrjgAhYuXMjChQu54IILSCaTLF++HJDW8imnnMKXvvQl6uvrqaur48tf/jLbb789Bx100Bafk23b4YCarQEjZuAIh8CRFA6TYVNezBYf0zBIJBIUi0U0TQu9rcmoN9T3Qgi0ssauDbsSb5JJ8tmzZ+Pv4lMf+zBHnZhg40Yd9V7k8xl6eiCp5bnwrCZa2mJkh7LM2mZW5UxjXZPDcYYFbY1tsvvZFcxsmYldbcsXNxDUttbi9DvE9BhLly6VgtIN6F3bS7FQpMqvIr0sjfa6hv2qTXmHMrql4w67JGYkMOIGftknm8sy1D+E3qDT0NBAXaqORCJBT38PJb9E9/puZm07C1dz6RnqwfUllUZGz8hO7xRhBVHgBzK05MlpbT5+KLh0XSbPRSDDRrquy7GmygtRFrepoXkaWiAT0mGoRpOT7qLPLZqjUAJYDWbauHEjhUIBy7KYOXPmhMI2WpY8mXEztnJIaCPeoS/Deupc1HlWULIzqmR8zQ/zL2Ot36hy2RIBqLwbpRTUvt+Mla4ZMgekJsBp5hYIYh3wR3NNUS8o6sltDShF/m5iWn1Hz+S9730vf/jDH7jlllvYbrvtOP/887nssss4/vjjw22++tWvcuaZZ/K5z32OXXfdlQ0bNvC3v/2twrL+yU9+wkc/+lGOPfZY9txzT5LJJH/84x/f1DDytwrFCKmgWdpo8jQC15Wdt1uCTYWTSqUS/f394bGV16AGmEwFmqZhV9tyBnJhNJGpx3T22EPj5ht9ZsyAWKxMTc0g8XiJHXfcyJfO6eZ973UQmqzlz/XnwnMaGBjAcRzsapvevl5eWf8Ka7vWhlac8CUdduDJYfOFQoHVr6xm1apVDA4O4gYuVsxCszSKhSJixxHPa4Xk6vHw6O3pZeXzKykEsns8m89SGCowNDREoVCQs51NSJgJXN2lu6ubVa+ton1jO37gUxZlBocGKWpFmcsIpKAUurye0BsIRsd1KstRxaN1TQ8rdVQIJbT4NcJchSGkB6IG3qtmMqgcUB/lP1JeRMh029c3znKN5j+ix5/sOUf7FNQ5Bn4lo7BSLOMqkhhp/BrxqiYi8ZvoeqbqAWwqab6l0IxRz2FL5keHCi0Y/XtsDmZrQHXCb4qt4J3AO06id9hhh3HYYYdN+r2maZx77rmbrBeOx+NcccUVXHHFFW/DGU4djuPQ0dGBruvMmjVrtHLFrkxA+77Phg0bACpCQIrWWHW4RtHR0YHjOMyYMWNCSzCfz4dNf/F4nGQyGYYCyuXyOG8kn89TKpVCxlWF/lw/2YEs1X41tXNHczaDhUFqMqt4+OG5/Oc/Cdat66C21mC33TKAhhdIegzd1Mn2Z2mc0cjw8DCFQgFd16nKVKHpGp3dnZimyYzGGRieQeAHWHHZf+AbPkWnSDFXxAs8ent7pReYqEPLaZT9Ms4ChwQJxLOCF994kbgVJ27HyZVypGvTeFmPgeEBcKCYk1PE8qU8RacYUnEEfsC6Neuw0zZt6TbwoTfXy1B2iESQCF98P/ClQvCRVUS69BqEJsYlYVWHs+dKQa8LPRSIqpch7GFAeiPCH28RRy11tX6UxV1fX09Hh+ST6unpobm5OaRmV2FD5V2oqqOxISSoJLeLjra0dCscTaoUk9p+ouS2YRiSeFBM7FlEEe24norBNtZz+OQnP8m2227Lt771rc3+diw0Y7QfJfCCkBRy8ydBaMAoxaAUtfLk3nIlVST8F3qhIzj66KPZY489OPvss9/SMd4M3j2+y7sIGzZsoL29fcJE8KYwWeng2AR0tAEpWp00MDDAwMDAhFPb1AKaSj8DyBdLJbk7OjpCLqf169eTy+XI5XJks1nK5TJ9fX1s3Lgx9Db+s/o/PPXUU7y28jUee+wxHnroIU464yT2/uDeXHHFZbS2trNkST8tLb0MDfVTLBbpynYx3DdMR3cHq1etZqBnoLJaSteIZ+J4rke+nKdQLtDX18fLr7zM2o61gJwtPZQfwnVcuju6Wbt2Lb29vWCCZcghQ9mZUvmZ60yCQiAH+iRsglJANpuVvQymgS50NCHnGORyOWLpGIZmyEqk5nqSZhIE+LpPTaqGZHWS4fwwru6GVnDYkDYCZe0qLqZQcI8kKpWA1xgV5mE9/0hHraZpMkQxkrRViiSagwrpKrTK7mLDMEL2W8WfpNaGrutks1nOOuss5s+fT01NDfvttx+PP/54xT5OPPHEcN+WZRGPx9l3332lByMCNKHx1a9+ldbWVhYsWMDtt99eQQt+++23c/jhh48sypEwYSRBHl33juPwox/9iJ122on6+nrmzJnDXnvtxa9//evw3VKjNieCOscVK1bw17/+dRwZ3ZZA0XdsiecwUdnq1gwhqWNMVvDyne98hx/84AcVfVb/LUwrhgkQTYBtCTRt4lGfekyX1oo/tUa3TXVATzbqc6J+h4aGBlpaWkJlpWrxlbWjtncch3K5jO/LyhxfG5nTPOxSKpUoFos0tcgyz3Vr14VCU/02CALy5TwuLpqn4fou2Z5sxZQ5ALvalh3QrsdwcRiv7FEqlig75fD6dVOGWXRPThkrlUo4OCSSCTCgYBQQs+X11W2sCzu0dV+nmC1iJS3MuIkmNIQjmUQ9z0OzpfC2DRtiYJs2gROQK+fIxDLU1dVhJAwGC4PASKmiYlnVRhhe/ZHYfzA6olSFk1R1kmmaYQe0Svbruh6GnKIWZtT6jDaXRUtQ1XpQIaqmpqbwnuZyuYqS0s9+9rPcd999/OY3v+GFF17goIMO4kMf+hBr166tWCsf/OAH2bhxY/jvnnvuCa/l/+7+P2677Tbuuecezj//fE477TR6enrQdZ3BwUHOOeccLr/88nCNaiP/U/0IUQaAQw45hB/+8IecdtppPPTQQzz44IOcdtppXHHFFaxYsWLCdTwWmqZxzTXXcPTRR0+aI5sqKpSDv/l3O1pcAIT8U4qbamslj6OTFqNKfIcddmDu3LkTzpd4uzGtGCbAW+lKnLCBTU1020yj21uhxpiMbmOi5F8QBBX7i34fj8dl6aXmSMbQEQNQJag3dmysSGyWy+XRcIbhEDfioEN+OI9lWBVKya62SdpJdKEzXBiWvQGBnFWgabIRzLRMMCBGDF2TyqFQKpBIJdA0Dddz8baTJ1W3tg4fH9eTyWMn6xBoAamalKzc8UYb7VzhoukatmHj+ZLDKTeUo2+gjyAIaGtsI56KI0whexKQLLDqDRG6FPyq4U74kbj5iEmpwknK0o+WlqpmPiEkh5JpSK9D1/SKsA2M9hhE8wBKccfj8ZAQbWBgIFyj5XKZP/zhD1xwwQXsvffeLFy4kPPOO4+5c+dyzTXXVOw/FovR0tIS/mtsbAyV8ssvvcw+e+/DsmXLOO6446iqqmLVqlWAzPd99rOfZcaMGaNVQyMKcWwn82WXXca//vUv/vGPf3DGGWewbNkyFixYwLHHHsu//vUv5s2bN6V8QxAE3HHHHRxxxBEVn11//fXsuuuuZDIZWlpaWL58Od3d3eH3M2fOHEfb/eyzz2KYBqvXrEb4goH+AU477bRwfsMBBxzA888/H25/7rnnsuy9y/j1r3/NNttsE5aY/+1vf2PvvfempqaG+vp6DjvssIoJcQCPPvooO+20E/F4nF133ZW77roLTdN47rnnwm1WrlzJoYceSnV1NbNnz+akk06ip6enYj8f+chHuOWWWzZ7n7Y2phXDBNgaiqGCM2nEUplMMagXJDp/eSr7nWybiei7o8eJKobosRQNgGVZBFqAIxw0Rwp21TfSsbEDIUTo8TiOM9owh4uVsNCFTtkt4+W88DilkpwDna5KowudXCknE3sBkh3TlBUkhm3g42PoBjFTztMulUoYcYOElUAYgvIieX3Vr1fjmz7lbJlkVZKgJJPXiaoE6GAGZnjtmGBYBqaQ4Z6qhipcRxYADBWHEI5g1qxZpOvSMpE80tQWTT7m83myA1kKpYIMxQ1lyeVyDA0NyWMI+axN06RUKJHNZhkaGgpzLfliPiQa1A1dUoHoBrlcjsHBQXK5HPl8nkKhgOM4YZkxEE57U89ChSOVwFfKRQkvkOs4kUjw2GOPVcSuH3jgAZqamli0aBGnnnoq3d3d0tq3TLbffnueefYZ+vv7ee655ygWi8ybN4+HHnqIZ599li9+8YuVNBn+xI1fN910EwcccAA77LBDeP9UfsE0TRKJxJQSri+88AKDg4Psuuuu4Wcqb/ad73yHf//739x1112sXr2aE088Mbzuj3/84+Ms7Ztvvpn3v//9LFi0ADQ47PDD2LhxI3/+85955plnWLZsGQceeCD9/f3hb15/43V+d8fvuON3d4RCPZ/Pc/bZZ/Pkk09y7733omkaRx55ZCgvstkshx9+ONtvvz3PPvss559/Pl/72tcqzmXjxo3su+++7LTTTjz99NPcc889dHd3c9xxx1Vst9tuu/Hkk09OGil4u/COJ5/fjXgriiFqiUcTdkbMqEhAKwtfVSXEYrEKj2Fssi+av1BJvrGIx+MUi0VKpVJoVRaLRfr6pFUcneAW5dEZe52qKa6sleUEM2fUY+jY2EHgBiSrZY+CmiugEt12ysYeks1+btYllpLCvVwuY1kW6do0+gadcrmM67vgyZkVuqVjOHLcZ5ANEIYgrsdxfdmIF+gBqUSKlJ3CXCaXbfLlJL7h45Qc6mbU0d/bz/DgME3NTXJ0Z2CRSqZYuGghpmnS0dVBsVykurqaxsZG2l9vp3eol86+Tuoz9dQ01shBQb1SMAQikE1uI+yp9TMqKdGj+NCHPsQf7/ojmpBVMLPmzApnVIzFPnvvwwMPPiCFcWCyww470NfXN2471a8QLWf0PI+qqiqWLl1aEYKqqqpi991358ILL+Q973kPM2bM4JZbbuHJJ59k4cKF4Vr60Ic+xDHHHMOcOXNYvXo13/72tznggAN45plniMVifOiDH+LxJx5n7733JpFI8Mtf/pJUKsXnPvc5rr/+eq6++mquuOIKGhoauPLKK1myZAme74Fb2bClZhKoaiXVy6CuQyVbN+c1rFmzBsMwwhAayOOcdNJJ4W+32WYbLr/8cnbbbTdyuRzpdJrjjz+eH//4x6xdu5Y5c+YQBAG33nor3/zmNwF48KEHWbFiBRvXbySejKMbOpdccgl33XUXd9xxB6eddhog3+MbrruBppYm2c8CfOxjH5PrY+RdvPrqq5k1axYrV64MZ0lomsYvf/lL4vE42267LRs2bODUU08Nr+Hqq68OWR/Uvn7+85+zYMECXnnlFRYvXgzAjBkzKJfLdHZ2VkxafLsx7TFMgLeiGCYL6YQT3SIx4bEWftQSG2tNRcM3m0tAR3+r6CV83w+Po3IEY0NX6tyUYnA8B2wQrqClWXahF0tFsgPZcI60ukfJZFKWyFqQyWRIJ0YaxXyj4pzjtXGSsSRxI07JL0mPwZdjL7VAw4jJxLGRMEgaSWzLlrkRzZMzonULsYs8T6vdIlaSc4XRJN+TXtSxbAsrZYEny0OVUo2n4whXUCrKnMesObOkd+OVKRaK6IFOXV2dFABaJTXE5uLJSniLQEytTFpAoI+Wom5qv7quh89WCVRVfRRV7Gry2pw5c4jFYlx++eUsX7684nyOOeYYDj30ULbbbjsOP/xw/vKXv/Dqq6/ypz/9CZAhr3O/fS4vvvgijz/+OIcddhg//OEPOeCAA7Asi+9///s8/PDDfPrTn+aUU04JBxb5nl9Rshqty4/OfIaJaTAmQ7FYJBaLVTaN6jorVqzg6KOPZuHChVRXV7PffvsB0N7eDsjxoUuWLAnDMA8++CDd3d0ce+yxgCTfzOVyNLU2UVVdRTqdJp1Os3r16oqw0Jw5c6RSioiCN954g+XLl7NgwQIaGxtZsmQJQJjLeeWVV9hhhx0q5iPstttuFdf1zDPPcP/994fHraqqYscddwQIQ3cw+i5OZmS8XZj2GCbAW2U+rK2tDWOu4T5jI1ZSpNGturqaTCYTLiAlrFVSd6xXkEwmQ4E8EWKx2LhyVhVOKJVKlEolbNsOr8u27ZADJhpqyGQyoTDVEzoMQ1yLU19fT19fH10buthm6TY0NjaSz+cxTZPq6upwX2W7LMNDhobpmrS2tmLbthylGTeZ0zyHTCKDkTZob2+XtNY6cqKbZUi6irSgIApUp6rJ1ErSvFg8hptz0Vo0gm0C9FU6szfOJr9jnqRIsu3SbRGeIF2TRlukUVxTpKauBpCCyk7ZpOIpGhoaEEJQ3VTNwtkL0ZM62WKWZC6JlpG5ANWwJgKBbdloaAz0DMheBl0f7U/xA3zhh1U9eqCjmRod6zrwxKigVFQalmGhB3oFieDLK16WHmVEYUe9w2h3swopKZoUVVlWW1vLwoULeeCBBygWi2SzWVpbWznuuOOYN28eMEqtHa2Ka21tZc6cObz22mtyDeqyysrU5bFeeuklbrvtNp544gl++9vfss8++9DY2Mixxx7LySefTKFYIGEnJK1GJJ+1aNEiXnnllfCclYJVhtNU0dDQEIbWlDeez+c55JBD+MAHPsANN9xAfX097e3tHH744RUhl+OPP56bb76Zr3/969x8880ccsghYS9IEAS0trbywAMPyHkUI41suqFXzINJpVLjylYPP/xwZs2axS9/+UtaW1txHIedd96ZYrEYrrWxCm+sZxQEAYcffjgXXXTRuGuO0v+osFZjY+OU79nWwLRimACqmuTNNshNRGuhWyPc/BHFMNFEtrq6unFKRSG6YCfCZN2umUwm5PNPJpPhddXW1lJXV0d/f3+FRZLJZGhoaKCqqkpae9UeCT3Bp/7nU2iBRkt9C5ZpUV9fTyqVIpPJyDGZIzFkI26AKa0c27KJBaMWn27oJKuSxIM4vu7LvIJuhF2pqXQKs2hSMkukqlPUN9VTPaNa0mWLMuX+MkPZIVJLU6RXpZmzcQ7u8S7FjXJaXmljCVyoqq9CdAv8rE9/fz/d3d1ojkasHEPz5XS1/oF+YknpcQRmwFDPENXp6vBeqjJUz/cwDZN0Ki0rlXRNsriaI9VmQSA7ooXsfTAxSafT+EL2QURDJqZhhorBsAw8wyOZSEomVrOSSiLaAa1q3KOU1oODg2zcuJFkMklNTU1Y0aSs0IGBAe69915+9KMfhdcEVHD+9PX1sW7dulFhNCLPDM0g0AO+8IUv8IMf/IBEIhEOcIJRLzPkQhJ6GGoB+MQnPsE555zDCy+8wI477lgx+1pVtIU8XSP7m4g6Y6eddgJkolb998svv0xvby8//OEPmTVrFp7n8cwzz4xb98uXL+db3/oWzzzzDHfccUcFOeeyZcvo7JQ9NXMXzB2nHCreq5FxrQTQN9jHSy+9xM9//nP23ntvQM5wVs/L932WLFnCTTfdVNE/9PTTT1fsc9myZfz+979n7ty5E5bAqme/YsUKZs6cGSq0/xamQ0kToKqqira2ti0eh7cpTNToNhHi8Ti2bW9VHpWWlhYaGhpIpVI0NzeH8VpFvNbY2MicOXNChdbW1sa+++7LzjvvzK677soBBx/A4oWL+eF3fsjFl17MbrvuRnNdM83NzcyZM4eamhra2tpobW1l5syZMlGYRFJQlEt4WRnaqq6uZu7cuTS0NOD5HoEXML91PgtmLMCKSYVWVVVFTW0Ns2bMYt6SeVjCopCXSstISoVWKpQo7SDDQdpTkm5DCWxN1yj0FAgIMBIGXt6jkC9gGAYlv0TZK+PkHOLxuKymislcRtktUyqWcAujpaGaroXlqb7wR8NFKlzii3CcpGJzVeEkVbmkLP6QzlxIKnE1/Mcw5JQ33/clH9MYWoloOCaq+D3PC3saCoUCw8PD3Hvvvfz1r39l9erV3Hfffey///4sXryYk046CZBhmW984xs8/vjjvPbaa9x///0cfvjhNDQ0cOSRR4bHVIyw1113HU1NTRx++OEIIdh999355z//yeOPP85PfvITtt12W2msaKPnC1Koff7zn2ePPfbgwAMP5Oqrr2blypWsXr2a3//+9+y+++68+uqr4XUqxTdRh3NjYyPLli3j4YcfDj+bPXs2tm1zxRVXsGrVKv785z+HM5qj92/evHnssccenHLKKXieV1HZdNBBB/H+97+fj370o9x77720r2/nsccf41vf+hZPPvFkxTlEe0pqa2upr6/nF7/4Ba+//jr//Oc/+fKXvxxu63keH//4xwmCgNNOO42XXnqJe++9l0suuaTi/M444wz6+/v5xCc+wZNPPsmqVav429/+xkknnUSxWAwT+g899FDFrJn/FqYVw9uEYrEYDlZR0G0dv1xZwVEulxkYGAjd0M1B5S4mC3O5rkt3d3dYugdUxKinGqtUxymVSnIecMbCzY3QdFs6fknG33t7e8O5052dnQwMDOC6LqnqFIZlUCzKTuaujq7wnHRbZ3X/alauWkl/vh8v54VMo3iACb1dvXT0dtDV2cWa19bQ2dkp8w+GTkJLUN5lpJHv3zqlYomckyPbk6V9qJ2XVrzEwNAAg6VB1qxbQ297r6y0IsDDo3N9J0NDQ6TTaTw8Xl//Oj29PVTXV4M38vKOUGqjySS068r5zoEf4Hu+tCKFtCIVJ49pmLLcNiB8s6JNaip57Pqu5IsKRDgoJxABruPilGUuRuU3ovTYiqLbtu2wmU4ZL11dXQwODnLGGWewZMkSPvWpT7HXXnvxt7/9LVQmhmHwn//8h2OOOYbtt9+eE088kUWLFvHYY49VeLmartHZ1clFF13EFVdcER5r2bJlnH322Xz4wx/m9ttv57rrrgu3V+cIhDmQP/3pT3zpS1/i5z//OXvssQd77rknV155JZ/73OdYtGhRRe9GlFp+7No+7bTTKiqMGhsbuf766/nd737Htttuyw9/+MNQ8CqosNnxxx/P888/z1FHHRXG69Ux//znP7PPPvtw8skns2jRIpZ/cjlr166lqaFpfJ+DRqjwb731Vp555hm22247zjrrLC6++OJwnyA97j/+8Y8899xz7LTTTpxzzjl85zvfAUajBG1tbTzyyCP4vs8hhxzCdtttxxe/+MWQXDMIAorFIn/4wx8qktb/LWhia1EF/j+MtzI0ezIoYdnc3BwuSK/gUe4rk2hLhO7qwMBAKKRU7DubzeK6LnV1deM8B0WN0dTURDKZHHdc13VDuo05c+aEvx8eHqa/v59EIlEx+GhwcJBSqURdXV0FNUahUGDjxo3Yts2MGTPwPZ/BtYO8uvZV/MBn1/fsSrw1zssvv0w2m2Xu3LkIIaet1dfXyyqgdR34Qz5NtU1057uxq21mz56N0+vwxKNPMNA/QGttKwvmLKBupzpK3SXJm+QHdHV0IaoEpe4SHT0dxGvj7LzzzgSdstt5yBxi9g6z0cs6T/zyCfJ1eeY2zyWrZxneOEzLwha8IY/ejb3YKZvmbZspFouUO8p4ZY+m7Zpoa2tj7dq1vP7S69i6zdKlS4kZMTrzncycMTOcumYZlqygAnShY2JiJGUPghAC3RqdFa0ZWphf8R0fDy8U6EoxBH6AKcyQA8otjSod0zCxE3aFh6BKUaP02SpuPzw8zNq1a9E0jW233ZZ4PF5BjzFRPD9aGBHNN0S/D9wgDKu4rhvO+lBUK2q7MNTlSqoJpSRUwhlGk81jhb8qj44OqVLiKHrupVKJxYsXc+utt/L+979/gretEsr7mOz6Nvv7CcJKqmM6eo1jsSkyvJtuuomTTjqJoaGhCgU10T7Us/nFL37BH//4R/72t79Nun2pVGL16tXMmzdvXGj6rci1aY9hApTLZdavX8/GjRvf9D4m7GeIbb7RTcWOlXIYi6k2ukW3UfMq1Mu6YcOG0FUtlUr09fWFVBnqXJ566imee+45Xn31Ve6//36ef+F5bv3jrex18F585oufoXNjJ+vb18v5yoUCGzZsIJfL0dPTwwsvvCAtfNsAa4Sh1NXIZ/OsX7+ebDFLTV0NgQjo6O1gzbo1ZIey6JZOuVhmQ9cGert66e/rJ+/lcQsuhXyBbDaLmTIRjiBZncTZVl5fw6sNeKacDZ1IJhCaoDhUlFPRjEDOU/A14vE4vukjPEE+m0fTNNLpNPFMHNd1GRwYDJledUOvEIDK6g6nurlBmBcRvhQiKowEskpH13U5vpRRIWrbtvQqFHPrSF5A10ZYTkUw2mEtREVhQJRQT1X0xONx4nE5ia6rq0uus80UT0RDUhMRwoVJ5JGPJ5otPRH5m7p2GB0tGvY7RAbdRHMlUQUSza9EK5zi8Tg33nijpEeZAtQ9Vde3pfTdSvhH2QrGDu+Z7Ljq3t944408/PDDrF69mrvuuouvfe1rHHvssZtUCmPP3TTNd4z/bVoxTABVk/9WGA8npMZQjW4TTHSLvjibKkvdHDUGjKfbUOWz0aqWaGWS53kVikjTtPClLZfLYVNWfbOs41+3bp1sMsqWw1LY4eHhUFioOQixWAwzZVL2y9iaTTkvZ237vk99XT1CF+TLeYqFIn7Jl01uQifQgjBkIyw5t8EreaFiQEDSSFLeWd6DmldrCLSAolvExsZKWrh5Vza5xWWTm5+XFrj6u5gtUi6XyWQyZDIZPOExPDQcxnejYRzf98OubE0b6WD2RigzjFHKBDX5zfPl2gkIQgpudV8Vx5LQREitoRkalilpFtCkUjG00WNHrdBoubOCoopQyn/sthMh2mw2kYWrQmVj96HWXbTayvO8kCBw7DGihop6p1TiO9rPoNbeWGWisO+++45yNG0G0XJYmHjm9eYwmXLYlGKIYuPGjXzyk59k6dKlnHXWWRxzzDHhOIHNHnvkfqkQ1zuBacUwAd5quSpM3oU8ttEtOrRdbbupDujNeQwTHTsqKJRAUdemasQrSP9GhMbY4SStbbJyJZfP0Z/txy/5oz0PkdCEeqljsZicl2C4xKwYflE2o2mGRnVVNXbMxg98Sk4JN+9KzqMR9lLd0NECKYTtpI3magwMDMgEtAaGa+DtJs85tVJWtxTcAqZnSg+g7OK7PlZMku8VhgrYpk2yOokIBG7RlV3SiYScNpewKJVL4YjOqDAOCEIvAo1QqHuON5qgHvEaNLSwczq0kEcG8kTHcnqBF444VZamaZhhToNADglS918J2WilnBJ+alqeYiONPuNNCcNNTX0LJUNQyQGmzj8aohnL9xRFtNRWrS11vVGmVbVmoiWtb5WwLvpuqf1vyTs9VjlMxWtQxzrrrLN45ZVXyGazrFq1ip/85CcThn4nPG5kMNDWHCe6JZhWDBMgKkjfbApGvUhRVxkIK5Oi+x0ryKfiMYzl14liIsWgvIBsNkt/f3+Fx6AUg/osOioyWh4Zi8XCSph17esQnsA0zDDurfok1Lmr8/BNn1gyhu7pFHNFKdh1g6raKtChWC7K/gQzMvHL0NEDKThi6RgEkBvOyfnEcQOv4BHfV3pGsVUxrJJFKSih+Rp2wsYTMrQUj8XxNI9yoUxCS1DXWEdDQwO1qdrwuubOnUtLWwuaqVEoFKRgHeFFCgX6SOJRMyRhXiAC3LIb5hPCaiRTKgY1t0HdUyVQVZgmECOhFNcfLRHVjXD4T4BkOo0K+bH5pqiymDlzJvPnzycej1dwNE1VEKq8RdQjURVZQKh4YNRQqAgXISpCTWOhJiOqd0t5C2rfUS/hzfQ7TAZd18M1/mbe56hyCKvRNqMYlMcCo9P83sx5q9+/E2ngacUwAaIv4Jv1GtSCBMZ1QKtkncLY0M+mPIZoj8Nk4aSJlJIKYeTz+bDaCEapoqOuu7LyVJgIRpWkmm63bp1UDLiV3ZmxWAxd10MOpfr6embOnkmyLomt2/jF0Q7ZuiapZMpuGa/ghTz5uqYjDCE7oA0DOzVyPwouuVwOI2ngF32SC5OINpk/aFrVhKd7lJ0yRmCgxTT8ko+Bgad5kuytDHW1ddQ01IBb2XFeXV2NHtPJF/MVM4x1bdTSDwX1iCErAoHruGFpq/BlFZNmSEJApVwU66pSzupZBAT4rh96cirsFARBSOSnQkpRARH9b8XEappmSLbnOM4Web3RHECFENNHn3s0rxHdLgwXGXJw0qas8rGKTYU11XqbTBGoEOWbFZBRr+XN9CZFlUPIobW530Q8njcz2GesR/XfxrRimADRJNJbCSdNmGewRxrdJkhAK4GpfjeZe765cJIqT1XdsTA6d1cpFVUeOxnVhrLuVNhACQLVCLWua50cBVn2SSaTIaFbIpGgurqaqqoqgiAIu6itags7aWMLG68slVVzazOxeAzLsPCyUnhruib5iXSBiUkymSQWj5GpyVCdqKZUKmGmTJmDcHy0940MsXmtHl/zKXpF4sRpbG2kKlFFTMSwEpa8F36Al/eIZ+IwonPVNVdVVVHXUEd1jYzXG5oMWSnvAJA8SLqk3DBMQ/JIAW7ZHWVhHRkGpOnaaOJ5xNuIhlwsywJjxFJ3vFAIhzkIIfeDIPTKwnLXiPCNKnE1PbCrq2uL1u3YZG10zoO8gNF1FeX3GncOuhH2c0wFyrNRXoIicIwqiKgn85ZmQEeuUe13S/YXViMJpjxDOhqO3dJzjz7XrdnTNFVMdz5PgtByewuKQQnIaDeypmnolj6OUK+trS10qZV1FqU/iCKVSmFZ1iYrHNQcBgX1Uti2TblcruibiLra0c9AWrqqGUzRCAC0b2xHQ8Mv+FTPqg5/bxhGeL4VPRyGTk1rDbqrY3jSmq6vr2fxvMUUO4sETkBQlmR6mtAQuiBmxGhra6O3txdzhknMiWFpct4CgF/wMXc34Q+QeSXDNnO3oc6uww5sEi0JciKH7/rM3Hkmfr/sPfByHp7hoQmNwA3o6upi5syZJBIJkskkfsmH8ug9U0LAMKXgVTkZPaFDfuQadakcLFtOotOEfMbqtwEykR6l5A6t76IMJxnWCNW2Pmr9hxTfIwlqtX5gtHtZrRUlRF599dVwKtzYNbApKK9o7OQ3NY9A00cT5+VyOQyRjOU/UucMEyfKo8eLx+PjZjtHhbc6hnoX1HZbYxaCUtBbMlNaN3UCAhkKdoWc8bEZRGdFb61z/29gWjFMgq0R45xsGLse0ytmKgMVPQQATU1Nky7YZDK52UTW2MVn23ZY4aK4ZxRqa2vD/UaPkU6nwxe+urqacrnMPvvsQ3NzMzvttBNW2sIZdjCEQX19vaTWHpO4BklDXCqVIA5G3EAUBX7cBwHxqjilnpLsEh520W0dUzNJpBPEghi2btPQ0IDZYhL0B3I6m62j2zpu3iX2PqmEEq8kqE/Uk6nNUO4p45d8rGoLb70nPRB7JAzjBmSdLIEfkOvLkW5KUygUSCZH2GINOWNABELmCkaS4AHSSPBdH9M2ZS7BkIJTkeF5rqTOCLwRBWdo6J4e5lSiilIJvMCQ5ame52FqZpj4VmWWsVgM4QoZtjMJPY+oN6eer+u61NTU0NPTQ19fH3V1deOMik2hIjmuhjnp0uNR4SSVV5iwYk+jgmxOhVAmW8cq3Bqly1DGBYx60OoztX63hoCNstZOpJQmQ0iD4knix7H0GWOh3p9oUcCWQK0F2PrT4zaFacUwCaJNYFsbuq0jsrLSYbKFNVZRvFmopGVNTQ01NTVhtU30Bauqqho3HWvu3LnMnTt33P522WWX8L/9os/Qq0Mk7ASJlkQoVFpbWxkaGiKfz5NKpchmsziOQ2NjI3VL68iuyeJmXYQvmD1/NtaghV/wcQYckjOT1KZraV3YSrFDMp4qhdXv9VNcX6RlaYv0ukoBwY6yWsTsMSmtLFFzYA2Y4BU9XMulUCygd+mkalOUh8uYtknSSpI38ghHCobh4WFSqRTpdFqW0wYjk7R8qdwDT5ad+q6P58pciBAy0SxcgaEZ+PoIE6spwnCD8hoMRpL4onKGshBCWqG+VA7CkN5G1Fs0TRPDNKQg8gkb7ZQ1rYSZsvAbGhro7e2lVCoxODhIfX39lMMRUSGmBLVpmOE0uzBJHmF1VUoKRss5RTDSMT6SC9mc4FVKTglBpYCinoLneeFxt4ZyUGFV5Tmo/58K46tuSsJE4ckw4+ZmSI8t290SRBXDfzOsNJ1jeJtRKBTo7e2toKJQJHrRPEMQBPT09LBhw4YpxSI9zyOfz29yLnVnZyft7e3jJrqNHbm5ucVWKpUmnEVtJAyslEW5T/Y6rF69mo0b5YS3bDZLoVAIp46p/QyWBhksDZIfzOMVPUpBiVe6XuGN3jdwsxH6byFfwMG+Qdrb2xkeHqZ7qJuNXRvp7+zHTEqB5Rs+7CzPR39E59XXXmUwO0hPbw/tHe0MO8Osf209z77wLGtWr8HBwcZGszTK+TIdHR2USqVwEl1XV1eoGKK0CEqwB34QjgtV7KmakGyktmXL8s5IvbtmjuQLAi209tX9dl03LM3V0cPqJkMftdxd1w0T2iIQYeWSssYnCnUqD7C3tzecz7GpkOj1118fEjRqmsYPfvADdtttN/kcNCrGWypBpfanQk9qW7nRaIw8WvI8UZxd5TSiMXWlQMYK1HB+NpUC881ibCntlPsddPlPhfmmMkN6rFKYcm4jUmH23yxdnVYMbzPUbN5oTF8zNGl1RBSDpsnB9a7rhhUY/f39dHZ2TriIBgYG6Onp2ST3kVpQYwW6KmmM7re/v5/169dX7E9ZakNDQyF1hxCCZ599ljvuuIO+vj5iDTECJ6A4UKS7u5uurq6wNFFdv1IMxWJRWj1VGl4g6UHSmTQODiW3RCFbwCvJEIVX8nCFi3Clddjf30/RKTKYH6RzneRN0jRZeaTtI6/Tes5i9Sur6R3oJWbHsLEJ7ACn4FBypPAvFAuSbymWwC/7OI4TNuglk8kwb+MLPxw9qumyEkcgm9fCckWN0DJW9zpa4hkmorXRWvioIFT3GH2010Eh2pmsqp40TQsT4Eo5REM6J598Mul0mvnz5/Pe976X7bbbLhzNuSlBdNxxx1WQ2qk8V2iRR8JJMHq9Qoiw+1ldk6IRUfuJ9l5MJHijRR7RMk91b1TILboP5VFsrYqdaNntVKDuT1RhB97UykqVt7Mlyejotf+3SlenQ0mTYGhoiGw2SyaTeUtDyCdrdNNtHd8ZtQA0TdIbFAoFSqUSsViMXC4XvkxjQ0u2bZPP5zfZAR2LxSgWi+F8h+7ubjllzbaxbTvkTymXy/T09IRUyMlkkmw2y3PPPcfQ0BCNjY0MDQ2haRrV1dUsX76cN954g+uvv54999wT27Ex+gxy2RxoclBJLpcjFouRTqfD3gc1AtMVMlHrDDh4NR5O4CA8wWBhkNrhWsqizBsvv4GpmdQn6yk6RUpleU983Sc3KPsZ0KXXJfYSaD/RyLyUwXIthopDzLRmopU0sEaqQzwdV3MpDhexmixSiZTkPBIGhUIB0zRD5sxcLlfBgqqbsi9B9R+oZqewCzoYpbDQdMn15PkeGiaPPmSwcYNOc2PAnnuPWs9qgJJKXotAyE7vQHoXKowSVTiYcmiSjszjuK4b5gKUsDr44IO56qqr6OnpCXl55s2bV5GPGItEIjFhIUN47EippqZrFaGfaK+L6sFAUDE/QeUYJkrCKos42jinoMI70RCPuidjFUj0fN8MojxU0f2M/Tu8NyPPWSXoQ+/S2Px5qDBimMeZwrmp323qOW5NTHsMk0DFHd8KLQaMH/WpoMdGGt0izTKT9TNsqtFtUx3Q0XJZVero+36oKBTUdUY/V70IhUIhpIlQYYmWFjnNbfXq1eTzeby4J/sQAmnF9vX1haEDlZCOxWK4rkuxWJTnkZRhmWJPESNm4AmPocIQXt7D8z2csoOHvPe2KYcL2bYNpmyIK+aLMkzjC4Ld5EsZb4+TGkxRKBZkdYwYGTpjmeCCEzg4eQdhC6ykRcyMYWKG9zuXy1FdXR02bAWMxP610UY35SGE/R26qPAsVHz9rv/TWbDY4MCDdD55gs7Bh5osWmLxxz+ONomFYRJtxDp2pQfgOqOzCaIhE02TniYCTN0MLeno9/F4nJaWFpYuXUpjYyNtbW1cccUV7LzzzqRSKWbNmsXnPve5kBcLKkNJE2G//ffjzLPPDKnCdV3nmGOO4dRTTw3r9RctWsT555/PSSefRG1DbcgI+uijj7LPPvuQSqVYsGABZ599tmTsHRGeV111Fe95z3uorq6mra2No48+OjxutHQ32vg2VimotftWKgjD+xvx2tR7MaGVrsqTI2R7IhCbLWV9M81v0VLbt3qNU8W0YpgEU+GbmQomIrUDJMEcTMibVC6XK/oZNqUYJut1iO5vbB5CWWHR5iXbthFChB7IWFc9OiM62uQWBAF6QtJYJJBWZ6lUkqWLIy+t67qh0gst3JhGEA/wh3ySqSRokC1mpaB3AgxkL0PgB8StUdZIO2bjaz7Z/qxMAiPwUz5sJ79vXNWIERjki3k5bEkzQhoSP5CVPuVCGavaImkn0X2dTCZDY2Mj1dXVJBKJ0biuejv8kRr+kWY3TTY4hB4DUOFF/N//6Rz/SZsNGyotxw0dcPzxNnf/nxkaHkoxoMs+iUDI0taxXE0qrq/pWkV/g3omY8Mztm2zcOFCZs+ejWEYXHLJJTz99NNce+21/POf/+SrX/3qhGtmLML9aqNVQmNDXsr6//GPf8zSbZfy5GNP8q1zvsWLL77IIYccwlFHHcULL7zAbbfdxmOPPcYXv/hFQA6v+cIXvsC5557LCy+8wN133x0Ov1HXMTbHEBWk0cY8mJiy+80imkuZaL9hOGnk4wrl4G1aOUSb3zb1/kYRVQz/DeUwrRgmwdZocFOYKJwUjoaMKIZoU1nUFZ9IMUS5aibzGqLbjB0Yk8/naW9vZ3BwsKKrVb0ISjGohRjtpg6b3EYUgxbT0OIacT2O7uuhBa6USTTPIISQ90ODICEFXY1WQ6AHlMolXM3FK8o+A83Q8IVPwk6E15BKpfANn6HsUBjD90s+7CuvuX51PSk9xXB+mHgsLhvRDBnrDtwA13Mlb1KVTTKVpNqoDst/xyZMBSPVNd6o0DdMYzR8EARhnkEIaS0GmsZZZ+tIuVCpGMRIQ9zXvh7D90eTib7vh6MxdV0qO6fshEJXPZOw23iE+VUTWgUlCcCf//xnmpqaaGqStOLLly/ns5/9LHvuuSezZ89mv/3247vf/S633377hGtmLEIBiLSOPderCJVE8yv77bcfZ511Fttssw3z58/n4osvZvny5Zx55pksXLiQPfbYg8svv5wbb7yRUqnE2rVrSaVSfPCDH2TOnDnstNNOfP7znx93/LEJYuUdKIWo1q1aI1sjSRvNsSgFNM57iHSGw2juUIjNK4ctbX5Ta2Nr0IRMBdM5hkmwtRWDivUraJqGHpODeyys8DO1bblcDoXpZIJfMaNGt53o2GqbaO226jgtl8skEokKF9dxRiecgbRqVMmo53lhKKm9vT28P2bSlHHzokERea3JZDJUDirEofiUPEOGi+K1cZJ9Sdkc5gqGS8OYgYkWaGHVUdpIhzH1TCbDQP+AJKFzfKy4LCcN9gjQr9TJrMxgCIN8Po/dbMsXtSxIJBMUB4uUvTKFoQL6PJ1YVQwxKGP70TyOEoZCCDCQw4OErM4JhbeQvzNMI0w4i0Dw0CMa6zdMHmMWQmP9enjy8Rh77zta0aOqekzDxPHlbAZVCqq+j5aHaqYG7ggtRzAqWPbbbz8uv/zy0OO0LIv77ruPSy65hFWrVpHNZsMOaVVOPBWosmqVQB/baAdyXCWMjPsMDJ555hlef/31iiE76jpWr17NQQcdxOzZs1myZAkHH3wwBx98MB/72McmnB2gwkrRGQ/RiieVjFchU/Wbt4KxJa2qEEAZUSGHUrQBUR8pLPGCcOjUZDmHsc1vmytRn0o+Ymth2mOYBOphbg3FELW2o5iIUC862jM6FH6iXMdU8gyJRIJUKjVuhrWyRKO5D6UIVE4iaqUpr0cIEXoM69evH7Vi4zqapRG34yStJEEQkEwmmTFjBplMpuJFjsfjpNIpEvEEdr0NBjSkGmhJtxDXpYLT/JH8gRGgBzLco5KkjU2NpOvS4BOGdPzdRijLX7XQ83Kug+/7ZGoy1CZrmTVvFg1VDXIecjwtQ1QNcUxMNEeW1/b09NDZ2RneW8Mwwt4D4YswnGQapiwbHQkt6ebIvGMBHR1TCz12dephCC8M22mEfQwqgavyM2ObvjRNC0kHVTjD9yU9yYIFC1i0aBHz588PR03Onj2ba6+9lieeeILLLrsMYMpTA9VzMyxDzsCOcBxFFVcqlQopQxBy3Zx++uk899xz4b/nn3+e1157jfnz51NdXc2zzz7Lb37zG1pbWzn//PPZZZddGBgYmPQ8lPeg3k/lFas4vPIiNkXotyXYVEnr2HBS+Bt9ap5D9B3/bzavTQXvrrN5F2FregyJRILZs2ePcwONmIE77MqQiCUXenV1dUUVlJrg5XneuMWjqDE21d2qBsMDYcJRJfFU7DQ6B0KNjVSLVb34qhFOeSaaJgn5+vv7aW5ulnTYBjQ2NFJ2ymTJVngnUZimSXVTNaXuEo7mIFKClqCFKlFFQktQsAuIrKzOwZBWalNDE8O5YWKxGDNmzCBux9F6Nby8h1Vt4ds+1iIL7VWNmRtnUlhUIBABdbV1FIoFYskY8+fOR7d0DMsgKAXY1TY11TWUi+XQklaeQgWvji5kf4IpQzcIpEfjjQ71IQA0aGmemmJobQMDI7zvarKbIYyQd0o9m7EkbCr/oOmjcW3XH52KFlXqzz33HL7vc+aZZ5JIJFiwYAF33HEHsGmG3igaGxvZuHGjbLTzpZGyYsUKDjjggPA40fJbTZed4suWLeM///kPCxYsmHTflmVxyCGHcNBBB3HOOefQ3NzMfffdx9FHHz1h2CQa2lLXEOZqIEzGj93urSLqsUQbzVR10th1PlXPQRkHW4IoVcjbhWnFMAnUy7U1bv5ki1S3Rye66dbEzltLS8ukccUoFfJUoGgxoLK9XiWnE4lEmFgGGYZSVrpSDCpJ/c1vfpPW1laqqqqkMDJ0dFMnlUxh5AxK5VIYuoJRIdTX10e5XGbBNlJYaEJDr9ahBKIkJFWI7M8ioSWob6pHG9aIx+KkMqmKHMBQbghv0CPWEMPLeYi9BdqrGvWv1+Ps71AqlvAdHzNuSoqMjEV5oIxuypnVdq0tG+UcQd7NY5hGeC9UXkUN3DGQ1rJgpDchGMnXiJHwzsgMhr33gpkzBRs2aExkKGqaYOYM2HOvAM/10QINOy6PI7SRckRhYJkWPn6lZTqCKE+SZsjhRrozSvWtvg+CgNmzZ+N5Hrfffjt77bUXDzzwQMXAmKkUVxxwwAGcffbZ/Pkvf2burLn85PKfMDQ0NOG2QoiQGfZLZ3+JvfbeizPOOINTTz2VVCrFSy+9xH333ccVV1zBPffcw6pVq9hnn32ora3lnnvuIQgCFixYUBGi2hTG9lao30yV/2hLoDyWinJWLVKVZlS+41sSVlJQBsCmzj1qNLxdmFYMk8C2bWbOnPm2HkPTJdma7/iYYx7F1qxZVq51Op2uKEvs7e0ll8shhGDOnDnjfrftttuyZMkSYJQ/Xy1sNXs3KlgyZgYv51FVXUVNsYZMS4ZSqURPTw+xWIzm5uaw4srzPVzPRdd0dtxxR0o9JVY/vJrujm5mNMxgVvMsdEsnU5OhWJDUGGij+Y+Ojg7y2TypYop0ID2i4P0Bxq8MYs/GMC0Tz/XIDmUxTZNSXwm/xmeoZ4jGoBHDMWisa8TKWAS9AZZv4VuVsXMValOlqqpfAeQwHcMw8BwPx3UwMDANE9My+cmlAcd+XNXnj95PTZN/XPRDBzXwBx88d5SWwcRED0Y4moSGYcvwiCKuU4nmqMWoGRMzh+q6zg477MCPfvQjLr30Un72s5+xyy67cO6553LqqaeOK/2cDCeffDLPP/88n/rUpzBNky9+4Yvsv//+4bGiLKvq3mmBnEF93333cd5557H33nsjhGD+/Pkcd9xxANTU1HDnnXdy7rnnUiqVWLhwIb/5zW9YsmTJlNd9tL9BeahjubqiFvZb9SLG9jiEVBq+OSG9zZYoh7DTnU1ztUV7R96uhjdN/Lda6d7FeCtDs6cKxV1jGAaNjY3h586AIyehtY42GGWzWfr6+kilUhXbTgTHcSgWi9i2PSnban9/P8PDw5JaeqTZDOR19/f3k0wmaWpqCj+fTCkJIUIenra2tnHfB05AsatId76bfE+e5m2aqWmqYcOGDWiaxqxZs+ju7qZUKpFOp+ld3Yudttlm6TYIX/DgHQ8y0DvAnCVz2KZtGwInoGpRFV5OJs8HvAFs26a6uprXX38d13Fp9Bqpb6vHiBnoXTqxnWIIQ7Di/1bQX+6nsa6ReFUcb8ijmCqybs064iLO7Fmz2WbZNriDLutfWk/RKJJoToAun9Xs2bNDgjdd17EMC0PIPICH7H62LRvHdXA8BwKwdAsrbqFrOnfdrXPmWTLRrDBrpuCSi3wO+5CDHpfehi5GqKy1ESUkdGzTxjDlsXRLKuRisRgmPlVOYiw9tVN0ZFOeVmlFq23/85//4HkejY2NzJo1a9zvx5aiTgTV5atoqFXnuOpwDvtg0MPmvYou6s1AhTdV7kApwc1V5ESFNIx6/OreKeW+NT2JkGPJl/1IIR37BNep7puGFlYkTnQN0fzFpu6Zyg26rsu6deuYN2/euAKUtyLXppPP/0WUSqWwlFNBt6U1oZqHoLLME6Cnp4d169ZNyItUKBQYGBggn89PetzJ5kTbtk0sFquIcQ4PD7N27VoGBweBSqZPISQza7lc5vXXX+f3v/89f/3rXyuuRTM0ioUiWTfLUNdQKMhUj4RavEEgCQTVvjVDI9OUAWCodyhM3uV6cji+FJjFYpHe3l6Gh4cZHh5mYHAAR3dws66s8GrwEXPl4B7rOYtCqUC5VJYjOA1ZTmvGTPKlPF7Jo5QtYSTktDhDNxClUcEYzTUIIWQSeoQ9VA3sCYIAy5SKQCDwAz8s5zzyCMGaNXD//XDzzfCPvwe8/mrAx46RvErCleytnpCCxdTMsFQ1yjkU+KPJTqWwJxJumqZh2lIQqpkIUWseRmdp9Pf3VxQsRGkaNpdTC0eZBqPnE6XqDuvtRRCOJo026W0O0dxedP+bK0OdKEmsjqss7LGzLN4qVGjJMEcLAyZriFPRAZAMvxNNgZuoRHYyu/3tpsmYDiVtAhs3bsT3fVpaWt5yrmHsVLVwBm5sJC7s+JgJ+Zni/FcvhKqwKJfL43IKkwn9KFRyulgs0t7eTqlUIpPJEIvFaG1tJQgCent7EUKEZamKJmPFihWUy2VmzJiBruuh9/HEE09w/vnns2zZMhYvXkx9fb0kohMmQTmgN9tLUAxomdNCIpEgl8vR3d0dWpVqbkOhXGD16tVyyE9NAqEJBgcH6enrwdIscutzJOoSNKWacMsuhVIhtFBzuRyu5eIUHZJCznIWewq0NRp1K+tYs2AN5VKZeFlWehkYmLbJsBiWSnq4RLwtjh2zcXwHIzAqiPOgkvlT6COhJIGk4wgCaSXqhuyU9kaa02JyLKeuCfbbT0n5EQNgZPyn4RvhvGcv8NB9qZx8/MocAqNMrCqpGvXmouE9wzSwhSTyw6Bie5BJ5J6eHtLpdJjzGev1qbW5SataJ5xxrag71BoNCfA0ySxr6iaeP8qltLkQUbSxVHkw6hlMhQE12i0d3sNIiEtV973ZaW5jEQrzQMPzvTD8ONH+NU1StOBR4XWN3WYsw+1EecQoud7boRimPYZNQC34rWFhqG5UGDPq05RW9lhCvSgJnRLsm+qA3pR1EX3Ry2VZxlkqlSo8kFwuJ2v/I+cYBEH4uRoJqig1GhoaAFi7dm04byGfz+PpHhYW5XKZXDlHvi8fnv/w8HBFJZRpSYZU5QEk0gn0uE7ZKTPYOyjDIkLgleUzSNrJ8FpVjX7ZL1MWZfyiL+/jHvI+Vv+7GsMyKHkldCEb0nRNJx6Lgwm5fI7SUAnNkMlfxMjL5o72KqgxpepvzdDCklIgnOxmGqYsYTVlV7TrjLDE+pXPQxHqqRp4QzNkUluTdNqhpY8YjR8HVIQUouWSEzGWGpZs6CMA26osUQ6CgCVLltDc3Bz2sahwU9RSnZQGQl2HEmZBZYe8Cm+YphluE1UGm9vv2O2VMhlLorc5qz+kL6Gy3yHaULa1GuEUDEvmmNRY2MnOT5UZa5oWGgoTnX+UaWCiUvUK7+xt6IaeVgybwNYsWYXJrXvDNio6oKGSN2lTXkH0pZmsn0E1zqnmH+WNROc5q2uMvujK6oqWQSoBoqqX+vr6GB4eHi3fszRiCTlgp6yXKeaK0oplNH4chq5GVl9ItWDqpDIpAiEVkuZoWDEL35HnqqgxisUi6XQa27YpuSWpGEpyQpu7hxTK9ss2mUIGLaERs2IQQKAFVMWrsGyLodIQTs4hcALslI0WaPiaT22iNoxPRwWKEthKuBMQdj/r/x97fx5vWVrV9+PvPZ995vGONXf1AN0NEvGHiAxh+opBEsWghEQTO4lpQMBINAkS1BgJIGqURCMaIFGDUUMcMCJoaBDa0ILddDc9Vtdw53vPPO55//547vPcc+5QVT3z+/56+aoXdtUZ9tnDs5611mcwpuQyNAFfjFOxsE8/+GpRkIumrmGwK7Gh78pusKePJBd9XduThpDXSb5mf7sIUAmMBGXLub9XLxO8vKceTRtDEQCTPTmVab7NNJIqTfbsSuHqnqX97SSZHPYf39Uu7NPwVfn7L6uD9FhC293tG+aM4sChL73K5CA/Y5pdvf818n+fSGguPJMYLhtPdGI4UmnVOZzoJl87XTEcdoM8GkG96Z5rHMe0220uXbo0I7c9bc05XYpPY8Vd11WD7AsXLqjj0jQNy7XIGBlSLWUYDElGiRoEBkGgbDTz+Twke1DWOI0pVUpgQG/UgwhM9t6XMcU5GY/H5HI5TNMkCANiPVZDwKSWkN4sBPTm7pkj0gT6iQjQIJfNYTs243iMN/Hwez5O0RG8BF2uoqjfIh86uStT8teJWHyTeLets6s8Kn2BVXLd99BrmqZgyvI9tm6TcTLCGU7TZnbbEiM/zS+RCXaamb7/vogS0b6Z9puePobJZMLFixeVgq+6dleZHKblIPaTIZW5TiIEASUPZlqC+3IxvdBNH/d+7aSrXQzl5mn6ekpp+CdqQZXXbX8ihMNlOg4kh/jgeZYJ5qjWmUzKzySGpzgezS7namK/SJ4M3RG7xMME9WQZKeGihw2gH82cQUoqSDimvKmmq4fp757uY8oFw7aF2uny8jIgVFZn2hmuQc7JkSYpw3hIEiXkrTyFQgHLsiiVSszNzZHL57BNW31/mqaUq2VMy8SPfLHAjg0MyyCYBNj6nnCg9JTQdZ25uTks11LyBMnfFOexcmdFKLgmE4ggCiLcrEvOyZHJZvBDH6/tYTomlikkOVJn9zOmFrjp/ngUR2p3qHbr2p7IXir/bxfXPu1jIEMxY+M9n4VdIVkl0jedkOTiLqs+eT2mF4TpdoNqV+0a/5Aw8zpd1xkMBvi+z9bW1oH3Treujqwa9D39JHlupiVX5GelpDMe0lcbRyGI5PHth3Ne7hndX3FMVw3yeJ+IobRqsU2dMrmhOKztN11BJnFyYL4FB13bnioQ6TOJ4TLxRFcMEjWRyWRmd0LW7iIQzO6OJLx0ej5x2OJ/NRWD4ziUy2UqlYpKDNPwxOnEMK2Eun83Ih9MwzA4ceIEICoGGWmaojmaqAqsLLliDiNj4CTCm2GmxDaglC9RrVYVca5er7PYWGS+NE9iJBCKQWYYi11/pVihXC5jWRbZbJZqtUoml1HqlqQQfatY6ApfLpA1spATScEMTRqLDZYby1x73bXU5mrokWAOZ9wMjuZgZnd34cGepMI0skrKceuajqGJvnKappiWkMmQ/xvHorWVpoc7fGnWntaOXMCTKBGtqt2qQ35f6IcKISV3udP9fDjYZzZNUyQwXcxWbMueSWYSrup5Hs1mcwYTLxfSyw2hVSUpbQh2wQSO46gFWKJ1pL6SjGkhvKNCJpqjdsL7k8LVmN8oFNFUb366pSbnb481phFb09+5X05j+js0TVNDaGnmdFgcNVOSMZlMWF9fv6yj46OJZ1BJl4np3dkTEZqmHUqak+2FxE+gsPf305yDTCZzJM7cdV0WFxcvS603DINyuUySJPT7ffWbDksMtm2rVo3cYcmHSD5ctm1z5swZQKiszlQMhkEml2HemKder2OVLLwtjzRMZ7YicSLQRW7qMjCEhIaVsViYX2DUHglYaKrBGJJMQjJOKJfLTGKB6T927JhYwHSTcBJiZA1iPyZ6boSdtTGbJt+gfQOZv5Hh0hcukfopk2jC8vwyZt4k6AZMtiZE44hipUgSCYjlzM5vqjpQ98MupFTXxFCbhD3rTcMQyKRd6Yg4idHi3Yd/X4KV75F6T1EQiVmDqRMnsWiz7TrJ6YGO7diKvS6vybQnw7Rpj0LzyJU7EccbRGLzYFkWCwsLrK+vs729TaFQIJPJqKHn/vtsf1sRxG9WSKup9pcMOQSevnemq8Pp4308Ie89ufBeKaHJf5dtVVkNS1CG1KZ6TMe1i9iaQYtNyWlMD/env2Pa+/soH+lpHaj97aXRaEQURXS73Styn64mnkkMl4lpga4nO3RHJxoebQpULpePNFORCJqrCcld2A+pm8ZDa5pGo9EgjmO1EGWz2Rnp7DiO+bZv+zaWlpa47rrrZoaihmGgZ3TsQAx1DdvAyBjEnZiJOVG7s267izkxIbvXV9Z0MYjFEESyjJHBtVyypSzpMCVv5qkv1Wd61ZPRhE6/Q8EpqEUy/dYU7U81rM9b8Dch18gxvDCk1+kxV55j0p/gpZ7waOiF2BWbuB8TB7ttI91Qpjv74ZIgCFzKxnJXR0nThJ+Cru0m0mgPLhoGIbazl7jV70xRCUjxJBINwxJJTl6bMAjRDbH7lNdv2jtDQWr3LUhJkuxxI3aTg4RV1ut1ms0mQRCwtbXF0tLSDKJHhlxw97eZJN9iOjHIe2A6AUzDbWUlMo2sOuoZk++RjO+jnsP9C++0bPzlKg6ZPORnTyYTkiRRgI/HkrQOU1yV3yd1z6b1r6Y3c7qhK3MoVT1qewlXnjd5L07DWIvFIu12m9FoRLFYvOr14Kh4JjFcJiqVijJWf6JjP4Zct/UZVqkMKZE8LYP9WEPOFIrFoiI7gbjp6vU6S0tLM9+h67oyTlHInKmFJ0kSXvrSl+K67kxS0TSNcqnMeG2Ml3psbW1RK9dwdhwiTbhtFQoF0CEIAxqFBsVKkWw2i5maFPIF2q02w+6Qa2vXYpqmYBnrAdEgwi/5hGFIqVQSftDdNoPRADJQL9XxJz7RSyLsP7UxPmcQjkPMikn0cMRodYSbdRm0B2z0NrA9m2McwyqKhywch0gvX13TZxa1af2eRBOaRomWkAQJliEWkTAIIRXVkBYJVJWWaMRRTGzEqr0Cu8khQVVRuiYWhiTetfvUUgzEd8TR3vfLeZNcCLPZ7J4U9L4du0pqSQSxgNpOJ5LFxUVFaKxUKoolvX9BnB5IT1uJyoGrvC/kwiXVe9FQbTF5z+9f5C4nCCcr2SvJw8iFd1oi+ygy4GEhk55s9Uho9vRc52pipsVmHPw3eTyHiWKCSA4puy2llBkJDdmWkr9xejYkq/zRaES322V+fv6qj/mweGbG8BRHHMesrKwcbL9IRzd/tsfYbDZpNptKIvko8Szf92k2m0eKm8nXbG9vH5A1nh4cTi8IMinNqElODSVXVlbY2dlRD/z0oqIbOqmVcvHCRUEUJCZbzqL5mtqRaZogdw16A3q9HuPxWKjMGrDd3abVbRFqIfE4Rnd3Mej9kM31TTqdDlEUcenSJVqtFrEWMxlOMHIGmqkRvGBXmuFLOnd//m4evPggsR6T9BNavRbb3W1WV1dpjpoEk4BoHNHpdtjc3FQ7YF3XZxY9NQxOd20/d5OGdF2TyUTTdpPKrkeDYYlru3/AqemaWjilUqqCl8apkPbWhcy3ru2xxKdnC9JTQ9M0/tE/+kfqOE3T5MSJE/zQD/0QnU5HyVOgIXgduwthsVhUar79fl9d9xlwxO6CdBha6bCBq7xPJZ9B13TVO5fvO3PmDP/xP/5H4GiVVznUlp93pZC/6Uowz8NiukUq1W0fK5xVzpYOg6FOf9d0wplW0L2c4c80FHb/eZMdhclkctWS6kfFM4nhKY5pxdEZ457dm0G2D2RM8xk6nQ6XLl1SD/B0RFHEcDicgZ3uj2k70OkbSkJH99+oa2trauGXzGu5m5L2nZ///Od53/vex3333Xfg+6ysReiHTMYTxuMxbtVFSzQSb0rUTN8b1nmeh27o5HOCoyDhroEXCLE/OyUNUry2pxjY/X6f8XhMREQcxoRpiJWziOYj0pMpWqhRurMkYJOZFCMyGPaHFCoFDM0g1EJG8YhoEGHaplBQ3U0EuqnP2njuhpSuSEmVeU8civNpmHsJVgsCjDf9PfT/+3+VCN/M8FC2j0C0eSxdSXinTMF/TWuPDMcsO1ku1HLo+G3f9m2srq5y7tw5fu3Xfo0/+qM/4od/+IfFtddQ7Sst2asulpaWOHXqlBJSPGzzcVRyUAPXXbjlNDkNduVd5DzmkIpmmvx22OK/n9NwNSGH9IfpSR0V0xBW+Ue2JR81+ESikY9IDPL7po9LDpYVD+Qyng7TXKNp0IBM9CBkTx7PbPRpTQw/8RM/sVeS7v6R7mAgTthP/MRPsLS0hOu6vOxlL+Pee++d+Qzf9/mhH/oh6vU6uVyO173udaxOK5c9jvA8j/X1dXZ2dp6Qz5NxJT7DdEwnhmkjnf0xjUw66oaQN5SUulhdXaXb7VKtVrEsi36/r5KVfO3q6iqf+9zn+MIXvsDXvvY1Lly4wL333stdd93F+fPn+aVf+iXe/e5384lPfEKR3WRlsrK5QhIlRH5Er9dj6A0JUtEOmkwm4rfpYnC2ubnJhQsXhO6TPxIPhZbSm/TwU5+ti1t4GU/csQPwPX/WgUwTD+JwMMQqWaBD9GJRalfvqpL6KZEdoaPDCJycg5tx8X2fQTIg9mPFkJ7eDcsFfRpTrohFpq4sSCWqSDd1tdhb/+2/Yv7P/4nxIz+CZQlWbJrs6QaphVLbSwSGvWfYo2CvsgWR6jOzhOnFSy7Utm1Tr9dZWFjgVa96Fd/zPd/Dn/7pn6LrOq961at45794pzD4SYUsw9/9u3+Xf/bP/pny7Lj++ut573vfyy233EKhUODEiRNKplvudO+9915e/epXk81mqdVq/OCbf5DBYKAS4qtf/Wre+c53qoG1aZm84XvewC233EIURbzsZS/j4sWL/PAP/zCWZZHJZNA0jUuXLvEd3/EdVCoVcrkcN954I3/yJ3+iFtFHgxiS52y6wj3UnvOQ901XDrIFJqvnq61cpltsVxPTIBDFSJ9ODuHsZ02LKU4nmXK5jK7rhGF42U3iFY/nMb/zCYobb7yRjY0N9efuu+9W//b+97+fn/u5n+NDH/oQd9xxh7rZB4OBes073vEOPvGJT/Dxj3+cv/iLv2A4HPLa1772CaG7p6kgVj1REDAZRyUGwzEOCGxN6yZNy1rsv+H27+Yu993yd43HY5UIxuMxw+HwQN9SVipy2DkajdTwGPaE2R544AEGg4HYvUcR4/GYwWiA4zokQcJgMBDaRqYwJhp3x+K3GRq+5yuV2OFwyCSaiB2RDv1RHztrE/sxoS+GxJkkA7445kJBwLhixPUe9Uekls4D503uq4rfVvirIkZiEOohhm1QsSsUS0XyhTxhEDJiRBiFpEGqFm9AQS4twxLtnKmBpWEIYyJNE3pGGqJqUHh938f64AdInn0jfOlLaH/6KdE+0GaHuwrNg9h164Yu4MvyOPS94W4SCQ2m6X69hF/OtCJ2F4oHH3yQP/mTP5mZCaRpqioHucuXEFaZXP7Df/gPPO95z+PLX/4yb37zm7n11lu5//77AdGmkIv3F7/4Rf7H//gf/Nmf/Rlve8fbZmTJYW8h1w19Ririt3/7tzl27Bg/9VM/xcbGBuvr61iWxVvf+lZ83+dzn/scd999N+973/vI5/NPiGDctKje1XAWps+t1PeKIrGhuZq1ZVo25IqvPaQFpmCtGkeK7x2mx6TrOrVajUajcdW2rYfF054YTNNkYWFB/ZFQqzRN+YVf+AXe9a538V3f9V3cdNNNfOxjH2M8HvNbv/VbAPR6PX7913+dD37wg7zyla/kec97Hr/xG7/B3XffzWc+85nHfWzTQ9YnMo7SPpo27pk+Bvl6mRzkwr7/WK+WzyAXkv1l8v4Hb3pHKmN6aG6apoLfPvLII8Ae8UqGW3QhBm/iEQQBTs4BE4JeoFpJYRAqnwHPE/pFhWwBXdeZBBOxywcmvQlO3cGyLayRJVpCMjEkgjfwl1+IuP76gDfcYvOb53wCUpwVm8HtecIkJDET8CH1U7LFLKZuEqcx43SMHuqCAT3dm9b3kCb72xKSq6ClmnKaS5MUwzQw/ttHYXOT6L/+Fum3fAvpe95Dqu0qjk7fTvIjNVRf2rRNDMfA0HbZ07uoIk0TrnHyukkxwWldnU9+8pNUq1XK5TI33HADX/va1/ixH/uxGXRQkojKxrAM1Qqbbme88IUv5I1vfCNnz57lx37sx6jX63z2s58F4Dd/8zeZTCb8t//23/iGb/gGXvGKV/ChD32I3/jN32BrfUvdi/IcqQG0tsckl7vafD7PwsICi4uLqmJ40YtexI033sjp06d57Wtfy0te8pIZ2PhjfRane/OPpnqQFaKcicVxzHA4vCyZFA7nNFzNMUomM+xptQFKqvsoCY0wDNna2iKOY3K53ONKCvB1kBgeeughlpaWOH36NN/7vd+rFpjz58+zubnJq1/9avVax3F46Utfyhe/+EUAvvzlLxOG4cxrlpaWuOmmm9RrHk880QQ3GdPCdweIbrpGHBw9Z5BJYr98NxydcPZ/9zS2PI5jBoMBGxsb9Hq9mQclk8nswT/3QQ5lyL70NMltegG1c6IkDyZ7cwk9p5OGKfEkplQuUS1VcWxRyUwmEzAhm8sKK0kSxv5YkMb8mMAPyM3l0CKNuLfnA5AkCXferfNfflVnaytmdcdiy9e5pyzOpfe7Db72tYSQkDRJRWJyTDJOhmASkGTEbny38FC7acU3SFPlYzzdg080gR7R0JTCqh6FWD/7AeLvfgPJ9dcR/qt3od1xB+n//t/qs+XiJNstgKoSNE3AVXVTh3h35sGUWxt7aCm5QMnK8qUvfSl//dd/zRe+8AXe/OY386pXvYq3vvWtM/19xeTeHYprqYDnyp78tddey/r6urrHFhYW2N7eBuC+++7juc99Lvl8Xn3et3zLt5AkCfc/cP9MtQUc+H3TQ9f9G5G3ve1t/PRP/zQvetGLePe7381Xv/pV9VlHoaUeTexfeK+2egCxCXJdV32/FI28LONa37fJuIqQyWjaMlX9uYyERqfTYTKZsL29/YTwrp7WxPCCF7yA//pf/yuf+tSn+PCHP8zm5ibf8i3fQqvVUqbs+2FX8/Pz6t82NzexbfsApHT6NYeF7/tqcCn/HBZPNMFNxvTu5dB20j5kkjTgkbDVw94HVy+NMa1PPy0wtv8mlr1WicaZhhbKB+T06dMArK+vq/nGtJaNaZlkc1nScG8Rqy/WmVuawwgNqrUqbsbFsfeSmq6LIWwpXyKXy+H5nmLyToYTnKyDkTUwxgbD3pBcLkccw3/5mEU0WmAyyZKkGvdecnjolPjO56xW+Nz/0Qi1mFiLGTVHBONAsLJNh9J8SfT3d3PqAfQQgg0tEUGmaYrzke4N/xSq6Nf+C2xuwr96lxiwvurVJN/yLRg//dPEya7MRhTvyW7sqshiMIOCMhyhlKoj5haKJBczMwuRFYSmaeTzec6ePcvznvc8fv7nfx7f93nPe96j7jt5XeR3RLEg1Zm6qTYNjuMQxzGrq6uqLTlNgNy/OMtzJdFZ8vpPtzrCKFTvnx6cTrcu//E//sc89NBDvOlNb+Kee+7h+c9/Pr/0S7+kPutyrmZXG4e1ba627SyrnGkQx/726+wbxP8cpoN0pWOcHqDLkPfIYRIasgqT8z1ZfT/WeFoTw2te8xpe//rXc/PNN/PKV76ST37ykwB87GMfU6/ZfxMedmPujyu95r3vfS+lUkn9OX78+KGvmy6Jn+jkkM8L7aADPcJDBPVs26bRaLC8vHzkfEK+Th7vUaHrOo1Gg7m5uRkZhcMSg/zM6VbDfvz14uKikvi4dOmS+g4ZaZpSqpWYK8+Rz4kBp+M4ZKoZkiARO2xNxzIFoqJWqynfg5PHT/LcZz2X+bl5TG0XnhmEJHFCZbFCsVAk3AqpVCpsbJR56JyLrkMuI37D3ecd7poLSUg503OxVufpjRaZW56jWqpSckrML81z47U3Ui1XsQoWFofrBMlFWcFRpzgC6AivB9NECwO0970XvveNaDc8a9eHWYN/8x70O+5A+9NPkbDr1yBbBrvJQvbh5UKSJAmpsSvDEe4SnnYThYSzSmilrBKnYbWGYfCud72Ln//5n2d1dZVGo6E8MeT1vOeee/aufyTOu4Q99vt9Wq3W3rGkKc9+9rO58847Z4yhbr/9dlVpxGFMvV5nc3NTDUbjON4DjaR7EvRRFB2Qxjh16hS33norv/3bv83b3/52PvzhDx95Lz+emK4epu/nKz3nmqYpEUh5ro+qPB7LEPrA+6fuRWU0RLInobErt2LbNnNzc2iaIOq1Wq3HxXt62ltJ05HL5bj55pt56KGHFDpp/85/e3tbVRELCwsEQXAAlz/9msPiX/2rf0Wv11N/VlZWDn3d1ULdHkuUy2VqtdoBGQvDEQ/tNDpJ0zRyuZzazeVyOcrl8oFjsiyLEydOKEnso6JYLKqe/vR3HJYY8vk8+XyebDa7pzC6D3IoxfTOnTs3UzHIhbNUL7E8v4yt2eq7jIyBbumEg1CI2Y33+BJpKlijhVyBXC4n2lGYpHFKREQSJuQyOayaRTJKKOgFPO8kl9YbJKlGORdhmhF+qPOVlsm5itgRPvfiMsNhGcMysLM2GS1DtVLFzttEowjyYJmWGiZPY/M1XVP+EZIoCLs7znR3VpOC9pH/AhsbpP/yXwvm6y65i5e/gnS3akgSUWUY+h6iRO36p4T3FGLJ2G1jBWI2oOtiFpJEidpJw2ybS1aDL3/5y7nxxhv59//+3/Pyl7+cP/7jP+Z//+//zf3338+tt95Kt9sV113f+7Gu6yqr183NTXVfRFHE3/t7f49MJsP3f//3c8899/B//s//4W1vexv/4B/8AxaXBRDhJS9+CZ/85Cf55Cc/yf3338+b3/zmPUfA3VbT6dOn+eIXv8ja2hqrq6ukaco73vEOPvWpT3Hp0iXuuusubrvtNq6//voDc7AnSi5bVg/7uTtX8/mWZZHP52ccCaf/V33HETyPx3q8sFtpJZFC4sn7JZPJqBntcDg8shNyNfF1xXz2fZ/77ruPF7/4xZw+fZqFhQU+/elP87znPQ8QbYbbbruN973vfQB84zd+I5Zl8elPf5o3vOENgHBdu+eee3j/+99/5PdIsa8rhSzpFJrjKQg1ZPITDOcg01PTtCO1UPbjxI8KCRGUbGr5246qGHK5HPl8Ht/3yWazGIZBoVDAdQXc853vfCflcpmbbrppjwMwhVHXDV1IYnRjxQYdDocMggGmZ9LutBlEAzIFMdOIokjtjqM4IkgDTN2knq+Tq+dgBGZocvy644wujUh6CScWMySJgRcGnDm9QbKWYX19ma8+4nDvcsC1HZNv7ZmM6oGAAdo6ru0y8kYM9SH9Xp9QC7EMS/kY7Jd60E0dPdRVgpqeu+i6TjLxMN//72FpCT4uABLs7uhSXUMrl9H/+I/RP/2nJK/+NvRYV2zbREuIwgg7Y4vWUpyqJBCnov0lXd4kaSxNhByHrNjkcFYunnLh++Ef/mF+4Ad+gIcffpi77rqLW265BdM0ectb3sLLXvYyYBbYkCYpS0tL9PvC6U62SpIkwXEcPvWpT/H2t7+db/qmbyKbzfL617+en/u5nxOs3CTiH37fP+Tue+7m+77v+zBNk7e97W3qe+QC+VM/9VP84A/+IM95znPwfV99z1ve8hZWV1cpFou8+tWv5v3vf/8M23ra7+FqJLwfTUxX0LLiuhLbWp4zKQwoZWTkv03zPPa7tT2akNdymngXpZEgWiYpQScg42TIZrNK6mQavfmovy99qla8Q+Kd73wn3/Ed38GJEyfY3t7mp3/6p7ntttu4++67OXnyJO973/t473vfy0c+8hGuvfZafuZnfobPfvazPPDAAwqNcuutt/JHf/RHfPSjH6VarfLOd76TVqvFl7/85au+cR6PafbjCXkzTQ/EALwd0RvMNDIzr5UcAVkyPp7vHQ6HhGGoLDlXV1eVYurMbnhKYVRWC/LBnJ49jMdjBoMBtVqNTCajZhfys8adMZcevoRdtTl95jSdToder0c2yNJpdtDyGktnltQiUXWrJOOE86vnaXVbVNMqx5aOkWlk0B2d8coY5sEbe2SDLLGd8vLvTEgnOieWt7n3ksPa2jJRZPLWbxryi18qEJPS+csuPa1NEAZknSxBEtCMmvh9n4yToZFrMLbGnDp5imw+qxjpMuIoxpt4pFqqJBjiOBYEtMEY+zWvRGu3QdutFiRRDcTfaRrRBz9I8trvwEBIiqdaqlpkhmUIT+gkRbd01StO4gQLa4+hPoV60S2dmFjh7KUchdTikTMRuYAZhqGYsfLv5R8N0aoyTIOxN1YaSmqArM06qu2PNEmJArFgTetMaZowsUnjVKkJw94OXd4r+7kH03aectMg763LiUY+1thfkcgNzpVmGxI4MT1Ql+deRzC/D7PyfCwxfV583+fixYssZhfJ5XNk6kJpuN/vs7GxwQ033PCY1rWntWJYXV3ljW98I81mk0ajwTd/8zfzl3/5lwrp8qM/+qNMJhPe/OY30+l0eMELXsCf/umfqqQA8PM///OYpskb3vAGJpMJr3jFK/joRz/6hO8mnozY3NwkCIIDmGPdFoJ607MSTRMXWyYTKZk8jQ4BUXV1Oh10XVftgMOi3W4De0MrefNPPwByEQiCgG63qyqF/a0kXdeZTCaEYagG5PvPf6iF7LR3cCOXEydPkMlkBKHOED4LQShw4qPRSPxuU7RzwjhkOB6i6zqL3iJplGJWTNChs9ZBq2q4jsuw2+dfvr3DB34xh46DaSRks2N6vRK37VislQOWuzbeJ0Z0X94l0RIcyyGJEro7XbzQo57WiUqRIqElcaLkI9TvNYRERRAFat6iKq1CAf/zf4lmCo0k4l1GbySE7AzLwM7YaHGMqQmYaxIn6JaOZVsEkwBDM/baSbtVgwQLJGkiIKypmENIv/AkFJ8h9Yemr980Qm2aWCd7/DJRqAHsLtkuTVKymSynT5+e0eaRWj1HIYQkKVAS/3RdV6AEmSSndYQkHPQw3SR5/03rJE2j5KZbek9U7Be7kwn2SqJ8cvYQBIGam3iet+cdkeoHKtDHGtPVg5RDyTQypIMUb9vDqTsUi8XH1eV4WmcMH//4xxWaZW1tjd/7vd/j2c9+tvp3TdP4iZ/4CTY2NvA8j9tuu42bbrpp5jMymQy/9Eu/RKvVYjwe84d/+IdHDpO/3uIoeKnhCLZtGs7OAGQ/U2qvt1qtQ/kMnucxmUyOvDHkzS/hjrquk8vlFPppf8jEICsWKY0xHo8Zj8d0Oh1+/dd/nXe/+90Mh8NDPyPjZrAcC2/o7bGegciIsGyLaByp6gkgSMTvqlQqaLHGKBmJ7+p2GHaH2BUbv+/T3GkyCAcYlsHJ42P++Q/1KeRc8m5KNisGpIlt4b9CfF75L8pi55kKZ7dcIUcmzRClEYZlCPSMFH7bbdXsP7+WYyl/ZkmE0g19T2hwdw4htZMApaIqFz7D2JP3ThMxl7EdWyyo+4aWso0i9Znk+5IwQbOEomvohRi6oeYN07tcSc6a3qXvX9in4aUpe8Q6ElQyGAwGalNyudB0bcZsSFY5cqe//77cPwDef74PI3HBo2NCP5qQCWk/tPZq3uc4Dq7rzrjt+b4vHPXC+FHxGq4U6t7TdUzbJDMvpPlbF1tKJfixxtfVjOHrMaQscbVaVYvZExVHwUsl0S0O4j0bSEQSHI/H+L5PJpNhMpnMcBtgT0JYlpvT0rzTMRqNFHfh5MmTFAoFxX6W8ghJktDtdul0Opw/fx7f91lYWMC2bVzXVYPLMAx5z3veQxRF/P2///eZn59XOG95rHNzc2DBoDOgtdOiUCjgOI5ITDmd3lqP4SNDSmXR0ouiiHl7nkq5InrLRPRHfYHtt2H++DyWbuEPfSalCQuFBdiEa04E/NzPGnzp3oTtfsDp0xEveYnB+DMJ/B5k78jihi4TbYIf+hTNIsVcUbjC5TP4vo9p7UIZk3TPunP6+hhiEZc7abVQpgKdFMXCZtQ0TQFhjYQ2URInEO/JREsRvSRKlC1okiSK8ZxEifJykMksSRNMY0/TKQkTUjOFYHc4bQmF1ukFTbKaJddB3htS5TMIgr3kMwU9NQxDmcfs7OzQarWoVCosLy9f3q9AR/AvYlH5Se+DKIrQrD3V2sMS07SC7P6Q95pMLLJt83gWwMuFPI7pSksex/R/7w+Z+H3fV/dIaorzGAYhduaJa4FNzxV1U8ezPTqbHUb3jXBrh2/0ria+rlBJX48hH5wnY3dylNWnpgsPg/18hmmi2/T/Px3Tvdcr8RmSJGE0GhGGIUEQKEE6GXKuMZlMlFbMaDSi3+8ThqFKTGEYKmTS1772NZW8RqMRg8Fgr5/tCI/m1paAQMoKJc2kBFHAsCXmHqPRSCDNzD2ggKZreHhEfoQ3EWJ72XIWzdMYjoZkyhlBkjNSvOGIm64zecUr4PnPH2OaGs7/xyE8FqIHOoW/LKCjM47GeL6Hm3NxNZfYmL3GaZoqMtr+kOSwJN5bhOMkJkl3h83JHsNYN3SFICGZRbBEyS4KJk6VxpIU25O8AFk1SC4HuvijaULe2cBQWzw90WdmDNOVw3QSk33/aSSTru/5ekitHsnsLuRF+7bT6dDtdmdaP/tjf8UzPWsKokAhuPa/Z5rxe9hnT18H+W9PVtUwHfuH0NOD5qOqclnhZzJiIGzb9h5oYArs8YQfq2VgV2wCAlYeOhxteTXxTGK4QhyGaX+iYr/x+nTozkGlVVk2Tu+SPM87FEkEl2dAu66rdjXTD9dhv3OaECT7xft30XIudO7cOcbj8QxiA8TDVCgU0A2d0UAkI5kY4iQWu6hI7DLlopDqKURQLBXRUg1f80m8hCiOCL2QXDWHoRl4fY/UScm5OTBgkkywPZskTlSiswoWk/9HJKjSp0s4poMXe3gjj0w+g42NN/bUAqsGssnh8smShJdEYhcooaVKjnv3d0iYq/jQvYQBsyJ6YSCuv7T1lFpRSZwQh/HeAq/t7cSVw1y6S4IzdxfKUOxaJUFquj8+vchNm+QoNrQxC6HVTR3dFGTDer0OCDKjnCntV+qVMa0VJFss8n6I45gonIWEyvaNvFemd9vT53x6/vBUJIXDQh6T4hVcps00LbxoOZbwIB9P1AzjShanV4r9z2upVGL52DLF+SJG5rHPWZ9JDFeI6d7rk/HZR+omOfoMgUW+XlYK0/DC/ZXB5UhwMiS9X+7Q19bWjqTTSwY0cGC4CeKBlXMd2XLaz3dIkkRYR7oWgR8w6A7UwmVnbEqVEpViBTux1fvCVAjulaolobekeUJhNE7w+h5u0cXNuER+xLA/pDhXRAs0JtoE27TJhlnFitctnfD14tiz/zdLdpAlTsSDaVhi0R1sD/BiD03T8CNf7cjT6Ai1WtOYYfvatk2S7sJGd5mpaZoqXSJDF0NZOXeQi6FmiDmBFOGTHAeZHOIwVt8hZRamJbTREBpMKUKzKUkgQvk5yGQwvfBOQ5OniWgy6U+3c3RToJQWGguKz7K6ujqzQB6G35fzFnmPSPdAydzdzxdQ52OKU3NANkbf8zKYNhx6KmNaskIe45X8pgHQIIpFdTiZTFSnQL7/sawxauMz1TKWtq0LpxaOetsV45kZwxXiyZLFkCEVTH3fV719mDXumXZ0c11XtY9c12U0Gs0Mc+Vnwt7u/rBeqPT3laxNGYf9TtlikP3WaQE3+d5pzaTDYIRSfC9XyGF4Bv7IR2sID2xN0/Cbvthxe6KHbhhCKyiNUhr1BhvuBrlaDqNpkAQJ3sQjV8kJN7ZgQG+7x9K1S1x8+CLBOMA6bmFHNpqnwe4IxvpGC/8GH+d+h+qfV9n5OztkShlydo5tZ5ucmSObzWJplpBaTyHrZtFDHSM52FOXC7RUwrQcizgRu2Et1cQAd7dnIhd+QHASolmXvjgSOlCWY4mKwBDGPVEkCH1+6Kv2VRzEEAgZiyTahYUawic6iYVMh57q6J4YSkax4CFIBItsH6XpnnS3hI0GQaBeM03+ksluvjHPpdVLeJ7HysoKCwsLClIrWfLq/EhHwnAWphnHwkKVEGVXOh1ykZX3jO/7B5zYJEoKUOifJ2vWcFTIY5xe0K/EfZDQZKkGLN8zIyNzFXbCaZoyHo/Z3t6mXC4f+p2PR0jvmcRwhXgyKwYQF880zQOD7WnjHjO3d5kkE1nTNIbDIaPR6MCcQbZ+ZK/5sJvGNE0hP7GbOKY5CvtDVjbT+vTyoZUP8alTpwCRGObn55WE9v7zV6vVKFgFckZOfTaI3qhhG8TjGAeHRkPYfXobHrlcjm+48RvINrKsfGWFwWRAGAvcf6PewHANIj/C0iwWTiygjTSwhDlM2A/RTR0zZ5KtZBm/boxzv0Pxz4s8918+l0wlg9/0ueaGa2AIPb8nDIF6KTvbO4K9vGuiM+3hOx1RKCCuUjYj8AN0xI7bsPcSShImewPZfWbvcRyrIbShG+oeAMGdUP7Thq5sH5U2U4JoKZlC+ltCQ5VyqpYeeh9LlrpED+2/xw8bAsehSHytdotmszkzk5K7+elQYoTT5y7dVaJFyIwflnAP02baP/CWr5uucp6OkNBZeRxXWtSTeHeuk+wlh+kZCxx+7g+Lcrk842HzRMUzieEK8WRXDJdjYR9m3DN900npggNJRdOUHPZRIXHXimk8RVg7LKQEwHRP2rIs1TY6duwYpmkyHo9ZXV09wKGQD3o2m6VWrpEOhOyHRF1puoDZjoMx+GIxlEYlxOBkHRI/IV/P03u4R5REJF6CW3TJRBk0VyPoBpw4e4KgGRBPYrAgJKR/oU/9TB3LtXC+3yH92RT7XpvJnRP0/0csTAW3QGIlRDsRI2OEqZmYLRO36mIEYhdYvKZ46EPvTTxWHlzBSAzMgsmoOyLuxeSNPPPPnsetuYJ30vPY+uoWmFB9dhXDMshms4CoGjYubRAMAyqNCg4OmbmMsEhNU1rnW8TENE416Hf6dFY62BWbsl2GFMJuiNtw0TIaYS+k2+mKCiHVSPSETDFDpphRM6nRaIRpmooLE4ahuv6FQkEhmbLZLOVyWVWBcRzTvNjk9s/ezrNufhY33HADrVZLyVpUq1WOHz++B42dRATdAKfmqCp4MBjQXm9TLpQpLZXUeRyNRkqDSPqF5PN5Wq0WURRhGAaNRmNmo9NqtRgOhzMyHk9XTMOtQfye6TasjGgcEfQCKMD65rqCeJ88eVJVbY1G44oEPqks/GTEM4nhCjG9o3qqw3AMolGkWgv7Q9M0tbA8lnBdV5EFL1cxyNfKh1ZiteUOKQgCHMfh13/917nhhhs4fvy4QivJ45zpJTsafscn7sQU54tsbW2x09mh3+8TmREWFuFot71liJ12Yib0m33SbEoj36CYK5JECYZrUC1UsWs2ftMn9VPsis3Em5B4CV29SxqlDNYHlE+WMc+YxC+OMW8zMT9hEr44ZBgMsdoWpeUSmV6G3qhHZO4qqfZM8gt5wnaImZhYuYPw335fyGkkkwTDNqg2qqw11/ADn7Vza9SNOktLS2L362gMtgbol3SyS2IGIu+txROLdFe6lDIl0ijFSi2sjPi+hZML+C0fW7PxI8EOtyYWiZOQc3LYJZtoJ6L07BLkxVykF/VIEK2lYBBQLpZZOLXA+vo6uq4zGo0ol8tsb28rnkK1WuW6666j0+mwtbWlZFCmmbPZZ2X5p3P/lMRLsFKxYajVajSbTbrdrvJZ0HWd1EkxPAM91HGKYgM0Ho8xbZNRb0TjZAPd0On3+wwGA8Xsz2Qy6jszmQybm5tYlqXuQRnz8/MzM44ZBNdTHNMbNKm8mqYp+Xyecrm8N5dwUnRPx9AMbrzxRnWepenVNHwYBBLsMHLpkxnPJIYrhFRgfTJDQkH3t5QkszUOYkx371L5vs/Ozg6apimY6FFxOXaoHMz2ej1AlKXT4oOGYShBPtu2OX369AzUbhplomkaz3ve8xTBbmtrC8dxuOaaa9T3SxTSaDRitbWK2TIpzAmF2XwhjxmbZBeyuJoLHly6eImskSVv5Am0gK898DViK+am8k3Co7lhEocx/V4fLdUoZ8pM2hMmtoDRFvwCmVyGSUH8t9/0ses2wd8JMG8zcf7E4Z7vuYdu3GW5tEwn7LB5fpNSroTdsGnTRhtpxJZw0pqsTzDPHuz/6rpOqVaiu9UlHsfojk6umkMbagRewKg1IqgHuK5LppEh6ASMtkYYVSFNIZN7Pp8nc0q0tjRNIx7HWPldwlrWQB/qhD3BR8CGfrOPntVxUodMI0M4CBmvjcmdyFE+UabZajIejKlWq3iJR3O9iWu7NBoN1tbWFFR5fn6enZ0dLMtiMBjQ6XSoVqtiZ99u0+l0qFQqM7LdTs3Bb/l0V7vc+cid/NIv/xLvf//71UZhY2OD+fl5MagtmASdAKtkCYRTqUS/12cymDBoDyg1SmqgHAQB6+vrNBoNdb8YhkEmk6FcLh8496Zpks/nGQwGbG1tqdfPz88fyeF5KkJu2kajkWr5FgoFSqWSIKYVLIKuOCf7W0FBEPDAAw9w8uRJXNdVz2ev16NUKj0lCeIZVNLXQQyHw0NFr3RT9LX38xkkE1XCBTudDuvr6zNtoCiKWF1dZWVl5bJY6+FwqDRepLbL9L9LY3T53+PxmPX1dfr9vuqLyh2abdtKoE9q5Exr1Ut5gDRN6Xt9Op0O0SQSr7eEx7OWahiugWM5pJOUIA5Ik5RMNkMYCRapr/vE41gRqSb+hHFvTGiFEMPGpQ02OhuMwzHmRLjEBU5AHMaMtkZsvWiLJJNgrpoU7ysS+zHjyZjmRpNRPEJHJxgHhFbIxJ8wbA6xihZ+yxctqn0hlW+z5SzzjXlKZolcOUdCQtbJEk0iel3xcJcaJaySReRHhM1QPfTq2rrCvS0OYvrdvkKlaZqGXbZJwgQzMgkQxkfD/pDBaEAapbjzLkE3IOyHoEOQCfDxmQwnmImJZms0N5swQPlfTCYTxuMxz3nOczh27BiO4yiPczlX6vf7B45T0zRiN6Y76vKP/8k/5vd///f5F//iXzA3N6dmT1Ld08yKaxANxL1gGAalsvC/aG8J03rXdVlaWhLIriRha2tLGdrLdlGz2VT3svSYBlRlIZE9URQpuZmnK2TbS8rSp2lKv99nbW2NXq+H7uoz52Q6VlZWGI1GfO1rX2NlZUUlkziOabfbrK6u0u/3n1Q01jOJ4esgLgcvPcy4R2rJg0BkDIdDgiCYGUJPa8oc5QGtaZraVcmF/WpC6r1HUYTv+/R6PUajEffccw+33norb3vb29Ru7zCJjGKxKJjDSUR3uyugs7suaXEYE8YhmXIGPCGNkSQJJibZQhYt1miHbVqDFq2dlhrCdre7rG+to7kaeiiS0sSaCERMqAkTnHyKkRhgw+hlQi6j9tkadmozCSYYsYFu6wRJQNWtsnxqmTgT43d90nxKGgktmv0htaHcrItZNnENl4yVIVfJYTs2cRhz6cFLhGFIvpLHLopk63d8Ru3RgetulSxa/RY72zu0t9p719QxMLMmruZSKBawHItJb8KECeEoxK7aGI6Bt+WhxRpLy0uQgzFjsmaWaBQRGAGj/oiaVWOuLhbx8XjMaDRSDPjRaMRdd92lmPDj8Zhut3tg/mSaJnpJ59/9m3+HaZj8wR/8Af/23/5b5ubmsG1b+X9ruoZVsIhGkTKXKRaLmK6JN/bod/vq8xYXF1V7UwrBSWi19B9vt9u0Wi0Fr7YsS4E4XNdVaLvNzc3HZVbzRITjOCwsLDA/P6+SXrfbJSXFzJsz50TGmTNnVDW/vb3N+fPnyWazVKvVAwniShajjzWeSQxXCN/32dzcpNlsPmnfMe0ItZ+0ozv6ARNw2GvLTLciJMMYZhnQR+2cwjBkfX1dOXUlSUK73Z5h5na7XbrdLkEQcNddd/FXf/VXrKyscP78ec6dO8eFCxe4++67uXjxIl/+8pf5lV/5FT760Y+SzWYZDodcvHiRlZUVtra26PV6dDod0jQVZDdbp7PTQdcEWWziTVhfW+eRRx5hq7slTHFCTUhBBAnlahliGHgD/MRn2B2imYKUZWomkR8R2zH5bF5UAYzBAGuy6ycdCYExW7MZfptIWIXPFLCxBZkwFBDQcTIm9mIszcKuiIV9OBhi5kz8pk80md3laZqmoMaTYIJdsnFiB83S8D2hLRWMAi4+clG0zep5HNcREgmDkE5z1k/EcAwKtQJplNLabM0sblbZQks1arkahXqBnJ1Dz+g0201iP8ZpOCRhgrfjUS1XOXbsGNXjVaJshKu5RP0Iu2qTJikL7gL1cp1ischoJLSo6vW6Yqy32221YRgMBgeqBsdxqFQqvPAVL+Q9/1K4xH3gAx/gV3/1V9XOfXt7W+hqJWNSUqL+XtVQX6ijaRqtrdaM7EStVmNubk61lgzDUOQ6KSSpacKQRlYRst3reR61Wk0x+7e2tmZMhZ6ucF2XxcVF6vW6mjdYBQs0GDfHM691HIfrr7+es2fPYlkWQRDw0EMPsbGxwdzcHLVaTelPPVntsmcSwxVCYrSfrMwMs1afBwT17IPGPTArjyETw3g8nikvr0R0k5BW6fssbU73J4Zer4dhGDPifHL3Foah6qFWKhVs22Y0GrG+vk4YhozHY9rtNpPJRBkjxXFMpVJBt3W6gy7xJBbKlFHAcDhkOBzS6rZwCg5MwE984iCmOldFQyMIA1IrJRgHSvPHMA1iLyYIA0r1EmmQ4ns+WkHDSiyYiPOjOzqZWobJ8ydECxF6X2f+r+aJoxgi0GOdcTgmSiP0QCdbzeInPl7TQ6+IJH1Y1aASw0Ts4AfegPFwTCFfoOAWCOOQ9mabbrdLsVFEz+4K7vkpvc0egT973atLVfKFPOEwZHtzWy2cuqFjFS3sxMbO2jiWgxZrBGnA2sU1jLyBmTeJJzFBJ2B+fl7wT5yY3EKOulMnbaVkGhk0U2Mpv8RSQ8yRpGObbdti8G6aFItFtQifO3fuQLuzVCqRyWR40y1v4p98/z8B4Ed+5Ee4/fbb1bzh4Ycfpt1p0/W6+H1f7ZALxQJOziEchwd29tlslqWlJer1OplMhlwuR6lUUogqmQhGoxGtVgvLsnBdV+lBzc/Pk81mSdOUnZ2dp71ygL0NhDx2TddI7ISd1R3WV9cPHGO9Xue5z32umvt1Oh12dnYoFAocO3ZMXVsZ29vbT1iL6ZnEcIV4MiUxpuOoRVwZ9xySGCRsdFrsa/r9V6oYNE04w0k/BRmHQVZl8pIMVhCLoERsSYMSSXT76le/Si6XQ9d19dnT57BSqaAbOkEcMOwOBdrE0BRbOAxDMpUMxBD6IUmQUCqX0C1dLKIWkAoPaMu0BAvZS5hMJuRqORzbwR/4hEaI4zrovi4E7qKIbDWLVtXov1a0MOZ/fx4yAv2EJ/yJYzsm8RL6vT6pm5Ihg23ZGK5B0AqIvYNyJdOVn12xyWVzaGgYnoFmaUSTiI3VDRISCrUC5UKZXCaHYzr4nX3X3dBYOLOAHguY6zQr3SyYwvc6MER1YRdIzZTtzW16vR520UY3daJxBBNxrpMkoR/3ySxniAYRo4sj7JqNntExJybVXFVJTszPz5PL5ajXRTVRKpXUtd/c3GRzc3MGcSYhpD/27h/jO779OwjDkFtuuYXt7W0FgR0MBgR6QLvTZrgzVO+dX5pnvjKPax8UfJODZRnZbJbBYIDneQwGA9VuGQ6HdDod1dOXZMxGo0GxWCSXy12VMdfTEYkjuCt+V3QmJEJJhmmanD59mhtvvJFaraaQS9NtYNibFckWU6/Xe1zcq2cSwxXiaU8MmnaobtK0nIaEFAIzZfO03MZRx5/P5xmNRjSbTbVjOeq1ktk6LdI3LS8skUsAd911lyLiST2Y6TaZdIbTbI32Tlu4T+Wy1Mt1SiWBUskWsmALLHyapmSsDI4rdsiRHqGZGpPhRAmUEe2SwUjJV/JigDvqo7s6lXKFmlPDsiyxq3Q1Bm8YkBop7t0uhY0CQRLgxi6GZjCJJ6BDzsih5UXi83u+GABHCZPNyYHzI+1aK5UKlWoFq2gxjsfosU61UKVSqeCEjmCrLpQplooUsgXm5ufQQ0HGm7knyo6AY/bELEd6aGiahlN1KGaLNOoNslaWQqVAPpdn3B5j5IVtqm6Iz9QiTbXxkkxC7kSO7k6XC1+5gFWysPIW+lgnGSS4rkupVGJhYUH1s03TFIzwXdSSlHOQYZom9XodwzD4wM99gBe98EU869pnsVRdUuiibDaLH/gkdkJrrUWnJVqKbskV3hDjg0PY/dHr9RQCqdvtYlnWTIvpsAF5tVqlXq/PEPyeLo2lw6JYLLJwaoGMllFSGRsbGwcSRKFQ4Nprr1XIsDiOufvuuzl//jxxHJPJZKjVasoDvNPpsLa29piP65nEcIV4qhLD5Xb3cgC9/xjy+TyFQkEtsoAyugFmdGeOGkBL5Ml+W8OjjlGWrvI9sgcsGdbTiSGTyVAqCfE1iVKajrm5OerzdWzTBl+wovNOXunkGIZBtpoll82RBAlpkHLq9CmONY5RqVbQTA1v4glnMFJs0yb1hFRAea6M7dhCYE9PsbIWaZQKJrTUNbomYfJiscCf/tRpTj/3NAW3QNksUygWKMwVcDSHVE9JMynj9phETzCyBkEnODBryGazYnaiC0imW3DR87poK7XGWCULUzNJvITWoIWeEeS9NEgxcyZBb7YS0TSNwlKBklMiHIbKdU/eE7lqDj0RQn71Yp1CtUA8jun2u+BCf9gXCWIsRPCk17dZNgkKYgi9fs86Zs4kU8tQsAsYI4PJeEIulxP2q4MBa2trisVeLBYP7OSjKFK/vdFo8Ief/EM+9UefomgW0T1dvcdxHIycARp0N7tsb2+L+8YVjPcgCGbmZPujXhebhkqlQiaTUTOQarUK7OkFyRaoRMRNQzubzSYbGxtPK2Jpfzglh1KlxFx+bqYlubOzc+S602q1mEwmbG1tceedd9JsNsnn8ywvL1Or1ZTqwWONZ3gMV4insmKYm5s7tOTVnV0v3jBFs/ducimPIY9P7oblIj09FD0K96xpGoVCYWaQdaWKIY5jHMdRXAaZJGzb5syZM4BIDIZh4Lquetj336j1ep1arUbcjYlGkZin6Cmpn4IjXj9/bB5vyyPoBiRBwqmzpxhnx+g5nUc6j6g207GFY/ieT98T0uHLy8sYiUHUi0g1oXZqFS3BODVRxLL4lhg+C6U/LpH7+RzuCZdG2KByvCL0jQYxeS3PsDOkt9ljcHHA3MIchDBeH1O85nDLRDlE9X2fsTkm6ARoHY2TCycZ9oboBR2zZDLqjOjv9JnLztGb9Ii2IgrLBSWZYZUt8sU8mq9RnavOiqWVLKJJRDyIicYRteUa2w9s09vp0bf7+AOfWI8p58rktTxja0y/32d+fp7FM4usJqt0d7o4DzlUz1SpnqoSPRLhd316vvDEaLVadLtdlpaWcByHIAgYjUYsLCyoxWd9fR3HcahWZ4/P63hsX9jmE5/+BK/5O6+hWq1Sq9Xo2l16Gz0mowlpLcXMmnTaHfrDPlbGYmlp6VBGr67r1Go1stkszWZTwVKz2axqIQHs7OwwmQgF01qtpt4v1UyjKGJjY0NsRKYS3NMVmq6Je7MTUJ2vKpthOS8B8UxKIimgYMEXL14kCALOnTvHzs4Op06dolAokM/nHxcr+pmK4QrxVCUGSYg59IGwd/v4/tElsCS7yZJeRq1WUzuIo2JaXROOrhgkPyEIAnK5nGgF7fY65Q5fzhiCIFClsJJHiGZ32HJuYeQMYU+5axzT6/aE7efurs4sCo2mcBSiGcKrQk90nKyQEwn9UDxcpkXWztKoNUT/+tg8tbkaRmSQRimTaMJOe4fmpSYZR2jl23/bJjoeoY00kv+a4BQdkiChv9YXbNP5Ajkzh5W1SMyEYBiIBSxvEfUjwsFsJSbx6pubm9i2TalUonqySpzG+Js+q51VJt4EV3dxSg4jT6CBti5t4Wke/VFfMLiTPTMYu27j6i66N/u4arqGUTQYjAY0LzZxsy5uyUXzxIDezJn0u31a4xaWZsF4dzi+24+uLFZw6g7NZpPhypA0SFm4bgErY2GMDKzEUtWBhD5LfSQpgSF9pieTCWtrawrVlqYpsR3zkU98hHf82Dt40/e+SWk3lefLVGtVKk5FzC4cXbRCAxQU83Lhui7Ly8vk83mCIOD8+fNsb2+rf8/lcsqDfPqek4RNydpvNpuKK/F0h5kzxfysG6gW2bSFsTTWmm4x1Wo1nvvc57K4uIimCevfu+++mwsXLpCm6eNSRXgmMVwhpIbQtLfA03EMuq0f4DPAHmrqsaIuJLlIkmjk3x0Wruviuq5qXZXLZSWPUS6XKZfLnDx5ki996Uusr6+rGzsMQ9rttiI8TYfv+3RHXQbjAQTQG/YYDUfKEhEgNVNCQsJBSBzEdCddzl84T7leZr42j2VbQsTO0Mna2RnlUqtoCVmIQCiapvmUYBLgtcT5MnMm/neL7zF/02RzZZOd1g7NC01a6y0SK0EzNQrZAk7BIY5ihv0hoRaiWRqT9YMWqr1eT+g+jcdUKhVyxRwLJxfQQo3ORofIjGhvttF0jVw1RxqkxMRovkZoh3hjD7+1Z95kFwQ/we/6JIHwKlAY/qxFYAVE44jRzojaUg0jNbB1GztvY9om3tCjE3aIx2KgfuHCBdUaytayGEWDdqeN3/IJeyHz185j5k2ySZZatkapVCJJElqtlvLqloTMbDbL8vKygk/3+31WVlY4d+4c29vbvOrbXkWxUOSv/vqv+M7XfafgLGjg6R6Jl5AEAnoam7EgNPqiIrkSxFTXdQX9dBxHSXokSUKn01GmUt1u98D75ubmFDJIJvH9m5anOiSBMfbjQ+ct8vimZxCTyURtxm6++eYZ1NbjZUY/00q6Qui6rnbBT3bIm1uKkc0ch6MTDQ/eMMPhkFarheM4CrEgdd4lpFWWoftlkeV3zs/Pq1bSdBlvGIb6TBDD1Re84AUzshi+74vFbxfdJFtLmia8I44fP04YhgrJ0mg0ZqoX3/dZWVkhHIVcf+J6Tp44iZ2xydfySs11fX2dOI3Je3miUcRac43NRzYZhSPOVs+ioTHxJwwGA2zNxswLjHiz2WQ4HGLHNtbEIpfJYTkWYS5k0p2IZKOH6G/Uyf7HLMa9BpM7JvQWeqStlJ7XY/nGZRzdgRiyhSxplBInMb1ej0a9QdAOCNpCJA72IIm9Xo/BYEAul2NpaYlarobf89FiDd/3cTSHznoHsjAajkjdlKJRJNZiRtoI27MJuyF2xUZ3dIycgON6LY9m2CRJEprNJo1Gg9x8jmF/SH+lT+4bc5RrZdr9Nm7ZZe6aOTbObZBoCb7mE21FZOoZkiRhOBxSLpeJwgi/49Mf9ilqRYzQYP7kPJsrmxQnRezEpqcJ4cL19XV1j66vr5PL5bAsSynqttttBVP2fZ/l5WV+/w9+n2//9m/n87d/nu/6O9/Fx/7bxwiiAG2gYWwbFI8V6Qd9dE1n1B8RuIG6f67UDpmbm8OyLHq9Hq1WS6HgdF1X7HwJZpChaZqCVrdaLXzfZ2tri6WlpadFE02GkTEwMgZhL8RwZ1Vay+UyuVyOXq+n1Aomk4mqSnO5nBI0lITAxxPPVAxfR5EkiVpQ9u9CDccQ+vbhbNUgd2pS5XQwGLCxsSGsMXdjZWWFjY2NQwfQ0txdtgqm5X8l8ml67iH/Xb5HYqelztP0gFrTNKVz4ziO8m+Yxl5ns1kh75GKxSTn5nAMR/lEyAVCy2jEWkzQDihXymi6xmQ0ITGEz0GKSFJ+6DPujNneEDvqXq/HzmCHSTIh6Adk7IwQ8dN9Rtsj+p0+0XyE92pRQSz/3jJje0wSJQS9gN5qj/a4LfgRxRKNuYYgwY3GBGGAkRVM4+nrIislKSSoaRp23mbpxBI5N0cySQjTkG6rCzrYjs2wNySIA7SJRqRFhHZIOBRVkqZpWDlLVI1hQjlTBlA74mKxCBUIRgHetodbcankKtQqNTKFDAtLC7i4uBWXRE+wAxvbEmCHfr9PsVTELokEpBkaaZwSt2Macw0Wr1tkvjZPXstjpIby5uj1esosZ/peXFpaolqtUi6XyecFkODaa6/lf/2v/4XjOPzZbX/G9//97xekzWxKe6vNuDdmYXGBTDFD3sgzmUzY3t5mfX39Kp4aMS+Ss4KLFy+qtuZ4PKbZbB6JzpFJ23EcarXa05oUZEjU22FSGbLFdOzYMaWXFASB4pZomka9Xn9cPgwynkkMX0dxWavPXXnq/XOGaTepabKb7/uqR385D+hcLqdkBIIgOBK9NB1Sfz4MQ9VjbrVatFotRqMRt99+O694xSt47Wtfq94j9Wz2Jz3TNCkUChiWQX/Ux9ZtdE2fORY5hIszMeEgJOfmhPTDyGN7uM3azhoRERiCgzDqjxi1R8o1LoojIkewp+1o91wYvlAuHQinOP8fiXNTuq1EsV9kpI3wQ5+wHcJQ+FKTgmmbuHkXA4N2sy1aVbukt2k02H5JEN0U6qIJwpPBH/lEaYQRGhQbRTRfozloinZXlDIMh5h5k6AbiMF8VuwgzYyJGZhUSgLDL9E3VsEizaQMN4egiXtJVpgS2lrL1bjm5mto1BvUnD1oo+/7LC4vMndmTqj4asJ/Ih0IIEBhuUClViGrZTk5d5L5+Xny+Tzr6+sHWjUSuXTs2DHOnDmjdJNuuukmPvKRj2DbNn/2uT/j7W99O7ZlC/7FhW3CMGTu5BzlQplqoUocx6ytrbG2tnZV6Bo5lJbzg0wmQ6VSYTgc8tBDDymBvf0hZTimxStHo4MyJU9V6JaOlbcI++EBqQwZ0kvl2LFjqoUrQ0JVpWfKYz6Ox/zO/z+K7e3tp6QPuZ+bMPNvuhi6HjZnmJbHMAxD7RhkT/9yUFh5Y62trfHwww+zurqqdiCygpmeDZw7d47bbruNe+65hwcffJBWq8XOzo4ael24cIHV1VX+/M//nM985jNK06bdbqtKZj/eXLbNen6PVrNFu9tmZ2uHixcvAnss7zCzmyhiR1iEBoFgQSPmBoZjEKfCQCj1U8WtiKIIbEjshLSbqkSql4TRjd/x0W7S8L7FQ0s1TnzihFhkoyGjaES8ExNMAnRLwEszmQyeL3rYwUQoZAbdgHi09yDKHayUXgahkOpkHPLZvOiL+2LQ3phr4DouhNAZdkhHqdChMnwxA2n7Snpd/nFCRyXbZrMp2oQF0aYKOoFoPY6EM1yz3aQX9DBDk3wuj9twSfwEIzTodrtKDkM3dTKNjCIZWkWLcBAStAIylYyQtQhSTlZPks0IyZP/+3//Lw888MCBayori0ajAYhn6Oabb+Y//+f/jOM4fPMLvpmiXsTKCBjx1sUtojTCLbgsVhaZn5+nWCwe0AA7KiTRTm50CoUCp06dUsztc+fOsba2dsU5YRiGCtL6dA2mrZKQygg7l9+kGYZBuVyeSWqSzyFJbo81nkkMVxFyuPtkubhNx+UW8cOIbrCXGOQDJFsZo5HYNR/lKz39nRJttL29rQZ/cpA33ZYClDub/D6Jd5eL/tLSkiA0+T733nsv4/FYCar1er0DD5zEuYdJSLPXxBt7TEYT9R4F29MhtVMYQTafJSUViCRTwxt6mBlT+BPrBvgQjkOVbKMoIs7HxH6MFYl+c5RE6GWx2EdxhPcPxO+Z++QcbuiSJil9o4+HR7wVqx1cGIa4OZdCrkA6STGyApvv7XhKDVUizOI4VnDdbDFLuVYmTVK8kccknBDFEf7IZ35uHidxsAs2sRfjmi75fB67ssu2bgfC0c+LscoWsR+Tt/JqEzAej4mNmNAIicKI2BeOcMFALKyBEdAb9vA7PkZGGAp1t7o4ukOrJdzY4jgm0RI6cYd2q00SJEJ7KUoIm6HgZjTE7z5VO4WZmgwGA/76r/+a22+//cB9AijilYREv+QlL+Ezn/kMb/qBN9H1u+DteloPYrY2tjByhkg+yyc5c+YMpVJpBl1zuWdQJgcpH1+tVvmmb/omjh8/rqrxK7WL9m+s1tfXn/LqQdM17IpNNIkOcGWuFLL1m6bpAfmSRxPPJIariKey93g5fSPd0Unjg3MGtaPeNRWXfs5pmorh6z4PaBlBEChJDQk9lcnkqJCQ1SiKBNR0SipDuoNN8xnuu+8+ADUrkMc5vQt0HEdIYuga42iMZVhoCPis53lqcdc0jSSToIUaOTuHZmmEXijY0WFEGqUYriGUKzWTdJyqxBKGYtBsZA2MoUGpKIhSbt6FAkRBRPSNEf71Prqvc+JTJ9AtnXAcMslNSDKJENDzIxzDwbEcMMDzPaJhhFW0iLyIoL3ns53P52cgyLotiG/5Sh491fFTH8Mx0CIN27I5Vj5GLpvDdEycxFFyI07NERXAOBIEuFSgqaJeRLVSxXEcgRKrlylWiljubksyTEnGCY2GgO/6hk+v2SMaRXT9LmbGxIosCrkCpmmys7PDaDQiJsYzPfqdPvEoJjOXoVApUDbKYhBNj1KtxJmFM8wX50kTAW644447BFBgXwujUChQq9W44YYbOHnyJDfeeKO4XzSPB9Ye4Mf//Y/T2+5RNIqChW3qYh6UyVCtVtWgPI5jVldXVRI7LDRNm/FtcByHM2fO8KxnPUtVLzAL9Jh5xnbRTtPy4RsbG7RaraeUMW1mTYyMIFLuF9C8XEhOx8LCgtowPpZ4JjFcRTxVXAa4vIyF4YgFZn87Sdd1tejK3alsM8jBsITbTs8Qtre3WVlZwfM8VXJfqTKSSBE5tAaUobzv+8p799prrwXgnnvumTlO13Wp1Woz5a9EiViWRaIJZNNSdYlrrrlm5nsBIkPMEpzUwXZtwiAUC68G/sjHzJukpmBB40EwCVQ7KYoitLKGHulktazyjtBsjTgfQwKD7xG7rON/cBzbtCllSpiWidbQMEpCjynuix09wCSd0Gv2SLUUwzYIh6EaHFYqlQOkRdM1qVfq2HmbcBCy2d9kwED4APsJJaNE7XgNS7OIJ3uy6U7dwcyZgiHcCbDLNuii3TA/P0+j0RDM4LkSxGBXbDRT2HyasSmSg60xiSd01joYmoFZMsm6WepOHV3TlTAiCP/oQTJg1B0RDSKcukN1uYqruWh9jda4hVNxWGgs8MIbX0ghWyCKIr72ta9x/vz5A7vVcrmsrCgrlQrHjx+n0Wjwk//+J/nt3/9tfuBHf4DVr60SDAK0rDApSgLBxt/Y2KDZbNJsNlWSWF1dFfLVV3gmpVeJ7L1L45zV1VVarZZide//HCniJ1uCg8GA9fX1p7S1ZFdsSCDsXXnutz8ymczjsjp9JjE8ingqbgq5C9d1/cAgWNM1dOvwdlK5XJ7Rsp9mPkZRdGAAHcexmpnYtk25XFatj8vJBbiuq45Nfr6EAk7LXtxwww0A3HvvveLYd5PrYfaMAAsLC5w5c4a5xTlMx8Rm96HYPQe5XI5Go0FjqSEW12yd66+7nlMnT1EtVdFNHX/kY+gGVlkI2umBjhmJ8ykTZWIlGBkDv+mTRMlegnLBrtuELwmJF2OsjsX1d13P0sIS1UIVTddw5h3sOXEe00GKERqMxiM2OhvsbOyIllKKGBwGhydXI2ugo3PszDFyTg6v59GLewzNIcPxEG/DIyFhEk3wOp7iBMRxLJJD0cTbEVWKXRFtp2SSqPNpZoXvdhzGZBq7CrybApRQqVQgJ1p/yUC8J3AEUquWEcl6OBzS6/VEpZMx6EU9Jt0J0UBURY1rGpiWSetii431DUpLJXLFHMv5ZfJ2Ht/zufvuu5XZz2Eh5R5KpRI/+7M/S6VS4c577+QNb30Df/WZv+LCpQs8fOlhmmtNdF1XrSTP86hWq6pV0u12L2taI5NqmqasrKyoeZesjCaTCVEUKeTS/gpCyn1LlrfU/nqqQjeFkm44DA+INj7p3/2UftszcVWxuLjI8ePHDzXOMRzj0EVHQkLljatpGgsLCywvL2NZFoVCgWq1qhZCmSCkpWI+n1cPXRRFRyZBx3GUFrx8TZIkMxaoaZpy8803A3D33XfPvHa6HJ/xgd6VkCiXy5iuKeCM4V6Fo8xYLMFRMDSDRq7B3LE5smYWI2dgYtIoNqgfq2MXbUzdJJNkaNQaLC8vs7S0RLlaxqk5xH5Md71Lp9NhcXFRzEUWslhFi8n3iqrr2G8dY35unkquQqFQYDgZklvM4cw7kIIVWWTiDLEe02v3GE/G6JZOEieCoLbbAgjDUPlQ6LZw7sraWerH6lQzVbyRx/pwna7Rpb/TZ/v+bYbpUJD5toTs+blz5wSb9VgWwzYYb45Jo12NpU6gZhvtbptmr8mFBy5gZA3ceZdwEOJte+IalYUn9Lg3xkosNEPDt3z0SCdv5JVKbDabFQNtR2NrtMWkMyEaRhiOwfINy5TrZdJJyub5TUaMsCoWy7VlnERwPh5++GHFYJZOg/JeaTabykvhm77pm/jc5z7H3Nwc9z18H9/zlu/hq5//KoPhgEcefISHH3h4hl0/GAyExtYuw18ypQ8bLMuZg2zpSQFAOUeQ97JsjbZarRnwxfSztbS0NIP+8TyhePtkay6ZBeHo57f9R9VSerzxTGK4iniq8c2SIHZY6BkhmiYXgsvFtKF4LpdTImqwN6iWicK27Zl21FHtJMlLgL1FfnqoJ/vrN998M4VCgWuuuUYNs6U/NKCQEwdgubouXNSigJXzKzz88MMHjyFroJka0UgorILwBagUKyRjsRN2F1zcvEtOz2FF1oxFqVW0MByD5kZT8Ad2H27DNXAqDsF3ByTVBO2ChvkHJsP2kHMPCy8CL/TILmeFtLWm42gORa1IEgtd/VRPhc5+lIj+cJqyublJr9djPB4LbodrEE9ils8uU5uvkYmFpHeQDRjoA9JmStgN8TWfufwcGhqdToeHH36YJE3IzO1Kk3R3FyUNNdvIZDL0gz6j/oi1S2vYVRu7YuNtegS9QHAMGmVqizVyWo40ThmHQpFV8zQaJaGG2ul0BPktimgP21zYvkB/q080jtANneu+4Tqqx6rYhk3QDph4E5pek+PHj1NxK7ia+AwJY5ZyGWmaql6/5GHcdNNNfPGLX+Saa65hbXONW991K6vnVzESg+ZKU8lA9Ho9giCg1WqRy+U4duyYMq3ZT+qSSUJuOEqlEvl8nn6/z3A4pFgsKi6O3DTJRHMY+nD/4Lrb7SqbW6nb9GSEpmnYVVE9B52nTvjvmcTw/2Nh2IfPGUDMJZrN5gF0iNTvmV7s5SxiutffaDSUrtLlbvRyuUw2m0XXdSqVCgsLC8rpq1KpUKvVmJ+f5+LFi9x+++0UCgUFEZX6/J7nEcfxDBR2NBqxtbVFt98VFpTdvXIfREus2+0y9IdiYW83eeBrD7C2s4at2ZQqJeJhTBqnGBlDwTL9po8/2eN1GI6BVbTIWlmiYbRHENI1zKJJnIkZ/APxd/r7ddrbbYzIYDAYCHatrZO/Jo+u6diWTbUmCF3JMKG1KexGjYxBNI6IhtGMVSWIOUMSJViaRX4+z1x1jlquRkrK2B3jpR7xdkyv1SOfzXOicQKAdrvNI488gqd56I6OmRXWkOgQezHRMCKXy7FwfAE0aG8IC8zsUhY9o+Nti+RQqVTIz+exHRvLF6TDcTrGdE2cyCFjCY/idrutNhPZSpbmsMnqw6uMe4JZfPra0zg1oT4b9kKCUcBEm/Csm57FdceuQ+/rdJtdNjY2GI+FgN/q6qpqCQGK0HnNNdfwhS98gb/xN/4G7W6bn/y5n6RerVOixKA9IAgCyuWyYjZLrL40rZHeDLDHpu92u8RxrJKDlBLv9/sq8cljSJJEJRrZdgTU3GX/4FnyJoCZmcWTMaDWTV2glMaRuN5PQTwjiXEVsby8/JR+nxT48n2fxcXFGXapZuzNGczc7OWLoojhcIhpmjMPys7ODuPxWBHgJAMZZhNDtVpVCo5yd72wsHDg+K677jo1XIY9JIdsD0gjdBnHjh1D13WWl5eV9IZpmgr2KucbUpq5UChQdas0V5pCOtvzyOfzhGFIt9vFMAzmsnMkScLmxiaareHqLo2lBpfuv0TH7HDimhNkFjP4HZ/uZpdes0d2XkhDh2HIXGWO/CBPf7vPsD1kLRVEqoXaAlESMXz9kNzHcpiXTNw/cBn/rTEeHo7j0O12qVaruMsu45UxZmJSPVZlK9hitDXCNV1ytRxm1iTshWRrWbp0BTPb97Ezwj8imkTMLc4RFkLaK230RGeSTigVSwTjAHrQ03sUi0VOnzjN6sYq7XZbILzCDHW3jlNzCNqBqlCMjMH8/Dzj1phxe0yvK9z3srUsfsdXg0y7ZONUHOy+zcbmBpPJhGfd8CySKCEf5wn1UCHPnvOc54gF3BgQ9AIuPXiJ4mKRar1KvVFnhx26wy7xMGYQDchmspw8dZJMM0N7u82oO2JgiRZQJpOh2+0q1rRs4RiGOO7Pfvaz3PIDt/Bjt/4Y86fmaT3Swmt7jK2xWox3dnbULCSTyZDP52fYvsPhcMZ9MJ/PUywWqVarRFHEI488QhAEatbV6XTodrvq3puObreL53n0+30KhYKCVluWxdzcHL7vK22mwWDAcDikUqnMJJcnIsycKRwKu4KjItV3n6x4pmL4OgxNE0SlKIou68+wP6Sr2/73SWTF6uqq2JHvslUlSmT6eyV6SZbOmUxmJnlMv07+kd9dKBSUVeh0i0hWB47jKFSTnInIagZEO6tYLCrdfl0X+lCyFSXRPXEckzopbs7FNmyiOGLkjYjTmP6kT3urrWC42WNZwjBksjOhvd1mOBSto1iPcfIOGTtDPJ5ii+oxTtEhJWXnTWKAuvw7y2hdDTM1FQ8jCAKyS1mskkXsxaTdlPyJPJEV0d3uMtmeCMVYSyfqRGRdsbscDAZ77aSx2F1aeQu35NJwGsw15ojNGC2j4QVCiC8chOTCHIuLi+RyOTFstVKSiRikO3VHQGuHId6OJ85jvUjWzTLpCUvVUTrCyAgnubAfEvQCDNfALtgUzSI5N8fW9hZ6SUdHp2yW1bXr9/tKiiFTyTDyR/Q3+jS3mmpRtvM2RtkgDEKaF5tsrm5SWC7g1lyCUUDYC9ESIZEi/TvkNQKxeQmCgEKhwP/4nf/Bzd94M2mQkjuR4/5z9xNvxaxdEMlbmiHJ56TVarGysqLktiuVCo1GQ1mUSk+J7e1tisUiJ06cwHVder2e8ncoFouHwjuLxaL6HFnxNJvNGVb+wsIC8/PzM1L0T0bYFbGhmBZYfLLiMf+ClZUVPv/5z/OpT32Kr3zlK08bhfz/rXFZPsMRc4bDYKsgoHeS2yDbJtL0ZDpkJXGUEup0SGE+SVrrdrtqJ9Vutzl37hz33nsvZ8+e5brrrjv08+T3S1VMKT2eyWQIoxAjI3rx8pglmxaEjIWbd4XmTwihFtJtd/FTn2FrSBTuIq6KNpXjFYgh7u5Zn47HY6yCRT6XF/3bQaDOd34xDxF0X98lKkW4Gy71L9TJ+Tlsw6bX69FsNtFtHXfOxXAMglFA0AwIMgG5cg4t1ZhsTASLOEpxIkcpX8ZxjJkV7SQJJLCrNpjgRq4g6tk6qZaK+YEphPoKcYF6rc61114r2kVAPI7RbCHNbeZM0TZr+ZSqJZy8IyTH0xQnK+CuJGLGEvZDgk5AabHEwuIChicgyFs7W6S5FD3WqTiVGcc+gCRNKM4VSfXd3xSLmcHJkydZOr5EppZh6A/pbHTYOLdBsV7k9I2nqVQr7KzuMGwNlSS04zgcP35cObxJORgQx6hbOnf85R18/zu/n3/zs/8Ga2zRXG0qbs7x48epVCpKbFG2ItfW1pTE9jSeX2onSRJcvV5XBMTpSmF60ZWw1fn5efVsDYdD1tbWZlq2ruuyuLjI3Nzcgeql1+s9IQu5pmvYNVuAMrqPHsL6aOJRtZIuXrzIr/zKr/Df//t/Z2VlZebH2rbNi1/8Yv7pP/2nvP71r3/SsubTEe12myiKKJfLhyKFnoxwHOdIzRbFZ/AS9PzseZbGOJPJZGbhr1arCsc9mUyUwfjM5xoGW1tbyjnq5ptvVvLM0w9OkiTcfvvtjMdjTp48yXA4VO8djUaqb1ypVHjkkUdI05Q777yTkydPqr7w4uKi0mgKw5DBYKC8hSWTOmtlGTfHbFzY4OTJk4p34Ps+nudRqpREYkhgEkzQEx0zZzIajeg3+7gnXDRdI7+QJ7eaY9AdMGqOMBfEa8rlMtlCls5IyFB4Qw/P9SjOFQWBbByx/fe2WfrlJRZ+d4HV71glS5adyQ7NZlPIEdQzBN2AdCjgq9VclVQXnIY0TomGuwPyCRi6QWIl9Pt9QcLSNaKxgBL3+330kk7YDHE1l17cAwvG4Zh6po7pmETdiFK9RMbNCPRTJiEaRYx8IVNdLBQxAoPx6pjcmZxwZgsyFLPC9zhxEpFINMGslcPx3FwOHZ1e0MOLPXa6OxSdIk7ksFBewCmIZGxZFtVqlXa7jVEWbSB/xyczl1FcGSfjkDmWYTKa0Gl2cHSHxblFTNtk0BzQ3m7T3mlj5k1OX3NayWBLtVZd19UMy6k5SkjvTz77J2y/bZv/9L7/xFw8x4XeBcqVsurzNxoNJbUdx7ECWcgKVQpMSjHHcrlMmqZcunRJbXIajQaZTIbt7W31W6efK9d11RB8PB7PKLbKKnuapZ2mqapE+/0+pVJJid891jBsQ0mwyDnTkxFXvXq//e1v5+abb+ahhx7ip37qp7j33nsVSmBzc5M//uM/5lu/9Vt597vfzXOe8xzuuOOOJ+WAn46QxiZPJfPxcjIWmi78GQ7jM0xjvqeHzXIwDMIW8LAdjKZp6uaXSIt2u33AOGWaLNfpdJQl487ODt1ud6aNNO3oJjWTptUgp3Xx0zRViWE0GqHZGgkJ4TBU7aRpuK2Vs8gVchiagTf2COKAnJtDN3TaG3vHbOZMygtlLNuCPvRaPcIwFPOUomgnFYoFomGkKi234aLHOjuv3yEshmTXs+Q/nadcLVMxKyyUF8QA3tLJzGXQDE3oHaUQ+ELDKU4FQc0qiAXE7JrEo1i16SQ6CUT1pOkaZkXIejixgA3bGZvuuEtv3BNEvEmMt+UJFrQZ4408vLG41t1+l0FmQGzEjM+PcbMudsbGTsVmRjd1cMRQ2nRNnKoj9JTGMXpWJx7GTAYCkdb3+2LO0I8Uhj6OY8WH0A2diTGh1+/hNT3hh7ELRhgOh4yDMWNtjGmZxN2YulunslChcbzBxJvQ3ehy/r7zbG1tkaaCoZ4kwmvikUceYW1tDS/0+Pv/8O/z+7/x+1TKFb7y1a/wt7//b/OVO77CcH1Ity1mCBKUUCqVOH78uBoyy2i1Wmxubqr7S977kuW/s7NDr9dTCKPJZEK/3z/0OZFOi0tLSzOVgSTATVvrggBqSLHCdrut4LCPp4KwChamOwtTfqLjqhODbducO3eO3/3d3+X7vu/7uOGGGxTaZG5ujpe//OW85z3v4f777+f973+/EkB7Jh5byMrkKPic4RiHkl5kOwdm20kg2kdRFNHv948kIJVKJTRNU3r6R4WcW0iimyS3ycXDMASK56abbgLggQceUD4R04kjl8tRKBSYn59XswtZSUSRUBXVQ53xcAzsJcwoioiTmGK1iGVaRH7EJJ6Q0TLojk6/2d+D0+oa+VoepyT4B9pAE9XDaISZN6lX6xxfFkznaBTh+z7ZuazgHKQaF/+euJfr/6VO1shy4voT5LScwJanKXbZxqk6aLFGxsygZcVAc6u1Ra/TIwkT8qfyZAtZSkGJTCCM32U7KQ5iZXikWzqZ+QyZfIZskiUYC42jtdYaG80NwiREt3S6a102Vjfo9XtUMhWq1aogHsYhA3dA3++jt3Qq1YpoJyVCEbc1adHpd9hZ3cHMmYLTMYnRUx1MyJPHtgR0ubhYFBj6lo839pRBTKFQEAghU2esj+l1ejihw7FjxxQPIkkSJv6EjdEGvuGTeiklSjQaDa656RqK1SIFq8B4Y8zaJcFBkCCP0WjE5uYmm5ub7Ax2+OZv/mZu+8PbeNb1z2Jre4s3/uAb+ZM/+xOMkYGe6gqp9NWvflWxo+WmSEKkp1tNq6urak4k25ie57Gzs6PUXOVsotlsHrqI7/c2GQwEckp+htz8FAoF5cMs4bASvns5f+srhV3dnTc0n5x5w1Unhg984AMzSJPLxbd/+7fz3d/93Y/5oL7e4unQaZ/u7R7aTsoc7s8AqIV1f0hIaRiGR96UMtnL9s5RMS3vLRODvEGl9HEQBNx4440A3H///SrJTUsCSyjhdItOokgKhQKnrj3F8fpxzPGuIurunEHTNMIwJFfNUSqXsHSLMAqxTEu0XaJISFDvRq4qpLrdvIuDw6Q5odfpCYnqgkUapGQLWaJxxHg0FpVJEazEov/dfcaNMXbTRvtPGnZRJIJ4HDNYGzAej3FqoodvBYI7ErsxiZ8wHAwZbg1J4oTitUWcksNka8J4YyyunYZSZZXwST/wqV9Xp9aoMV+chxEMgyHb3W3WV9YZB2MKcwUIwJ/4tNZb5HN5tYvVTZ2wELLV2WLYGgqZjlGErusUS0XMrElrqyVaOlkTp+6QBin5bF5ocQ0S5ubmxLmuOaDBZEvMS8IwVKzlcrmMbumM9BHj/pioG7G8vKx6/9JeM9ADQjeEFBzPYaGywM3Pv5nTN5/G0A2iVsSdX7qTlZUV1c+3bTHL8X2fTtjh+PJxPvtHn+V1r3kdYRjy4z/z43zxji/ib/viPOzKzK+srLC1tcWlS5fY3Nyk3+/TaDRYWFigUCgo7kK/36ff75PP55VcRzabVcS1dlsAGEajkWqtXi4WFhYUnHaaLCfnCxJWK/kSURQ9rna7pgsNrTR6cuYNT0iD6rbbbmM0GvHCF75wBib5TDy+mNbY2R/KB9qLhRz0VFQqlQMOcIDyJ5DIn8NCejlPJhO63e6RvrGyYoiiaGZoCHu7KU3TVMXw4IMPKo0liVo6zJ1LDibTNGV+fp5SqcTOZEcxiTVdsFmlT7Xrupw5e4bxzph8NY8f+7hDlyAI6G52KS2LVpVhGtQX66TDlCiMyE1y5MmTxAlWwRJ6QK7DsD+EMRg1g2Nnj9GKWjiRw/Zbtzn1nlNYv2wR3xpjnbIYjAdcvOcilm1x9hvOYldskiAhG2ZJs8IBzvRNOq0OzopD8boiueM5JhsTxn0BH7axCeIAq2ypqmEymRClEeWlMkmY4Ac+vc0eY8aYY5P04ZSlZy9x7PpjXLrvEuPWmO3z2yycXVBM31arBTFYpkXohew8vEPlhoqyf9x8eJPmehMMMX9y6g5pM2WoD4lGEf2dPuX5MpqhMTEn9Df6ZAoZfNtnMpnQ6XTUPZYkCUW3iN/0QROLpNSmkouklJQoO2Waq03KtTKZuQzLz17mwv0XaJ5r0tppMbhmwNzCnNo4RJHggeSLefyWz2/+59/kfb/4Ph5Ze4TX/4PXs3Nhh7gbk3WzmGVTVQGFQkGpInc6HeGiV6tRrVZVq9LzPObm5uj1emoz5TgO7XZbudK1Wi3hyb21pZLlYSElsIvFoho4S30mOb+QXhWFQkFsJqaewV6vpxjZV7sR1W0dq2wpmfUnct7wqFLWBz7wAd7znveo/07TlG/7tm/jb/7Nv8lrX/tanvWsZyltnGfi8UetVjvQy5RxuTnDUTfWeDzGdV2hOXRE9ZfP55Wr1XA4PNK4J5fLqZ3P/u+Ti3smk+H6668HYGNjQ5mzS5Of6YjjmGazyfb2tiLDxXEsKokChJOQcVO0k/Yzw3OVHLl8TpjKlAucXDhJuVYmHIcz56e2VCNXEK2r+lwd13KF5r0GuNDeamPlLcxEYMatrEVxvki9Wqf8fWXiG2P0gU76XiHxYWdt4nyM53us37+O4RiiPZN1sBJLuIK5gtDXWm0x2Z4Iw3c3oDls0vf6aLZG0BbOa2mSziC1NEck17lr5yi4BRzTQTeEz8LGfRv0Rj2Wrl9Cy2h0V7q0VlvKw3t5eZlj1xwjU8owTscM2gMu3X2JOIwpl8vMHZsj9mM6zY5AWDliVpIr5CCC3lqPOBAtmERLoABe3yMdi5aU3HGXy2Wq1aqYWVQcoeszjFlcXFQ7aOkRfenSJda6awRWwPraOiv3reCPfI5fd5zj1x7Hzbh0NjpceOgCnucpDkGaCtVcM2eSxAlv+rtv4mf+zc+gGzqL1y4y0Sbc85V7sHxLVZvyuFzXxTAMVUFLiKvneZimqfgMchEHVAKxbVsNxldWVtje3r6ikZWu68qoqF6vY1nWDKdBVsvTz7SckTSbzUPnFJcLK29hZk3BZTmke/BY41Elhv/+3/87z372s9V//+7v/i6f+9zn+PznP0+z2eT5z38+P/mTP/mEHdwzcfnQHZ3ET468iWQ7R4ZEUtRqNQAlV7A/pI+v3N0fFvKBk/1c2dOVdoO2bYudXj7PK1/5St74xjcqrsNRQn0ShSW1mgaDAefPn2e9tc7maJO1hw+3aDQyBpqtEfkRSZjgZsXCWC1WZ2QENF0Tg2AN4VJm64x6IzbPbZIpZbBMS+gcxb56n5UTekKmbpL+210o5Uct4ofEw33sxDFCN6Q9bNPd7oIOSZRQWagwtzRHrV4TvWDfp/tgl3ASUqqVsPM23tgjzsZYRUvISmxOMBOTXC4nFqaCwM/3hj0KlQJuxqV6vEp1sUrYC9m5bwct1KieqmI6Js2VJr2VHkkkoL8ZN4NTcyhVSkR6RHurzUN3PsSgO6C6UKVRbyjmd7fbxbANKicr6K5OPIrpXOpAusuIX6hBDhhDOAoVMEGCAgCMnEEv7LG1sgUenDhxQrUIpZjd1tYWsRZjVSy8yOPiAxfZurDF2evP8vxvfT6VWoXYi9m+tM1wINBpkjtil2282COOYsa9Mesr67RaLf7lT/5L/u4tf5c/+MM/oKJXKOaLipswPz/PsWPHZjYS00x6iYAbjUa0223W19fVhmd9fZ1Op8NwOFSy8mtra2xtbV1xPiBl1+UmS4YU/pO8DRDJpFQqKXHKnZ0d1tfXGY/Hl/0OGXbFFppXzSdOT+lRJYbz58/znOc8R/33H//xH/P617+eF73oRVSrVX78x3+c22+//Qk5sGdiL6ZF6KbjcnOGMAxVn1VacSrDmGxWzRDk0Gw6stkstVqN48ePHyC3yZCKrNIrt9FosLi4qHbz5XKZRqOBrut85CMf4Zd/+Ze55pprFKxxf0luGIaCxMoHQkoNjEYjIifCG3iEI7Fj6/V6SjJ5e3ubldYK5zfOc/7B80wSAV01MoaAku4+LGmaEhohg4mYnQSTgM3+pui3r7cpNUrEk5hxOsabCPmI5qBJq9NiOB5yfvk83gs8tECDfyGOe25ujnqjTuiErHfXidOYxEuIekKNtHqmKngNhsawM6R7TxcSqCxUMByD9mobu2RjZgUayW/5FCiQd/PCdMg1KFgFsvUsBavAYDDAWrRYPruMGZhErYhsKqoz0xbKqt6mQC2BSH7ZWhYrY2FbNr1+j7WH1li/tE5hvkA1X0WPdLWrNWyDyokKuMJ4yGsKTa1iscji6UWMrIEd2EwGAhI9jdH3PI/QCPHw2LiwgZVYnDx5UjDVd+XHTVOQBAvFApXlClbeYtQbsXL/Cv1en2f/jWdz8uxJHMMhHaZ4fU+1DDVdw8gboIvZyqA5oN1ui/lCGPDP3/3P+cEf/kGCZkDkReqa74+FhQWOHTtGo9FQBLZ8Po/r7poj7YoIaprG1tYWzWZTJQ9ZLa2vr7O2tnZAamZ/7K+m5UZrNBqxvr7O1taWkvuQVp0yQUjf6ysJ9Wm6JlqBcaoAEY83HlVTKgzDmex3++238/a3v13999LSEs1m83Ef1NdbLC4uPm3f3Wq1GA6HVKvVA3R9OWdIvERpKMmQC7A0u5FICwnX8zxPIYna7faM9EUURRSLRdVuOqo19Y3f+I1K+0jXdXzfV7szyYCWUL18Pk+hUGBhYQFd1w/lgxSLRTqdDrlcjrm5OYbDIefPnwcQfIWRaHHUr6urOYVsCSRGwjAYEnohgRWQM3LMVefw2h7+wCdTEglup7lDmIY4kUMYhGihMLBpbjaZPzYvoLqXmizOLeIMHaI4oj/us9XeIvIi0ltTrv3StZh/YJL8nwT9b+qcOnVKOdqtj9dZyi7h7/jYBRt73sZYNPD7PmWnTNAK6N3To3BDgX6xj9/x6Xf7ZK0sZt7ELAgYorflCWXNrIC01hfq+D0fv+OzublJtVIlcoRk9FJpCdu28ds+lRMVtFSwY2Mvxi7bWAWL+ZPzJPcnhJmQVEvpb/WZTCYUnSJVvYo+tUcslAvYN9jEOzGTddH+ciqCtb503RJbD22RG+cEx6JeV/eHbFPusIPf91l9eJXla5e59tpr6fV6qj05Ho9ZXV3l9OnTnLruFN1Wl/Z6G22gkUwSlk8tY2dtHrnvEQpGAWNsMBqMhH83EZlSBj3VicKIcBTy0z/90zzrWc/iQx/6EL/zv36HL9/5ZX7xZ36RF738Rfj4auMyfR9Lr3TZ0pGMavksSFTcaDTCtm0l3zIej9V9t7CwIAAQh7R6jwopoyG5EJJz5DiOGugXi0VlqXvULG5/6JaOXbPxmz5hP8QuPT6+1aOqGM6ePcvnPvc5AC5dusSDDz7IS1/6UvXvq6urqk3x/6aQg9SnA50k0T6H8hk07Ui7z2myjST9aJo2M1iWQ2JJDJIhH5pphuphIc+H3P1LJzbXdZXukYTo9Xo9hUxqNpuHlsmmaarBeBiGuK4rFoMowjANyMKwOSQJ93wUPE9IQDgZR/Rao4Bxb0xiJLS6LbZ727TX2+p4HccRAndpRMbN4BqiJaZndHbWdwQRzE8YhANSLUUPdFIrJQ1Tun6X7nyX5Pt3oZBvSyEWx3327Fk0TWMwGTDOj9FdneGFIZPWhCAMyC/lyS/mcWoOk+0J/fv6uJaLVbIYjobCxnEUYbom7oKLmTcZbg/ZeHiD0AvRAo2FMwtkbYGc6nQ7ZOYzjCdjNlY2GDkjPM1j5+KOuh/CvpDbTsKE4kKRbDGLEzoU5gvkS3mCnoDC9no9pdQ6HA7Z3NzEyljkTuSw8hbjS2OCfqCu0eK1i+QKOZYLy1jmLMkrl8sJVFHRJtRCVh9aJefkVLI/c+YMmUxGCT76vk99vs41N19DZa4ikuKORy6bo7ZcE0zfKGW4OuTCAxeEnlGtQG2hRsbKkEkzlEtlbrnlFj760Y9y4sQJHrnwCN/5fd/J+/7d+9i5uHNVyCLZzjl9+vSMv8jy8jJnz57l5MmTqk0qNZguXLjAcDhUC7gUHhyPx5f9LsmFWF5eVh4PUkdLfm+lUlFVzX5OxlEzCNM1sUs2YT9UFeNjjUeVGG699Vbe+ta3csstt/Ca17yGF77whTMzhz//8z/nec973uM6oGdiNi4HWQXRTkr85NDeokwM4/GYQqHA8ePHZxBJURSpYaf0CwBUUmi32zz88MNsb28feXxyV+V5Hs1mUxmQp2nK9vY2vV6Pra0tlpaWuPHGGxWL/CiSjzweOQ+R9paWZeHhMfEm+C1/z9Ftd/htmiama6JZgk0cEwuLUEOj3+4r71xlEWonmIaJ6ZgU9AI4gA2hH0ICo86I2IkxU1M9JSkpURox+KEBaTHFuMcg/s9iEc7n85w8eVIYuywvULi2IAzdN0Ny5NAdnVE8wmk42DVbaAdtaET9iMRN8CNfeEbHiZA+KAsZ7jiNGXaHTNYnOFmHxZOL5LQcpWJJLPRVh2FvyLgzxiyZjOIRrUmLdkcQCcNByGR9QjyOqV9bJ41TJlsTGicbLJ1YAh/crEs0iggne4TFjY0NwjgkcyJDbMQMzw+JhrvtKVOncbqBYztKt2d7e5vz58+TJImSh3DKDlEacfH+ixTcArZt0263yeVynDhxQvkkgECNuXUXp+6QBAmdSx20RBNKtIWEjtdh7fwaX7rtS+xs76DlNZZOLNHINijbwuP5Na95DXfeeSff3d5QAQABAABJREFU+Z3fSRiF/Npv/Rqr51bZPrfNoDdge3v7Ufm2B0Gg5hRnz57l5ptvZn5+XlVJku8jB+t33HEH999/P+fOnePChQsKmXRUWJalNKhKpdIBVVfJ1Jbh+z6DwUDNIA5znrOKe8PoOHjshNxH1Ur6wR/8QUzT5I/+6I94yUteMoNQAlhfX+cHfuAHHvPBfL2GxDRLvPNTGdMMaNmymQ7ZR0/8BMOdLTmlP7NklE57L4BYVHO5nEIL9Xo91ePsdDpCpkHXaTQah0L1BoMBX/rSlwiCgDNnzsz4OEgDeMdx2Nraolarsb6+zuc//3lOnz6tvKH3V5jyeCXBTqrFyl6y4zqMt8dk5jPYtq3OC4gHLc2njLZHeBOPeqOOPtSJvIhha0j5WHkvKerCV8DNukRBhJM6UAIv8YhDgcYZeAOKpSK0ICIS0FIzYGgMyf9oHvPHTbR/o5G+MUWraDPtOL2gk1nI4Ld8nMRhMpoQZSJ6wx6TZIKma1T0CtbQIgxC7BM2yWaCt+WRXRKLZaVewQs9IULnhYxXxrhll/nGPF4ioJbFfJGVcEUwqE3Q0BiOhwyDIWWnjJmY2GMh2WxXbfKNPNEgEjaiCyXcnEvQET15rSOqzI2NDVzXZWVlRchLuBZlr8zwwpDcKVFF6JbgOHg7HuOdMZcuXSKKIsIw5Nprr8VxHJaWltjStxg3x3gtj9xCTnFePM9Tbcfpxc10TYwFQwEDvMgjdVKoQ2fUIfETNs5vEE5CFpYE+zwZJeTn85iuWM5+7/d+jw9+8IOiIi5oDLtDeu0ehaUCw+GQkydPKuTbUdHv92m328qvWs45rrnmGur1OtVqdYY4J/2hpWCkrFIcx1HztqOg39LudDokIqvX6ylVVynlISuUZrNJt9ulXC7PwFztio0fCc2sxxqPmmFxyy238IlPfIJf/uVfPiDJ/J/+03/iO7/zOx/Tgbz3ve9F0zTe8Y53qL9L05Sf+ImfYGlpCdd1ednLXnYADuv7Pj/0Qz9EvV4nl8vxute9jtXV1cd0DEfFZDJR7ZinOqTVJxwuj6FbOpqhHcqClu0keaPKkBLXIJKDxKPLXbxlWaq0HQ6HCsu9P1zXJY5j9TopJdBsNmm1WkqXxjRNBVuVgotSTmN/SGE+XdfVb5eLiaZp+KZg4QadQCW6IAgUec/JO0RE+D3h/5x1smBAd6dLEiYz1ZJRMHBMh9RMSUYJhWyJ+87brG0uMGmWmLR8so0stikeNEuzhO1mMiF4U0ByNkFv6STvOrgLTdOUsTUWMum6TrFQRBtojMMxXujhGz4eHpW5CjWnBh3QbE3Ydo72qptsNoue0wmy4tpHo0h4T+gldHRM22T59DKGLWYRhmZgp2J42p602Yl20Kqi5ehteuTNPHk3T7QTkUQJdsEm08hg2AZe02OwNSCbzaoeeK/XY+JPCCsh6DBeGRP2BQDAyAhjIzxYqi4pCeuvfe1rBEGAZVksLS9x7Lpj2JZN1Ikol8p0u112dnbY2NhgOByyvr7Ozs6OavdohhimFueLVDIValaNarnKmWvPMHdiDjNj0tvpce7+c6wN1kjihPHaWFXNmqbxIz/yI9xyyy2cPHuSOBfzZ5//Mz708x/ivq/ex+23335A5mV/yOdDDp2nn6lyucyJEye49tpr1VzAdV1Onz7NyZMnOXPmjEIZtdttHnroIR566CH1DE2j+I4KOQSfVnVttVq4rqv8JySZTlqTSiitHEY/nrjqxDB9cp7o199xxx386q/+6gziCeD9738/P/dzP8eHPvQh7rjjDhYWFnjVq141w8h9xzvewSc+8Qk+/vGP8xd/8RcMh0Ne+9rXPqZF/Kj3PJUG4IfF5XSTQDygR3nCOo7Dzs4Oly5dmrkZp9Vbc7kclUqFpaUl1baRi7JpChbxUTMBadgj8eZyxx+GoapMMpkM1113HQD33XcfmUxGiZrtf0Ak41sK6kkpcdd1hayxleLkHbxt78CcwbZtTNskNVOCcUAURxQqu0in0Ri/588kxdiIsTIWGTvDV+9JueWNAW/4nmX+4Zuv42Mfd/jofxzxB/8zpDhXJE52z28AY8ZgQfCeXbjhr+rEd8xalj7wwAOcXz3PkCFBLyC/kMctuFixhZWKqrPn9YiSCHfeRTd10jAVzOu1sbqeig2NT6IlOHVHqKMOQtbuWmNjbYPIiKjN1zBMg3KhTNWsUslVcF2XIAzoeB2sRYvs8SxpkhKNIsbrY2EPmqRirrEkVF2zkyy2JnS1kiQhCAK2t7fZbG7iLO6xoOVMwsybWEWLklXimhPXoOs6w+GQ++67T8E8s7ksmYaQAQnboaq6d3Z2ePjhhxmNRqysrDAcDtna2lJKu1bBIjMnYMS5MMdSdYlrzl7Ds5/7bOZPzDMcDHnkoUe46/xd9Lf7TLb2IKRynnbDDTdw9vqz/OKv/SK/9T9/i3f+i3fy4FcfnKl+gyA40LfPZrOqrdlsNg88e7Zto+u6YmmPRiNM0+TMmTMsLy9zww03cNNNNynjK+lV0ul0VLJYWVlR7O79a4yEuk6ruo5GIzY2Nuh0OpRKJZUgpNXudBWkGRqZ2uGIwquJq04MZ8+e5Wd+5meU2uFhkaYpn/70p3nNa17DL/7iL17V5w6HQ970pjfx4Q9/eKacStOUX/iFX+Bd73oX3/Vd38VNN93Exz72McbjMb/1W78FCMjir//6r/PBD36QV77ylTzvec/jN37jN7j77rv5zGc+c7U/TcWT7d/6WOOq5gxH2H1GUUQ+n6der888DPuTTalUUpWJTAqapilM91F2n7KE9TxPvV6W2FEklENzuZyqGO677z5lORqGIcPh8MBnAmpuUKvVuPHGG1V/d25ujvxCXuj7hLpKHq7rKk/rfC2PqZtiQa7msQyLlJR+q08apzNJ0Spb3H1nhg/9CmhhRCmrEycGX7inSKcL/+sjW3zxL7Pki3nBfQh0kjQRPgwviQlfE6LFGto/00ijvR2rXFS2/C0m4wnehkfjTAOjILwo3NSFRHg0R16E3bAFq9if4Hd8RhdHxH6soJM4MBqPSIIEd94leyyLHuiEGyHnv3aeESPm5+bJlXLomk7ez3PixAnm5+fFDGBnG6NoULqhRO54jtiP2bx7k9aDghRn2Aa50znsjE1+lKdarCpLTGmQ1Bq1yMwJdze/5StopFWyMFyDbJzlumuuUwvhww8/rKoA3dKxqhY7OztYkaXuvTRNGQ6HZLNZ+n2BlNrc3FSbNN0WxDszZxL1I5zAoVFrcPaGs5x61ikiLaLVa3F+/TyP3PUIrfWDwndnzpzh137t16hUKjxw7gHe8s/fwi//wi8ThYIvs7a2xsbGBpcuXVKmVmmaCvXcjPi9Ozs7h97/cmhdLBYZj8dC/G/3WZAbohtvvJHFxUWSJKHX67GyssLKygqPPPII586d45FHHlHfvX9u4LouCwsLM0RXuR5IMp1MINP2upubmwy9w5+tq4mrTgyf/exn+eu//mtOnz7NC17wAt7ylrfw7/7dv+ODH/wgP/7jP853fdd3sbS0xC233MLrXvc6fvRHf/SqPvctb3kLf+tv/S1e+cpXzvz9+fPn2dzc5NWvfrX6O8dxeOlLX8oXv/hFAL785S8ThuHMa5aWlpSH7KONK7Eanw5UEogdt2QSHxZGZk+Gezpk/zOfzx/oYcqb67BkKBFBctGXUNfDqoZisYhhGEwmkwMyxJ4ndvW2bfMN3/ANgJBul3r68kE5LCT3otvtCgnubFZJFifZXQOcVqTsGGUv+MyZMzz7pmdTm6+RDBLMrEmhVCCNxQIUDkNKpRJLS0ti8TYN3v8LWYJxg/OrVa4/FmAaKb1+joe2R1TnL/B7/8Vg6fgxsoUsy/Vlbr7hZqy8WAz9d/mk+RT9KzrRL+whQRYWFqhWqyQkNKMmo+0RyThh/tQ8y89eprZQwwotoiCi0+vQ3+4zNsZM7AlJmhCMAvoPCY/lcrks2mipj98Ti3GmnqF8qoxt2VihxWRzQm/SI/Ij7JqNN/DornaVDlWSJDz44IP4oU/+ZB59WSfWYlrnWnTv6RKNIwzLIH9GSJ3QhLnSHMePH+f48eMKspm4iWgfIVBPfssXGkhVB83UsH2b66+9nlwupyQp5HNjuRbzp+fRY52sllX3p7y3s9kso9FIKTZLIpqmC5nwTD1DEiRMNidoocb111/P87/l+SydXkLP63gjj0fueIQH7nuATqczIz75pje9iXvuuYfXvOY1+IHPv/7Jf82LX/RivnLHV2Z28p1OR/BiVlZotVrk83nFKzhKUC+Xy7G0tKSg2Q899BAXL15EenDX63VOnDih5gyy/SSBEP1+n83NTcVrmA5J9rRtm0ajwbFjx5QcDYhW18bGxoyasnRrPKxVe7Vx1Ynh+uuv53d+53c4d+4c3/u938v6+jq/+7u/y4c//GE++9nPsry8zIc//GEuXLjArbfeelXY249//ON85Stf4b3vfe+Bf9vc3AQ44BswPz+v/m1zc3NGTvqw1xwWvu8rSr/8A1dODE9XZDIZ5ubmDvAYZGi6dqjaqud5ql+/H2sth4P7bUu3t7eV01W9Xlcl6lHtJHlMURSpakG2k2RisCyLQqHA0tISsNdOcl33shaIEh4oEVMzyaQIQS8g8mdheRLqd/rZp8lZOcJRSHm+TNkt06gKpq9UANU0jc9/Hr54p42uGYx9DVOHaxYDRqMc7aHBdk8jn1th9cES191wHeV8maAnkqldsdFOaHjvECQw89+aROcjdRwnT54km80yMSZ0Rh36F/tiIXctiqeLVOYr6L7OpCeSAROwaha+7mNmTJIgYfDwAMaiops7MYeu6eo6u3WXYq1IvponiAPCYUhnpyOG7dqQ4faQ1XOrVCoVwjDENE0lLFc9WcVpOCTFhP5On/4DfcbrYzGQPybkw/2mj5u4nD17luXlZSzLotVq0Q7bDCNhnxmPY6GRBDgNkTCMscHp06c5ffr0zP2VJAmFSoHjZ4/jmi7u/5e9P4+2La3re+HP7JvVN3vttbvTV2NRVXT6GpsIkYBoVAwmxBCNCvdVr+EqQlCQNBBbwCZxoMZ4byQx90YFgiaoUSEJhHgl9FVF9XXa3a++nf2c7x/PeZ6z96lTRdUplDLj/Y1RY9Tp9p5r7jmfX/dtTE91jrVaDdsWqq5hGJIkiUBGHXknDc/A63rotk7YF3um9fV1vvqvfjXP/Zrn4m/5LGYLrnz2CtuXttne3j42Hl5fX+f3f//3+Zf/8l9SKpX4s0/8GS/++hezGC9UZyulOKQA4Gg0otPpKATSEzGe5fskx0p7e3s88MADqsuXo61Op8PJkye59dZbueuuuzh9+jRra2uUy2WGw6FSsJUJ6ODgQLnTSW+UowXqYrFQLPTt7W1GoxGO49Bqtb7ggv3J4mn/y83NTX7kR36EH/mRH7npbwrCAe6Hf/iH+eM//uMnrITh8VW6NMR4svhCf+dnfuZnbijd8ZfZXEh3hA3m0c8udzHlclnB3yqVimCRXufMJcNxHJbLpZoP67qOZVmP03yRISsqOT4qikJJZURRpHx0i6Lgu77ru5hOp8qWUUp8H42jv65Wq2RZRq/X45577sG2bcbjMUEQcNstt+HrPtFBhLFlqAW0HF+ZZZNMz1juL6mdqYkqK4MiL8gWGWZZPPp7exDGOjs9k412ypW+zunVhP2Rx5UrJ2hUHmWtMWFw2MDIyxReQTyIcdvCLMeu2yxetcD+jzbGPQb8CBTvv7pAdRxOnjzJ+fPnmSZT7J6Nc+BQXiujGRr2ho0xNtBCDTMyKbtlJssJmZ1RMSrYDZtknLC4ssBpO7htlyiISOeC76BbOuWVsnAg61RYzBaUtTLDK0NqrRpJnBAOQ/bYY+PkBovFQkk/+L5PqVEi14UESCkvER2Kr201LayKRRZlxLMYMzVZ666xu7dLkiQkScJgMKCK0JEqUaI4LNQ1hochZmCqAxU4No5ZWVlh89QmB9sHwpb1qhz26uoqu7u7grB4tfqVS2z1fBga7opLMktIJkILy2k6lCtlzj3vnPCH2A4ZXxpjG/axd3q5FKq53//9389XfdVX8X3f933cfdvdNMwGLq4iYspkJQ2tZNWfpqnydy6VSo/j9+i6zvr6OoZhcOnSJabTKRcvXuTWW2899lwbhnHsXarVauzv7yuF2Ol0ShwLcMVsNlOF1lGLW+l61+12j3EpJDGuVCo9ZTXsG8Wfj/3PU4hPfepTHB4e8sIXvlD9XpZlfPSjH+Xd7343Dz30ECC6gqPM48PDQ9VFdLtdVVEe7RoODw/56q/+6if83m95y1t4wxveoH49nU6VVPCN4ku9fJYhSTQ3OtANzyCZJuRxLrqHLFMVfrlcVqxNuch9opDqkFKlUrawJ06cuGGy9TyPTqdDEARq/DSbzRRj0zAM2u02lUqFN7/5zTz00ENKSVJKJDxR2LaN53ksl0vG4zEbGxvYtk2WZYynY+rNOtEgop/1hQ3m1TBNk9FohBVb+HOf6qkqdlUwg03fJJ7FxHrMcrmk3fYBnwsHFudOjDmxOSdJqnzZlsFnL1YZTh1a9QmRcZnHrjj4hk84DNHHOs/56udglk3sps3ixxdUXl3B/D2T+LdjrL9rqeTX7XbZSXeYT+aU98t4TY9MyxiOhxhNg0paQYs1bN1Gj3VSI2WezNVznkyEDWeRFhiOQboUiCLd1MXit1kj6SeU6iUhPW5YzAdzml6TcTImmkXsXthl7dSagg/v7e3RqDTQMg3TN4mIqFgVirwQydYVDnSGJ3gyySBhvbuOYRlKEHEaTkkORLUvJbvdFaHPJCt6p+mQ5zm7u7uMx2PK5TI7Ozu0Wi1W11exezYHiwOazaZiy+d5ztbWFsATsoqtioXhXvWKOAyxahZmyWT9lnXIxD1bHi658PkLwt611aDX66nK/bbbbuO//Jf/wu7uLuk0JRgEXOlf4XMPf47XvOY1SnhPwqlLpZJiPSdJwnQ6VYqxpVLp2HO8urqK53lcuHABy7I4PDxU8jA3Ck3TWFtbo9lsqmW0fH+jKFJug3LhLRGDaZqqd0sSV6fTqUIJPhMU5ZcsMbzkJS/h3nvvPfZ73/u938vtt9/Oj/3Yj3HmzBm63S5/8id/okhzcRzzkY98hHe84x2AkGSwLIs/+ZM/4VWvehUgVDzvu+8+3vnOdz7h93Yc50klra+PjY0Nhbj5UsVsNlNwtRvZcuqWjqYL2KrhGGqp6ziOapOn0ynL5VLxIeI4ZjKZoGka7XYbuOaPII3Vt7a2FI77RqFpGi94wQtUpyLhptd3JPI6pOqmlNSWssxSttiyLFVpOo7Drbfeyuc//3n1QjabTWUhqp3UoA/FvICKKCwMw2CxWIhuqQArswh7IU7bYbQzYrA/wPd8rMJiES947nM1Njd9dnY0zu/ZvOA2jfsvL2k4HrdsRuS5QYJJpx1z+eAA13RpFA30oU6wCChVSrgrLtPnTEm+N8H+v2zMN5ikX5tinRCVbqfTIc+FWY/iKmz5VKtVpkxZzpdUS1W0VMMzPAazAVmYUWvXKG2UCLSAeBKThRnzmSCztd02lVWxc/HaHuV5maAIWN1cZTQaYZdtzLlJnTqzfEY0jdi7uEd7o62YtiNGeHgUswIaULbK2K4tLElnKVmckQUZ3rpHnuTEvRhnRYxMyuUye3t7TAfC6SwlZRkuKS1Lgi/ScIhGEbqpExvimfA8Twks9vt9MUqsV3Edl3KtjGZpyqLz8PCQTqejnp80TRWC7ugz7666JOOEeBxjhAYb6xtYusXhw4dClHEnotgp2K/u41WFPed8Pld7rlarxdyZgwE//g9+nPsevI/f/d3f5d3vfvexojXPc/r9vupeDg8PKZVKCnbtui6NRkOdK9VqlVtvvZXDw0OCIODg4EA903JndH1IRrTczy0WC6bTKaZpqi5fGl0pUMLVkDsQqff0VKU0nii+ZCddpVLhzjvvPPZfqVSi1Wpx5513Kk7DT//0T/OBD3yA++67j+/5nu/B931e/epXA6IFe+1rX8sb3/hGPvzhD/OZz3yG7/zO7+Suu+563DL7qcQTidXpuq5QOl+q+ELIJE3TjsFWq9UqnU5HwR1ldX79EnmxWDyOwu+6rpLVDoLgmCmPJPvd6PvL65SyGPLBLIpCVTGTyYQPf/jDHB4eqkQym82UtadhGOrfS5STVHs92krnec5sMcOqWWhLTbnHyWspioIojijcgmAo9H50TyechQRJgB6LRz9NI/7FvxCf4ZErFeahxlYnY3+c0a0ZkJZ42csddAuW8yWTcELu5BixweSSWJzrtjig5q+dU5wr0A90+FHUz8IwDDY2Nqit1HCaDvEkJh7HNBoNLMsi93OCLGAWz5inc3RNJ52mHFw8QDd1/C0fu2GTzlNBvtMKxo+NFZvbcAwhiOc28W1hXt8508HreliORaPUwDd9wl7I7HDG2toa7bbQm4qMCNd20QqNUBfyGWbFxF11MSvCYW5xeaHua3QYsRwvWS6XdLtdOhsd3IbLqD8iyAIW4YLgMBAGSFWLeBLj4ChYpUSkgeAH9aM+6BAPY7RCdLODwYB+v8/29jaXL18mSRLlRT4ejx/33NkNwcXI45z4MGaltULnTIdGtYGpm2Rk5PMcN3XJkmvWqrIwyrIMt+byyr/1Skp+iU996lN83dd9HT/1Uz+l3jcpoCfHaPKZlp3C0SU7iCLFdV2lDSYVbKWFaBiGN3yP5WfyPI92u82dd97JXXfdJaTNr36v0WjE3t4eFy5cYDabKT00+W7P53Oh5nvdvXo68aweqv/oj/4or3/96/nBH/xBvvzLv5ydnR3++I//+NgS9hd/8Rf5tm/7Nl71qlfxNV/zNfi+z3/6T//pprKlxBU/G0MmhjzPb2j1CVdhq3FOkV0zJj86NpJoBtlNyJf0Rl9Tkt6k1IW0I5Rdx9GQnIRer6cQFpIQKP0X9vb22NnZ4ZWvfCX/4B/8A/7H//gfpGmK4zhqhnoj6Kp8SaRqq3wBpFmMt+pha7bwJr6aGCTctigKtLJGHMYk44TmZhMSyPKMJEjIYiH//W3flvO+98H6usF950tUXDCtBY5v87Y3Obzg+QaVRgXDMPAcj7Scgg3z7TnxTCyinbaD0TBY/NMFhVZg/bZF8r6EPDuOFHNaDnEWs/3ANtPRVMgr6IK4l2siuRlVA6ts4S09FlcWaLpGaaskMP2JBbqoEKcXpsQTAfm0aza6pRMNI6GvRSFc5comi3BB50SHZqOJN/fQJqIybzQaOCUHp+xQ1susbK5glkySSSLgp+s+XlcsosO9q4zwrODw0iHzgRhNrq+v0+w2aW+0qdt1Ks0KdkWM7TRNI7dy4lFM2SnTbDZV0paghLzImSG6u+nOlEF/oBBp29vbPProozz00EOqEh+Pxzf0Yjbcq4tpRycexDSrTWprNapulValRWOtga2JLipbZkoWWz5XW1tbvOnH3sTn7/s8L/trLyNJEt7+9rfz/Oc/n4997GPKflZW5BJR1ev1KJfLyr9Bxmg0UtyMer3O2toaW1tbiiG9v7+vbEifLKTVba1WY2NjQ42O5Hs3GAy4cuWK4vJItVh44iLyqYRWPFsG6F/CmE6n1Go17rnnHoWVPxrD4ZCiKBTp6ksVUoJ3ZWXlhrPXIitY7i6Voub1kaapYoVLlMne3p4QMmu3HweDe/jhh5lOp3Q6HeWqpuu6qoRkLBYLPvaxj7FcLjl58iSA0syR2jLSaP2tb30rH/zgB3nNa17DG9/4RnzfV9IWlmXR7XYJgkAQo3yfXq/HxYsXMQyDtbU1lYAmkwmtVosXvvCFLM4v2N7bRu+IRblhGPR6PcIwZHV1FX/mC22h0z7bn9pmmS/xqz5ZkWFUDLrdLq7rkmXw3/5bTP/iDq0qfPU3rDPdHjEOx5hVk/3L+4yHYxrdBlZuUZlVWFlbofEcIaGdTBNmj82o/moV89dN8rWc+CMxzjnnWJV84XMXSEcp5dUyq7etqqUmcyiWBWEe4jQcyosyxbKgfKosSHCWTrAfMDwv5EHMskmr28KwDeyWDQUE+wEhIYtiwdraGsO9IdMLU8yKydadW0QHEVFf/NupNSXKIvRCp5SWKHfK9Od9SkUJz/RwO67Q+R9EIkEZgnSWJimHw0O0ksba6TU1uiAQEFa7YZMlGcvBknEglsBlr0x1s8oiXCgPEAlc8H0f27AJD0OmwZSFtlB7qn6/j6ZpnD17lk6noyCYUsn1RuPddJ4KufWrrOHFdEGtVaNxosHkcML+5X1m0YzWVouz584K2Y8jC+7t7W1+97d/l7f/9NvpD4Va9Ac+8AFe8YpXqMX0aDRSMiC6rnPXXXepIqwoCnZ3d48hquQ+wvM8RqMRk8lE7QyazebTcm4DMVaXir5xHCs0VaVSYW1tDdd1GY1GbG5uMplMnhT9d6O4qY7hP//n/8zHPvYx9etf/uVf5nnPex6vfvWrnxF29tkQN8L1SzOPpyPA9ecRR4lZNwrN0EhJ2b28e8POR5LBgGNjmRt9TSlJEcex6hDkSyhhsDI8z1NY78ViwWQyUfA6eT9lhShFF++55x5F5pHQUekR0e/3lWSBNHOXgmNHWdlS6dJb9TALkyIQ7X2e5wpJlSQJmZORRWKc0FpvkQUZcRFTxAVZkqnPbhjwkpfY/NVvcDh7BpbjGX7LxykctFSj3BAkt2SRkOgJS2dJvIyZX5iTxzlW1cKqWsz/tznFmQJ9T8f8R0LQ7OjPsNKtoLs6i8GCw0uHOI6QtC78gnKjjFmIBXlQCTBcg+XBkmA3IJkluKsujXMNKCAdpySIriQ8CClSQTYLRgFZKNBctU4Ns2YSjSN2L+7ibXiUTpaYjCeML40J+gFJmrBIF/Qu90iTlN6yx3A6FCMhwF1xKZ8WaJ08zjEtk5pfoxgXHDx6QJYIIp5ds7HKFuPdMXuHe4RGiB6LXdZwPGTv4T1M3VT7rOVySbVaFZpelo7TdjBzk3gcU6lUlEy767oMBgP29vbUvkvO7W801jTLYhSmWzolq0StXMNzPOJhTGO9QXW9imUKc6Qrj11RXa181gBe9LIX8e9/89/zrd/wrdxx2x2cOXWG7e1tQYq8uge7++67FQmu3++rRDCbzWi326yurh5DOY1GI3Z2dlRilIv2mxn52LZNs9lkfX2d9fV1KpWKgmFPp1PlW32zcVOJ4U1vepPC/t9777288Y1v5Ju+6Zs4f/78MbTPX8aQD8mN4ku5Y4AvnBgAlsmSPHy8daYMqcEiO58nIrrJxCD/X352OaI7OvaRPAl5WMtdjeQyyNGBbdtKGuORRx5RIyTp6wvXILaykZVJQx72lUqFdruthP3K5TJ2zcYv+2TTTLnO2bat2vbCKcjIxLy75eA5HnmUk+apwOFfdz9rjRr4sBwu8aoemqmRTgQM1nAMgmUg3MXSGbEVk0WZkLGIMtyuS+EWhO8IKbQC83dMivcVSl9I13VW11cprZSEvMQg4GDngHq9TnetS3OrKTrWWJjR7MV77E/3CZYB8Sgm6kW4TZfK2QrkMD4/xvAMhe2ngEangbbQiALhz7x22xqmaxLsBezt7mHVLVrnWtiODREsD8WOqVFvkEwTxpMx82LO/uE+s32hn+U0HPxNX7jfFVCqlLAdm2ycsffAnjKLsupCBTechARRgLPi4FouGuJ69h/ZZzadqdHMMRkHS2POHCd3WPRE4SJ1ieSzMZvNVCESRdENHQjh2mLa6ThYCAmRPM0JDsS+aePWDbyKx3K05MqDV3j04Ue5cuUKcRyzsbEhpC1Ob/Dj//jH+dV3/iqL3QW7l3e57777+Nt/+28r+PQtt9xCq9VScvJxHCs+gvSSljafjuOoQkh2C6ZpquQhn/uniyaybZuNjQ1e8IIXsLGxoXaC8oy+mbipxHDhwgVV+b3//e/nm7/5m/npn/5pfuVXfoU//MM/vOmL+VLHE4nVyUPq2ZIY5OF7fcRxTJiLw6HslB/353BNg0WOjZ7oa8qHVkpbJEnCcDhUXcP1WljValUhnWRilVWYxGQbhsHtt9+OYRhMJhPCMFTJRCaG67uRcrmsEEzypZJGQrLaBKhv1alYFdq1tlrqOo5Dt9tldXMVty6Wk0VU0FxpCs6HURAHjyfJ+b5Pc71Jq9Mim2Y4LUeY34wjCl0coL7hi2V2HpKbOVmYER6GiqUbfVlE/sPiPjhvdkgevKaRb9s27a02pVqJNEoJ+yG9w55IPK6B1/RYaayQL3OiPCLVU0aLEYUh3PrC/ZBqowodhHfEFZFMrYpFMk3QuerINhMz+YKC9eesoxc6y90l+/v7OFWHU885RalaEvLZgTAMKhdCDmMZLsGH3Z1dBlfE4Ws3bJyGg2YIQmW1WQUbloMl/c/3SeYJmqaxcW6DRrtBPBXdZuZnVKoVfM+niAvCfkgQBMdm8rKAWDu5ht2wKRtlluOlqqbPnTtHtVpld3eX/f195VMid2E3Ck3TcOoOpTMlyCGdpcxHc+J+rLgfzc0mWZoxvDxk9+IuFy9epNcTP4vbb7+dc7efo3W6heM7FJOC3/j13+B973sfL3jBC3jd617HeDxWXY2U45YHcxiGSiI7TVM6HcEkP3XqlEoG8/mcK1eusLu7y3Q6ZTweq13e053yy+8tv8/1IqdPJ24qMdi2rcYLH/rQh5QkRbPZfEZZ6ksdT1Q9P1vWMKZpUqvVVCt+fUwmEzRTwy256OlT+9FKzwNJ55chuwD5+0dnmbI1PlppS7luibaQCUT6O+u6juM4VKtVzpw5A8BnP/tZAAWfLZfLjyO9HUWDpWmqHNukP7RMQqWVEvV6nVpWo1ar4bqushv1fV95N2fLDK/lUXErrLZXOb11mqZ3/HCR/AO35ZLFGfVSnZWTKxiJQd2v095oc+e5Ozm3dQ6n5jALZuR2TpEK8pvhGWimRvADAcULCrSxhvsml7gfK6RSpVahvFqmVCkRzkPC4REJgxJERUTVrbLeXBcKuVrGZDxBd3QM3yCdpDSaDerrdYzCIB7FZIFwbCuyAtu0cXUX5kIEzik7dM50YAHhSMBB7YrN5i2bIqmbOstiSbSISPdTTExyPccqW/T2e4z3x+KgbTsYjgEaVDtVyo0yuZuznC2ZPTITchWaxurpVdY31skXOXEYM2NGYRU0G02c3KGiV47tXba3t9nf3xcIrrMbVFer1I06RSzGg7Zts76+royj5Ljy6Cz/ibTOrJJF+fTVQsh0cAqHYlwwn87JtZwTX3aC1a1V7MLGWBgspgt2dnYUP+rMuTO0Trdorbf4Wy//W3zDX/8Gsizjl3/5l7n99tsVk1qirjqdjpJckeRP6fUsXQ3b7Tb1el35mRweHjIYDLhw4QKDwUBZhz5V3+frwzCMZ0Rwu6nE8LVf+7W84Q1v4Cd+4if4n//zf/I3/sbfAODhhx9mc3Pzpi/mSx1yAfVED9iXumPQNI1Go3HDRZWc7wNUW1UFZXyikEiiLMvY2tpiY2PjWFtvWZaaXUqZCRCL+KPObDKkDPD1IyzJgAaxi7BtWwnqfe5zn1NdRhzH6mU5iiiTaq/yM8rEIXkd58+fVxhxt+OSzlP0VOfEiRNKggNQnsp5lgvP5VYDMzGxfIssyMjjx48PDcfALJnki5xSo8Tq1iptry12NVWXmlXDKlmgwXg+JkN4IqTLFM3UyLWc8BdDCr9A/6iO9RsWUT9SDmvtzTZu2aVULqHFGlW3qu5xZEdkWkbJKNHwG8JgRwsIpuLgdVdcXNvFsIQHMob4vskkwapYmJ6J7/noS51kJgzmKxsVGp0GjKFWEiJ/Vsmie6ZLsyKSY+RHkELWy4gHMeVamUqzIvylF6mQdL4qfZEGKatnV2lvtGluNtEMjeX2ktmjM+Eat15l8+QmVipY1KEZggeVUgVtrilpEcnGPjg44OLFiyRJQmurRWerQ8fr4Jouw+FQidKdPn1ajSF3d3d54IEHlDDdE83rrYqFt+phWAaVekWwtUcF4TJkOBqyenKV219wO93VLnZgUywLBQnVNI2NjQ1KnRKn7zjNb/3ab/Hv/69/z5kzZ+j3+7zuda/jJS95CX/0R3+kdJf29vZwHIetrS3a7bYaiR7lT5VKJU6ePEmn0xFGVGGouBDSV3p/f1+xov8i46YSw7vf/W5M0+R973sfv/qrv6r0UP7wD/+Ql7/85V/UC/yLDKnfc/SHd7Rb+FInhicLuWz2PA+3KiSOb3TYyZAVitRfuVFIhVPgGAwuz3M2NzePEWykDafEesu9xNHEUC6X2dra4lWvehVvectbeMUrXsFwOFSmJDcK6Y8rKf9yThuGIQcHB+zs7CgSkdkwWSQLth/cVgkqTVPG4zHjxZgwCdENnSIWjF5SBK7duHZIHY0wDOkv+8zmM/JZTudUR9hSDmN6ix6aoVGzamiuRpEVDGYD8kxU2eSQpznZVkb6EyJJmz9lYjxsEPUj8lh0SSsnV6jVa6ytr5FOUvJMeA/rlk7qpARxgGu7WLnFYDigH/aJZzF5nIsZesuhSAuSZUJe5ORZLj6LAW7bpVKuoA91HBx0Q6d2uka9UicbZApKqzs6rZMtVuortGot2qfFQRbOQ0YXR7QaLUxPeFEnQcJ8OVfm8+kkFWOxNUH0M3zRvUwfmpKME9yWS3erS82sUTJL1DZqwiuggGA3IJ7GGIZBq9VSJLJ7771XyHZ0fFrdFhUq1CuiIz04OCCKIm677TY2NzcVdv/8+fNK/G5/f/+GXb7dtDE8A8MTvI+KXoE+JGEi3N20nMpmhZUTK5SMEovDBf2DPrPZTLGTuye7VDYqfOvLv5VPfuiTvP2fvB3P8/jEJz7Bz//8z9Pv99U46vDwkPl8rsa3Gxsbx3YJBwcHAnJ9FQJ7yy23sLGxIcafV8enhmEQhiF7e3scHh7+hU0vbgp7eeLECT74wQ8+7vd/8Rd/8Rlf0JcybiTq9mwZI8mQh+LRhW2WZWoZXK/X0W1xKGdhhm7fOPdLwbDZbEa1WlX48uuThGmaJElCnufcdttt9Ho9VeEfTaC6rnPq1CklhiZZyK7rKglq6SX9Ld/yLdx+++24rqt4DEfvcxSJpen6+jppeo2fIMdTq6urHBwcqMWdJM/V63UO40MmVya4Ky7ttTbb29tKI8fJHTztKq8jh0IvONg5oL/s0/AanKqeEmOSI/c6SQUCaTqcEs5CUi9ldjBjt7fLeHVMtshorjTR0bFLNlquCT2fjsvi0oJkmaB9u4bxXw30D+rYr7MJPxgS9kLcFRe7bFNpVsT+oxCjqMAKBA/DLQjiADM20QqNeBYzMAf4jk99UgdNHP7T4ZT5wRw/9/Ec4RedLTN0U6e0UUJDg0NISqKb8DoeYS8k6kXoDZ1er8fKygq1zZpIWmkOHbjUu8TB7ADjUYP1jXWKtODg/AGxEzP35zRrTfJxTtSPcNoOzqrDPBWM4nSUMjs/w1sVsNd6V4gPJpOrcFYydh7coRbXqJ+tUzlZoVarceXKFaIo4pFHHqHZbLLWXaOUlyiigulkekxcz3Ecms0mYRji+z6GYaguuCgKOp3O8e5T14Rcx2GIWTGpnqqiX9ZZDpdkreyahljNpm7VWc1WmU1mjA/GLBdL6o06SZJQKpXwVj2S3YTv/rbv5tu/7dv58bf9OD/0Qz+k5CziOFbL8TRNMU3zGMRcXqMsnIqioN/vU6lUaDQaaqcGYk8kxT7DMKRcLisU0p9X3BSP4dOf/jSWZXHXXXcB8Hu/93v8xm/8BnfccQdve9vbbqjl82wOyWO4Ed73KErgS81+huNchBMnTqjDMo7FQk0ewlE/Is+Edv+NQhKIpKiZFO7a2tpSB/WlS5dYLBZsbm6q5NHv95WcQLfbVS/o9dcYRYJoJdFB139v+efSJUxyHvI85/z586RpyurqKpZlKar/USmQe++9VznOGYZBp9PhxIkTPPLII2x/fptytcwtL7iFMAyVY5xjOLTtNnbZJpklFHnBzuEOh9NDKn6F22+9Ha9z/H5J7kgxFweT23LZPb9LOkupb9UxNZOSXWKtu4ahidFTMhWw0nSWsri8QHd0odv0jT7avkbxAwXh2wS81GmLZW64H4IJ/f0+83SO3xa8EQpgDBWrws7+DjNzxurmKpuNTfJASGAvkyX9R/votk7Da5AHOVZT2G+Sgu7rRAeiS/G2PDRPI9kXAnQLY0FsxWiaRqfTwbVdwl5IPInZPdhle7FNrVFjvbFO3a0zHwo0ltE0MEyDWqmGHdrots44GxNGIWWvTKkosdxdkkc5dssWz6EmNIxM32ScjpmP5oQHIWWnzNpz1rArAlhw6dIlJXG9trbG1saWWuwHVsDFSxcVyMF1XcrlMq1WC8/zODg4IE3TYz4kEuIsI5kmxJNYmAcVBYsLC5IwoXKqgtO8hvyzbZtZb0Zvp0eap+ROzjwQHUC9LpJENssggFKzhFEzlEbRG9/4Rj71qU/xpje9iZe97GUsl0tlwVkqlVS3HQQBs9nsmGqrHGWfOHHiGLz8qOqA5EF0u121y7g+nuxc+0JxU6Ok7//+7+fhhx8G4Pz583zHd3wHvu/z3ve+9yn7MDybQzJ24do4RTIkv9TxRFaf0vVMhuEJFvT1zFsZR6W4pXSvRBDBtU6pVCopHwRAKaOGYcj58+fZ29t7HGtaVkdHZTFkSDz3n/7pn/KLv/iLfOpTnwLECyLJQuvr60pZ8ujP4WhID+ogENW17DJ830f3dWajGcEsUGgocWEQJzHoQsaiSAuarSZaISw3F5PF46TL5Qs1y2ZM5hMWwwVmWSxm03GK7ujKqrHICjRdQzM1pntT7KYtRi5pQWImRL9wVYL5X2q4HxI4+6gXCf5B1SKYBaRmihZphDMxWkuzFCqwSBesNddoak0M3WAUjzB8g2gU4VkeVskSCLK68HaO+7HYtzg62SLDqlsUZsH+5/fZP7+PUTPQDI2yVsbObDXaWIZL3I6L3bSp+3W2KlvkRc7uZJfIi6h2q9TNOnpfJ4syxvMxEyYkYYKXeBR5wTyYo9U1qrdVseoW8UBwPdJFilUVO51SXqJcK+OuucyiGY996jHmA+HvffbsWW699VZWVlaEpISp47Zd4jAmnaRKzlzXdRaLBf1+n729PeI45vTp09RqNeUGd//99ysTHDmuNCsmhmMQDSMM26ByawWn5rC4tGBxZcF8Nmdvb0/4MbTLnHrOKVqNFnqgY2WWMhTKsozESsi8jMVoQbAfsNpeRdd1/uzP/owrV67wQz/0Q7z61a/m3nvvVUVVr9dTfg8yIW9ubqrRkez+pSZYnuf4vs/m5iadTgfHcZQf9EMPPcR99933RVdsuKnE8PDDDyvjlfe+97183dd9Hf/P//P/8J73vIf3v//9X8zr+wsPSWV/NqOrjkJMn1AewxOHYRY8MSZajqKWy6U6PL/QkkvCTBuNhoK8HuUe9Pt9ZVQixwJRFB1DV8xmM97znvfwlre8hfe///2K+XyU1WpZFnmeq5+D7GJkwpKVoEwOkgnqeR66p5PkiZDHvlpxKX0cBHrHqoqlsasLg5gszpgEE8WYlSHRJnmRY3omRVLgmA6pJ/wn7MTGKlkEi0BIVcwSpvmUg8MDRrsj3BUXq2Kh2RrLO5akr7+a6L5fw+k5wou5F4IGftnHt33cikATJaHY1YSpGH3YZZum1yQdp8RxTG/ZQ3M14lFMtV6FFGbjGc6aQ+lEiWwhILSGa0CO2H1YYrHc3+ljlkwooGpW8QzRKfV6PWbzGW7bpXGyQdNt0tJblMtlBuMBoRNSPVOl5tVwJy7FrCCMQ4bpkDzL8WOfIhXPgeEZ1G6r4Z/wydOc5ZUl4WGI7uhomUYVoedVOVEh0zIufOYCe5f2yPNcoIHOnFHPumZpzPU5w8GQ0e6IVqulGMPSYe6RRx7h4ODgGHQ0CAKxYxqP2d/fZ2dnh/l8jtkQnz0aCqG/8pkybtclGkRMHp2QRZnyo07yhNbpFqdvO0233uVE/QQlp6SEIsMiZKbPiMOY/Yf3aVVbPPjgg/zDf/gPcV2XT3/603zP93wPP/dzP8d0Oj0mASN3JqZp0mg02Nzc5LbbbqNeryup8itXrrCzs8NkMsFxHNbW1rjzzjtpt9sYhsFyuaTf73N4eEgcx2r0+0ziphKDnI2BgKt+0zd9EwBbW1v0+/1ndEFf6rgemZRlmXJ2eraEHNUdNQm/PjT9qqje8okTgzRGAZ4Q8heGITs7OwqLDSIxZVmmEstRO8J7772Xz3zmM9xzzz1sb28riWc5GpCSFadOnQLg//1//191j3u9HlmWHXODk4zz4XDI5cuXVdVnGELKQu5AZAKS+k+FU5DNM+WvLF/GiIg8ydEMTSCOgpxWu0WRF4zmI9IoPXbPNE2jUqmIjsAoMF2TIiyoVCqEVoiWaei5TkJCkRUUSYFZmJi+yeHOIYtQdBhmyRQyFH9vSv5Xc1iA9ioNx3OwypbwUNYF/8SpODiuQzbNKHJxz0rtEm7dxXZtakWNcCoWkruTXfG1MxPLtCiWhThAWg6VWyti/LIbUCDsO+srdbAgGQpTH93QKfKCMmVKjugg5fPutB2qm1WaVhM7sBn0hS5Pb9bDOelQrpepFBWMqQEx+F2fSq2CMTdIlkJsTtM1ShslqrdVMUpiMR3sBQIckeUYC4P11XU6t3XQbZ3+I30G2wN172UMBgNmy5lI+kHCcrRUXiErKyvU63WyLGMwGCiTpFOnTrG5uUmlUlHS7UEQCDjo3i6BIRjiyUzwL/w1n9LJEiWzRHlZJl/mStdoPB5jVSw6ZzuiKMrLtL02FOL5z7Uco2VQGAX9C33MxORd73oXDz74IH/v7/09iqLgd37nd/grf+Wv8NGPflR5Kti2fWwUK0EW9XqdarUqbFmvAkVk0Xp4eIiu65w7d467775baTAtl0t2d3cVQuuZnMU3lRi+/Mu/nJ/8yZ/kN3/zN/nIRz6i4KoXLly4oST0X6a4nssgq9ZnUwchH6QnYn3KMD2TLBLCZ08UclTyRB3DeDxW1oFxHKvZ6HK5xPM88jxnuVwqrwe5NJtMJsekLSRaCURHcO7cOQDuv/9+xWSV+4DDw0OWy6XiUCyXS9UxHIXDSnvEo9cv0VCao5FpGXFPyDxLrX9MSPKELBAGL2hQMkpYnkU4DwkyIXFd5NfumTQa0jQN3RXmRVoo5EdyL4cQMjI0XSNPc0pGiepKFc3U2D+/T2qnkAuhPbNuMvknE4rVAu4H7Qc07LqNXbfF6C/NqRpiBOOaLulUSJiPx2O0qvi7Rm7gJ75YdGsaqZNilkx816cIC6ZDcbiYnknlXAWrJsY5WZDheA61dg10iCYR88lcPCMUlPKSgrHK599ZdXA7LlWq1PQay5k4fPqTPmbHxK25NGoNanaNbJRhlS3qK3WSUcK8P1djEbtiU7ulJjyjM+EZnU5Tskg4wDXKDU49/xR+1ccYGYS9kCIvVJeYpqlgz5dtKq0KVmahJcJbQcpnb2xsUKvV1PNULpeVzHu1WlVGNrJI0B0dq2yRTBLSMFUM7/LZMl7Jo5bUMJdCYXYymYixaZHirDjYDRs90XFih3q5ju/75EVOUSpwag7z3pzlwZITWyf4d//u3/Hxj3+cF7/4xZTLZZ773Oeyt7fH9va2UnkF1HszHo+VAqt0qJTOcBKFdXBwwPb2tmJqS09oWXxJkb+bjZtKDP/8n/9zPv3pT/O6172Ot771reolf9/73vekBjl/GUJWqtcrjj4b9gsybNsmDAV7VIr73SjkOOnJOA2Ssi8x/xIFdLQVtW1bHcrSp1YmTKmNJBOn5DPIuftRB66jfIazZ8+qMcCDDz5IvV5XjGXgWJJZLpc35Jj4vs/JkyeVr/HW1tYxxUy9qgtcf3HtaxqGIZJGkImDoWqhL3Wq9arQrZmOydOcdH7tnkkp8GazSb1Zx67a5GlOHuZMwgnTeEqxKCjsQoyT5gkNr0GtWyPPcg62D8itnGyeUT5ZxjhpMP/ZOYVRwP8N/CuBs3faDoZpkEwSmn4Ts2riFA7pUhiy2K5NZEfM4hle4bFeXUdDE1VyRafUKWHlFtpUU8+ubumUtko4HYciLkjDFNdzKTVFd7CcLQnnIen06sGYOEK2+qonhqZpeF0Pv+3TsBu0rBZaKvwceuMeeSkHHdyKi27rxOOYLMkI05Dx/pj+pWsKorotrsVb9zBLJlmSkUwTkmkikEKJyannnsKqWIQHIcFBwO6OMPg5am2bGilWyaJu1SnZQpLddV22traoVCocHh4qT4eDgwNldWlZlpKhr9fFYW5UDXRLZ7I7YfvytiCJOhrlU2XcukulqFBJK+RRruRWNE3DKlu4XZdGs8Gqv4pXiP2KbuiM4zG9oMf+9j77D+8zOBzwFV/xFfyX//Jf+MxnPqO4XnEc8x3f8R38zM/8DJcvXyYIAprNphLjk2MhSTBtNBpsbGyonZ9csst3VHpLb21tKbvQm42bgqvefffdjzPZAXjXu971jMwhng0h54YSkinRDM+mxCDn6iC4F0+k+KoZ18ZJVvnG0LajXAUpOidHMtf/eRzHSgZbejhUKhUlP9xut2m1Wor8liSJSgxJkhCGIZVKRcFUz549yz333MMnPvEJXvnKVz6uIyiXy3S7XVUJDQaDY38uxzyXLl0CULDFlZUVKpUKrfUW2r6GMTdY2VxRGlFFUhAcBORRjtsRc+WyXsZcM2mWmpieQBaZJRPNEDBe+bLWajVx0CUQTkOVaEp+CWJBGIsGEfEkprPWIQsypoMpPatHy25hzk1KWyUWX7sg+pEI9+dcih8q0L5cw3yhib6mk6dC9qK11aKf9Fl1V/EdgVKKioi8krMYLaj5NeIgJtMyrly5QqVSobZZI+kl6EsdvGvPgdfxiIyIZJ4IraNySRw8k4QwCDEQbGazbGIsDLTSted9Op/i1B0qRYVsnGGmJovJAr2hc2nvEmZuspquUm6XsSoWwU5A2SmzSBeE05DR5RHNLUGAk1BewxZqtGksRnfxMCYNUtyWi7cq4LSTgwmzZEZYF6Y1Utp6MBgQGzHRIqJpNGl0Gxi2ofzAl8slly5dEonu6tjTsixOnz7NfD5XncN4PEbXdSrlCrP5jDiPSXPBe/F9H7/li9HkRKOhNci0DNc+YkOsC4FB0zdxxg5hFLLIFsLHpAiIsoh5b066k9Lr9Dh1yynlTFetVvmN3/gNPvrRj/LRj36U97znPbztbW/ju7/7uymXy2RZpqxYAQX9lt1RvV5nsVgck9UPw1AszMtlpSJws3HTfgzj8Zj/8//8P3nLW96ixgX3338/h4eHN30xz5Y4Ok56tvEYQMwhpSbK9RLh18dTGSfJkLA+OY6RD6JMDEdHQYDyxJUSKZPJhHK5jOu6Crl0NLke3Q+USiVuueUWAD7+8Y8fu+cS461pmlKolCOj65nVvu+rF2l/fx9N06hWq9RqNVFJdlxYgo2t9g+6raObOukyxXAM7JpNjRq3POcWkYSu3ispfHfUAKharQoI5bktIQVd6VCpVqBydY+R5hi+QTJOyBYZ3VNdvJInOhBHdBPKt/gHEtK/nqLFGsUrC+hdrapPlQRqZjtidX0Vx3eI+hEawl1vnI6ZM2c2nNHwGiQzQdDa3RXIIbNqstxbquuHqxj+toNdsxUqq9FuYNUsyl4ZcrE4z5YZ6SIl6kcUeaEMZnqTHrmTU2vUMFyDEiWikQAVTIIJVwZX6G/3ycKM9pk23XNd6s06lmbRv9Ln0ucvES0idR/thkBsWZ6F3bCxagKttLi0IDgIsOoWlUaFulsnn+ZEs0gRGdttwT7XfI3BdEAySNAKDV3X6Xa7ZFmm9lYHBwdcuXKF2WzGcDhUXaP0Eh+Px4wnY3I3xygM9ES/5rXQ7zFMh0RuhG7o2KHNcm9JGqQKNj4ejzF8A2/No1Qv0bSbdLwOqyurnDp7ilK3RGEULPYX3Pvxe1XCMgyD7/qu7+Jnf/ZnaTabXLp0ie/93u/l+c9/Ph/84AeVrafsEo76MBRFwfb2thLqkzpT8/lcETq3t7ef0V70phLDPffcwy233MI73vEOfu7nfk7R0D/wgQ/wlre85aYv5tkSN9JMerZ0DFmWKXTCysrKF+zQnso4Ca45uUm/BdM06Xa7NBqNY4nhaPUsbRpXV1dpNpuqo5CyFpLsA+L+yS4CxIF+5513AmJhLXcA29vbalF9NJ5sxGcYBru7uzz88MM8/PDDhGGo5s1O20G3dYLdazjxohBjnywQCcjtirl33Iux6hZ5kpMbOck8IU+uMpRXVpQn78HBAZVqhcZmg4pTIV0IW0ujLtA/uqmDjlDyRGfz3CYr9RVcxxVWl+NYSXRHvxCRn8rRLmvkfzOHGHRDp3y2jG7phHsh6JBnOfP9Ofv7+1QqFWamgM8G04CW36JkldRiNXADNENjsj1hdjg7dq+cpkgORVpgOiadEx2c1lWzpFiY6uRpLryU+6FSAsjznEE4IM5imvUmekXH0zzWSsJHOsgDeoseV85fYTFY4Nd9Np6zQX2rjuVbLPtLHvmfjzDcvSYFbZZM0T1Ygo1c2iph+AbBbsD8/Bzd1inXyqw2VnFzIXeyWCyUxa3ne6ydXUM3rsJ+MzFfv/322zl16hStVkuNIg8PD+n1eoxGI5IkUSq9pmmK597WhanQLMa3fOUVkeUZqZPir/rork62FEiv4faQLM3UPiBOhL+1u+LiWi4NrUHFrHDm3BluecEt5G5OMAo4eOSAvd09sizDcRx+7Md+jIcffpjXv/71lEolPve5z/Et3/ItvOhFL+LSpUvs7++rZbN812ezGZPJhNFopCQz5L6iUqmo8+tmdZbgJhPDG97wBr73e7+XRx55RKFaAL7xG7+Rj370ozd9Mc+WcF2XarWqnJrg2ZMYZLKybfspzRClEuaTwVYBVeVLotzRkMQ+uQSUjGM5r5XqktIqUUIF5WxZOrXBta6hVqvxkpe8hF/7tV/j93//94Um/9UFtGR3A+zv73NwcMBkMmEymRxbYsuoVqsCcno1aaZpyv7+Pnt7e0JyoOsRTSJ6l3tqadef9imygizMMD0Tq2YRDSPSLGUwF251WZERj2PF+ahUKoRhqKrNwXhAYiQUQUG8FIQwvSpQPmbJJJ5l/OmHIt77H0zuO18mngleQTyPieaROJDbOtF7Iopygf4/dLLvF0gkwzLwN30h/LcQ8hWD3QH5PBe+wa06M3NGb79HQUHLb9GpX8W4ZyGHwSGT2YTx3phoGB1LtFZV7DPkstvturjrLpmZMe6PCfuhMOg5iIj7Maurq0qfa1pMWcwWNEoNmqeatJttTlZP0qq1qHVq5FbOlceu0N8VBjutjRatsy1CJyQOY4JLAYsri2tyHLYukoMjeDf+lk/pdIk8zpk9NiOdpUqrq11qY4QGeSaegW63i1/2BVckL5jsTIgj8fPa2Njgrrvu4vTp09i2rfZxRVFQLpeVbHulUuHcuXO0Wi2cqkOhFwx3h5iGqeSy6/W60lrSPZ3d/V3iaYybupCi2NiDwQDN1nC7LlZVKN2G+yElpySEATeqaIXGwUMHPPT5hxSnoVKp8Au/8At87nOf40d+5EfwPI+iKJTcuFQ23t7eptfrYZomGxsbNJtNsixjOp2SpqnyjcmyjG63e8zp8unGTe0YPvGJT/Brv/Zrj/v9jY0N9vf3b/pini0hTTCAxx2SX+rwPI+NjQ2Fg5bt5pN1DlK/psgKNOPGCc4wDCqVCtOpMHdfX18/5sMgK/ajpjlHo9lsKgGxlZUV7rrrLmFKf5X5LNFPMkGYpkmz2eRrv/ZrWVlZwXVdWq0Wruty6dIllsulUlOVxDt5LTciu21sbLCzsyPw/b0eeZ7TbrfF0nizCbtwcOGA8kkhd1xoBSkp5tLE9EyctsNjn34MPdJx6g7FvGAWzKhrddJliumLV0WSpy5cuCBkP3SDptNkcbAgcUUlWqvV+MgfxvzH92mkQcC//bDFIrR42V/JeP0Ph9xxxxhmsHb7Gk7bIcxDkl9NsP6+hfEeg/i2GPONAt5q12zSKEU3dHzHF9BIM6dSqZCsJMyvzNm5uMOZLztDraiRlTOGkyGaJ4QGK16F+WBOKS8J+fCr9870TPSO8HBIRkKmIppFZGHGtD+FAuyWTbgnGNrtDaGfNBqNCIyAdJDSPtHGXrXR+zp2ZGPVLSb+hMnBhMMrh5RLZdyaS7VWZe3MGtPxVCym+yHJJEFf0Sm1BU/EaTtqEW36JvW76ywuLIj6EfE4xm7ZuC0X27IJkoBS9YiDoQGJn3D42CH6WKd7pku5XFbjSt/3mU6nak4v320pgXHhwgVWVlbY2Nhg5I4EOTGylf2nZFkbrkFWziisgtlyBkuwbAvN0sAXlfxyuaTVauHXfExfmDSFhyFNv0nltoqwv92ZEvdjLkQX0D2d+XxOqVRic3OTX/iFX+BHf/RH6fV6OI6jJO9/8Ad/kNe85jW88IUvVHIfct8ix66e5xGGoer6n0yS/AvFTSUG13VvCN986KGHnpHU67MxXNdVIoHPljAMA8MwODw8JEkSsSg7Imh3fUgBtDRIn3AJDaLyllwBWe1LzXtJ9HqiKJVKiuuwsbHB3XffTRAEapl//b/1PI8zZ85gGIZqk2XlL2ejcvEmyT9ZlimZjWOf7+qf93o9RaazbZtKpYLjOEKV9WRNEIDGMX7bJ01TYmKswBJcgZKFXbYJFgG1lRqJlzCbzCj7ZaKDCLtt43ourutSKpWUPpPneVQrVSrlCsOp4GJ89IE2/+hHc051cu44GfPXnrvkgx+v8JFP2cQ/k/C6N+S84E7Yv7BP93RX6Pe8KET/xzrmPzOx/rFFdDbC/EYTu2mTH+QYnkF1tUp2JSMYBsR6TKvdIlkkZPOM4WAoRiNLk3ajzaXFJQpDqIcu/AVu4BL1hKaRpovkoNvCzCbqRSSDhNXVVXp2j2AvYDqYUskq2A1buMMlBdWTVSVRkqQJwTDAci3Mlsng/ADv0KPWrJGv5Ay3h8wPBJPZLJmsrKwoxFusxThzh979PYyyQfNUk1q7pnyr42Es1FlvrRJ1ImaPzgi2A5JJQuWWCn7kk49zMiPDcA3G4zGj0YjYimEBu+d3aa43aTabmKbJiRMnFAxaouls21buafP5nMlkovZrG6sbFEkhEG01S/FrpKvc5q2bjHZHzMdzkjQRYowLMXIqV4R2l+/7wpWu45AuUpJxghEabHW3WLaXDHeGpNOUYBIwSSbKKVFqi3U6HSVZ8yu/8iv8wR/8AX/wB3/Ai170It761rfy0pe+VHUEjz76qFIZWFtb+6JMN25qlPSKV7yCf/bP/plq6TVN4/Lly7z5zW/m27/925/xRT0bQrqPSVTNn6dg1VMJyRU4Gk/F0Q2OoJMWTz5OMk1TVfay6i6VSlSr1RsmBYmcSJJEwUt931eKrb7vK0z5jb6Xrut85CMf4bu+67t43etepxigKysrqsqTf1d6Q0i58OtDyhXLvcdRJ74gCLCrNqVGiWgYwVUkbpAHFLkYJ2mGsO7U0EhnKeVWGc3QGE/GzGYz9i7tqe5R+j1IDkecxqycWME3fczM5od/uOCByzY7A4vh1OA5JyJuWY+JEp0Hrnj8zv/dAlMnm2fs7eyRail23SZ6bUT+t3O0VMP5AYf4c7GooMtC8tqsmjTPNIXPwoFweNs4s0GpWSKYBeLzajDbn6FrOnbFxrM8cRi74rAND8NjMim6cXWU4xkUs4KG38Bdd8nXchbLheg084LgMGD26AzHEMzb9lYbr+oRDSJmoxmJnTDNpgTjACbg1l1m8Yz+pT7TQ2E1KSXToyIiaSdYKxbxIqZ3f48r911hMV1g+sKWkwLCgxDLt2h9eQt/yyedpow+MyKNhax52AtJpoLlaxgGpWqJzMqYDqcM9oSnQRRFCkghOQ1hGCp5irW1NdrtNrquM51O2dvb43Of/xyP7T3GcrAkmot3SyKednZ2iOKI7pkup287TaPawLZE4WPHNmXzGhpILsHNkom75oox4jDGSRxO3HKCztkO9XKdttUmmAeMRiN1DYeHh6yvr+N5Hq94xSv4ju/4DkzT5CMf+Qgve9nLeNGLXsSHPvQhkiShXC4zm83Y399nNBp9USyIbyox/NzP/Ry9Xo9Op0MQBLzoRS/i3LlzVCoVfuqnfuoZX9SzIeSN/mJrkNxM5HnOYDBQMr4ynshY6EZhlkyyOFMWjE8UrVYLQI2pnqxLkGxleU1HmdDj8ZhPfvKT/PEf//ExOOlwOFQJzrKE7sxv/dZv8du//duqepMPtpyXyh2HlAkYDAaPsz/0ff8Y7ltWTRIDDsLlrcgLoqE4LHJyMi1TTGev7omF7yKkolewKhbL5ZIgDgTvoRCvi+d51Ot1cchJgb6yQ321zuUHdNJgCWjcd9Hh3ks2ugEvfcGCsptxMDL5/MMOe9uims1nOfv7+6RmKqCePxVQPL9AG2p43+eRHWTC+U1HjHxqNp3ndHAtF/ZgOV3SWGvQ7XYpooLZYobv+pixiV/xyYyMYlEwWUwwGgZFXhAehMck2aXqqF2zMWKDmlHDbtqk7ZRlviSLM4q0IOyFTB+dUizFnN5pOWimhhEYpHFKYRdMmOB7PuWsTGEVBHnAYw88xnw4Vw6AeZ4LdNGpNp07OhROQTAI2L9/n71H9khSIUJoeELPKJtnVG+tUn9+Hd3UmT44JdgTC/Z4HFPRKnRXxZ6r1q7h13wG+wNGByN2d3cVOMayLFW8yOdxNBrR6XR4znOew5kzZ6jVaiRJwnZ/m8d2HiM4DOiudFlZWVF8Hqk4MEtmNE40WO+u0211BXLIqBAdCnb94eEh9913Hw8++KCSGZG7neggwnd81r9sHddzqVGjalcZDAZsb28rQ6zV1VWe97zn8Y53vIP/+l//K69+9auxbZuPfvSjvPSlL+VbvuVbqFarQh23ViMIAkWe+wtHJVWrVT72sY/x/ve/n5/92Z/lda97HX/wB3/ARz7ykWPSsn+ZQ1bj8/mc0Wj0jFiEzzSkqqJlWcfu71PtGECgkzRdU/aSTxRS+VGSZ47O+Q8ODrh8+bJCBR2Frcpfm6apZJPvvfdezp8/r7x0wzBUpDiJFpHIqn6/z8MPP0yv12MymSghQ+nYJq9tOBxyeHj4OEMWwzBot9sKtieht2EYquuvNK8e9v0lpi6+ZoSYqxd5cc3fmVTJXhiOwWwyEyzcxbUFriTVJUmitJrchstwCs87t8CxU/JC457zHp94yGVzJeGlL1hgGgUPbduMxoZYahYWeSgOkdRJMRsm4a+FFN0C7X4N74c9tFwTo41ZQjSKMMsmK3ev4DgO1tASCqdlm/F0zGK8YDQf0Sg1xOLWF0Jzw/0h5y+dx2oLJ7vwMHwcUs2qWrgrLo7uUKGCVbWISzGFJ/wriqIg6kXMHpsRHgpmst2yBZt4qTOfzUmLlFE+wqt6NMyGQFg1yiwHS5aTpUrUshtvdpqcfeFZKhsVkixhfjhn9/5dolGEVRdQ1nSREh6GOHWH1le2cFdcosOI+cU5aSjMiYpJwerKKisrK1RXqrRX2yzGC6b96bEiQhYYa2trzOdz+v2+0iFaW1vjK7/yK7nzzjuFrHXNYjwbM7w0ZLlY4vu+2oPBNSkMd9XFr/mU7JIQZ8wLlntLZoOZ8hN54IEHuO+++5gGU+wVW4ATJjHJMKG+Uaez1cFKLLzMw9AN5eswHA4VWfTEiRP8xE/8BB/5yEd43etep0h9q6urnDx5kq2tLXzfR9M0FgvhQnez8bQTg0Sl3HfffXz91389//Af/kN+9Ed/lL/+1//6TV/EszFkNR4EAcPh8EuWGMIwVBV5q9U6Nj88apzzRGJ6MjRNw/AM0kX6pNwMaR9ar9exLIvBYCAq2iOMaNmhHIWtpmmq4HISwVQUBUEQsL+/TxAE6oWSO4x+v49pmoo5/7nPfU7hz5fLJeVyGd/3j5EMZZsul25HQ0FUr5r5eJ6n5Cykv3S5Wxbyzz0BvQ1zkTSyQCReuySqwowML/cwSgYFBbqmQ4JKrBKVJZeTYSignWY9pdLY56ufu4OmFcSpxsc+7/PgZZuvuC3keWcC0gwqXQERrdfrOKmDaZiCN9Ky0U5qhP86pCgVaB/ScP+xK/gHGoS7IfE0xvIsVu5YoVqvCsnuXFxTlEbs7eyxP9mnbJeFO52VMx/O0dA4ODzAqBsYrjAMSmbHEV6Ga+CuupT8EhW9QmO1QWWlgl2zxcjJFYqus/MzFjsLirigcaKBXuiUihLTyZQwChklI+y6EP3zDI9qs4q+EHBP+dzIZ8qwDNbOrbH1ZVuYJRNLt0inqVp82y0bcjFaooDGcxuUTgm+SdgT9yMaRix3lriG2Al2T3XpdDusllepemI8elTjTcKsK5UKk8lE2WlmWcaJEyf4mq/5GtbW16ACk/GEnUd3eOihh7hy5YoidpbLZbHAvtpxRZbwzc7zHNM1WauscaZzhkZduB/O53MefvhhHnjwAWb5TEmRRz0xQu2e6bK+ss6KvYKWa/R6AkV34cIFJpOJ4lWtr6/z8z//81y4cIF3vvOdSqtsZ2eHl770pXz4wx8mjuNnRDZ+2stn0zQ5efLk41r5/9VCCnQB6tD7iw45NgEUcexoHGVpy/n8k4VZErPqPBIIiyeKowf+0d3K0e8ljVEcx1GS13I5Nx6PVecxmUyYz+eEYag8HY7Kmnuexx133MFDDz3EZz/7WeUfLufCRwlyILrVxWKh5L+PRrPZpNVqKeG9LMsU5Fj+3VKlRNgKYQm+5lPv1ikmhUAelUz8uk80i0i0BLuwqVpVtE0NMzDRdKFkariG8tSVFV2SJHiex3Pu0omMJbWqxXPOTLnvsRphrPN7f1ahUx/z8i9fYJdMvubFNtlUQBqrfhXDMdQuxmk7BM8PiH41wvkeB+09GvYZG+NHDeYX5iwuLOCUqPC1dTFrz8KMaBHh6i6GaTAbzkS1bpTBA6MhioLUSzk4PBB2kqYQ78uTHLthq3ukm2LvoFuCBKgZGrqlozviP3NkEo5DlheXZIsMd8Vl9fQq/Ut9amaN0WykXPy63S7GwGA6nVLulPEsj0AL0FxNJX8Jzyw1S5ysnBTjo1BAdINhwGQ2obpSxbZson6EVbEony1jeAbhYUgWZWRxRhaIsZu/5lOtVyl/WZlklJAMxbX0J336/T71ep3V1VVlqSnBNEfFGyV3xfM8Fs4CbV8jiwU0dD6fK2JlURRUq2IpP4/npEbKtDfFd3xqjRp+7lOySqy31zkYC9i1lAqv1YR2VDgJGR+O8V2f+mod13cpjUvMizleyVNdVp7namm+u7urYPW9Xg/DMPjpn/5p7rnnHl772teysbHBq1/96ic9D54sbmqU9I/+0T86xnj+XzWOagR9KRLDZDIhSRIMw3hC6JkcJ32hjgGEh7Fu6qSLJ/+7ktCUJAlpmqpR0VG5bxnXj5OkeJl8ceAajE9C6uTfl/BBSXT79Kc/rQqOOI5ZWVnh5MmTxxKi4zhPSPWXyVyaoUj01urqqvoa9XqdM3eeodlq4oYulm5heIYaJ5UrZcHYLSzFxi20QsBVCyjygngsqjHTNGm1Wtx99910u10sy2Jra52/8+pzbPctzm71WWuKinyyMPhPHy9jGPCON83IQ4F40R3xCubLXI12prMp02JK9vUZyU9frej/CRi/Y1A5W8FwDZZXlkT9CMM3sOs2SZYQEFCEBW23jW3ZTAYTFvkCIzWwTIt2qY2pCWHCg4MDMifDaThky0wRxGTIKthpOJALC9SDgwMm0QR7xcZf89Es7dpIZ5TS2ezgmz4Np3FNq8nW8boe9XadklNC13V8fOq2EEB0XZeDgwMODg6I4xjdEknJaQkr0slyQpInjPZG9Pf6BGlANImEpPqqi9f1sGs2pm9S5AXpLGX26IzFpQXkws5Td3Tm+3NGgxGz2YwrV67wwAMPMB6PaTabdDodBV6QyKU8F+M9y7JY3Vxl65YtTrROsFJfUc/vwcEB+/v7ah/QaDSwXRuzbrLMl2xf2WYwGRDmIdpSY7O6yW233Ea32z2m6ZXoCUtjyd5oj52LO4RxSL1VZ7W8ympple5ql1arxfr6uuKUxHHMeDxmOByqZPH617+eN7/5zayurrKzs8O73vWuJ33PnyxuCq76S7/0Szz66KOsr69z8uTJx+0VPv3pT9/0BT2bQo4kvhQdgyRrgaiEb4TsAZT43BP9+fUhHcaKvFCwxetDLlevV6OUo6ujOw3f95WcsazMK5UKhmHwvOc9j/PnzysC0OnTp5XOUhAECqZ69913A0JS5ahekkSCzGYzdfBeL6aX5/mxzy6rT7kU3t3dZT6fK7c7XResZGfVYXl5KSw2Oy6MxZioXC7jbQqtHs0SCq3pLMXetJlP5jimAwuE/HWtRqPRUJ9Pokj+zt+xybIl7/t3EXedG7H8fIvJwmCp2XzNN3vcdjJgfmFO9VxVQFUPQrJY6AWxIuRmiqIg1VNqr66hXdawfsWC14K+oVP6KuGOFk9j8ijHrJl4VY8kS1joCxhB3a6zCBdMhhOa7SZe5uFoDnqqMwknlEolDg4OaLfbeCsCXRQcBDgt55i9qVk20W2d6d6UcBkShAGaqdGsNRWLO4syooOIdJ5SrpYxQxM91RVoQNM1zIaJEV6VCokFVyKzM3p6TzHk77//ftbW1oTgXdnCcA1W7BXGgzHLRGhzzQYz5vocz/UoRSXsuhix5XGOVRIdWBZnLHYXxNOY0okSdlOMorp0KfklDvrCAOehhx6i2Wxy8uRJOp2OMvORHAKJBCyVStTrdSqtCvFeTNkrkxap0gCbzWbUajUqlYqS/sYRiK9gGbBcLGm0G1TSCvpUZ721juZee/c0TWMRLLA9m5yc0Xik2N1hLPTFqrUq+/19VSRGUcRoNFL8I6kA8Hf/7t/lO7/zO/ngBz/Iv/pX/4rz588/pXPhcefEzfyjV7ziFc8aJvCfZ3wpOwZpVykfzCf7e0/r6/oG8URIMJulG//4bdvmlltuoSgKPv3pT6sEsbKyohjNSZKImfxVjkKWZURRpPSVJI9AJo4rV66QpqnqGKRQn2ma3HLLLVSrVZrN5rHdgfRYyLKM2WymRNRAJIZ+v89isWBjY0ONm9bX13nkkUfUgjNNU8WaLpfLKrHYVZuoHDE7nDFNpvimr8QGdUdoKWXLjJUTKzjbDsEkIC5iltMlK40VknFCvVtH0zVVZQ6HQ1ZXVzEMg2/91hpf/dVDHvr0lCLyKa/7fO2LdLTMZ3FFIKNm52dUbxES23k/FyORmWCtHh4ekmYpw2JI7Y01yttlzP9owivB+IiBc8IRPgKWRjJO0C3RqWm6xryYo801PNvDSQUrOHMzojgiGAbYdVt5dluWheGIvUI8iIl6EXbdxixfezZ0W6e2VaPQC3bP7zK6MiLbzET1rEM6S8mTXIx/gqucC6uKa4ouTe6ZGo0G1dUqYT/EmlnC+jRfoFWEoY40vQ+CQEllex3hThcOQ2bzGYEhvBwW8wXhLKQRNcT+pQA08NY9olEkeAXzlOnDU9yOK5bqhYOd2zRva7K7v8tgMGA4HDIejzl9+jTdbpd+v68KMckmlnIxJb+E7dr4C5+8misp8KMdrHRcsyyLVEuJPeGkZ6YmeklH0zUWvQWYUO1WMWxD2ZDKbtltuyTzhHApnmHf8UkOE4zMIMkTZcgjx7nD4VAlYWmX+9KXvpSXvOQlfMVXfMXTOh9k3FRieNvb3nZT3+wvW0i7TCkX8RcdnucdU0/8YoRu6hiuIR7WJ0gMMmT1PxwOmUwm1Ot1bNs+ZooDsLKyouxPj4ZECh2FoJqmqfTii6JQLM0//dM/5dSpU7iuy/33389wOGRnZ0fBZ2ezGfV6/ZjFquxSxuOxYmJLko80bHEch36/TxiGnDlzhpWVFYVjB0jihGAngDUwckPAeQ0h7ZxPc6r1KvW1OmbPZBgNRdsfLPELXxnbg7C4lc9LEASCO2GbfNkLwEmmNOoGuuai2bqScEhnKfPzc8rnyqqTS+YJricw9/IAGBUj0p9OaRw2MP7MgG8A62MWWSUTPg8th2SSQAau5oIP82yOkRl4vocZm1CG5nqTwwcOObx8iN7SOXHihBoP6oaOs+IQj2JxsMYZdt1WXaWmazS2GhiuwfYD20wuTcjTnO5aV+xeJteY6dlS+DuEUYiGRmAIX+PBYMDW1hYrqyuYrsl0b8psOKPICkzPVDLsk8lEdAdXf+blcpmSV8Ke2ETTiEW0YOksKTtloXK7H6L7IplrukZps0Q0iITPwjIl2A1I5glOU9is6nOds6fP0ul0uHTpkkJI2bbN+vq6+hztdhvXddWObL6Ygw62ZQvui6cp+WvZLZfLZeWfbpqmeH89mCZTgoOARqPBIl0wH84Z9AfUV+tU2pVj/JyiKKi0KxiaIZBlho6WatTNOlf6V5gXcxzHwbZthULKskyBQCTZ7Si0/enGTe0Yzpw5c0OTmPF4zJkzZ276Yp5tITVybNv+C0sMcq7/dEKSYp4qcsosC05DFt8YQCDRG0eZyyBgs57nKV0jGU8k/R0EARsbG9xyyy3cfvvtqrvpdrtsbm6qpOe6rhoVSQa0JNUdTSTyxZGyE3LvIqWUQdw/KfENKJOexWKhRjSmaQoorp5SWamQxznT0ZQCsYQeDof0Z32WwVIk0LIY1XiFh+EaTAMBgVyOllw6f4ler0ccx2qpuFgsiONYIFYMjdzLyRMhTFcUwt/ZqlhYdYt0KZKDVbOUT3c0jDA0Q2nqa7rGzJvR+xc98jtyOADtGzSc+GqCWaZCn6duoVs6VmRRdgX6KnZj7JqNPbNZDBZUNip4hcd8X0A1ZYcWRRH7+/sYVQOn6SixuOt5L9WVKmdeeAbLtphdmbF9aRuzbeKuuGiFOCitpiUq4XnK/JE55li4y6VpyoULF7hw4QJG1aBxpkFzrYm1tLBmFoYuql7LEvwROZbZ29sDDeyGTWlNjHVWvBX8so+37mE3xWfbvbBLf6dPMA7w1jz8DV/sGGydZJoQ7AZiZDeNCQ4CKuUKd911F+fOnVPdMMDOzg6DwUD9PC3LUl7LGGDUDBqlBr4m+BBSWFGi9jzPo1QqqVFTnudggbViYfomWiLGPst4ycHlAy49cIk4jKnX68d2cPPlXBg2rQg0WJ7mEEE5Lwsr2slEca1cV1jU1ut1tra2lFz9zcZNdQwXL168ISopiiK2t7dv+mKejSFb2qc6w38mIT1e0zRViIinEmmaEkURYRg+pYfBcIURfDpPMZqPH0WNx2MODg5Uq3zq1Ckl7ys9Ep5KRFFEs9mk3W6ztbV1DfVy9V7KUZNMCFK6u9lsKnipPNgHgwGz2UyNnGTINn80GuG6LoeHh2RZpmQrfN9na2uLvb095vP5sRFKkiSYNRPLt0iWCcEiQDd0rJLA+gd5wPBgSM2u4TQcalGNoB9ACWbBjCzO2BvvUelUFPt0NBopcUGJbPF9nzzKBVN3LLoMp+mQJzlO2yEaRCwvL/HWPKHsGogk4qw4tNttHMdhOBzi3+YT/1aM/S02+nkd/W/o2P/ZJgrEfF8uYcODkKJXUNZFUqmdqjG+PGa8PcYsmzgVB2vPYu/8nlK1lQl1b29PaFetCp+K8CDEbtjHuku35HL2/3OWS5+9JAx1ygHVrSqGaxDsBGTLDLMmpDCiYcTyypKV8gpO0+FwKFROF4uFGCGeqmL5FpPLE7SxSCqmK1jxlUqF+XyuzKHgmuieuRA8gDiMMUsmxUoBe7AYLpj355TXy6ycW6F8okw0jAgHIeksJR7FmL5J1IvIAmGcdPR5kvB0iVCSbPs4jul0Otc65QC0ifAq2e3vKlOjRqMh1G9nM2az2bFzQ9OF3HjX7zI/mLOzvcMiW5AvcxbTBW7NpbZSY21tjdFopPg3pmdiOAbm1OSEdYL5aE5MzNJeMo2mSuK+VCqp50WOlW42nlZi+I//8T+q//+jP/qjY7O1LMv48Ic/zOnTp2/6Yp6NIdmtwDNSK3wqMR6PBTLjBnpATxZPhwENKAeqZJpQ1B4vrCe5KmkqFmxyuS01aXzff9xDFwQB0+lUKH9ePRglRlzyGWT1lKYpq6urx/wfoijiZS97Gffccw8f+9jHCMNQPeSmaTIajUjT9HE7l3q9rpaEkhAnE4qUB7j11lvVizadTtVhPZlMSLKEervOYG8gDiHTwSqJEdk8mRMtIjRfo7PRwW271IM6g+WAUA8xcgMt0UjmwqM3TVNms5nqoKQjF4hk7DQcolGEZmhKdjuZJnhrHsFeAPtg1SzSLCVdpBiugVW1lLmRZVkUzymI3xdjfZOFfq+O+SqT/LdzoQJr6xiOUGXVXZ3l9pJ8lrO4sqC8XmYym5AEV/cRThkjMth5bIfsVKY6NOlr0Ww2qXQqxONYwUftxrXRkmVbnH7haaaXpxSTgmUuElv5ljLLy0vSSYpZMXHXXdJxSjSMKAUlTjZPsj3fZrlccu+993LrrbeKUV3JZHZhRhEWGDWDUltU3BLIIEOicRqNBt6aRzpLSWYJNbOGf9pnOp6y3F0yuzRjOVpSPlGm1q4Jjkc/Esl5lgjv6EnC9KEp/qYvoL+6pipvOS6VmliVSoU4jtVziwV5khPvx3iWR5IkjEYjBV2t1+vUajUWi4XycZbjJskVaSQNvIlHUiQEccDsUHx+27CVcqqUnLEsC3xYBAv8jo8386imVbqdLllZ7I9831cQ91Kp9IwIbk8rMXzbt30bIA6W7/7u7z72Z5ZlcerUKX7+53/+pi/m2RhJIkzN5fb/zyskQxJQLmhPNY7CSI9i9p8s5Ew7XaRY1eM6UHI+KpfvcRxTq9WIokh1T7JjlNeZZRlBEJCmqUoM0pDnkUce4b//9/9OtVrluc99LoDwz726dGs2m1iWxc7ODvP5nI9//OPcfvvtamHZbDZVkplOp5RKJVXlSlE72fZL1y7HcZjNZoRhyHg8plKpEAQB/X5fdWOTyYQgCFjprjAajIjSSGgSlcUeI05jTM3ESK76Sds6lU6F+cU5iZ6wyBc4ukMapNSaNWbOTMFwJZJNJtmiKAiKALtii3m8KZJDHgnpa2/DI9wVBC7d1cnDq4e9Iw575aina5jPNzn49QNWv2sV/X/oWP9fi/zXRJfhrYrxldsWUtaLKwvifiwkMByYT+b4tk9ptYS+r2OGJuPdMVEUKfn0xWLBcDgkiiLxLDpCnTeIApymozgwhmFQP1UXB+5hyPD8kMzN6JzqEPVEt2G4BnbLxigZhAch2qHGycpJekZPYP6nU+EhULWp31FncXFBepCSFilzd858IQ5lKUEyGo0IguAYWsgreyTTBG2u0a62SRoJo50Ri/0F80fnFEHB+tl1SlslzLJJsBeQzBIhRx8JcyC7JXy3zZLJmTNnGI/HHB4eMpsJ9vJgMFBGOCsrK1SrVeyGjTf3yGYZiZ2oLkHu06QNZ7lcVqqnMgzTIHNFQi5mQrY99EOKrGC2PcPWbDRPYz6fM51OcV2XKIrEiNcIcEoObuTCBKzYorZRw/CFL0mSiAX1M/Gpf1q9xlFq9lG8b57nRFHEQw89xDd/8zff9MU8GyOOY6Ub9HRn/081JAsYUBj8pxOy6r7eGvPJQjM04TQ2T44xiI9+DbkMnE6nFEXB6uoqnucxGo24cuXKMR0pOfa6fkdSrVaZzWb0+316vZ464OSh3e/3mU6nXLlyhbvuugsQcGc5s5f8COmP0Wq1yPOcK1eusL+/T5ZlNBoNtRORrb48THRdxzRNKpWKUl6VJikShqvpGl7No6AgIiLqReiaQKUUVoFZmEpbyKpYtFfbGLFBs9tEszWs3MLObMVebrVaisMhdx0HBwfCRIdAyTHnUS6glAXomo6/4ZMuU6WNlEWZ2Etc576XJAnJ8xP2f3Wf3MnR/lDDeb0DCWqPIa+1tFXCbtgkiwRjLryr5+M5uZXjrrmsNFZoZk3Sgei26vW66nIWi4VwxXOFx4Bu6oJpPLnmbKhpwhnO7boMpgOG+0MuP3AZs2pSPlMmT3PiQYzpmPibPnbdplgUrEQrdCwhIic7lazIqJyr4HQcwsOQ+fk5wTTg4Ycf5sEHHyRJEhqNhtI6krIPg+EAvazjrgl9JTMx6XQ7rN+2jmVa6COdxc5C8E/KBnErRm/rFFlBHuekkRgxhYOQcD8kCzLBdzlzhs3NTSGjfVWL6ygzv6CgulGl2WjSsoVUhqzYDw8Puf/++5V0izQ8kiGTzGw5Y27Mxc6l2qBRb+D6LkZkkA5THNNhsVhw+fJl9Q71+31GsxFDhsz9OeFCaFgF+4FC7nme94yEP29qCHXhwoXH6fH/rxqLxULBHp/qqObpxnA4VEQ2icJ5OnF0QfxUdJNkWGVLmdXIkElBLt5HoxE7OzvHEo5t22L5ekTtVZLV4LhzlG3bSrF1uVwyn88VpHU8HjMYDFTCeP7znw8IaQx5gC8WC9I0VQgn27bVYQ/Xupt6va4kQwzDoNFocObMGTY2NtTOoVKpqER3Pdmu1qlhe7bQBEoLkr74vIVZYDmW8Eq+Gl7bY3V1FS3QSJ0UwzQwEgM7E9cmx0kA83nAf/tv8Cd/Uuazn4XhcIJeFQziqC8OfbthkwbCxMfrehSJOLCKXEh1XG+047quQM98vcbhuw8prALtP2g4bxJL42R87VqtijCtd6oO1VIVz/Eoe2XBnSDDbJk0ug3aZhv2IA9ytceRBEFdF4gfZ0UI7SXTRAjxXV1Ma5qG23JZP7uOYRsEs4CLD14kDEIq5yqCodwX8hZux8VdFSg/Y2yQ7WQEBwG9gx4XL17k4sWLOKsOpVMlKm4Fb+phBAaT8YT77rtP6Wutra2pn998PmdnZ4fpbIrTdPC6nrBsdWzaG20syyIexcTjmNHFEcvBkqk+ZVFbEBkCgZVMEtJpSpZmareiZ4K5feLECbrdLltbW7TbbWU1u729zWA0QKtqGIXw5djc3FSkTMuyGI/H7O/vK3FHGbVaTT3PAEERMEbwNSzjKqTasKkWVRpOQznKgSg2Dg8PhfqtHjOvzJkzJ9wPiS/GrNRWntaO8kbxtBLDxz/+cf7wD//w2O/923/7bzl9+jSdTofv+77ve1oH01+GKIpCZd4/j88mD0sQsM+bXRg9HUE9GbqtC/TI7FqFL5OfZVlP6LOcZRn9vpAXOPqwy0ruennw9fV1tezd3t5WozLDMAjDkOVyeSwxPPDAA0puQ0I/rw/5Qslrk+Maief2PO+YkmYcx7TbbTUSA1SykH/35K0nKXklrLJFNhcSC7qui18vr/lmS/9kXdPFUtkSe42KXqHqCr9pz/P4b/8t5hu+IeWv/TX4+3+/zP/+v7t8x3cUvPe9Q8HstUVy0C1djPYmCVZduKuRQx4JbkA6T4/5N8vP2+12cb7d4fCXDinMAuO9Buabr40I1b26qnOkaRqVUoXqehW/7JMepsRhjF/zqZ+uU/bLBJcCeud79A8FGucoWqcoCsyKKTR+rspiH02YtdUaJ285ie3ZZGnG7uVdRrsj/E0fr+upzyGTleEImY7F9oJ0L2V+OOdg/4D77ruPQAuonKvQ6DTYKG/gRR7JIuGxxx5jZ2cHXddZXV1V4y8JfQaED0LbwV11ses2Tk0omsazGNMycXQHfXLVyrQeM7bGTKMp84M5US8CTTDcw14oxPtMh83NTdbW1hSYIggC5Yd9aecS42ws9KgijU6nw1133cWJEyfUjvL8+fM88sgj9Pt9ZTpVLpdZX19X6DPd0EndlLk2BwPFzWi4DU5UT3Bq85SSDped03K5FGoGlZSwEbIIFowfHMMI1rprj3/pn2I8rR3D2972Nl784hfzjd/4jYDw6n3ta1/L93zP9/BlX/ZlvOtd72J9ff1/KZ6DTAxHl9BfzPA8T83tr9dCejohK+mnm1jMqknUj8iiDMMx1EFr27ZCN0hdeRmO46hDfTAY0Ol01GcBlP2l3D80m02q1aoiFMVxTLPZZD6fc3BwwGw2Y3NzkzvuuAPbFmqdsjIMgkAt/wCFc5cjGpnIoihC13WlfyNDaivt7OywsrKiYJmVSkXpOal74ZlkfkacxBiWgZu5tGqtG+5jdFPHbbtEj0WERcjayhrtRhvd0vFtn9/5DzPe/naLKCqQb/hg0MJ1d3jrWwNMc8nf/ls+4WFI2AuVHHM8iHFWru6MRoKImGQJaCKRm961V1aiYKLvjRgWQ5qva+L89tWE85Mi4ei2eB6suoWbuQS7wv3Mut1i9NgI5nAYHIIDrTMt9JnO+HDMLJ5xmB2ymC84dfoUhmEwGAxIkkShlpJJoq7Rbtjopo7X8DjpnGT3sV2W4ZLBeEAYhHQ2OvgnfVHVDmPMqonTcUjGCWmY4hkeHavDYDEgSiIeevAhOqsdNtY3hDbV0GA4GbKYLTjIBWNb6hx1u91jIo0gipMoiqg2q1hVwaJe7i/RBhqlVon6Sp3FZEEwD9B8jcROGA/HGBMBGXZXXUzfJM9ywoMQ0xNueupZubqDk7uyZrOJp3lM5hNWTq1QrpWV8ZRUDA6CANM0FdJKovLkTky+E3me49d8sVifJownY/FZc5dutctad40gFHsWiZrc2dkhJqaf98nGGewIdv7NxtM6RT772c/ykpe8RP36t37rt/jKr/xKfv3Xf503vOEN/NIv/RK/8zu/c9MX82yM6xPDkymT3kxomkaz2VQL25sN3/c5ceLE07bzM1yhnyQrUsuy1MOq67riCxxNOI7jqJHXwcGBSiZHJSuOVvm+7ysSnDRzl/sCucjOc+FlfMcddwDCDVAmGsk/AJEYJOHoqNKraZoqkUmElOQzzOdz5REhkUtPhNgwayZhelWm260oroDhGySz4/sYr+yxeXaTVqVFmIRoJY0szFgehPyjt5bJcwPHialUZlev3WI8rgPwzncOSNJc4P81jXgQYzdspcXktIVOkeEbAns/FqzkG/lpOI5D8weaLH55QaEVWL9pYf4Tk+AguNblaEL7yF11iScxTuTQeU4HoylGLixh//59rI5F54TQPCqigsPzh9z3qfvUwRbHMXt7eyyDJXbDxl1xhQHQfqj2VZZvsXnbJo1agyIv0B1d+FYHOd66h1k1SecpRSLGaHZVgBw8y2OjvUFDa2DOTXo7Pe5/+H5CL6SyWqGz0qHu1qlkFQ4vH6rnTnFGjnQ2o9GIyWTC9vY2k8UEZ92heq6K7uokg6tezOUS3TNdGpUGZbNMa7OF3/XJY/F5+tt9wkAkhSzOCPYDomFEnuZKE6xeF5pPg8GA3qzHMl6y88gOSXStk+12u5w8eZLTp0+rsWoURfT7fTGOusol0XWdarWqFu1W1UJv6kRaxGw+o9/rM7g8YLm3pGSXlHyIJOZJOZhpMWVQDLi4c/HJXv0njaeVGEajEaurq+rXH/nIR3j5y1+ufv0VX/EVXLly5aYv5tkYkhD1dJe7XyiWy+UXNcncLAFPPoBZmJHHOeVymU6no5anvu/fkOAnjUuiKKLX66nPUiqVcF33GKpK13W1FIvjmP39fYqiULNiy7JUB/A1X/M1vPjFL1ZLv2azieu66s+l54NhGAoCWxQFjUaDzc1NBaGW0N/pdIrneep6fd9XZiaSOR2GoSLP7R/sM0mFllC71cZyLKJ+JLDyeXF8RGPbnLzlJO1um3geM42mmGWTz39yxnptn8VCJLZ2u49hiI5rMqkRxxaDQc6HPjRCMzScFaHJFY8EGS0LMrJFpmb6VtkiT3M1+y7yxz83mqZR/oEy2r8SPyfn3zjkP5Zz8NCB6vY0TRMz/rYrBPhmBlt3btE80STMQ6JpxKVPXUJ3dDZOb3Bi8wSGabAcLXnwEw9CLJJ/nuf0ej0GgwGarYmZ/lVf8agnDk7DNlg9u8pad42aU1M8iHgUY5UsnJaj3PMMz8CpX+UqxNButek2uriRSzEpGA/GUIVSp0RrpYVlWeihTjpMWUwX7O7uCgmRI6CHRqNxzFhnZ2eHeTHHP+njNIW9abgfEuwEeE2PldMr1Mt1LN8SDPAkZngwZOfSDpcevcR0OUVzNbIgI9gLKOYFq51Vzp07R7fbVXpFvXmPKIlIhon6OS0WC6rVqlJ03draolQqqQX0UT9z4Ni5YDkWrRMt7LYNNoRJyHB/yM79OwwuDsgS8bN1HIeVlRXuuOMO7rjjDrpbXfTGXxCPYXV1lQsXLrC1tUUcx3z605/m7W9/u/rz2Wz2JbfA/GKHhH+urq4qbZJnGovFgl6vh+u6Yon5RWZVP1XIqgzDN9CnOskswWk5X/gfgJrLDwYDRQpqtVpP2PlIaYM8zxWNX/oryEX3dDrlta99LSAWrJJlfVSrStM0qtWqIiH5vq8W94vFQi224zg+xtyu1WpK0x5QiKhut8v+/j4gkprneUJaPI0wlyZhKSRf5FQMoWqazoSUyNHrWT25ShRGzIdzls6S3V7I827TmUV1NGeE40TM5yV6vVWKQqPfb9NojBiNRBLTTR13xSU8FFW3NHGRZC6AIitIw5SgF4ABXte78c/4fwMS4Aeh8u8r5FHO9o9v0769TalUEvuXdU94GRyEaIaG1/FoTVtceeQK894c7UGN9a116jXBxN0ebLOYLdh5bIfVzip+2yfMQoUsa7fbOE1HEMeGEeF+iFWzMMsmtc0a8SgmmSfors44HlNMCxr1hjLhKdJCwHdrYsmfL3N8x8fdEBBNYtAXOmbVxCosWkYL3dApUmGIk2c5i0Ig2Gq1mtotySJgPBZw3NlsxowZ1VL12v5smrB4bIFVs3DXXMhAswTMuBSWWIZLEiOhf6XPsDek2qpSrpRhKaQ/zJLJ6ZOnaTabQl7DCAnygMFgQNtsY9SE6Y7cKUieQ5IkCnZ9FK2UZRk7Ozv4vq88y6USQBRFTHoTlr0lWZQx2Z2gpRrVblWIHV59j0qlEuvr68/Iq/5pJYaXv/zlvPnNb+Yd73gHv/u7v4vv+/zVv/pX1Z/fc889nD179qYv5tkYMntfXwXfbCRJoqCpRxmdX4yQ+HPXdVlZWXnK/07TNMyKybK/RPM1bO/abFI6rfX7/WM6MlLlUcJRZ7MZnucdm9kfjUqlwokTJ4CrhjJRhOM4x2wW5RJaopAkFPX6+14ulxmPx0p6QI6UpARxo9Hg4OCA+XyuiHpy2S25FZLRKiU3pBNbpVJhOp2SeRnhOGR2ZUa5W6YUl9BMjTzNhQChL5bdFy9eBKC12aJ3sSd8EGoupl7wFbcu+PjDJTQ3otkcMZtVCUOPOHY4OOhy9L3VravJoSf8BXRbJxpESgCuyAuKXiGWonuC7+Cv3/he878jlpffD7X/UIMMDt58QOmkqLhN08TfEmSoYDdA0zVWzq7QO+wRRzG9QY/cylnvrGMWJqdapxhWhsyiGRoabuLiOR6TRMjC93o9NjbELsDremL3ML62e3CaQrF1djATvs4lk8PhIY1yA698le2d5mJpXHNI5glZkAn5h0oZ3dFJlgmzwYxJNGGZLumUO5RLZSqtCtFuxPxwjt2wlT1ss9lUnuOe5yk+SxiGeHUPK7eIhhFu16VICyEf/sgcuyWu16paOL7DYmdBlEUkfkIYh4x3x8zcGWun1vBcsVBPFymlSom77ryLnd0dFosFmZmRLBOS4tr4Ub4nvu9TKpXUBGI6FeY+zWaT5XJJnudq/Cn9zkulEo7j0NnskHUzZr0Zi/4CPRFQXLtuExohhV6ov/tMUElPKzH85E/+JK985St50YteRLlc5t/8m39zjKH7r//1v1ZGK/+rRLfbVeOkZxp5nnNwcEBRFLiu+4z3CtfHUTGtpxtmyWR+Zc7BIwe0N9tqV1GtVplOp4RhSJIkx37ejYZwppLjhaMPorwO+XudTodOp6Ne3MlkQqfToVYTrNR+v6/GQ/JwnkwmImmZJsvlkm63q6j+lUpFmfH0+31Go5GqruRhIHkNclGuaZoS17Msi/l8rroOaaAiiW8ALb9FspsQN2LMtkkySsiTnGSWYPrXfA0ATpw4QdSNWC6WrK8s2Z+7rJd17jqZ88C+i23HtFoDdnY20DSNzU2QNZUUcNPta8lBKcz2RXLwVj3hYtYP0UxNjZT8Df/GxcX3ASYU/1tB7fdqaKlG/619gnlAc1UQBksnSsKGcnsJOpx9/lke/eSjLPpCVyoxE051TlEEBfWiTnulTV7O8U2fxWCBG7lERURzo3mtg7oq+2B4YrQUHoSYFROrYlHbqqEZGr1+D83XGIZDSnGJSrkiLDGvdg523Sa1UuJZTDyJhRxE1SQtUsJxSBInXJ5dpuyXaVfbRHqE4zoUk4LCLUhKguBVLpcVrF4uqeW9lnFw6YDczGmcaMAY4kEsZNbrNu6aQDVNH5mSRzm1eo2QkGAWwAiyWobdtBkPxiS7Cb7n0210ydoZmq6hRzrj/TE5wtENrhVay+VSjTYlMjEIAtrtNt1uV3mYHFUHtm1bQVzra3VqnRrJVNi9hochk+WEvJwz8SfKo+Fm42kNoVZWVvjv//2/MxqNGI1G/M2/+TeP/fl73/te/uk//ac3fTHPxpBmIiB2LPv7+zd1w4/qIEn3ry/2COkovPTpXqOmaeSWgEea2rUkKPHW8nC9UUhSlPw8URRx5cqVY7sHqb7qOA4HBwfce++9jMdjVdlI1FIYhrz5zW/mhS98Ib//+7/PYrFQKKWjPs/SDW6xWCiuiVKzBJXYZIIKw1CJ8UnbwyiKGI/HKulLRq0cRWXlDMM0iAYRuZkL7f8CkkkijH2u2xGtdFYorZQoeT6v/DaTh7YNttoFp1oOmlYwGFyzZv3n/xwMQzxT0jMCUMmBq19a7hbQhaS0XbcpMrEMj3oRy+3l4whwKl4D2ns00KH6+1U6P9UhP8wZ744FsU/TKJ8qY9UslpeXaJFG97Yu9dU6TuwQzkIe6z2G0TIwfVNwOw4BHebGnFE8Yng4ZHB+wLInrmOxWDCbzYTsQ9fFrJiks1QksqygtlVjY2sDMzHJkoyFvqA37hGHMZqhic6IAqtu4XWEaGEapoLVjcfG1galegkjMVhOlpzfPk84C0mKBEqgpRr2wqYIixui/I4mBcM3iM2Y+XjO7qVdJuYEraOhWZpKanmSU71dsJyLWUEpK9Fd66JbOvEoZnFlwWQ8YWksOZwdsnNhh+n2lGJZCOlyC2aHM/qHfdI0VRwcWcStrKzQ7XZVZysLx5WVFaFEe4SPcL1dZ5IlGFWD0lZJ2LF6JeypDX2Il/HjfNGfTtxUGfxEDlpPFxHzlynkISQF655umybNbDRN4Jy/GGOp60OqkcqF1tOBvxZFQWZcrXTC4/WC5BPcCK4rZ/nlchnDMFRFJH0bpBcyiIP34sWLPPjggwqHLrum6XSqDnFZ5X32s59VzPper8dyuVRdipQoGY1GLJdL9dnlZ5bsZ2kKlOe5asmTJMFxHOWABSgWtBTjyzJx8Nt1m2AQsBguaK23xOF3eUF4GGJ0DPVv5TWdPnuaK+YVXmDn8L0Jf/z7BretJyxCj/tTk81NkRRe+Upx/2SikCNA0zSPdQ4UkAXCxMdpOZROlMjTXOw6KoJBTY5g/do3eKb+PqJz+K6C8u+XMTSD4J0B8WGslEe9Ex5chuXlJf6aT/2FdcaPjTnYO8C2bHrTHhvrG5gVk3A3ZPrQFKNskJs5gRWwN91jGS6pHlYJtRBcMdZst9tK2C8exYS9ENM38Voem6VNhjtDxvMxlGCaTWnnbXU/pP2sv+ELRFY/Ih7G6J7OenOdoCE8HrRAYzldoi00vIqHV/eIkxgv99DnOpmdYdiG8kUul8vH9kObpzcZ7Y8Y7g9ZDpfEZXH4upaLkzqkyxQ91oVOlC2EJ9NJiuEbwkM9SkXnFEdorlDSnSwnDB8d4jou1VYVx3OYL+f0e32qtaqSxZY7H9cVMusPPfSQ2r3J50o+s9Lv5Oi5MRgM1Fnk+z61szXSSUrYF+z0KLt5eP0zn4/8LxxSI10uPB3HuanEkGWZ0i1ptVrHlk1f7LBtW13j00kMcRyDBk5FSCsc5TXIQ/5GiaHX6wmV0quzUCk7HUURtm2zXC7VvZJSGtIVb3t7m7Nnzyo9e8MQ3sC33HILIBjQgPocUklV7iUajQYXL15kNBopYbyjXZjUWZK+BlLtVHIjVldXSZJEsaezLFO6Su12W3QZNYtoHDHZndDsNrFqAlETHoYY1jXNoKOdkeVYJPWE5z1X5447M7Yfga9b5rzpxyb8tW9qUxQpRWGo5btMuv1+X4ERjiaHPMlJ5gmaIcYs5dNlZo/MBK+iIha2xW6B03awyjcAf7waNFOjeHWB90EPy7BI/kVCeBgKKGQ2o9FuYGER7Qk5kPrZOgZitOd2XCzbwmyKkdByewkTaDtt7KbNZDFhGA4J5yF2KoT2ilrBdrBNsyXGVm7HJV2kxOOYYD/Aqlm0Trfw+z79wz6NbgOnLnwlsigDDeF5YGg4HQerZgmNo0lCGITYNZszJ88wiSb0dnqUzBKu7lIEBZEdEVgBTKCSVDB8g8FsQIFAKB2V1bAsi85Wh1q1xmB3QLAQ6rkLY0FhFFT0inI7NB2TIhaS9EVekCc5pm1S1sv4iS8MrOKEtJwSl2KSRcJyvKTb6tLP+iR6orwfpCifjCRJlAje/v4+juMoC0/pQ3J0fyf9TIBjJFDHcXC6Dt7ME7uom4z/f2J4kpAVJKASg9TafzohzWNkZf3nGdKS8OmS8RQctOZhYJBMEoyOweHhodKJkq5WR/ctEjUkZX+r1apiPktbUDlmkg+z4zgKIrqzs4Npmur7+77PbbfdBgh59+FwqGQI5vM5vV6PkydPAle7nKtdhq7rj1t8y0r+KKNc7jHkS+X7vkp6SZIQRRH1ep12u612GNEkIpyERKMIt+XirrkkM6Hvr+VCguPo6E4mxKAISJYJtzynSTbPMPIps4HJJJhQqVTUfWm32+zu7hKGoTJEgmsS02FP6PfEo5gcjT/7rMX+TplzlTmnT6VYZSEGF/Ujob90RAVVxauEPlbxHQXm75loC43sNzPGvTF5mjOIB9i+jV/xCXYD3FUXvaOjXdSwxhZhJWQwHAgY6IaNVbMId0PqWR235DJ1psyXc2IrpmpWCYchnu8xCAcs6qJ7sEqCaBZPYuLRVX/nustGeUMsrIcxVt1ikS1IponwlCggGSeYnkn5XJl4GBPsBsKIZ5ZQaVVo3tEkTEPszCadphz0DtiP9zn9nNPK7rOUlFgUC+Ii5vDwENd1lc8zgFNz6BgdwqFIloEmdjEGhvieiwDN0hR6LFtkwhzI0sW+Kc7QQg0t0XBx0cs62XomvEtindVslf2dfQbhALfpMhqNjk1eLMtSqL2jhUIQBJRKJTY2NqjVase6nfX1dZIkUTsLpQhLhF/xqfrVp3UGHHt3bvpffhHiV3/1V7n77rsVHOurvuqrjkluFEXB2972NkXeePGLX8znP//5Y18jiiL+j//j/6DdFnC8b/3Wb/2ieUIcFQqDa/PJm2FAS8jkn3ccVVp9OnH0YLbrNlmUKXN6uayFx392Wc3Lfy/x1HJOP5lMjklQSKltOa45WulIFqf0bwDBrs/zXDGfh8OhOoTlaE52ZE8kVa5pGtPp9NhOQ15fo9FQL5TUqpJcCcn+NksmhVEQDkOyUMhk+Fs+eZbDDLRcO7Zv8H2fcrmMW3ZprDXwXZ9KS6hsRttCm0cu9EEcCpIwKEeOMnTrqv+Ab/LJj+d839+NePW3p/zd7zR4+XeW+Gc/ofGZj+fohg4FpAsxz5eif8fi20H7gEbhFhgfMjC/3WR1dZVqvYo2E3P1kT4isAImVyYMt4eEpZBoFtF/sK+EMi9dukRsxZRvKWOXbPzIp623aZaawvGw5dK9vUttpYa21Aj3QnYe3SFNUtEBNB2llxT1I/I4x27baIbGfH/OsD9koS/oz/tEiXh20iAlGSTYNZv6c+oCcpsWLHeWLC8usWJL6CRtepieiRVYXPjUBR45/whZOcMpOzSdJqW0BBnKRlTu/UAYWLktFxeXFU8QMnVLx+k4BJoYXe0f7lO0hNlSHuQkk4RkkWD5FnbTxvREV5H0E/SejhZq2DWb8skylU4FP/eF1MYs5OGHH1ZilMPhUIl1VioVqtUqpVJJaW8dHh4eI5PKsCyLWk14OGxtbann1/f9L+jQ+GTxJU0Mm5ub/OzP/iyf/OQn+eQnP8nXf/3X84pXvEId/u985zv5hV/4Bd797nfziU98gm63y0tf+lJFRgJ4/etfzwc+8AF+67d+i4997GPM53O++Zu/+YZGQk83rk8M8tDNsuwLKq0WRcHBwcETLmz/vEIeZrItfSohSV5wFZbrGhiuMG6XX0Meutd/bpkYjoqESaaz7F729vYAFIxOsqtN02QymSiJ6m63S61WoygK7rzzTgD1LEgznyiK1FhuuVziui6VSgXTNI89F0cjDENlTypbc5m0dnd3ybKM+XzOaDSiKIpj6ra6rtPd6LJ1egs9FwvHIi8wfVOYymgmLCENr90XqYHT6XSEqJwpkE+ldgnbsDFHQmqh3++rJFcul1U3efT3QfAc/vOfurz57RZ5nPHCWwLatZTBzOQ/fcznX/26xic/cVV4TxPLW8mJeFx8M2h/pFFUC/Q/1dFfptPwG6ydXcPVXbSJRmRFBHZAPslhCVEpwss9zIlYmg6HQ3Z3dxlOh3ibntAk0myaWpOO02G1tkq9Waex2aBxpoHmaKSzVIyCpoL4ZdgGTscRbnFhRtwXEuOldom6WyebZmR6xigdMZwN1c4nHgrUUPlEmcZzG8LWdJ4wPz9n8vCEPMrZuGuD8lYZE5P5xTmf/5+f5zMPf4b9xT6u49IyWriZgABLj2YZZsnEaYndQjy8JmNvV2zxvfKEg50DDsNDwXGxcoqkINgPSBepEgk0fIN0mbK4uGD22Ix0mdK9vcstd9/CiZUTeHhYsUU0ixgOhvR6PdWhTqdTZrMZtVpNEehkl727u8v29raCuB4NuXdbXV19xpMJrfhiazw8w2g2m7zrXe/iNa95Devr67z+9a/nx37sxwBRra6urvKOd7yD7//+71cG9b/5m7/J3/k7fweA3f8fe38ed8l51fei35qr9jy/cw9qzZKFjW1sYxsb8ABcpjghEEwCFz4JAcOJMQkJJJxAToJjLjEQzDkJ5BKmBA6TCVycgIFgbGxj41GSsaRu9fSOe55qnu4fz/tUv29ParXkIeej5U9/JLn33lW7qvaznrXWb9jdZWtri3e96128/vWvv6VjzufzggAlKevyeHt7e2iaVuxgd3d3iaKIbrd7Q3lsiUCSQ9GNjY3PigPc7YYcGIdhSLPZFDOFKMM/8Bn6Q3IzL6SHrzc0l+qrV1+Tfr/Pk08+iaqq3HPPPdRqNf7qr/6K/f19VFU95ghXr9dZX1/n8uXL7O3t8c53vpO3v/3tvPa1r+U3fuM3qFQqnD9/Htd1i52R5C4MBgOCIGBlZYXNzc3rXutz584xGo1otVrceeedjMdjJpNJYRIkFVcrlQr33HNPMQSU0goNp4Hu6cJism4KcpaXMLwwJFdySk6Jynrl2AA4z3P29vaElEqS0zbaaLlGMAmYR3PoCX6H5JzI/rLU8JeRpnDqFOzv5XzB6YAHT0WMlyrvf7TEaKHy/DMhL7wv5if+XQ5pJshllk7iJegl/fqtpY9C/hU5ykAhuytD+WOFfD3HG3hMB1OiPKJZazK9NCW3cmqdGspMIbADpkyLhUtKmxiJQTgRu3/VEB4Sy3yJGwnUmKmbGImBozpYtkWkRrQ32mi6Rp7lYue9jFF1Fb2qE3sxo/4IP/bRysIQqayXKdvlK2ZBVUMM4KcR7gUhq61oikDonCzjxz6XH73MfH9OEAckTkJ7vc3JtZPYuU2SJKRWSnO1WWz+5GYjC4VulWqrWO0rmmGLxYLpYEowFZBiBYVKqUKj2iCeiaRn92yMqkGyTAgnouV1tFJKlglZmJGbOcvpkiAKiLWYeqeO7diFE2CWZdi2XUjmDIdDPM9jMBjgOE5BGq3VateF099oXbuV+LxZrdI05dd//ddxXZeXvexlnD9/nv39/WO8CMuyeNWrXsX73/9+AD7ykY8Qx/Gx16yvr/Pggw8Wr7leyIXg6J+bxdGBpvQ7vllFIpEyiqI8I8XUz1YoikK5XD4GOVXNQ1VRNyVLs0KG4npxdTtJRrfb5cSJE0X1oCgKjUajGNZallXo2kg9pGq1immaPP/5z+eNb3wj3/7t317ASHu9XuGUBhSieXIRTZLkhgbo0rNhPp8XzmoSIjscDqlWq8WcYnt7u2h/ye+8jJeopoqiC8c2KeVQb9VptBpYjiXsIg99tOXcotlsMp/PORgesO/t40UeZtWkrJZJ+2lBZJL3QSptHo33vhe2tyFJFT52zubj50zatYwvecijVc145ILFX5/TeewJVVR6EzHANZvCtN7f949JqwPwhaC8VyHfzFGfUOHloD6pUlmrsHrXKp1GB1M3cToOhDDYGRBbMU7o0NJaheDbfD6n3++zTJdCeK4skmeWZEIiYxKi5RpLb4mLi2u6XNi7wHB7yOVPXma6O4Vc+Dk7q8JkKJpEqIrK6slVeq0e+TInzVJcxEA4z3NQBGs57IfoJZ3mC5rU76ujWRreZY/xR8aoM5V7X3wv93zxPbS6LezQJuknDIYDpvmUXM9RfZWwLxKaNLjZ3t7GjVyMpkEWZEIe/RAc0Wg0OHnnSTbv3aRUF1W5mqmQQWmjhNEw8PqeGNBrUNosUd4qoxka/oHP/K/nJEFCruToqk73ji5rm2uoocr40pjR3ohGvVEAXcbjceHrLOXQazWh4Cuf5+3tbfr9/nVViG83PufD54cffpiXvexlxe7xne98J/fff3+xsB/VZpL/ffHiRQD29/cLpuvVr5EyB9eLt771rcekPG4UV7eSgELy9kYchMVicQyB9EwUU59JSAvNp2MRenUYdQNUjslyXy9s2y6cro6GHJAdHVhLw3NVVdnc3MS2bT796U9zcHDA2toa3W6XJEnIsowXvvCFbG5uFoqs3e4Vnfksy9jd3S10rCQMdTabFbo1R6NSqRRkotFoxMbGBq1Wi/PnzxcMVIn+iOO4kNeoVCqMRiNhLWokdMtdVEMVrNkVW6CWhqFoPywSwn6I1bEYzUcFvHZtbY1z585x/tJ5OAlrzhp2TegVRf2IkToqoKpHQw7W9/auIOCyXOGTF2yiVOFl9wW87guX/OFHKnzygsV4GqA7CooqRPnIweoKBdNgEGBUDYy6ceXa3APKXyjkr8lRnlDIX56j/JFwiKtuVcUAOK/gzTz8kU8Yh5ScEuWwTL1bR2/rhVaV7/vi3q46RJOIxEtoNpuU47Iw0lFUUlIWywV6TYgpekuP8GLIcrikudrEaTkCveQJ9FIWZjh1h636FpN9AQKx6kKSPFkIlzdSQQLUbA27a2N1LbzLHu5ll/mn5/i7PtUzVR78kgcZXhwyvDREm2qESUg/6WOYBnWvTmlewqwKs6UkTZhMJsy1OVW7ihFcuceKKirJSrVC5Z4K/twnW2Qky4R0kBI7MVNziumb2Ps2TtXBKBuUT5WJlzHhgfDA1kwBd0UFu2OzZq5xcOmAYBZwaX4Jq2qxtrqG67koilKwpmXLVlYJrutycHCA53m4rkur1XpWZpmf863sPffcw8c//nE++MEP8l3f9V1867d+K5/61KeKv7/6B34rOkBP9Zof/MEfLNiEs9nshsJ/10sMqqre8LOlcihc0Qb6XEQURVy6dKlg5d4s0jRlMplcd6CuqEIqI43EIHq5XLK/v39NheU4wrhmbe36+u9HFzwpQbG+vs6pU6cKZrmU9paKrlK1UvoleJ7H2bNnUVWVKIp45JFHWC6XpGlKp9Ph9OnTxUDbdd1rzkEO/xVFwfO8wqhdmqlIPoOsRqTIoWRZu67LaDkizVJUS2W5XHL+r8+L/reSEkwCzI5ZeCwYXBnWyxab4zgkWUJaFrv5aqOK6qlYrvB2OBpJkhTicL3ecSBBniv89SWb//mJEhUn46tfssQyMiorJlmcCT/ppljMgv0As2Vi1k2SZXLMYAeAE4fJ4fk5ylAhf1UOf3LIYG6YlFZLNNYblMolVF8ljVNG7ojJpQmlrMRdd91Fr9crCJuKqmC2hKwEOZi6ycbJDeHU5ms4OKiKSq1Rw27Z0IBYj+lv9+k/3scf+KiGMCzSq7rwxfBS2uttGp0G8VTIZSRWwsH0gNliRpZnpGEqzIfclMqpCp0XdYQjnpsw+fiE2cMzWt0W9770XrpbXQhBW2i4fZeRO2LsjxnvjzFcg6pZLSRZpu6UUTwSLZ/BtQKGTs2htF6itFZC1VWml6bEy5i4EjOOxxwMDpiNZoTTEFVTqdxRoXJSrAvhMGT26Izl5SVO2eHkvSfpnu6iWRrhPGS5v6RdbrO2ulbM0eRzKQfWkrPk+z6TyeSYVt0zMRb7nFcMpmly5513AvCiF72ID3/4w/z0T/90MVfY398/tuD0+/2iipAU98lkcqxq6Pf7fPEXf/ENjyn1z2/l3KQMw/XiaAKS8DKgsJX8XIVciOWQ/GZyHr7vF5LK6+vr1/x9o9PAyAyyZUZezQvv2qM9S1VVb8rrkLuder3OYrFgY2OjQFzISnE2mxWICzm8ns1mvP/978fzPFZWVvA8j93dXbIsY2dnh3K5zObmZjHXqNfrTKdTZrPZdZOyFCaThvKVSoV6vc758+cZjUY4jkOv1yvguZ1Op+jl6rpOnMQEWYARGKSWkMKejWYstAWltITdFDvWcBTCDPIkJ9KFcubGxkYByw2igMZKAxRoJA2yZUawF+CsO0X/XNM0TNPE933uvLPP1tYa29saRyeC5/dN/uAvFb7yi1y+7SuXfNEXVVBSwWuQu9ugH5AlGeWTZTRbKxRapcidoijQBeU9CtlXZ6jvVcm/Mkf5zwq8UbQUmyebpHpKPhGS4G7uEoQBB2cPiNOYtTNr6LrOfD4/di+bnSbpTCjF1lt1qu0qoz1RSW2c2gAbTOuKvtFkMiHcDWl7bTHcrxmFgZEUFTQbQn12djATw+PUxR251MtCOC9exCSekLSo31fHWXdYXlgSDkPCaUhpVbR27JrNweUDTNckCzMW3gIsqGQVjKVBqV7CbtvM3TkpKctsKYhsQ1ERHp3ZSIViraSxaq8y350TTAP0ukAojRdjZr5Q7K1HdVRdJIjETXDPu8wenRH2Q6p3Vel0O1RrVfr7ffyZz8H2AZ1mh1q3Rmu9VfBwPM8jiiIWiwXL5bIgtD7++ON0u11WVlaeEfP5c14xXB15nhOGIadPn2Z1dZV3v/vdxd9FUcR73vOeYtF/4QtfiGEYx16zt7fHI488ctPEcKsh7SqvTiKLxYLt7e1jF17qnpRKpc85A1xV1aKF9FS7BtmXvNHCXqvVWDm1gqEaaIHotz9duG4URcWuRsIyJ5MJZ8+e5fLly1y+fLlADck5heu6vOtd7+IVr3gFP/iDP8jm5iYgEDv7+/ssFouCyXr0XCXs9XqYCqnYKjXyVVUt5AhUVaXRaGCaJq7rslwuiypCekYDLKKFYB4niSC4BQI1pFoq8UwkNqttYddtWCDmEYelv2VZRFEkftRxhN21KW2VUE0Vb9vD2/UIfPH9Jb9BONMlvPWtAyDn6j3K/tTgne+v8LVfr+BdWJCrueAKTIThT2lDLJbLc0ty8mIOcI2/Qw3Ud6ukb0hRYgW+BXgbkItz6W526T7QpXlHk1a1RbPUREkVxmfHBMOg2MHu7OwUM7a9gz2SklikUy+FAFZPCYSXEigoMwV8UBAzrkiLSKspw2DIbDJjsbMgGkdoJU2YF+UUA+bVU6u0Gi0IISdn6k05GBwQRIItHo5CUbmVDZoPNqk/UEcv6Xg7HuOPjYmmEStbK6xsrFCulamWq2TLjP5+n6E3REFBd3V65R61ao1SrYS9cug90Q9YLpbXPGOqrlLZrNC5t0Or1KLhN6hX6pRaAtoch7Hw2LA1skB4jVfvq2Kv2ITjkPFHxkwemaAmKpsnNumd6FFdrVJtVQWqa9dHCRTq1Xrh/HZ07pAkCb7vc/nyZT7ykY+wu7v7tH6nx77Lbb/zWYgf+qEf4r3vfS8XLlzg4Ycf5p//83/On/3Zn/HGN74RRVF485vfzI/92I/xzne+k0ceeYRv+7Zvo1Qq8c3f/M2A2CF+x3d8B9///d/Pn/zJn/Cxj32Mb/mWb+F5z3ser3nNaz6j5y7ZxTLkD/kzoYF0O3ErnAvZGwZuqIoK4oE3GyZqrEIkKpGr8dRZljEej9nb27vmByN39JK13Ov1mEwmbG9v8/jjjxcENYkUkkJ5RxnQtm1Tq9WIooidnR3SVJCHZNtIGvGsrKwUUgNXh23bhQTB0apKWnGqqsrGxgarq6uAMCGSkECZ0Bb+AnTR49ZrOpYu4JJ6RRcJw00KD2StosES/LGPYRiFquv+/j7nz58XqJO2TeV0hdzIOfj0Abuf2iUKRDLXNI1er4eqqrz85QG/+qtDrlZS3tyE//SLOi9/QwXN0nDPu6BQzBmstkXlVIU0SFk8sSgIcHbXLqS3CwMiC7Tf1Ei/53BQ/c+A7wUO/1NRFcobZeHH3KqytrJGw2qw/PSSfCKGs9IHQ7Llh8Mh02CK0TVQNIVwJJjV1oqF5mgsBguGF4fMhrNCcRQLXN3l7MFZLly4wPTylHgSo5U1MVAPha91tVnl5F0nqZVr5HFOkicMxgOG4yGKqghznQOfeBFjr9g0n9ekfLoMCniXPRZPLtBSjU5bWL6qloplWiiBIpzZlITUS0lHKe7YZa+/R2iGuAuXwdkBly8KDsLVsFGzZlK9p4pVtTDmBm29zfrpdZqtpkhsioLe1tlf7DMajKAC1qqFVhYJffyRMbO/nlGxKqxvrgt+xpqDVtbYu7jH9OJU+FroBhsbGzz44IPcd999PPTQQ5w8eRLLso6Rc28nPqetpIODA/7u3/277O3tUa/Xeeihh/gf/+N/8NrXvhaAH/iBH8D3fb77u7+byWTCS17yEv7oj/6o2L0B/ORP/iS6rvO3//bfxvd9vvzLv5xf/MVffFa0iI6Krx3dUcsKQspcy2H050NCkHErFYN0QTtaYVwd0l1NK2logYY+04l1wRA+2s9UFKWwJYyi6FiVJa1AJaFN9vllEpDHkYlBIohKpRLtdpvRaMTHP/5x7r33Xi5dulTASiVxrVqtFu5spVLphgN/eR+lmB4IQpk8npRllkzkKIoYjUZ0u92CdFQqlcisDBIwVAO7aePuumRJJoTmZkJ5VVEV7JaNm7kiMWhGoa8vlTOHwyG9Xk+Qtu5psPjognSQsvepPTYe3EA3Bcmu2+1ycHDAF3+xy8c/bvDwww329mBtTSi0ikddo3KmgnvRxbvsiXmHIngXVttCvVNl+eSS+RNzyifLwgda2nMekchWDRXtZzSSjQTthzSUn1VgF/gvgCMS8MgdUWqUsCMbo2wQHAR4j3sYKwZ+4OPmQrpEVs5S5LDVamGWTDEnCMTx6pU6qZYyHozBF8J2uS1mTomSMM2mzAYzukGXbthFMzS0kiY0pJZCOqO91qbRazA+GDOfz7FNmywVIoGqrpJ4YoHXqzqVkxWsloW/4xPNDtVfSzqWY3Fm/Qxjb8xoNgIFxvtjnJqDkiuwhCRMmJanhFEo/KN9nTAIC8SQtOgF0AyNyukK/r4vUFaxKsyIdIXETViOlmKDoSdMwgl5lGPEBqVGCUMR8yGprFs+WUZ3dHzFJytnDL0hru9SX9QxKyZGzTjWul5bW+Py5cvPyFTs847H8LmIG+F95/M54/GYcrl8zN8gz/OiL12v1+l2u9cgoz7XcT0OxtUxGo1YLBbH5ImvDonD7/V6OJZD/2wfL/SorleveU+/3y98aK+esYzH4kcr+/wf//jH6ff7xeBZOq3df//9PPDAA5w/f55z587xb/7Nv+G9730vb3/723nTm97En/3ZnxGGIRsbG8RxTKvVYnNzs1hsm80m1Wq1QHDc6HvJ833yySepVCoFGinLMrrdrpCdjmNqtRonT55EUZQCDWfbNv6+T6lSwmybDC4OKFtlVs+sCvhkRcdsmAUHoqSXqFARBjBOwv7BPtPplE6nQ7vdvmL3uAy59JFL4EOpV2LteWuohlhoFosFo9EI0zRZW1u76dzL3/EJBoEwYLJV7KYtXPriFPe8S+IlOGuOkPJGaBJFk4g8FYxevSpmD/Evxej/QEeJFPhi4PfAL/kFqKFb68ISciXH3/bxxz6REzGzZ8SqWJTq9foxP/LNzU2UXEBS0yBFsw+rgDhluDNkNp6h6Ap6WRfQU89jPp8LroRmUNbKWFhoqoZqCZhoFgvuhFE3SMKEzBOkszzNWXgLYmLq9TqGIlB2Zl0I4gX9QAzjwwzFEElEURVSJcXNXRI1QU1U8jgnI0NThZ9HaqTkhnDcC/yA2kZN+GsfAhWkNae8HxK2SwqqLXy78yTH93xCLSRSIqGztIiFB4dt0+l1yBe5sNxVwF6xsddtFoGYKeRZTh7mVPQKJauEUTEwqkbxvKRpyu7uLidOnPhfm8fw+RjXQyUBBVNW7qaf7kX/bITczUu0z9WR53nRhrkRUe/qUDSFUrcEEQTTaxndsqq6HttbHsP3/UIXxjAMut0u6+vrRQUQBAFJkhRy51I36QMf+ABJkhR2n0fRSkflMKIoKspoKTFwo5DnmWUZp06dwnEcwjBke3tbeCQfci+kL4Rc4JbLJbmVYyomJKBXhWlPMheKp8kyIYuzYt5U79aFfWeSo7s6WxtbBYluMpkUVZ1VsVh//jpZKcPtu/Qf7heMainsdzUYIk3hz/4Mfu3XxD+zTKG0WaK0VSL1U+JxTDAKSHwxE6ncWcFqWvi7PsuLS7JUqJgWs4fDXXQWZRjfapC+MyWv5fB+4GXgbDvFvZyHc8yWKUheZypUT1Upp2XWojUaSQNSoZclmfW1Wg1N0wrHOqtjFX7RxLB6ZpVT95+iUq4IMb1Zyt2n7+ahhx4SXQIV3Nzl4uwiB4sDFtMFcSAWzizMhBptgvDL7liojsrCWzAfz9m5tMNgPiDOYsJxSDSKsNs29XvrBYEtz3JQQU1UKlGFSlQBDVI7LYh4SZygRzqltEStVxPcGrWBjjB+2t7ePobyUxRBbHNWHAFPzYRabpZm2CWbmlaja3ZpN9rUejWcnkNCgmEKsUZnw0GxhQ3p7BMzzIlJp97BtExUR8XVXCbRBH/uC0/qkeBkaJr2jGCrzyWGm8T1EoM0Z1FVtbj4nwkJ7WcaEvZ5o0G4hGXKAfutRqleQi2rwnPXv748hmxRHQ0phSEXCWnpmSQJ3W6XWq1WqNk++eSTZFmGZVk88MADAPzlX/4lQCFw12g0CuMjVVWPaURJpVegMN05GlKoTEp1y/bO+vo6p0+fLgT7pPDffD4nSRJWVlZYWVkhz3OW0RLTMsk8oVOkV3USPxFoFRWiWVQYB1mWcDCTNp3ZJMPRnYLgd8wzu15m9cFVskrGor9g/OiYaC4SR6VSOUaW/O3fTjl1Cr70S+Gbv1n889Qp+J3fEdj46plqgUzyd33BSlZVyifLQs56ErE4uyAN08Jgx14R5+gf+ETTCO0rNJI/Ssg2MngCeAm0PimIkGEYEuQBVtsSnIOeQ/WuKpqu0cybbLDBir2CrunXIPU8z2O8GGN0jGMJyTAMNu7Z4NR9p2g1W4TDENVV6TQ6xWYnJ0ctqbiGyygaMXfnxEkMiRhOB/sCkmv3bDbv2aTRbZCTszhYsH1xm9FcyFUHg0C4r50sUz5ZRtVV8ihHczS0qoaOTsWr0MyatLttSisl0GAynTAbzsimGaWyaF02tSb1Uh3DMJjP5+zt7XHp0iWeeOIJJpMJelnH7tpiR69RGBMB5JHYMLTLbU7efVL4NSuCcW23bJbGkok+YZksWWwv8B/zqXgVqpa4v6meEjohZtMsFAukE+DtxnOJ4SZxdWJIkoT9/X3iOMZxHFqt1lNqJn0uo9lsFru0q8MwDLa2tm4Kxz0a8lpomsaJe0/Q6rWIxhFZciUBSIE8uH7VIElmcuGW7E6g+P+XyyUHBwdcuHAB3/d56KGHUBSFS5cuMZvNOHPmDHfffTftdrsQ11sul8WiIdtBchGSsL6jsbe3x8HBAc1mk7vvvrtAIkkFWdu2C0OfKIoKnSZN0zAMQyz49RqxHqOlGtWyQI5IaKVe1kn99Bq2sWqo2Cs2buRy7tFzZL5YqOM4PjYorLfqtO9sk9ZTFtMFi3ML/P5xVuuv//qMt7xlh37/+Hfb2YG/9bdEcjCqBrW7axgVIVk9Pzcv7pfds6meFp7Qi8cXomUBaKaoHo7yHtQvUEn/LCV9QQoT0L5So/cHPUCgyxRLEbv/MEMv61ROV9BKGiW7RD2rU1vUqKm1gpyVZRmPPfYY+/v7XN6+TKiLXrqiiCQWjkOskkXzhNBCytOc8aUx7sAljVJ6vR7NZlMQHbWMncUOu+4u43BMlEUkvtBl8rY9DM1g494Nzjx0hsZ6AyVTmO3P2NneEQizQ5SRoihU76pitS1hKxqL5Gq1LJREIdwJseYWTtmBkmDCj0djBhcHJL6oEHVPZ62zVsi/L5dLRqMRjz32GB/72McYzoZYXUv4VUc5Rt1AMzVyJS8MmdJJSq1XEwz7WYxSUlAbKnpdJyyFTNQJ/Xmf0YURyYWEeljHUiyazSZGxcBetTEahvheg9vXaXsuMdwkjiYGKYonjee3trYKFcP/Vcc0iqIcGyA/nfdZbQsUAQs8+v2PmvJcHfV6nV6vh23bwiHtcBgt7RZbrRYvetGLCra03LX/8A//ML/5m7957PiqqrK1tUWpVCJJEuEadpgA5WIukVZXVw1HKxs5NAS4ePEi8/kcy7IwTZP5fF60BWQFdJTDsYyXGKZB1ahSLpcxG0IhNAsyVFMlmorEInHmcIjsWSkTpiHb57YxIgNVuZYH0lnp0DrVon26jaIp+Ns+i/MLsjQjSXL+7b/1UNWMlZUDdP3KkFHeije/WbSZNEcTCJkVSxCq/npWQFSNukgciqmweHKBt+cJ74FDXL69YqNoivCEaGak70pJvjqBGJw3ObR/ok2WCDSa7uiYbcEJUA2V0noJRVNQHRXd1on2Inb/apftJ7YLDomUoDh79iyX9y6jNoUhTuqnheCe5ohEVelVsA2baBox358zGoyKatcwDObenIPlAaEjGOl6RRdD3gtL3Isuuqazec8mZ77wDM3NptitjyHxEiEj4scC3lozqNxRKRBUKMI5z2paZH6GNtNoaS0a9QZqWSVSI2aTGeEiJF2kRPsRdbvOiRMn2NzcLNwPJd9qr79HZEfESsxwZ0isxVgtC9UU85JoKionzRGtq3SWig3cyVUamw3hatfW8HSP/fE+44tj9AOd8FJINBNs93k4Z5JP4NY6xNeN54bP3Hj4LIezcpjqeR7j8bjAvn++h5R6iOP42BxBMoxvpVKQw+friQbGfkw8igXOvCVaOVJy4qlIfpcvX+bChQukacrm5mZB0JGD8k984hMF9FUic573vOcVswTJcD6KJpJzAYnrlgN4gI2NjSIJzmYzRiMhQ7G+vk6apuzsHJq4H+5oJe8iSRJWV1dZX1+nXC4Xku4SzdWyW+iJXpDT0jAVJj6ORuqnuJmLl187kP/Upz7FbDijW+qytr6G03NQ9Wv3aWkgfBZiLyZ1xbD24ztlvuz1Kqur+5hmRJLo7O2tkqbHn8n/+T/h1a8W/55nOe62i3vBxagaVO+tYjiHrZlU+D6HkxCjalDeKouF6jCkwQ4ccjZ+TMX89+I+uF/hEv2niOZG89j5qpYqYKE7Hrqto7ZURudGpH6KYiuUN8ukukCiSVVcwzAEg351jXSRFqJ6RsMQA9s8x5t4DHeFmJxmCoSSoisF0s22bWzbpl6vCyLc7gwjMjB1E6thYa/ZIlH5Eek8FTpJacaSJbEeUzWrlJ2yYF17KcFAEDrNlkj60TQSMyQlI1IjwiwEDYhBCRXyIAcDqierNDebhaOitK2Vy+1yucTMRRI0SybVThUjN9BCjdzPUTRFILSSHLMpmOsguhau6zKfzPHGHtWkih7rYj5iQF7JWSpLNFvoUz300EO3NXz+/F/dPodxdSupVCrhOM7nFSz1ZpHneUFysW272FFLS0DJ7L1ZXO+7ypZalmWstdYEHE9XMWoCDnojFJQM3/cLlmy73abb7TIajYTa5SE/oVKpYJomcRwXrZ7HHnuMe+65B9M0GY0Eg1Zqxkiy4UMPPVRUCtJ7QR5PchF832cwGAjy3soKmqbRarVI07T48ZZKJXzfL+YPg8GA/f19RqMRlmWxurpKHMcs4gW1rEYwC3CaDpqlYdSEOYxqqahTlVzLr2lndTod4RGRTVlnneBA9OoxONb602wNq23hBz6+7gs/gb0F9205fHq7x+rqPoaRsLp6wP7+yrHkcJgTxX1UFSonBDJqeXbJ/FNzqndWMWqCX1A6UUIra/i7PouzC5wtB7MqFiO9rAvS3FRoIKX/OCU7lWH9M4vy/yhT/roy/B6wfni+HVGdqKaYZ3iXPLJBxtrz1hjsDAgPQpZnl5Q7ZU5vnWYRLtjd3S0G/5VKhUazgV7RC1vPxBZEuXKrTKlZwp/6jHaFVEWpWmLj9AZu6Bas6+FwKBB3tYqoTOc+2p6GOTCpdCo4qw7miondsfEPfPYf2ydJE8JyyLw0p7wsUylXcDYc4qmoJrSSuBdGzSCaRGiRhm3ZBJkw91ErKpiQTlMWn16w2F9QPlWm2WqysrJClmWF8KBsqy6nS6JZxODSAKclNheqolKnTjbJyFXhFCe1lXRdp16vU6/XidYjNEUjGokqY9gfsugvMCwDxVEIeK6V9BkJ27bJsuwYxv962k2fbc+FW42jBjtyYUrTFM/zSNP0lobmEl56tEKSnIQsE9LBRs0gmkUFuetmkWUZFy5cYLFY0G63OXHiBI7j0G63WVlZIU1THnnkEc6fP89isaBcLqNpGn/4h3/Ij//4jxeyI5LxvFwui3kDCAnwo0VwvV6nXC4X3JckSQpZD13Xj5kInThxojB8yrKMXq9Hq9US8NRD6RBpWWqapuBRLOfsjfcYbY8KHR2jZqBZGnmcoxs6uNfySVqtFpqmkWQJvumjmiqjSyMuPHbhGi2q3MiZ5TOWwZLADHAaGl/2fI8vfShgOe2RJDqGEbO6uo+mXZl5XU+6qrxWpnZ3jSzOmD8xx9/3C8y/3bGpnKkI9M95F2/fI08PN0eaaB/aHdFeir8uxvvPHnkrh48ALwI+ePh82IKpnEWZgFTeURFe2U+6dNe61O6tQQvcicv4U2Mc1+GBux/g5MmTtNvtKw52hkpohlAR8iKSE0AGpWaJzfs3OXX3KRrlBuEgxIotVtpX7FpXVlZot9uYjonaUkl7Ka7usn95n71P7LE4tyD2YpxVh7tffjcrJ1YgQEiPT6bsDnYZ7A1I9RSzbZInghCYpzml9ZKYF2QqTu7QqDdodVq0V9rUNmtgQrgbMv/EnO1PbxfVb61WY2Njg62tLXq9HqfvOs3anWukccp0e4o7c8GB6qkqVk9U4dPdKXuf3MNf+MeebdM00QwNZ9Wh/mCdyklhnBTHQkLE3b9WM+xW47nEcIMIgoDRaFQ4KF0v8jzn8uXL7O/vf94Ooa8mukmIqlzcnipqtdo1PtWyZQOCL2HWTfSyTjgOi4GrHN5eHRLPDhQzBmlMYxgGw+GQfr+P67pi4UwSbNvmJ3/yJ/nVX/1VHn300QLSKoeZFy9epFqtFsnqaNi2XTjKAcW9rNVqGIZRJHVFUQqDdok4M02TcrnMyspKocwqkVRJkhQQWz/3BZTRS4rPMlsm5KDpGkQQe/FxQxhdL7gvw9EQq3PIfF1GHJw7IPTDY6/trnYx6gaz+YyT94dcnFjctRHzVS/2cWiSJhqGkVAq+SgKbG0J8tv1wllxqNwhEE7+no970S0QZkbZoHpGVBLhQcjywvIY+kxzxEJkNS2yl2bMf3VOdncGe5C/Kif+ucMhtiWMeCQbvHpXFVVXcc+5VLUqndMdlE2FqBSxHCxZPrGkGla5Y/OO4lhhGPL4449zfuc8w2RIqApimZw/kIPTcKht1bBaFnmcM7o4IvdyVNRizrW2tkar1cILPCI7Ql1TyaoZaSB4HcsLS5JFQvdUl7tffjdrp9ZQEzEjWs6XeK4HKeglwa2I50KtVtVVSieE4yEupJMU1VCprlWFCGBTgBDCsyGLxxYFw1zOyOSzYlgGtfUazXYTO7IJJyHTxRS9pVM7UyN0QmaDGRc+cIELn77AYDAoeDrF70pTWbt7jftedR9bD2xRaVTQlNtHSz7XSrpOSDOMPM8F2eQGJCk5vA3DsBCD+3wL2YaRO2O5MB5lj99OSEepIAiEh0LTJE9zwmGI3tLZH4pW04kTJ45BLKViKYjqwfO8gugmB3VyOCwlO/I854EHHuCv/uqv+PjHP859990nvJjDkMViUfAiJFnu/PnzrK2tXdMmk3BYEBIXy+XymmrPcZxCdlvTtELaYTAYFFyGMAzxPI9Op0Oe5ywWC5RQIZ4LRJJk3JpNk3Ackis5iqsQhRG2cwUa3Ov1GA6HzGYz0jSltd4iTEPm/Tk7j+2wddcWRtko7leSJIwZMx2P+Qf/0OAf/eMSX3RPwCseiDm3W+fJfsZyKe7rT/2UZERfP+yuDZkADyRL4TRm9SyspoVqqJRPlIU6az9geX6J3TtE6KhKAW3VyzqBGTD9hSnODzs4/9PB+E6D/OEc5e2KQDh1hWd1PI0FM/uyi3vRxVl1WFldYWpP6ba7JKOEYBgQTSLMhom9ZrN0l8Xz6/s+tVoN0zBxcLAGFubCLDYlellHK2m0y22UPYX5bE5mZAzCARNrQhzHRTs1jmPKnTLlRplkmuCPffZ39nEqDuVmmfpKneZmk8XugsnBBCsWCU7RFMIsFPOw3Caf5UINoCzMkMK+ECjULI1ap4bZNJnvz8n6GdksY/eDuzgdh/qZOqOlEG2sVquUSiW2TmyJNlN/TjJPmG/PmVfmOGWH1pkWXt1j/uSc4KK4lnpH2I7atl1IuIDYiHRPd2lvtik/efvT5+cqhqtC+qvKBUy2FW4UchF7Nk0ybjfCMGQ0Gh1rRRytGKThvTTmuZWQdoNXYxTk9z5G5GkLdEUyToR5CddelzAM0XW9EK6TXgcHBwfHJMulzIi0/XzBC14AwMc+9rFCcqNUKhUWndPptFBrHY1GBQFRRhzHXLp0ifl8jq7rNBoNWq3WdZO+REzJ+y4XbwlSkKQ3KeKnKAo4YoibeleOqZd19JIOqmiFBOPjSahWq9FsNmm324RhiKIo9NZ7OF2HREnoX+iLxHLYomo0GtSaNfS6zl139fn3/y7kU/tltgc6p1dyvuCUxqtfFPLbv5nz9V+f3bSKVRRhbG+1hKc1KgR7gu8geQ12T+g4aaaYPXjb3jEIrmqqOBsO5fvLeD/hMfl2AblV3qHA64CheI3dE7pM0TgSkhQdS7Sw+hkrvRUMy8BZd6jfX0fv6MSLmPlfzzFnJqfWTxX6V8vlkulsipu7TJmKRXoieAuJJ54Tq2axevcqp+89TaPaIF/mhOMQJVUKRKFpmsIm82AXzxDtsMzJWPgLBnsDdh7bYXBugGqrbNy3gdN2yKKM1EuZL+ZCsG9ywGQ0wZt5RPOIeBZjtkzKd5RBg3AnRJ/prJ1ao/mCJvqKDjr4Q5/d9+8SPxkz35uzs7PD3t5egZDbvHOT7pkulm7BDIJFQLPZZOueLe582Z00u03s1IY9SCYJhn4FVSg7GAcHByy8BUbz6SMOi2f3tt/5/8CQnr9AAaeTWjk3QiHZtn1MFfRzGXEcs1gsME2zQCHIlk+SJEXCKJVKt+wqNxgM8H2fTqdzrCI6+rlyXqGoAs8eDkKMpUGsx3iedywJySrsqL6U3MWNRiN0XS/0jBaLBbqu0263ef7znw8IYyd57ltbW4RhWCzaUr0U4Pz58wWiSFEUoihiMBiQpmkhgX09pIaiKJw4caKYZWRZVpgAyWomCIICfij74bmao5iiatBKWjFrMZsm5oGJF3qE85C0LZBFMtbW1kjTtEjguq7T7Xbp58KRy5t6hfCdZmt0Oh2ByFJc7rr7gD//wzU+9rjNYi+m10i45+4QzYnZOT8hN3JWV1dv2DJUNEUwsg9ytFwjSzPCaUgSJNgdYUKkl3XKJ8sEg0D4LfsJdtcW0NxD0xqraaGXdMZvHrN/ep/eW3uof6aKucPvgvp8kRyCQUA4CHHWHVRTtLGyKKN8QkiCu77LOB1T26iJlsowJJ/lNCtNyrUybskljuPCMvfEqRMoqUI0i1jsCXHDaq8qoLNVk26lSytoMT+YM5/NqVk1VjorhPmVZ0Ze+1PPO8V8OGfWnxFGoiXq7/moikqj0yi8qZ3YEe50RLipizfyMKcm5UaZSlZB0zScFYc8E/MI74KHXtZZu2cNf+ozn8wpUQIPooOIRE+Y2TP8lo/hGIVVZ/neMm7fJVpGJLMEo2FgNSySUoKqq9SsGoqnoBwoRFokDKOisGjP+r5/wxb4rcRzieFIBEFQyDY3Go0C6nizkAukVBy9HV7AsxVyFy9lIWQ/X9f1YiEzTfMZt5HgirS3FBqUi7+iisXGjmy8gYeneOSdK74VjuMU7ZqdnZ0iMeR5XiB+zpw5Uwy8Jens7rvvBgTMU1YhSZJwxx13FF7QEporPz8IAiaTSTHoVVWVPM9vWgGCaNtIzXuJWBqPx4xGI8bjMfV6nfl8XiShMAwF/HDVpJJVSP1UVAqH16O12cI6sDAxiSaR4Acc6vkfTU6y/1wqlQT7+vB/lmIJB7aKcGDr9XrspXuYVRMtVfii+2PMV5qkruh/x0EskpCSshPtsLa5dkN2u6qrwkOiHwrGb0kjHsf4e8Lc3uoI1raz5qCVNMJ+iL/rEy9jnO6hzANiptC+v81evsfO1g6r/2IV46JB/sXC20H9RrVoK4X9EKsrPtfddlk8ucBZc4gycT3nizlJKaF1b4tknAjdp6VGza7hGz56WadaE2Y6aKItNvbGhNOQ2WiGU3WodCuUG0J8rnWqRd2vE80ioe5qqDTKjcJtUW5Suhtd2qttBpcHxMsYP/LJjRzDNMgiIZNtlsTAV1VU/MjH9VwCLyDei/HnPr0TPeJljIKCsy4qjaB/mCAqYpOjaEILKhpHLPtLonGEN/IEL6IZUbqrhFWyKK+WsZaWkAcJU5SqQmzFEEAcxKgVFcM1yM5nmDUTq2sVHjVBEFzXsOpW47nEcCR6vV4xcDwaN0PaSDkGOWf4XCYG2aKRrk5yMTi6Ow+C4FmzG5Xs5aurKUVVqK5XmU6mZNMMb+pRbh6/ppJBLHf/EkkiWczVqiCNyYqk2WzS7XYZDAacO3eOhx56iCzLcByHu+66C0VROHv2rCCamWYxbzg4OCg+76677mJvb4/lclkInUnG89UiiO12myAICnLbQw89xMMPP0wURcRxzP33319oK0kPcD/2KZmlgphVwJxrJQwMMZz3U9F2aF7ZxUdRVHg/yH5xq9UiCAKhFtuwSV3xvjRIMVtCSE9VVcGYHYSEg1BILtgqylhhxVhhNBvhj30uu5dZO7VGpX79GZhmChhmMDxMPhuG6PfPItIwxWpZGHWxY9VtnWAYEM9ilv4Sqy3mEoqmoGoqvXt7bOfb7PynHdb+1RrW+y34JuDjoP5rUTnI87V6QhLc3/Xxd3yctoNe05kupnieRxzH9Ho96t064Vi8x1k4mJrwPknDFM0S5DHVUtFbQpbE8zy8sx6arVHpVqi2BGfDcRzSICWex7gDFz3QqVrVwiZWPo9e7qGVNWqlGlomkoDRFmziyWxC5EWkSSqqzmoNpangzT30UPg9GDWRwEfbI0rlK7pV4SAUNrma0HayezapnRLoAaZ/iCbajxiEA0qtEuV2mUW4AAPMyESf6Kw0V/BKHsvdJVmcEdZDgkWANtRwFg6ldolSq0S1W31Gv/PnEsORkKgUGbfK/bNtu0gMz8Zu/JlEr9cr5BtkHP1OT8VbeDpxM5EuVRP2jO6By3J/iWkI0a+jiIxOp0OSJEXbRlGUQhhPYrXl4Png4ID777+f97znPZw/f56v+qqvuiJxfPhdu91ugdbQNI0sy5jNZiwWC06fPl2I70VRxHw+p1arFXMNqd0kQybR8XhcMN1rtRpnz55lsVgItVnHKSoKmQS8zKOSCv8D3TliaVrVSUPh+iYTh2wpyZlFFEVCmvpQrG99fb04J7WqCge2sRgIy+pB7vj7F/pk+0KvyF6xicYRHbXDdDnF9Vy2H9umt96jsdZA1a5tI2qOhtW0CCcCZVbaKBGOQuJZTNAXPXyrJUxmSusl4kpMOBDWoYkr2kt6SccwDdqn24yUEYN/P6D38z3M/2jCv4X8Qznqr4vzDfqHlUPPonyiXEBR9bJOu9Rm7I+J45i9vT3h891xsFpi9xwMxXujSYRZNZlFM4I8oFQpCXx/FLGcLEndlNnlGcEkYOXUCpqtFX+MukF5Vsadu6LaVGPR/gmDYuOQGRlZmhGMA0rLEqV6CatnkS8FmCD3ctyxS5qnmBUTa93CSgWHY9Ff4OquSJ5TIaVRXi9DiLhu/YBoGlE6UWLroS2W+0vBaYgioiwi2o+YHkxBA8VSyHUx83Rch1qrRuV0BXfgEmkRYT0kK2XoirBCdX1XML+V20dKPsd85sbMZ6nJv7KyctMFVbJkHce5JQjo/0pxcHBQOK893aTnui79fh890mmVWriZi5u5xXA5DMPCyPzixYtkWUalUqFarXLq1Cn6/X7hD93v9/nQhz5Et9vlBS94wXXPRQ7CXdctDGMWi0UxrG6328XgUdd1Njc3C+2rXq93jVnR7u4uu7u7hYufqqo8+eSTxHHM1tYW999/f8ELcRynaD22jbaYlaxceWZc1yUKIrSlBqEYTDtrh2zpNOWTn/wkYRgWPthXR57nRaspWSbCLU5FyHu7E5aLJVqo0a60sdrCBCdZJESziLk7x41ckjChWWvSXGliVAWx7eqIZiJxWS1LtJXmcSGRrVoqZl0ggRRNGOFIxJGiKZhtU6CadKFAq4eCPWy8y8D4PgPFV8g3cvhNyF+cFxpFcjjtD3xST0A+MWCezYlS0V7a3NwsKtM8y4kXsZh5eAme7xFkAYqlgA3VVpV6oy5afOMlVmZhaiaapaGUFKbulHK5LO53ioCfLgK8wCMgQLVVWu1W8exEUYQSK2iJRq8p/DNyKxeVydQjGAekyxRDN2ivtTHKBsuDJZP9CVEWoZZVDMtAUzWskkWpVcJIDIK9gDRIsTqWMBBKwB/5+IFPkAQoqULJLImZVhIRJzEqKnmW41QcKrUKlmmht3W8wKNWrYl7Po2Yj+cM5gOe/6XPf475/GzHjWS3r45b5QR8rqLf7x9bHG918HwrIa1YZRvraDiOUxDM1Ejl4NwBCQl6Wy+SgpQtv+OOOxiPx4Wb23K5pFKpFPMSx3G48847C79myTfwPE8Q7Q5nFLZtU61WCxJfo9EorEDlUF4imMrlMrZtF/OIqxNDrVbj0qVLwqN4Y6P4gUmp70uXLhXXVVabruuKqiGqFH4DQOHv0Gl0YCo0eqSJjqZptNttdnd3GQ6HdLvdYxWfZPIahkGn08GoGmiOcPsKRyGWauHiktop02BKfVjHagqGrmZrqGMVbarhGR7ldplkmZAshUS4UTWO+RebdQE7jiYRlmYJOKijE4zE4hcOQ1E9NAWaqagehgKqmS5SrK5FuVJGqShEekT8VTE8D/Rv01GfUMlflcPbwH6TTTAMCPoBds/GWXUIB2Lwq6QKdaXOkqU4hyPPlqIqmHUTo2qQLBOMuYGzdHA9VwyilwuWB0tq3RrdDXEtUz8lmkcsthd4oYfneKiWgHuWy2XK1TKO6xAvY5I0wUosyr0yURJx9uxZPM+jWqmS2ZloBy2hVCnRON0gO5nhzl3SeUo2zwTL2tbQGhqWbwlpDS8gN4Rsd+iHrGysULu7RjAMBC9jGlPaKlFaKWG6JhVPuPqZZZOyVyb0hLyLF3uouUo0iMCF3M4xE5P6Vl1cl4YpgACLMdx8lHbTeC4x/D8w5vN50Y7Rdb3gCshWytPpPT5VUhwOh7iuS7PZvKa1pKpqIfudGRmUIJtlMIO5MS9IbdIzol6vM51OsW2bVqvFfD4vOARyYYUrkhqmadLv91FVlZWVFUAACBqNBltbWwUUttFoFLpI0phIJg3Jhbgequwoj0EK6zUajWKWJBEtWZYxGo1YXV0VmPvUp6QfzhoOE4M0Asq1HKsphsnRLEKzBQ6+3W4XRkdSn0uG5GyEYVj4iktPg8QTO8Q6dab+lNAOWaQLlKlCnuQYDQOjY/P4wxrzA4dGR+dFX2JAKHrtyTLBqBroFb1IEGbTJExD/H7IR85a7B5orK06vPQLYtJFTOqJeYpRMTAbh1yCkk44Eu0d95KL2RDDUKNmMFvMMFYNnD9yML/fRPkdBeUtCun7Usz/aBKFEcEgwO7aYgYxDEnDVHgoU0EN1CLJSgiurovzNWri3M2libWwCL2QhbsgCRNml2fki5xqp4peEhWc4igwAH8hqhPP8QriovPHf0yz3cX40q8QVdkyBhPqZWH9muc5Y2+MpmgYicHo8ohKtUJztUm1VUVpimclHsfMdmdkXgaqIA3qiU6cxHgzD10X/I+8mmNUDabRlHgYE5wLKI/K2D2hkJosE5J5glEzoATVsIrlWqR5ipd4BEZA6qYYM4PlaElWzqi0KlSaFdbvWxe/uduM5xLDTaLVahWL11OFhInlef45nzNIVIJctIAC5XN0KH0rYdv2MWmNq8OyrMK68WYzhzAU2jmlrpDXLsUlVEuludLk4OCgkJ2o1+uFjozkEly4cKHQRfrTP/1T/tt/+2984zd+I9/zPd+DYRgFIU2yky9fvlwQD+M4RlVV7rjjjmJXL3WRitbEoaaUaZrC6evwu7quW0hwu65LrVZjNpsJQt9hS0rTNKEueiglLquGWI9RwysLmjxWkiRUGhWyMCOchITjw+tyiESaTqeFM6BMytLvej6fF8gtWVHoJaFjpM908mEuoNNlwcqtLCv86R9nfOf3W1y6bFIvazxwImJtLeRb/n7KC146pmW0YA7xQvhWywriXX9u8fNvD/EWIR95wsYNVDY3TX7mp3Re//KwENZLg1QkhqqOs+pgVMXgOhyHxMtYeCTnLkZuYGgG+f+ZY73Cgh8A7Xc0skcy9F/WiTcEm9ju2Vhdq2gT6SVdeFMPAlRHZRyMSbO0UOkFjiUIY2lgLkwCLyCIA0q1EombCNaxkmNWTdon2kI4cOwJHsIyIln08d76b+lMJ6hPPomxVsWbeGR+RktvkSgJgRIQJAFpnrKMlsySGfE0xnM9jF2DxkqDerOO1bHotrrUZ3WW+0v8uU+SJ6iomJZJqqREQUQe5eTTnNALyZ2cZbBkMVxQmpcEsqonfLyjWYRqqKydWSOJE+b9OdZUJIiskeFOXcK9EKthEcwDxpfHOFXnmFrB043nEsNN4ukMamW5r6rqFdLT5yhs22a5XBbqoyCQSRJ//3TiqXqTR6UxZA/86vB9n729vWK4andsAdv0bMGIrVRYLBbs7+/jOA7r6+uF2Ji06pStoXPnzvHBD36QdrvNd3zHd9BqtQSh51B7SbaWpMtelmXFbv2oLLe8txLFJYfgy+USy7Iol8ssFotCVl1ah3qeVyRY13ULCKxUe5UeGJYlSFyyajiaGKRkRhqmJG5COBZ+BFJYb7FY4Pv+sdZWs9nE933iOGY8Hh+zmpVM5EalAbswG8zwAo/3PazyMz9eZsUJ2DcsZq7GXz5mc9cy4r/83BjCjOe/YkSn18FMTJKFaDH9zw/ofNPfMchziy+8M+D5ZwI+8oTNzo7KG75B5bd+0+arXxMXMMpgGKC7esGGLjvlQvxOn+sosUJcjQkqAU7iEPydAOsFFnwzqI+rGF9ukP+7nPj1cdFWstrCH1nyQsyGSTAJyKYZqZmyt7d3zBZVXoeignBNnIVDFgqHOtVU2d/dRxkrVMoV7LKNXbGx6zaplxL+xm+Rrt9H6j6M8o53oPzQDzENpkRxhImJkRnYmk3FrBBpUdE+LpfLBIuAYBawd26PA/OAxkqD3koPqylacfFCzGmiRSTkufMUp+GgKiqJm6BGKouJ4GEoqsIsnOFmLrOp2ITUV+tkSSaMjKoGnZMdso0Mb+zhjl2CckDdqeNFHqmaEuQBi+HiGiOtpxPPJYZnKaQNpJRsfibZ+pmG3EnJXryk3t9OYniqkGJyWZYVSqhXx3Q65eDggDAMhTqtesiStlTiqdjRL2ZXtF9GoxGlUok4jvF9n263W/hvS6vPD33oQ5RKpWOkM6mGKl3R5E5+dXWV6XTK6upq4cMs5x+TyQRFUWg0GkWlEIYhk8mExWJBtVqlUqkcq7ym02mRfGSlIofD8/m8qBiNujB1T4P0WGKAQ/7AobVlPI/RLK04lpTeOBqKotDpdNjb2yuOeTWsWjVUWidbaCWN0eUJv/UrBtOFSr2S8qK7Aj75pM0yUPn0ZYuD6QpWqc/z7hfwyMZag9pqjWiW8p//r4SX35+wO9L59LbBAydiXnBGVA5xqvDm71P4uvNi9hBNxM4+cRPSKBXyEA1TQFwrhhjM7qUsDhbMvBnWaQvVUwnuDrA/aKN8q4LyZwrWP7RQvk3B/z5RdTsrDmbdRNVVIZyXQnm1jF7Sme4LmfVRMiKKIsENOLIhUVSlaI+lnmiZeQuPLM7I7IxpOsWaWZS8kjBhmo+x/+t/JvvONxHNXk38++9G+9ZRcd1jYmItZhEt0DwNSxEbh0azgdNwYAU81+Pi2YsM94dMx1PURKW11hLVXUWjXCljzk2MmUGySMiWGdhgNAzs3CYjIw1T0jglzcRMYllaoqYq5lBwJxRTwV/6OK6D3baprlapdCvES5Gk9b5OruSMwhFe7jHLrnUvvNV4ThLjJuF53rFd981CQi3h+u5ln83QdR1N0wr3MmnIDqKyeTpANEkIu9F7rhbUu15ID2ZpoCM/y6gY2D0bP/DJ3RxicJcuBwcHhdWnTG7S1vKuu+7CNE0GgwEf/vCHAYo5huu6xblILwU5J5C6TuVyWQjf+X5hwqOqKmfOnOHMmTNsbW3RbDaJoqj47vV6ndXVVba2trBtW7TCDlVnZetI0zSCICBN0yvGQAZkilj4r04MALqjYzUtyBEyzplGo9GgXq9f95mzLKto141Go+t6eQPUu3UuTDb54MfLNCoZhp7TqaW8+B6fTl0cf7Iw+K/vWuP8Xhl8mF6YMtgb8IFPaPz+nztc7OusNBNeeGdIGEPFSXn+mQBNzbl8Gd77XiF3YfUsQVZzhHdAPI8J9sX8RDEUSqslmvc2sZs2zGH01yMUQ9ifBmpA+vsp/IA4b/MXTSpvrBB/JMa95JKlwhHO6ooEGo5CrLpF766eSL4zWOwt2N3eva78h6IIIpm9alNZrdDtdCknZRRfIVRCxoyZZ3OSX/ll0rWTZF/3BviGv0meZMT/9x/QpEmv2qNRb4gF3tSgBL7h40YueAiy3zTGNm3WTq6xeecmtUaNaX/KhUcucPHJi5w9e5aLly/iKR7WqkVpvYRe08mSjNRPaXQbrN6xSmezQ71Zp2JXqCgVal4NArDWBEx4MVrQ3+mz88QOu5/aZXJ5QpImAl68JfgSmqbRtJt0lS4NGtd9Pm4lnksMN4nhcFjIKNxKfD7pJsnFXCJ6dF0vnOiejhLsYDDg0qVLN6XX3ywxzGazoi1SLpfpdrvHdneqqdI82WTtxBpVsyoExKbzIoENBgN2d3cLvZwoinjwwQcBePe7310cU+7S5bV3HKcgH0p/BamTI30ZZPtLVdVCLkRWIFJLaXV1lXq9Xsxa5LXVNI1ms3kN90GaxHiex87ODvN4LlirqfjOV+tOGQ0Do2aQhgLx02v3WF9fvyHKrdFoYJoCpXOzDctBX+fCgcH7P+WwN1ZICNloJ7z6IY9TK+Ka5bnKwO3RvqONoir4Bz6DCzsoSsr5fZO/eNTh8R0TywBDgwdPhXzJgx6qkhVeD4qiYFQM4W/QMFE1lTRKr2gY+Qm6o7Ny/wr6qk6apwwfH5IsEnJygklA8sMJ/D7QAu0RjdrfqcH/jfCjDgSJzV6xQYHgIIAM2ne06Z7uCkmMfsTg4qDQlLo6FEVBL+mU18t0TnfodrvYsY0yVwh2dhn8zi+hfcVLsTab6JurKK97Hfze75OMl8TDGH0uuBUbaxu0Wi2BRlpv4Kw56FUdb+px9hNncQcurWaLU/eeornRRNVUlv0lg8sDDvYOmE6n7O7vMokn0AKrYxUaUpqhUTtRo31Hm84dHTpbHaqVKvpCZ/mpJWkkpL+X6ZLJbEJ/p8/lRy/zxF8+wZOfflKoGnRMnDWHcqtM92SXTvn64p+3Es+1km4ST5ficbRikJIUn6toNpuF8mih23OoDCp37s9WyMRwtFLK87xw55LtHNnyufrYmqaxcccGURoxmU5QXZXR9oj6Sp3BYIDrupw4caIgpD3vec/jox/9KB/60IfY39/HMIRMRBRFNBoNoaNz4gSf/vSnWSwWJElyLCFVKpUCjZSmKYqisFgsCilu0zQL8t1RdJBMtLquF3IKQOHbfNTDWl6TWImJUsFfWFlZuZYlfig+KEXa4kmM2lVZukuWyyWrq6vXJB9JYrzZHEt6MWRkLLIRT45SBrMad67ofMWLPR69kPIXjzqsrSnUmjWskkX/Up/Vps5L7o04u5uzO9LZGRrsDHU69ZT7tkK+8M6QtXbCZschz65AXaVfg14W7aU0TEmChLQv5EHMhsnKqRV2jV1SNyXxBepHszWyJMN6pYX5CRP+DijvU6j8swrhh0MW/2yBc0a0leyeTTgKCYYBZsOk0q5gVS2Gl4dU9Ar+ni9mDGX9GAT32LPmaJSdMnbbxh/7LP7D75Gdej7qd3y3MMIp6yT/4G/Bz/8k6f/4bZK//fdI/AR35qJaKlbDotKuCK4FAt7rpi5aoOEuXBbThVCnrZdpn2iTBAmlYYk0TgUYQU+LmZtt23TaHZzAEaqsM43SZgmrZZF4CXbbFoTGQYB7wUW1VVZqK/g1IdcS+RHpKCWaRYx3xpx4QPiJBPsBqZYKb43bjOcqhluIWx0kG4ZR/PA/1+2kcrlMrVYr2MMgWi4bGxvX4PVvFrfy3SW89OhAVDpoyeOuHa5UnucVr7l699zqteie7ApbwsGSfJZjambRu19fX6fT6fCSl7wEgL/4i78ofB983y+ktk3TRNO0QkBPymocDckw1nW9EB174okniplDpVK5JilIkcXNzU1M0yzaRuPxmPl8zmw2I0kSfN9HVdWignQzV6B3FPNYopahGqoYtpoKyUKQ1+bzeTGIvjpk9XezeOUrYXMTskxjsagSxAoDf8F7PpXz6csmX3hXwPf8zTkvfYGY61iWxcaZDb74q1ZQLY37tiJecq9HoxIDCsOZznsfKfPfPlCh24YHVj28XY9oEhUe0iBMeuxVW4j+GRp5Ksho/r6P4it0u10279ukcX8DpyuGw+EwxL3k4ls++Z/m8C8ABazftqi+sUr4vhB/zy/IYEbFEMPtcYhu6KydWaO8WRbcjmnE9OK08D64UWiWRiWbsfLT/wftL38VUWLi7/kE44DtLGf8d/4myk/8CKVGQvlkubBu9fY8Zp+asTy/JFqIeV2j2WDrji26p7uUO6JVuRgu6J/rMxvP6N3R4+TdJ+lUOrTUFkZqkCSJsJidjVg6S1iBKI6YPDbB3xc8iNJWifq9dZoPNbE6FqRgLk3qQZ318jprm2vUV+sYukEpKBFfikkWCXpd52D7gIcfefimz8jN4rmK4SZxO6Rwx3EKxuTTWYCfrZDIICnjcHQB+UwNxFVVvQa9VKlUjnkWyDaW7/uF5/TBwUExVDUMg1KpRKvdYjqb4hs+nu9hJRZu7OK5Hmvra7zgBS9gdXWVTqfDC17wArIsI8uEIb3ULpLXXVqESj5HkiTHBvK9Xq/QyJGQ20qlco1uEogEKaWxdV3nnnvu4dKlS8UAWnpzrK6uYlkWu7u7jEYjTNMUlVISoM21Y8qqR0Mv65h1k2gcEU5C5os582CO4zjUarXrJoI8zwsvB9kek6Fp8NM/DX/rb8Fs1kRRoF6fYZamfPR8iyd3q/zKT3t45xekLTEn0B0d1YLv/UGLb/97Gi993gGv3Uh5/EKLv75UIk5ULvZNvvRvq1i1UCz6Xlzs/PWKgM4qilL4JMQzwZXIokxYwJoqqKCUFLE77lr4Oz7BMGDx+IJ4JabyLyuor1LhW0B7XKP6jVWCHwkIv0kI/ZkNE9UQRjphHGJ2RAvLalnEWsz00pTlfCmMb5r2MbXbY/G2t6HOx9g1lew9v0eCxSLVyeMEd+Me3EaL8jveQeOf/BPsjkBKpUFa8DWiqdBospoWRtOg2WzSarVIkoTlfMlyJKCq+TgnK2eYLeHP4E09GlpD2JUewp4DAhbKgnARUplXKPfL1FZrVLoVnBVHSJXv+QQDwZZO/RRlqVCxKtTX6qRZSu7lzP56JjgQUUI8jK/9zrcYzyWGW4inAz2t1+tFO+NzEculaEE0m81nTSzvVuMoXNVxHDY3NwG4fPkyQLFbliJ/kuV8VPNI07SCkBZZEZZqkU5SmkoTLdawKsKH4YMf/GBhBfrEE09g23ZxnDzP0XW9gJnquk6apsznc5bLZaHAKiWuQSCnLly4ULjBXa2dBAK6K92zNjc3ufPOOwGKpCeRafI7ep7HbDYTvtH6gk7QwcgMnKpzXT8Ms2GSRRnxIqZChUUm2lVXQ1dlSBY4XPEjPxpveAP81m/BP/pHsL3dJM+h0Zhxzz1j3vKWJq/8hhrevtj1p36KXhPJ6W/8DY3sF+Gtb02Z+Cl3nhyy1qkwDer8kx/W+dq/qZP4CB9kS3gRS1a0oomZg17WBfJKtpcOOQ9pKGQ0NFsjtVMSEhp3NLBWLNwLLv6uL3wbXlDB+piF8ncVlD9RcP6pQ/LhhOjHIoIwQK/qmB2RSIP9oFCB1UwNra6RRAmj6Yh6WMcqHbLAr04QjzwCeQ7f/d2ogAm0NB1n9RTTk/cQnnoB7iDAvbhDuV4W8x3HRN/UcdYdkllCOArx+2LB1su6mBmVDerNOo1WgywVLcJkmZB4Ce7CRbEVUWX5EEYhelknV3PiOCZxEtSKKpz8njxgf3ufaqtKe6NNebOMWTMJJ8KjIw3ENQ8PQlRdRS2p5OT4ez7VpMqqdq20yq3Gc4nhWY4b+TZ8NkLuIJMkIQzDIjEkSVKclxRre7rSGE9VPfm+z/b2Nq1Wq9i9SmQUUOympV3nZCJMXY4mUVVViwGuZDDHWkx1tYpds4UA3SLGxGQWzjh79iybm5tUq9XCoEh6Z0j4rBw+yyoFxNBZalsd5TOMRiMWiwXD4fC6ZD05wJb6SFJdVsobNxqNoiprNBpcvny5YJ5ntlCZzfdyams17rzzzmshqYcw3izOcCIHJ3Vwly6TyeS6icGyrIL4NhwO2djYuOaevuEN8HVfJ1BEe3tNmk2Fu+6aomkTXF+jvF7GqBjCyW2RkEc5qqXy9V9p8DVfs84f//GYg32XtcaC590V0WjVSFyxC7faFuEoFOfdE+edLBMh/X3IP9DLooqwV2xBNJvFZFFGOA8ZXx6j2AqGZlCulmk80CAchszPzpk9MsPu2ZR+u4T+Mzr8S9B/S0f9hEr6/02JTkXCJa9ukrgJQT/AbJo4FafQ1or0iEkyoRbVsMc26lxFr+qFyx7vfjdcBd9WgBLg5Dn+LGA2CQhmoZA6mXps3rFZmEyZTROzaZIECdFYaEz5uz6hGaKXxHF0R0eviD9pkLJqrOLOXEJCQjUkiQS7WbM0mo0mrXYLXddZzpYs95dMR1MORgdcunSJO+64g/pqHbtnE40idEenvFUmmkR4O4dtvUTIgyuGgqE8Z9TzXCCqBQnRrFarBaM3juNChEyakzxdaYybhed57O3tMRqNcF33mNqoRA0dZeuOx2OyLLuuN4R8Tb1eLxZhEOgds2bij33iYcz++X1ChMXm1tYW/b4wtqlWq9xzzz3s7u4WekiGYbC9vV0wuOM4ZjKZHNthy4H4crmk1+tdN2kqilLwGObzOeVymXa7XVQH4/H4mN1np9MhCAIh95ymaFUNf+zjzt1jny/ba47joBkaVssiSzPKyzLuQiSGTqdz3VZgo9HA87wi2V7dUhLXFF796uIdTKcUVYhs+6imSjSOyNNcWH6Oxe7/y1/e5D0ftNjemRKdC3lIGVEPqjgVp+ArhOPDe9yy0FoaeT0ncQW3IXADVEMVi2NJ/InnMcpCoRSU8FyP/uN9Vk+tYjdtrI5Fu9Fm+eRSCPQtYuxvsbFfbKN9u4b6hIryGgXtxzSiN4o5g+ZoBacii4Sp0erqavE8LvIFmZ5RNapEE7GAG9XDIfXRKms0AsuCSkUkiFIJZzUnWATM9meQQDyIyau5kACJQiE7b+vo6zpZV1R78Swm8RMhsW7GqIZQxtVKGqWVEk7bKSQ3olhUQEEQYAbCttRwRFvVDVzhbR1ClgppmNFwhFNxCLKAklKi5gngQGmjJMh0rmjd5VEOz0Ae9bnEcJOQto9PF10kCVKqqtLr9T4Tp3ZNyGoBRMujkGs+/Kfsn5umie/7tyyNIXfcN0IxSeKZpmkFke5otSIJdXJ37LpC5jhNU9bX169p07Xbber1OgcHB8U8QM4vvNBjFIxwmg7NaZPv+O7v4GOf/Bi/9Wu/xdoJ4YRWqVQK/4XFYkEYhhiGUaDEJMQziiI8zyt24lKKW7rgRVF0XchotVplNpsVMutSusN1XS5dulQMppvNZlG5GYZBuVxmZWWFy49cJsmTY5WlbBfJ62TbNoquYJdsbNfGHbpMu9NCD+poqKpKu90u2N9SGPBmIbkSR6+97uioK6pwTUuEhs+fvDvnF/5DzGBgcDBrEygTur2Ut3yvx9e91ilaQkbVIF4Iy1izKZRXjZqBXtXJwkwsgJOIeHqlitArOpqjEW8LY6HB+QGdoIPZMNFKGtW7qpgtE2/bE/4PmzHGHxjYP2Cjv1tH+ccK9rttkp9NiNQIcjFQTtyELM6w2hbdbhfLshiPx7ihS7lexqk7gok8FXaccjevksHLXw7dLvz5n8PhtVEUBafm4NQc0igV6qWTCH/oM3JHGFWDRqshRB0NMecw66YQ4zucrWRxRp7mhf2o5oj2m1N1MH0Te2kXrwv6IhkqZSFPv3pqlcQX7Hjf84nVmOliiuu6VKwKgRWgKiqVXoXaVo16pU4SJmIece72ATDPoZJuEpVK5bbkLSShSmonfTZCGs6oqnpsF341t+Io0e1WolarXVeSWsJRpcFMtVotoJVH+QwyMViWRZqm7O7ucnBwcMzO8mjI5KIoSoH0kcN0OTfwIk8Qgnoicf/ub/8uDaXBamu1eE2j0Shc5qSchkQnySR31Mp1Pp/TbrfRNI29vT3Onj173Xt31LNjPp+jaRq9Xg9d13Fdl8cee4ydnZ2iFVatVgt3ucVigV7TsRWb2L9y/aVAn7xe8/mcaTRlHszxIg8jN1DDG/9U5TUDgQa7VUKmDKnPpGgK9opoE/35H8V8/z+G/997LS4PdXp1ldONJmpg86bvbfPf3+9gtS1BalvEoAjJ7mgSHTuGZmvYHRtn3RF8jSAVXgzDEM3W6N3VQytrJFnC9GCKf+AT9AOyKMPu2NTurGE1LMggMRO8n/Hw/3ef3MrhD0F/qY7zV8JdLg1TUBDHOAhI/ZRarcbKygqNRkOIDx4u3s66IzwLXLGIhv/190gv78L73gd/8ifXvWbS0MhZc8itHCVUiAciqW1f2C5EHxVNVGHOmoPdtQXgQBHXQ9GFXHk4El4WWZih1wSJz2gYqIYqks9+REfr0Gl2aK+2aZ5s0m626VpdqmaVdqlNRauQ6RmhGbJ7sMtfvf+v+OQnP8l4Nqa0VaL5gmtBFLcazyWGz0BIuGSe558V2Gqe58UQ8uqhqUwM8jyOLkDP5HjD4bDA8UtDe3ksmRiOwkSloJ8c+pqmedPktLKyQpIkbG9v0+/3ieO4QBmBaPm89GUvBeC9H3ovKNDUmySjhNHuCFVVaTQa6LrOYDBgOBwWHAPJXZD+wXLHb1kWm5ubGIbBZDJhMBhc99zq9Tq1Wq1gXJdKpUK3x7ZtkiRhsVjgOA6lkjCPcV2XarVKqqZ4kUcwufJcNBoN1tfX2draotvtCpE+y8RqiBlCrVIj90R7pt/vix3wYdUlo9lsFq23p3Nv5QBbzlYA9LrFD/wri5VGyheciehPdP7iUYezuxZaWuMFpzN+7t8FpCkEdoCv+kIWJc7w9jyCQXBNUlU1FaNmiMWyIyqiaBIJYEGnCVUIVVGFRdMIb9cTNpy2SmmzhNkU8hjokPy9hMVvLEjuTmAIytcrWP/Cwq7YqLqKgkIapvh9n2gWFYRFGWma4npCAdZZczCrGtmv/BrBt7yJ4Gu/heRtP0l+k+Sq6ir1tTpbD21RX6ujZqp47p4ccfnsZSaTiUgQqoJeEeKCdtdGtVQxdM4oZhBZmhGNI6LxYWXdMrFXhelRPI2JL8WYS5NOvcPK6gp1p07LaHHHHXdw35fcx+kHT1OpVHA9l9lwxvbj25w/e57HHnuM7d3tW34Oro7nWkk3CTk4dRznaVcNpVKpEF57Nl3TrheyWtA07RrYqG3bKIpyjSf1rVYMNwq5yHY6nWKxvjoJyQVKopEMwygGpFKE7ugPVp6XVC2VC+pwOKTRaNDr9Wg2m4UX8ytf+UoUReHipYuc7Z/ly175ZQy3h8STmO3JNs3VJromVE/lvZTtJAmPdRyH2WxWoIpOnTpFpVJhb2+PixcvUq/Xr+ntG4ZxRU788LOkpLnjOMVgezwe0+v1ius+nU4FvDRL8aYepVbpGHxVViOyIknTFK/pkS0yDMvAG3hCr8e88h5d17Esq5DLcBznaZEXJZlPyqdnWcanPtXjY4/qlG2VB06GvOiegCd2DC4PDC4PdHqNlK1Owkff49Ja66PZGn7FFxayMwVv2yNxE5xNB00/js472krJ0ozUTWEJFaXCMl+SmRm6LTSOgn5AvIwLcls0FsgmRVXIviBj+etLrJ+0cH7Fgf8L1D9Vsf6LRXqXIH1lYUYwELtysy0grZJNLyVSOp0Oxu//Jvof/xbpBz9KcjAl/Jf/GuVdH0B/5YtFm+k6jncAmq7RWm/RWG2wGC2Y9Wek85S5N6d8Wgz1pRmSdI6TA/rEFb8fraRh1AzyJBcEx1lcXCO1pBKPhTxIfj7HrJvUTtRQTZV4EhONIqyORed0B9VWmfQnuGOXbJIxjab46e0rMDxXMdwk+v0+/X7/lkrzq0Mmg8+GPEa5XKbT6Rwb+so4qmV0lHWcZdktSWMMh0MuXLhQVCTyM3u9Hqurq0VSgGsF9WzbZmVl5RgvQFGUInktl8trjhcEAaPRqBgCywG6bD9JOKv0epCieh/4wAcIs5Ct+7fQO8LWcLI7oRJX2GpvsdpbLZzjgML/QQ6oy+VygUSSmkhpmnL+/PmnvP8y8UkdJtM0cV23QD9J1nWe58J8iIiZNyOa3Xxnr2ka1c4hIiuMmPtz9FCnbJWLyi9JElzXLUyO5P3N87yohp4qKpUKvV6v0JC6cOEAVc1wA5W/etxmd6Rzz2bE804H6Br0pzofOWtzeV6lt9ojD3Lcvsvuzi6+42OvCgTZ8vEl4SQkS69//Y5WEa0TLdq9NhWrIuYFJQ3VEbLl/p5PsB+I+URFBwV0S0fv6oT/NGTxcwuylQzlMQXlixWUf68UPtWKohCMAvwdQZBTFKVoi7quy972Nsm/+TcoX/u16C95AfbXvBqnkqL93DtIJMroUAjxRm1hVVWpd+ts3b9F584O9W6dZHHY5x8FDPeHRRWtGgLNdLS1Fg6FF7he1bHXbGED66YEuwGpl2I2TdG2y3Lci65ow1U1ISlyEGApFlt3bfHgSx/kgZc8wMm1k6ywQim5fR7Vc4nhBvFMZwNypy4x+5/JkEzd62Hj5bmASFJy5w48Lc2kKIquiMNxRVPo6vM42qpSVbXYQR/t50s0jBzOHg2JSkqShGazSbPZpFwuFzwEoPBDsG2bl75UtJMeffTRAsnU7rXRahpJNSG3cmzVJltkLA4W2KoQwZPGK3Bl1ywXDFVV2draKhzibnSdpAud7/uFDpSqqmxvbxfvmUwmmKbJysoKq6urRVKLtAh3JhjRTxVm0yRMQqbzKVESUc7KrPZWOXHiRNE/Pwq9BTH/uHjxIpcvX2ZnZ6dgokt9qKujVCqxsrKCoig0mwErK/uoakqWKzy+bfLJ8xbNSsYX3eNTL4tz7q2rNDea3PHQHTS6DfIkZ7Q9Ym+wBy3I1ZxgLxDchEl0wwQhtYzqG/ViwZR8ENVQUTSFeBHjbXtkQVa0ZHRTCOSlL02Z/8ac9CtSlEhB/2Ed5SsV2BfXzqiI4fjy4pJwGh6bh0X//b+z63kEP/RD8mRQf+ifYv3+r+N8+gOYTVNIXg8Cgv2AeB4L5NYNvke1UaWx0Si+hzfzWGwv2P30LrsXdlkul4LvcygR7qyJWQ2Av++zPLsULHFVobReonyqjN2xMWoGRlPMIIJBgHtePDtZKgbW4VjAhmu9GmvPX2Pt7jXWymtP+WzdKJ5LDJ+hOCqJ8JmqGiTr96lCKoHKAeXKygonT568ZbhqEAQMBgMmk0mB2b9RtNtttra2iiQlHckkfwLEtZGL8NVVg0wMcjgtE0MQBAXUVi4aaZryqle9CoD3v//9RbWkaRqlUonxZMwknFDeKGM3bOIoZnhhiB3YNKwGKipBELC3t3fsPHZ3d5nP57RarUJz6nohzZmkaquExpqmWXzXNE2ZTqdFO1LKfS/DJXN3Tji9viLt0VBUBaNhMJlOmCwmBFFAOAhREJ/XaDQKkUEQCWt/f79oMcZxzHK5ZDQasbe3x6VLl459XykZbts2q6urPP/5KpubEY5zZQ4ynOn85adtwkjlhXcFvOz5Ea94hVggNUNj9dQqW/dtUWqXSLOU/kFfNKoVSOOU2I0J9sQCliU36d9rKlpFY6bOCMwAo2ag2qrQJsogGAUFcirxBCyzfLqM2lOZvXVG9LaI3MnR3qthvdoi/40ri3Ce5XiXPPxdH1M3We/1MH/hF8he+Ur2V1aKjQdf8RXwRV+E8qM/glE+nBH0bNHCmcdiWD0SLnM3vWc1g8pmhfKqqCTDYcjg8QHbT2wzHU+v/HbzI+TQwyE1ivgMvaQLPsd6CacjzsNuH87yBqHgn3gJ/q6Pe9EljdIiqdTueno+z0fjuRnDZzDk4veZIr1NJhM8z6Pdbt9UfuOooujTPR/XdZlOp1QqlWt2pTc6FlDIVIzH48Jr+WivvlKpFNDVoy2wo4lBtl7kZ8qqoVwuE4Yh5XKZl7/85XzTN30Tr33tawsSm+d5xQxFnrvu6MxGM0aDERutDfShTnqQsggXJJpYPKWPtBSok/7OR5VqjzLapS6TaZrFLrzX67G3t1e4x12taySd9JbLJXquUxqXCl/lm0W1UaXSrDAfzZmFM2xTWGBaHesawTg5bzhqRyrFE8MwLIQAj95jeZ8sy6LRqPF935fxxjeWURRBDgYIY5WPnrM4vRrzH38qJhllqC2zEJQrlUpsnd5iOp2iZAolrSSkI2YReTnHqBuFd4NeFm5x8r1HQ9qYhoTYVZtys1y4sMXLWLRZ3ADN0kj1lDRKcTYcwlGI99UexgsNnLc4qJ9Usb/LJv2TlPBfhgKFlIkWT7yMKX3wD1n70IcYvu1tuFDYvqqqCj/yI/BVXyUQSq95jWBVW0L7qeBo9IVTnl4+JM1p184hTdOkt9kjXUuZj+fMB3OSRcJ4OmbCRBDaTL3QmNJsDXLEMZaHxzBUjIpRtNLydo7t28IBcBQSuzGqohK7AhbsrDvCk/spnqmbxXOJ4TMYR3fpz3ZI+CM8fZ7FrYREOsnZQrlcLvrQt3p+ly9fJo5jNjY2rtEfsm2bZrNZtJVkHF14syyjVqvRbrdZLBZMJhO63e4xiKxt27z1rW9F13UuXbqE67oFaqherzMcDhmNRgVCKUkSliyxTIt4GTMfzzFUAy3QmGpTGiuNwmYUYGNjA13XC+TO2tpa0YoTbZdm0TaSA+719XWefPJJ9vb2WFtbO/YMxHFMFEVkWSaMa3KLyrhCeb1802trGAarW6ss50sOdg9Y+cIVsuWhR0HHui4fZHd3tzjW0esvE5YM+Ro5kAV42cvgl35pyU/8hMljjzVQFAgCm81Nhf/PT5l86f9LE3IUB4GQgaiIa3LU5xuEWVG6n9I/16fhNih1SiiaUiyuekkXVcGRBFEqlWg0GkynU4bDIfqqjl2zC3nyeBGLBXEWE8cxykw4vTk9BzTISzn+O33MnzbR36Gj/ZaG8wGH9GdTohdHxFpMPImZfrxP6cFX0vkbb8BybJwwRJVtQ5kN3/EOeM1rinO7mqORuILpHc2iQp1V6kUdDU3TaLQblO0y8/4cd+gKKfYYsITqa6Zm6IqYoUijIckDCSchykxUEHpFL5KRs+YQDkOiUUTsCWLd4uwCv+oTmbffwn4uMdxCfC5tOm8UcsF2HOeWWkJ5nhe72FKpxGQyIU3T65KmJBxVto2ksNytXofFYlF4OFQqlWs8GEBc0+vJTkjOQpqmBefAMAwx4KvXC8kPRVFotVoFm/nChQvFd7Jtm8ViQaPRKFpQ1WqVra2twsFNVVWWyyWKpVCulyGBeX+OmZgoukIe5viKX2gpSSn1fr/P2tpakYxLpVIhe3H+/Hnq9Tqbm5tFO2oymVCtVov+va7rGIZRCP6FasjwYIhW0XDqN6/GOp0Oe809lsMlg90BG6c3iEYC6mi2zGPX2DAMGo0Gk8mkEBiUSfdq1FKz2SykyGVVEUURr3xlxste5vHoozHDYcrWVpcXvSghDD2mSxOjZIAP2VgYzpgt8xoEj6IqeIqHuqoyGo8IhgGNVqM413geX6kgjiSIer1ekBD7/T7r6+vCgOpw5261LLGjHgYEffEnGkVCDLCso1U00v89JfmyBOstFuqTKvrX6+jfo5P+aErcivFe8RKW9z5IkHqUg0sY2ZX22iLL0BUF5+Uvv+69kBwNzdbIM9HWSpaJ0ItSlStVhK4UCST1D6vgWoXGegMMUBKFeBkTjAToQisLwEGtKUiqBZopuYJmulq00FkREOBoGhGMA5JFQuqm+KPbb2E/lxg+CyEH0M+W2moYhsWifT0l0OtFmqbs7+8DIpnIHvP1fCN83z/2+U8XlSV/zHme02w2b2g6c6OQiSFJkmIRK5VKJEnCYDCg3W7TbreLXe90OuXxxx/nD/7gD/iGb/gGPM/DsizCMCy0mAzDKBbnOI7p9/uUSiVBerJUMiNDLauERkhJK6EsFbJlhmu5OHWHZrPJuXPnKJVKDIfDgtEuE5zkA8hB+cbGRiGT0Wq1imql0+lQLpcLn+nxeEzmZmiXNDYf3HzKqqG30sP3fPb29+it9jBbJuEoFDLVreOw2lqthuu6RFF0jU/00ZCggaP3ScqZR1FE7VD/HwZMJgIZdhQ0kIUZ+TjHPBCeC2bl+P3udDqM1TGu4grj+nFId62LiUkaCTvLbCIWPr2so9d0NFOj0+mwv79PFEUcHBwcS8iyh2/UDEobJYKDAHfbxb3sougKVsOifLqM9ZUW0UMR2o9qGL9kwDtA+yMN7Zc1rK9/EX7fx73gMoteiN82KZ0okRs5owPxW2m1WjxVp15RhXCgUTHIIpEEommEv+eTZ7mQBDlMfFpZO548dQFlzawMXNFCmiwmTHemlNtl6l3hvqjqKmbDFBWYl4oq4ohooVYW5DujeihJPg1RDm5/Q/vc8Pkm0Wq1rgsBfToRxzHb29sMBoPbgr1eHZJxDBzrvz9V6LpeLKRRFBW7x+shpkqlEq1Wq4CaSlLarYaqqgVM8nraPUcjCAL6/f4xxJN0TrNtG03Tir7v7u4uvu8zHo+P3ZN2u82b3/xmfv7nf56//Mu/JIqiY7wNiYzyPI9Wq4VhGMWuWEpayxnBMl5idkysFQscCF1hlNJ/rI8eCXEz13WL802SpGhXqapayI3IBGBZFtPptBj4Sh9qKfWRZRmhGmKbNon31CixXq+HU3awyhbL0VII2LWsYjE6GoqiFNdfwmdvNSTMuVqt0u12C4ixVK6VbTxVVVEtFbWqEmSBkA0fCfVPOeyez4V8eL1Zx27ZpFnK3uU9ZukMo21gNYX/dxoJ6KZ32cPv++RRXpgSxXFcPPdXh2ZplE+U6by0Q+N5DTRTw9/zGX1oxPzJOca6gfKzCsF/DchWM3gc8i/OUX5EodQu0XpxC2fTET4Yj8yJtiPs1CZPxG/tVn+7WZwJjaRDroVqqmiOhqIrkCNkL6Lr2+SWqiVO3HuC1pkWRlPY3y73luw8ssPu2V1CPyzui17WRZWwImYSUrwvGAbkaY7VtYQSa+vpbciOxnMVww3iKN7+mYRshUiW7VHc/+2E/IHL/vbTCekV4fs+hmEUi6fE7MOVHv/R7/505ySNRoNKpXJMfuJGIQXopDc1cE1rrNPpkGUZ+/v7zOdzVFVlNBpRqVSKauBLvuRLuHDhAn/xF3/Bl33ZlxWDYt/3i+phNpuRZRnL5bKAq8qKSdf1IpEsFgucikOYhGTlDKfuUNNrpPspqZfiRz6D5QBtU8iAS3E927aLll2pVOLEiROsr6+TpinL5bKQ0JADaV3Xi2pjb7hHruR077q27XY0TNPkxIkTwmda0QhHoTDGaZhE06jYScsQw+RGQYS7nZBtO03TmEwmBaNdig3KijhNU2zVLnbLbuCSadnx6oKM2Ihxxy7simey3qoLD2Rf9NMTNyEchETjCKNq0K62GS/H1209Hg1VVSlvlHHWHNyLLouzCxZPLAj6AaXVEtZXWMQvidG+X0P/XR3+NfAu0H5Zo/ZADWfFwb3girmNY6EaKu7SZekvicKIldVrHfiyKCsE87I4K8hpZtNEtYRasCTyJV5CMkwKtJFWEm2xo+cv52NBEDAfC++GcB4SGRF5KRdtMkfMMDRTE6KFjSutrGAYFFWEs3r7xNrnEsNnIUqlErPZ7FlJDHKHLzH7TyeOJoZSqUQQBMSxGOAdHBwI0a6rrCRvJ+TCJ2VBbhZHOQ1BENxwXlKv11lbWyvaHhICKyu617/+9fzyL/8yH/7wh3Fdt1hAJQ+h3W4zm8148sknCcOw6KtL0b3pdFok21qtVgxkHcdBNVUa6w08PHAhWAQkYcLuuV167R65m+PYDs1WsyCaAcUQVg6c5SxCSovbts3m5iaDwQBDNVjOl+j7Oq211nWvgQxpCKPkwqdZ9tbzLBekucPhpYyr2eW3G9LwaDgc4nkeo9GokDk/umCqtko0iaiGVXItBwfiVDxnSZJQqVWoVCuYsYnhGSROQn/SL8QXtbKGYijgQTSM0Ec69UodAsj1/CkreFVVqZ6uYvdsZn89I57EeHtCYsNoGJg/a5K8LsH6IQvlowr5C3OUH1Mw3mxQu69GsB/g9330WKdRaTCbz4i8iJ3ZDq21Fk7ZIfPFXEXKXGu2hlE30CztGpSYqqmoNUHmy6JMLOKemBWouirQRiW9mK9IWLOz4ZCsCEdAR3VEwhyFTGdTtLJGrVujVCkda2WlYVoMxIP57cvxPJcYbhISoSENWG43ZGLwff8Ze0G3Wi3K5fLT7tvDlZ34UcKW53mF7o70Mbid88vznH6/T61WQ9O0Asv/VNIbknm8XC5ZLBaF1pC0xyyXy8U5WZZQzFwul0UFUKvV0HWd17zmNZRKJUajEU888QTPe97zikF7o9EoeuiSfNZqtTh9+nTRRpKIoizLijbK1TvsTqfDbrSL3RTkxVathZZqMAViyNSMaBGRBRlpOy3kIAzDoF6vF1DRLMsKJdTV1VVWV1fZ29tj/+w+yyeWlJqlmwIK5IbA931cxaUUlojnQjoCEC2lnGOVg4wsy26pkrtRlMtlNE1jNBrdsGJVNRW7Ywsp7GkEIdQaNaENdMiKz7JMmDGNI9E+WniMl+OiTWUYBrmVk5FBCG2/zeLcAs3R8HUfvabTbDVvujkyygbN5zVZnhM2nKqpCknsRYL+Kp3kXQnWD1oY7zHg+yH/3Rz1P6uUzghtJveSS7pIaVaazMIZyTxhuVgSOzG6o2M2TeyGjWqrt7w+qKYQdjTqRjGUThZiIVcNtagkVF38BuX1AOHyF/kR0TyCCfgjX3gytMvUOrVjw/m8keOrz0lifEZif3+f/f39W5IVuFlYllWofj4bZLfbTVRHSXdyFyulJgzDYG1t7ZpSeTwec/HixWOSGNeL8XiM7/sCXqjrnDhxgmazeUt9bfngywQVRRGj0aiwrdze3mZnZ6cQ36tWq4VktzyvVqvFyw8RJJ/85CcLkbter1ckUcuyCin1q0XopNy33F1Lc5+jIfkYkj1ebVbRazpKU0FpiH51GIQMtgcMnxji7/tE04j97X2eeOIJNE3j1KlTRYtLDvgVRXghq2WVKIg49+i5p3zm0jSl3+8znA5xc6HbnwYpZt3EqBlEM+E7cDTCMGRnZ4fBYPCMmP22bRcoIRnX2wDoh+QwzdaEqf0wgFzcB0n4M1smRtWgrtepmqIdV3BADOHfUF2vUru7RmmrRJqkXHj4Ao+//3E+9aFPceHcBXZ3d+n3+9clYGqWkPC2GoLv4aw66DWd1E8J7RDvZz28H/XInRzlvQr583KynxIbEWfNQbVVgv0Ae2ZTrVRpnG6I3r6jkQYCOpt6KXn29K6nRDVZbaH0arUtVP0KgS44EPLbV7PFTcdk/c51KlsVlKqotGfbM7Yf3mb/yX38pVhfZBVxu/FcYrhJPJswVYlIkjvTpxuLxeJpSVjcKCRBzfO8QgXSsqzCXe16IZmxNwrJbgaxq5Y7fSkL8lRxdHe+XC6PkdzG4zGTyYTlcollWQU89ajKqsTlv+51rwPgwx/+MA899NA1ZLwgCIoqRg4VPc/j4sWL7O3tFQlXutFJsbWj90yinI7ySNI0JUxCzLpJ92SX5laT0AhRjEO8/iQhGScMLw1J3ZSyVS6SnAzDMFjbXMONXUbbIy5fvnxzM/vDNt1sNuNgdoBqqoRj4cN8o+QgNydS2vuZxNH76nkeOzs7xwAExes04UpntS0harcnhPHkd1MUBbNh0lhvsF5fp6bXKJfKhYeGTPCqoWK3bRr3NaierKLZGsuDJdOzU6bnp8wGM6bT6TVM+r29PQbjAVEjIlZjvLEHNtgbQsE0jVOivxGx+N0F0V1DFF9B/T6V7BUZyScT7I5N/f46VttCSzRSL8VqWdhrNst8SZqkwithzy+Mgp72tTycOVidwyTRskCDeHY4VD4UE5RSHLJyPnHXCTp3dDB7JrmZ4099vF2PoB8Is56nmayOxuc0Mbz1rW/lxS9+MdVqlV6vx9d//dfz2GOPHXtNnuf8yI/8COvr6ziOw6tf/WoeffTRY68Jw5Dv/d7vLZAgX/u1X8v29u1Lzl4dz4angpQruB2PhjAMGY1G7OzsPOPkcJST0Ov1Cr2d2/WoTtO0kGuu1WrFYmxZViEjfSshq4bFYlG0sjzPY7lcFr4KkgkNFL7NQRAUaJWv+ZqvAeDcuXPFYp6mKVmWMRqNePTRR0nTlFKphOd5TKfTwsO53+8zHA7J8xxN0wiCoEATSRtSEFVXs9mkXq9TqVRIkoTRaMR0OsX3fXq9HrZjk+kZsRnjrDus3rWK3bDJsozd87sk44RklMBc4PjTUODbu90u1ZUqeZZz+YnLxXW9UayurqIoirCd1DzIhfNanl8/OWiaVrR/ptPps7LRgCsy61Kq/HrPt14SZCytpBFNosJzQYZRMSivlmmVWjT1JoZuFIlvb2+vQAWpqsr9z7+fU88/Re+BHpVOhZpZw5pZKAMFZakUUhVpmhZChkt/iWd7LJMl490xB5cOWKQLjMahR0R8wP4rf47Ji3+XzMnQP6LjvM5B/Q8qRsmgdk8NZ8MhnsfMPz1neH6Il3qMkhE0RHWU+An+gY+/7xPPr93t30pIDoT0sLBalvC6mETFoh/PY7IkK7xXNk5ssH7nOtUTVWobNVAgnISMn7w+iutW4nOaGN7znvfwpje9iQ9+8IO8+93vJkkSXve61x0rB3/8x3+ct7/97bzjHe/gwx/+MKurq7z2ta89pl/z5je/mXe+8538+q//Ou973/tYLpd89Vd/9TNuAT2bIYXaNjdvjlW/OvJcwP5AJJdnKq8hdYSkxPONbCxv9dwklE/qGoHwlZZEtFsNCe2UM4osywoUUb0usNzSkrTT6dDpdIiiCN/3i533nXfeye/8zu/woQ99qBgof/SjH+Xg4ADP84oFS7rNyUQgk9J0OmU8HjMcDosZx2KxII7jY8+STK6yepHnNxgMSNO0aEfJHbRu65y48wRKWaEf9umHfdGKSIU8dNAX6p/RIOLM+hlKlRJqoHLp4qWb7uxt2y5aY3v7exhNscglC3Hdr5ccjqKn5HP1TEMOw+FQsXRv77r3XkJr7Z4NOWJwPo2Kna3uCF0gUzNpqk3aDcFVkbDY4nMOW29O2UFv62QrGZ17OrRbbfSlzvyxOcsnlySLhG67S6vRomJXsHQL1VSLFlA2zoTW0qky5f/+i7iLy/Tv+nMufc9v4b3IQwkUzP/dJHxpSP8P+2iWRuXOCnpZJx2l5Ps5sRszGA3wFb/wmlAN9QqEtB+QuLe3ey+SRFdoJVktC1SKdpO/L/wmsigr2qRG2cDu2jhrDj6337ZW8s+WxdgtxGAwoNfr8Z73vIcv+ZIvIc9z1tfXefOb38w//af/FBC7k5WVFd72trfxnd/5ncxmM7rdLr/yK7/CN37jNwJCBG1ra4t3vetdvP71r3/K487n84JVexSmeenSJbIsY2Nj47aHdc80pHWmqqpsbGzc9s7+6pD+DU+VpMbjcXF9rh42zmYzJpMJiqKwvr5eXCM54JVchNsZaD/yyCMsl0tWVlZot9uMx+NC5O3q42uaViTc6XRaJL9PfOIT7O/vUy6XCx8IVVWLxGXbNidOnKBWq3Hx4kVmsxmdTqfoc8vEJFnT1yMo5nlOHMeMRiPCMCw4Cjs7O4UndK1WI89zHn74Yfr9fsFCdhxH2E/qlpCbTgT80Zt5DC8N8TMfo2Fw5p4z6JZArSi6ck0b59FHHyXLMs6cOUPNqBHPY+yeXUAhZWIwqgZmQxgk7e7uFlXKjVR5n25IToq8371e74ZD9DzPi6ErqlBBldo+WZIJobw0F4xuUymee3zV6JEAAFxiSURBVHmtG40GhmGwv79ftBLX1tbIfKGEGk2EHwOaSMzSA0KzNIEMChKMqkEe5Si72+iveSmT/+NHCac+4Qc/RvrmH6Dxp+t0f6aL6qtkZkb4fSHZP8igJJ7xfJETBRGhEUINypVyAQ6plCuknoCoegvhH2KWTczqFRjr7Uae5aRBSuqnBZta1dXiO6qm+Hy5nl69rt1KfF7NGOQOS+4+zp8/z/7+ftE7BtGieNWrXsX73/9+AD7ykY8Qx/Gx16yvr/Pggw8Wr7k6wjBkPp8f+3Oz+FzlTqnMCVd627cbruseQ95Mp9Oit34j9dCnCjlwlKQxOPzBH3FK297eZm9v72l97lHNHrkAyM87GtVqtSDTyUVc2mnKRKrrOgcHB0wmE9rtdmEsJElbQSDcxtrtNqZpXtnlH0IwJYLoeqABySbf398vbEHjOObixYvF30sTIEVRWF1dLeTLq9Uqvu9z/vx5xrMxi3hR2Ea27mqxes8qlmVhWzaz/oxwFOLv+/g7YjAZjkOBRMKk3WiTZzkHBwfgiIGrJJmBqBzMhik0hsZhwZ8AkfifDeIlXBlKS7c+yVq+XiiK4FvYq2KHHQ7FcDpLMlRdLdRMw2FI5l05v+l0KhRxd/cY7A6omlXUQEX3dII9kRBUXRVzja6FbuvCBCdIyZNDpdWmgVk3ySORePiVXyJ68ZfT/Ob/N5tv+nbu+NCfcOp9f4T9D21mvz8j+uIINVJx3uZgvcEi/WSKpmpQBqNkYEUWSl9hMViwvb0t5O0P3duMtsGUKQN3wKVLlzj78FnOffwclx6/xN7O8d9enue4rluQJJMkue69KWYSbQtn47BKsdRC2M/fFeqvWnr768XnDVw1z3Pe8pa38IpXvIIHH3wQoJBwuFrPZ2Vlpfjx7e/vH2tjHH2NfP/V8da3vpUf/dEffba/wi2FJDrdisCeHA5LJM4zOeZwOERRlEIETi50Ejv+VHG95ChnOkeHvEcXb8uyjiWJW0lsaZpy6dIlwjAUqqi6fmwYLUPKTWiaRpIkXLp0iVqtxsmTJ/nRH/1RfvVXf5Vf+IVfoFwuMx6P6ff7PPjggziOUwxfl8slSZIUUhaGYeC6LovFopghzOfzohK5msUt3eBk26vX6xUoNjkcTtMUz/MKmKeE40p57izLmM/nhUdEuVxG0RSqm1Xafpv92T5G26Cz2oGUwjQ+izKBhslzankNP/HRlhrDC0NarRaJm+Dtejg9B0VXMKoGiqoQjkPIoNaqFXyPZ3Pjo+s6q6urBRP8qWDVqq5idwXrO5pGBPsBelXoDBl1IZXt7/kioZV0nMgRJEPPx8fHV3wM26BcL2OUhNaSaqoF3FOqoUazSLjCBQGKIVjJWZCRfXwb++d/kuzt/ydRoJBaFczv/i6st/8rjO/6NuLnN4h/LSb7tQzrX1von9Cpfm0V838zyf63THhOzALcvovv+WRkOOaV30Oe55iWSaqnogUVp2SBqArzaU62zLDXhc92Tn5dO1lFUVBVtWhhys+VnQRFUYSlaU2BFPIwJ/ETwvmtM92vuY+3/c5nOb7ne76HT37yk7zvfe+75u+uLrsK7fKbxM1e84M/+IO85S1vKf57Pp+ztbV1zesajUYxjHy2QsIxpQfwjSIMwwJh0W63b7v0XCwWx2YU0m2sUqkUu+Ob7RgNw8C27Ru20q5G/shEIHfcUiNIsoGfKsIwLDgVZ86cKWCNkuUsQ1Ymkt8wHA6L/v7jjz/OuXPn+O3f/m3+/t//+8Vivb29zV133UWz2SSKomJBbDQaDAaDAs4rd7m2bVOtVosZxdUtMcl3uHz5cuFHLYl0QRAUXtiO4xQoptXV1aLFcnBwUCQFicaS0GZVU0n1FCuz0FQNPxSSHlcLEmZphhVZlDolxsMx5VKZPBY743AQknppwZSVstBBPyCaRbSbbXRTJ49yUkXIOKAe/t7U20flqapKt9strm+e56SJMJXRVZ08O0S5paItkmc5eZoLQx5PKKfm5ALTf6hUGs9iskBYdLY326SkLLwFS39JoiSMwhEVo0K71mY6nRazqqNqqFJjKPVS0WYCov/+5yRf+w9x3vAGjLJBskgIvvm7MH/xv6D/1L/D+vEf//+39+5hktXluei77rXqXl3V3VXdPT0XmGGQQZwNolHPiUajBjXxROEJkidocHuy40YRxXvCxiAEg7d9iCZ6fATjlmz3jgg7OxDQEwGjiYqAcnFmmGvf6tJ1v6z7WueP1d9vVnVXd1f39DijrPd5eHS6q6tWrcvv+33f937vCykpwbrGgvabGpQPKxAeFhD5qwjs+23ot+qIvTSG2FiM+VRrT2nABKBOqhAVEVNTU/61Wpohof/Mnp+JWE3L77WIHgTHH+7zuJN0adpgBJ9TymRXQywW+9WffL722mtx33334ZFHHmEnEQCrJxeLRRQKJ92IyuUyyyIoPa/X631ZQ7lcxste9rKBnzdoeGkQtkISYzlisRjq9Tp0XYdt26s2k6mpSXTSzSAYFBKJRJ/uUzAwrIXlmU2z2YRhGIyWuhzLpTUikQgbSBsmMKiqyryTg/4H1GQlkKqpbduIRqNIJpNoNBoolUp4zWteg7vvvhv3338/3vOe92BsbAztdhsLCwsYGxtjsgO9Xg+JRIJ5QlOwyeVySKfTsCyLCRaScNzyQCjLMqLRKFzXxeLiIiYnJzE+Ps7+hl5PlqRkw2oYBtOBosDgOA4qlQpjG2WnsjBaBvS6jla7xRrmQaYXL/DgVR6iKiI60n9+jUUDVtuCmBDB8zw8xwPv+jtMo+7bSUoJadWCMhnG+P8I/DsYLwYlG0vGM/CW/r/rod7wpTSW+3JQwOIEf9cbyUbgZT3YHRuu6YITOUSnoz7TZtGAa7q+eJ4sIZKMIG358tzdbheiKKJer6PVaqHX6/VRsEljSIyJcEy/Qe8cOg78ywOw/uhd6FUcSKYJXuDhRuPQ//TDkO76G8jXl8Dnx6HkFLhJF+Y3TdhfsyF/Qob4lIjY/xWD/g4d5rUm1HHVb/rOa+jN+M5tSAPZHVnIMV95lggLwEmmoud6cDS/HzEi+2V0IeJPQ3MKB9dzB25K0uk0y1iD/5Ge1Wpe1cPgjAYGz/Nw7bXX4p577sH3vvc97Ny5s+/3O3fuRD6fx0MPPYT9+/cD8CUhHn74Ydx2220AgIsvvhiSJOGhhx7CFVdcAcDnLj/11FP41Kc+9cv9QkOANGtowVlN/4VokZtFMCgQFzwIkmWmCdxhoOs6o26uJu8RzBgAPwhTYFgLQSOcVCqFarXKSm6Ddq6kalqtVqFpGmMp8TyPV7ziFeB5HocOHUK9XseuXbtw5MgRaJqGSqXC5ERI9I56DM1mExzHsYxBlmV23kZHRweW3FzXRTweZ/7KpKZKdeLgrjmZTLKHWxRFZrM5MTGByclJZvDTbDb9ae2IjOR4Es1iE4IkoNlsolwus+MZdA47nY4/WStJkLMyXMeFq7mQx+U+qYbIWMQXXfM8iCkR9WYdEcUf4vI8D3D9BYst8sDJhX5A6anvGi0FDwokrueCd3h4loem10RSSSIzkvEDwipZiZJR4OgOo7aKMRFyToZVt2CUDchp2a/hSxJGR0eZXIfjOKwcWKvVsGvXrhX3tyALELICvPfdAvvwY+BqM7C+p8Oxu+CdLjjwcGwXvV3/AeZX7kPkvW+HFJfAy37vw7nWgfFaA+INIsQHRahfViF/V0b3z7vAb8C34kxLqDxXAeaBYr2I1FQKkVTkZBYUuBZBmW7P8ctATs+fj2Dy3lEBgtSvq7Se1MmpzKqc0cDw7ne/G9/4xjdw7733IpFIsJ5AKpViJYTrrrsOt9xyC3bv3o3du3fjlltuQTQaxdve9jb22muuuQbvf//7kc1mMTIygg984AO48MIL8ZqAwcZmQA82+QFsFUj7flBgIBeyU2Et6Lq+ZlAgpNPpoXV0aDcL+Dud1TSfKGOgwECLKS2Cq30vGmIjlszi4iJarRaTy6Y0nBZ04GTWQ5nXnj172D10ySWX4Ec/+hG++93v4v3vfz96vR4Mw8D27dsB+Is+9Qg0TUOxWISmabAsC4IgsAluAJiamoIkSQPl0z3PA8/zyGazrPxH9y5RQkn4L8jsWlxcxJEjRxCNRrFz507mskfezBRE0vk0erUePNtjZbZjx46xwB5ErVZDu91mpbh8Pg8lq0Av+aqnSu7kTp0WOWPRQHO+iS66MGwD8XT8tDgOFhIFtptv99owHZPpLK0GcjWzOz57yek5EOICPMHzMx7TgZz2Ax71MnieR6FQwFNPPQVd1/HMM8+gUCiwkl4QnGtD8jSIn/849G37YOx4IexOFWK7BsnoQRQlmNwr0D7UhpjwaaNidEl24oUCnPscmP/NhPhhEcIRAcm3J2G+zYR+vQ4+wyO9LY1WpQWn66B2rIbkeBJqQgUncCf1kZYxlEgAT4pLcG2XMZvsqs0E+oSoMNAMaCtxRumqq32xr371q3j7298OwH/wbrrpJvzt3/4t6vU6XvKSl+Cv//qvWYMa8BfCG264Ad/4xjegaRpe/epX4wtf+MLAvsEgrEZXXU673CpQvdvzPBQKhb7UulgswnVd5HK5TekhASeNdmjBOhU0Gg3m10xKsUFd/OWgBZzUQz3Pw8zMDFzXXfFdCbquswV9bGwM0WgUxWIRx44dQyQSwYte9CKUSiVomoZsNttX2qLGOs/zmJqaQr1eR6PRwN/+7d/ir/7qr/CqV70KDzzwgJ9aLzvmSqWCbrcLnucZDZKmtcmYJx6PM/l16lVMT0+zBa1arbJmNQCWvdRqNWZdSlPbuVyOMaU6nQ7+7d/+DaZp4qKLLsLk5CRc18WJEydWfMderYfy0TKchINGu8HomXv37u0L0KZpYn5+Hs1mk5ECJiYmfPmHqgE5I6+QSfBcD/qiz/LxFA+JbIJ5TZwO9Ho9LC4ustLI6OjounaxdJxWy4Ldsf1sRPINcHjJZyAttwjVNA2HDx9mA5LkHZ5KpVa4BhKMql96E1QBnrU0mS1zPr21ZcO1Xd89LerTX0n4zi25cN/vQvxvS3TbvAv9Ezrc17nw4KFersNu2oADqGkV8bzfL/Ncv68iqiuVVpfDtVxWbnKtJeE+VYCoiqtqNa22rg2Ds2qO4UxhtRM4NzcHy7K2PDAAJxelRCLBFu8geyg4F7AZBCUHTgX1eh1zc3Ns0KxQKGw4YNVqNTZItvxvXdfF/Pw8bNvuOxeGYeDxxx8HAFx00UVsgV2e5Xieh/n5eViWxbyv//3f/x3PPvss3vnOd0KWZRw6dAjT09Psb6gnpaoqarUaJEmCKIpsx03Bi+QjstksIpEIs8rcuXMnJiYmAPg7/06nw1RZATC1WI7jcPToUSwuLsI0/R3y6Ogo65ccOHAA1WoVyWQS559/PtrtNpvDoLkLwF8Uq0eqaGttCCkBjUYDvV4Psixj3759fee0VCqh0+mw/glljGbdhN21ERmPrFhEPc9Dp9zB3PE5CFEBEzsntmy2YRAsy0KlUmGbDdK9Ggau7fpCeEveFZ7jG+HIIyt9s2kDFuyLcRyHWCw2uBTnetDLS3pOo4q/EHf8gAD4jDDP9fw5gaVSEC/xLEjgXwD8CcAf9c+vdZkF8yYT3DYOzU4TWkkDOoAoiEjkE2wYztF8raVBSqsDzwFJffeW1F2DmURA3fVUAsNZ0Xw+23E6Ymci4ddyqSxB9Wmgn7s/LHq9Hnq9HmMwbVWaqes6Op0OM+/ZTBazWikL8IMGlYKCPRVZlqGq6opm9vJZhqAZDVl6ep6H888/Hy996Utx7rnnolKpYNu2beA4Dr1eD8888wxs22bBwrIsjI2NMfYUeUPEYjE250JZk23bmJubQzabhaIojCmy/JxToCF1TGqMiqKIZDIJWZYxNTWFTqfDNgSkHEsyG+T0lkwmkRxPwpv3kBnLYHx8HM8++yz7DHKmA/zSIXlQEBVWVVVEUhE4hp85RMb7Naw4jkNiPIERYwTVYhXFI0XsOH8HU4fdalDWWa/XEY/HN3Sv0owCOZXZmi9h7eiO//OUxN5PEARs27YNiqKwc9lut/tKgdSwFUXRn8zOLZXe6n7pTUosTZN3bdjwfRecrl/SktMyPOvkoB5/IQ/hBwKEvxLAf56H9E8SxO+L0D+sI3lVEvJ2Gc1WE5Iu+dlPyx+yU3IKxKTov1dndaVVdg6WFFqRWjIH6vnHZS8Gyk2qcEpaSWFgWAOns4ZHevwEGjQiBc+NgKw0ATDXra0CTQvHYrF13zfIrU6lUuv2ZUgLCcAKlhN5IwSNdAAMlFqg80jaOiMjI7BtG3fffTcAMOluwzDYeaJMg3bvuq5jfHwctm2jXC6j0+mwcoxhGCx4UansyJEjOP/889ksQrBWTr2FI0eOYGRkhPlCaJrGZiYmJibYZHSxWGSS5aOjo1hYWEC9Xsfi4iJUVYUsy1DiCuLJOOy2jchoBHv37kWpVGIif7TDp9cHsbi4iImJCSgjiq+107AgZ1YG+NxUDpqlQatpKB0uIb8rv+bO9VRA5j9B0MzIMPcvawRrvqyI2TLRm+1B6vgGNbSYkscIgZh+hHa7jXq9zhz1FMUX/NMrJ88T+S7LaZnNRJh1E1bDgpJToOQVeJbn9wN0G9Z1FvjX8VBuUMD/jIf6URX2vTa8v/CQ2Z1BbDIGz/VglAxYHQvd2S4ESYCUliCl/XkTz/RLZ2bT9JvlUf+/5UwjXuJ9ufVUf7nJ7tlMaXUzOKsmn882UGA43dU28kQAwNLdYUFMG2DtpvBmQU3RYZrUxK0mdk8Q5GxGO36yxAT8Xe6gUl1w4pkW3rX0r9rtNgzD6JPXdhynT4KC5/k+D+ZqtQpFUZizWj6fRzqdZtLf5L5HonOKorAAVKlUkE6nkc/nV1BxS6USut0u5ufnGXMmnU6zaWkyEKLj6Ha7qFQqkGWZaS+RRhNpMEnJpd2r7mc2qVQKIyMjjMZKQZM2FhRQSeiQkzhIKcl3SdNWBlie530v5hEZmu5r8VDJhibRTxdI8bZaraJcLg+tcyaoAtS8iti2GKSkBKNqoHWgtcLmlOA4Dubn51l5kxhopPG0sLAA3dFPnqfuyfNEMxHRqSgSuxOQkhL0ko72s21YLQtiXIQ6oSIyGoHwYgH6/9JhfMyAF/Eg/ruI2BtjiNwegXZcg9NzEClEoEd1uFEXnMzBalnoHe9BL/oT4GJC9Bf9ZUqrqymn8pJvBqTmfdps0KxpowgDwxA4nYFB13UcO3YMtm2zBWEjf1sul1lJaqNBZS0E9fWH0VQCTi7ag1hVxWIRCwsLbOKa53lEo9GBU+vBzwX879lqtZgD2GqfXSqV2CJKswLFYhHf+ta38Mwzz7DdKAUHjuMYC4kWdkVRMDExgXQ6jenpabarJe9m13VZ6erEiRMDF8xut8vsUnmeR7lcZhId8Xi8byLcsiwWmKi3QcZCQRpspVIBr/LgJR71+TpjccXjcVSrVXQ6HSwsLMBxHDZlrSgKKy1SU11KSBAiAsyaOVD9MxqNYmx8DDsu2AExKsKoGqieqLIs5nQhWErs9XqYn5/fkES9qIqIbosisSsBXuTROdpB+3Abjt4fYIhU0Gq1UC6Xkc1mUSgUWMZlGAYqlQpKzRI015fSdsyV5UtRFRHfEUdqbwpCTIBe0tE52oG2oME1XYhJEdHpKKQ/l2D90ILzfzrgTA7qX6uIvykO6z4LlUMVdHtddNwOTM6ElJRYJmfWTRhlww9wLiAmRGa8ZNQNP0hUVhfo40V+oFHTsAgDwxo4naUkAvHwLcvakAUjlUU8z2NibFt1vM1mE/Pz833a9sMER0rRB02K06JH8ww8zyOXy7FhrkGgLCHI8KGa8HLU63UmwSCKIrrdLiYnJ/HZz34WV199NW6//Xa0221WphAEgS3ws7OzfQt8LBbDnj17kE6noaoqdu3ahXQ6jVQqxfSAKKiVSqUVx6NpGgRBYOyler3OfLbPO+887NmzhznPUdntggsuYL0CjuOQy+WYAi5lW41GA1JKgiqoEFxfCqRWqzEZ9XK5jAMHDjDhx/HxcaiqiqmpqT5atDLiXwuzZg68rvF4HILom8jYso1WpQW0AIE7PT0H4ORcCpEumBHREoNp2PeQEhISexKITkVhd220DrTQm+8xKe5EIsGeFU3TsLCwwNhRdJ4EwVe+dVWX6Th5zmBPEkEVEN8ZR2x7zHeIa1swFk8u3K7tQrpIgvA9Ae7XXXjjHoTjAlL/KYXsx7OIHo3CKllotBto9prwXM/vO4woPiPK9nsIVtOC1bLguUu+z1EBcH2ZdW1eg764eRXXQQgDwxqIx+ObagRvBESFpBLFMCAbTbJHHBsb27KgoGka6vU6GzgjQ5lhuO3LG8VBUGDodrt933OtPkQikUA+n2cMHY7jVlU4JemSHTt2MG0jSZJw2WWXAQAeeOABzMzMADgp45FMJhGNRmGaJo4fP94XHILHRXIX8Xic+TTs27cP2WwWmqat8Mkg9tHk5CSTw6hUKkwjie4nmlKVZblf5sJ1Wflp+/btbMq/1WpBszWIERFJ0S8X0fAglalarRYOHjzYd46D18N1XZi2CSWr9El0D4Ku65ivzcOJOYhGohC74sAS1FZClmVMTEywclin02FKsMOC4zhERiNI7k1CSkkwFg10jnWglTQ4usMsVUn0kDJZylqmpqZY6U/OyYAHdEodxnAaRICQUzJi22JQMoovPcLBnz2p+gu32TCBywHuFxzwbsDjPEQeiGDyjycx/sA4uBKHzokOyvNl6E3dn9HI+OKHrF8i8gAPv4/QteE6rq+mqvD+Z21hkAgDwxqgwLDZeYK1QDc6NQt5nl/hPrUaaEepKMqWBgVawAD/uyeTSWajudqEdhDBUtJykPx2qVQa2i6VdJpUVUU0GmXHsPz9SZ9/cnKSyR4DftP1LW95CyKRCBYWFvD444+jXq+zRUfXdUxNTSGRSDBJi+XQNA1PP/00yuUyW9BLpRIajQbrfVDJKIigvwTHcawcRNedVFjJWpVKd81mE7Ozs2i1Wsw3g3yrAb83I6UkiJyIZMT/HtVqFdFoFOeeey6TFT948CAcx2FMHLo+CwsLKBaLsDmfEWO1rIGuY6Zp4tChQ/5CyDkYPXcUvOLvns26uWU700GgxnQ+n2esrs3c44IsILY9huh0FLzIw6yZ6C30oJU0CK7gDwAusbdID4s+n3zVecFnQfWaPdgtG/V6HTMzM6yH1LfJkXgoowrkrAwOnL/7T0m+iU9vycRH12DdagE/BPAfAK7NIX17Gjv/fCdiMzHYdRuLRxfRme2ge7wLu2P79qdLgoKu4YJX/IazqIq+mKLu+LRdhffnOyyXucptFmFgOEMol8t9/H4AjGo5DFRVXXPQbKNwXZdlIdRw3ijWyhgEQWA+y71eb8MPerD+vJq8Bi3cIyMjbDdomiabgH/kkUcwMzPD5hZInO/888+HqqqwbXuFd3EkEmGfTTMOlmXh6NGjrMdDNf6jR4/2lT1IGZaYMEFqJrnKdbtdLC4usgG7ubk5Ns8QlKyWZRmxWAyZTIaxZCJehLGiqBG+PDjMzc2hWq3CsizwPM9UX4vFIhzFASdyfRLdBPKroAyn0+2AT/KQMz4zRy/pK2rvWw0q2wVZeoZhbKj3wHEclLSC6FQUctrf/Ts9x6/PL9rIxrOIx+KMHj0IQkRAZjKDpJSEDH+TSKSPmZkZVKvVPtqyFJcQKfhS2FbTgmu5UEYVKDkFnMjBbJjQJjUY/2TA+bQDL+FBfFzE5P89icL/KIDneH+gr22hN99D62ALZs1kNFTXdJlBj5ySERmLQIyLgLs0a7EkL45T2C+GgWENkBLqVjvBkb4/+TjH43E2fbsa+4MW7kGm66cKcmKjRuxms5C1egwk1QD4u+lhAprneYxOSAY4tm2zrIb+//KGtCAIbICp2+3i9a9/PQDg0UcfRblcxtzcHMbHxzE1NcWyNXI1o0WawHFcn95Oo9FgnruCIKDVaqFUKjGnuPn5+b5jIbXU0dHRPhomNblFUWQaSCTIRzr85DBHAajb7bJgISUlOKaDkVh/EBwZGcE555zDlG3p9cQUI2VXKkdaiu8lvJzFk8vlkM1msW3bNnieh8OHD2Nubg4mZyIyHgE4+Hz/5uA+xVYhSGSg61MulxnJYFgIii+voYwoJ82OOMBqWIiaUYxERlhwpJ5OEHJSRjwbR1pMozBWYL0I13VXbHRc1wUv8IjkIr74nuXCKPsCgEpWQXQiCiklwfVc6Jfr0P9Fh/NmB5zLIXFnAruu2YXsc1lWlnL0JV/pkuaXiBwP4ABbt6GVNRiLhj+Ut/TeyogCIXJq/aAwMKyBer2+ogl7qiBaHuDvgkmHiWimgxRPg6nuap66pwIyB6GFI9hPaLVamJ2dHYqRkslkMDk5uYKHbhgGarUaY9psBNVqlZnwcByHxcVF1rCnpvQgi0ra6SeTSbzlLW8Bx3F49tln0e12WdM++DArioJisYinn34apVJpRY3+vPPOgyzLzMzHNE0250AeG8RyCu5oZVleESipdDQ6OspmLqg0RYqruq6zCe1IJMJ6KxQIy7Uy6nodTsdhTXyi/GazWezZs4fdW47jMPVWnucxPj6OaDTqz500a2g6TRgtA2bnZHCgck46nWaTw+TdwUs8IuMRX466ZUEv6QPLUacDtKvvdrssuxr2eeA4DnLa32Hzol+XF+O+vIXbc5nBTa1SYyys4HvLGRmcwMFtukin0piamsL4+Dhr/gN+UJmbm8PCwoJ/T8gc1LwKMS7656qow7VcSIklWmlehXCuAOOvDehf0+Fud8HNcZCulpC8PomIGUGP68GxHH/iu2v709aKP9PAgYPdsaEVNXSOd6Av6r4j3ogMtbB52e0wMAyBrVqIaWfueR7T+ieQaNpy4xT6G8MwGJNnq9lSpCFDfYsgXNdd1UlqOUhSOLgQBmvr6XQa27ZtG1o1luNOWjrSDAEtxrZtswV4tfcjnn8+n8dLX/pSAMCTTz7JhOgcx2G7Q6KxmqbJHN+CkGUZu3fvBsdxaLfbOHLkCOtJmKbJRPPoehEtl74zlUNM02R1fp7nMTExwdhLFDxppsLzPCYhHXSII4kNW7BRrVUh2uKK65ZMJpHL5TA9PQ1BEBjDh84rNVcBwPAMNLQGThw6gcWKzwIyTRONRgPFYpHNf0iS1Ce1IqdkqOP+4rPcv/l0gIIVybJQOa5UKm0ok6bsQYyLTN5bzvqNXtd00Sv3YNZM1Io1JoMCgE1Ge44Hs+5fc1VV+zY7NHtCm6GZmRmUyiUYggF51A8sekWHUTXgOi4bUFMLKqQrJFj/asF6rwVP8sA9wCH2qhiSX01CkzRwMQ5m3UTnaAdWxx+uUwsqC9LwfK+N9nNttA+1oVc2P3sSaiVhdU0REkjbiArpWiD/ZFoQljN9BqmPkhYPx3EYHx/fcs2m9dBoNNBoNPp0jDaCcrmMXq8HURQxMTGx4Z4ISVFTeatUKrFF03GcNdVjg3j44YehaRr27duHYrHISjxEB52amsLs7CyOHz8Ox3FQKBQwPT29ggU1MzODp59+GpZlIZVKodFosOMhtgvNDAy6Xq7rYmFhAZZlQZZljI+PY2FhAdVqlS18RMkl2iQphtq27dt3wl/4W60WzJaJuBRH4byCb86ztCCNjY2xoHrs2DEmzvjCF76wbyEj3r5l+rafkiwhPZnuM4GhgEDeF8tF9pb7NysZBYJ6+qit9JlUZqQljGxFNwLHdPyZDstlrnGu6aJZbmKxvOgbBqkiRvIjyGT9zMDu2b4oYVoeOERGm5Zut7uiJJXNZqHyql+688BMhILPved5cH7ugH8fD/7/858Xe8xG7cM1yJfL8OoerLoFTuEQm4r5+lci70us6y6stgWraaFWqWHn/7HzV9/z+WzDVk4+93o9po+ey+UG0j+XBwUaYgJW9wPYLKjZuZX7gnrdH7wK1vyJ7js2NrapRnkwYwjONRAjaBi2FAC86EUvwt69e2FZFnbu3Ald19FsNrGwsADXdZlAXyaT6esdLO9fFAoFTExMYGRkhA0Wbt++HWNjY6xHo6oqPM/3YA4uDCTRTefCNE02h0APbjab7ftOsiwjEomw96Uss9vtIpPJQIyJaHVaqC345clqtdo34wIA27ZtgyiKaDQa+PnPf96n00+0ZI7nEM1GkUvm4Gke67vkcjlMTExgbGwMiqIMPN8ct+TfvCTQpy/qvqmOffrKSxzHIZlMMkpwJBLZFHtQkAVExiOQ07LflC7qgAtkt2exc99OxDNx2JqN0pESjj9zHFpDg6AKTKuJ5iOCID2sQqGAqakpZDIZdmyS5LOU1IIKV3LRWGigM9vpowFzHAfxhSL47/Dw7vHgbfcglkWMXT8G5c0KMAtEd0XBCzzaR9qo/6wOraTBc/wZBzWvIrEngdR5wz0bgxBqJQ2BrVg8KRtIJBLrOpmRIQ4tKqQaulWg4SFKv09VmpvQbrfhum6fMifx0inoOY7DzHGG0cQJSmGQuQ0pi6qqOtCLeRCSyST723a7jUwmw0p09Xqd+T5s374dqVQK5XIZjUYDkUikbwiPuO6RSAS6rjM6M80RVKtVJBIJZsZECzJlnolEggXKYrGIbrcLXddhGAbLMBRFYb0mEusjjIyMQNd1xjIayY6g0qugMl+BHJeZ1pJhGEyYj9RaW60WdF3Hc889h+npaSiKwphxRH12Og7ElojMeKZPBlqW5T4XxUHgpSX/ZvJYLjr+xO6S3/TpgCiKzK+DQI37YanmbCI8KsBq+JmT3bUhZ2RMnTuFdruNxflFWJrlU3W7np8Rcb5UtzquMtvUQceXSqWQSqWYXDrgl6UM0UBH6KBT60CoClCTKmKjMahxlTXHuTdzwOsA71Me8JeA+piKyJsi6L2tB/kGGbzKw2pYaD/XhpSWfJOgpD/dvpaM97rnddN/+TzAVtbyide+nn+0aZos7ZckaYW15qmCsVGWbtJhS2TrBUfaedL/J80ioP88Uo1cEIShvlcwYyCfBACMWUPTzOstABzHoV6v45Of/CR0XcenPvUp1hcwTZNNn5NuEx0nyXPLstxnTek4DkZHR9FqtbC4uIhUKoWxsTEYhgFN05gfNQVBqjvTd45EIshms6hWq4x1RX7cRKOlBTsITdMwOjrKyjoAYFs2Fo8tojJXwY69O/qCDhn6jI+PI5VK4ejRo2i323j66aeZiB/ZjfI8Dz7Jw9VdmDWffbTagr7cajIIMeY3dK22Bbtt+1z8lAwhdvrMZYLHQrLkJD2eTqeH8m2nmQUxJsKsm9CKGqS4hHgqDvUcX0xRlVVfpK5rQ9d0CLpPH1Un1T6HtUFYPigbiURgJ2zokg7HcNBpdtCpd8BHeUQyEYyNL7EDVYC7kQOuBqxrLUj/KCH2dzF4D3iw/syC8Xrf/tVYNGC1LChZBXJChuVunsEYlpLWwFaUkpbz2td7MGgnTCb3W9HbICxvZAfr0Fvx3gAYp56E4paDFnAavloPy1VVR0dHmXkOZSbDlsQsy8Lf/d3f4d5772U7ZWqsUy+F/HIzmQxSqRQkSUK73Ua5XGZlMvoORDcmhVNBENiUMvUIFhcXmZxHo9HoO55EIsFoj71ejzU5KWNst9t9tX6iapIMOiGby2JkfATZaBZwTwYdwF8kyawmGo1i9+7dTCeq2WwiGo1idHSULawcx0HOyqzBuhye56FerzMTq9XA8X5zOpKPQIgIMOoG9KIOu2efdlHKZDLJ7o12u43Z2VmmczUMyDlOTvkzG9qCBk/zy4bULOYyHBpeAw2vgW65i86RzkmBO2e47xeLxTA+Po5t27ZhbHIMsckY+BgPt+fCKPlZC52rTqcDbVyDeJ8I83+Z8M7zwFU4yO+REf+jONJGGtGpKOAC2ryGzkwHvYXh5z2WI8wY1gBNrg5yHRsGmqaxdH6Y/gDNMaTTaWiaxhaLrZq8rtfrjHM9NjY21PsKgsAGwtYCyTu0Wi22Qxv0/sS8Mk2TlVrWApVy6HVUiiMKJw28kR3mWrjgggtw3nnn4cCBA3j22Wexf/9+xizRNA3PPfccOp0OTNNkngzUAKaaNh0/4AckURQRj8f7rEApaJGXQ7vdxszMDAtoQXpjJpOBaZps+I9KQLQjp7mKTCbD/LOJGpvJZGDbNlqtFnKTOeglHVbT3zHGYjFYlsUyGmI6BUt7lNlR/4aOiRf9QTajZvim9LGT14jj/Aa367qsyb0W+vwTmiaMquGrgKakFcY6W4Xg3EitVmMMKyohDkOZpr6JGBN9me2GCbtjQ0r7x+04DkRFhCd76PJdGB0DSTkJyZCAuh9cRNXPnFYrMxFI1j4Wi8Eb9WBoBoy6P2Fut/1Jd9r8cBwH5RIFkUciiP2/MYi3iOD+jYP4myKS70wi9vEYumYXRtmA0VrbZ33NY9r0Xz4PoKpq3850I6DhKzInH+b1pVIJ1WqVceQBbJmiJS1SgN/8HraRnUgkMDk5uW7m4rouG8AaNA8RBH32MFLOFGCCfQmqHYuiyBhJ9Xp9Xcoix3F461vfCgD41re+hW3btmF8fByJRAKCIEDTNCb7TBLhVGYJZleKorBFlOizJGnSbDZRLBZx9OhRAL5VKZ2TVquFo0ePrhDey2azbMCR3N+ICVStVvHcc8+h1WohkUiwpnej0UClUmF8+Va7BTkpw+7Z6Da7mJ2dZfReosIuLCxgcXERi4uLSCaTiMfjUFUVoiiiUqmwjAnwy0FiVITZMFc0kemcU7lmGPCy33+IjPnlKWPR8GW9u6cvg4hEIigUCozsQYF3I+AEDsqI4vcRRP+49bIOVVaZnAoX4+CIjp/lCW14MQ/wfBXU3nzPn7IeMpPgOA6RaASpyRQiYxGAB7SKBsVQwLs8G3hs9BqYe9scDv2vQ6hfVgfnccCXAWGfgOS3kkjvTft/v0mEgeE0IChyJ8vyunRKmmqmBSGojaNp2pZo4dOEL3nfbjXIiYwc1dbKspYrra4H0ukfNMgWj8dZv2GYkhIFhvvvv9/ffSkKM3N58YtfjEKhgNHRUUiShHg8jtHRURiGgQMHDmBmZgazs7MwTZOxTYh6TASBer3OvBwajQbrKxCFtdPpMO1/Kh0FZc1JFI+ay6qqwnVdHDt2jMlqAGDlKeLNNxoN2KINXuRRL9bhui6KxSLrnViWxcpkwElv6lwux0ph9Xq9zwtBzsgAt1KFNWgmRSW5YSEoAiJjEURGI+AEjmn6WG3rtMxAUL9mcnISmUymb4NDvaVhwAJbLuJbgJZ0WDULmYQvuhcb958pbVFDvVuHMupPIcsZuS9IaCWNyVmsBvK3Nqp+xhYdiyKVTCErZTGqjmIkNcKk1aUdEur/Tx0L/2MBxgsNoA3gQwB/MQ/psVB2+7SAhrs2KolBu36q46/VV6C6v2marEZN5RtqVG704RuESCSCycnJoemdG4Fpmmx4ilRI1wIFBtM01637koEN6RR5ngfLstgDTYGI47hVJbmDuOiii3DOOedA0zQ88MADLGg7joN4PI58Po9YLIZer4fZ2Vl0u11Wn69UKjhx4gTzqAZOltqmp6dZk9owDFa3N00TmUyGZZ4UIEjVk6asKUMgyQ1a9Ek+RNM0HDt2DPPz834fYGkQkud59Ho9JhchJAXEpTj0jo5KpYL5+Xnoug6O45hPNWU+3W6XldKy2Syj787Nzfl/w/u7ZcdYqcJK5UKa2t4ohIiAyGjEn/xVBF8/aF6DUTNOyxQ1yXoHe2r1eh2lUsk35xly8yWoPr1VGVHg2R60kga36SKXzSF/bh4RPoK46GticQIHMSbCUi0mx8GLPOy2L6jXm+/5DCjNV0J1DIcppFotyy9HRcW+z+QcDkJHQEpMYWpiClNTU/699xoVC/csYP7WeVg5C8IxAeq7wsnn04Ju10/JB6luroZ2u903e7BeDZ20+geVX2gGgBQ6Nwqq4xM202hut9uYm5tbs6TV6XQgSRK2bduGc845Z933JB0fOsbVQPRPKlfwPM8kB4LlGKKaFgqFdb8jx3F4y1veAgD4n//zf/bJTdRqNSaxTfX548ePQxAEJJNJZDIZdDodlEolRielz4tEItixYwfzUKAATD4MhUIBiUSCBU2i7S4uLmJmZoY1snO5HGRZRiKRQKPRYIN0lmWxgCQIArZv346pqSkoioIdO3ZAkiTfn6FdQ6VWgWj4LCcypSEjn0ajAV3XmeoqnUOSKyGF3bm5Od+mVeEHqrCS2REAZqK0GfCS34NQJ1SICRGO7kAraf6OvHN6sggALBhTz6RYLKJYLA4VIDjOX/Aj+QiUjALHdKAVNfAWj5HCCGRbZgZBJNkytzCHpt4E4oA66bu8iaoIR3PQm+mh8VQD7YNtGDUDvMKfDCQS3/eZal7tb4r3PAi8gHQ6jdxYDvoVOg7ffxiV/1SBK28+wIaBYQ1sdDGmgSXAbyquptZIWF73X15+If75Zuw6LctiN/tG66pBuK7LyhUEauQRMpkMc8IatlFOxihr9TqoCUuLNU0B02IcXIxoJz4M3vrWt+Lcc8/FhRdeCMCvmUuShFQqhWq1ilqtxlg91LgdHR1l17Tb7eLw4cMoFot92lbpdBq7d+9mryEXt+eeew6maeKCCy44SQtdst1MpVLMk4HnedRqNdZniEajLFukISmaqAb8UpwkSeh2u8zKtFqtombW0Gg2EBWjbLKbRAwpKLdaLZimyTYxiqJgcnKSbWaq1SoWFxdRqVQgpSS/vl7rV2Gl/gqwdoAfBrxwUhpCySkA77uYMX+B3taZ0AAn5TVI24uo0MudBtd7DzHuD6vJGRmO4cDqWnB0B3pJh+f4zWLyCm+321hYWMDszCwatQYMzT+fvMxDSkuQR3x/aUf3B+30ig6rZcExnJNSJLzfFFcLvv6S3fYDhNk0EYv6XuLRsSh6H+rB+rfN01VDVtIa2ChdlfoDnucNVbKh3dqwdf+1uONBUCObehxbaTRETmJUr1ZVlTF2NoL1mF7NZpNlUrlcjs0GAGAOX2SLGQSVY8jecxAuueQSHDx4sG9obXJyEoCfIdGQGQ2SkTfC+Pg4k8QmUsHyoJ3JZJjgnCzLrM9ABi9jY2OsFzE5OQlJkhir6sSJE6zBTjIbqqpC13XmPV2tVn13sSUTJQLJe7fbbciqL9Ht2R6y41lGDY7H48hkMiiVSohEIn5GwPNsYVRVlR0TfU9iUClZhbGeyH4SODkcOYyR0zDgON82U1RFuI4Lp+cwCQqO48BHeIiR4dg+w0AURTZt3mw2+3o8623sgscsxZd8F7q+25pe8WcTIpN+CVfraGjX29CaGmzTRstrARIwsWMCclxm38XzPHiWB0d3/EDTshgbiZd48DIPXvH/I0kOq3VyXkRKSCjkC7AdG1YmDAynBRsNDCRONuzryTpyGDospaS5XG7NKWjyPqZG9vj4+JZ5NtBxAP5unRZR2m1pmgZFUU55SpuaqcBJgbxgYJBlmamPLodpmmwXT1nAcqyVWSQSCbTbbTadTItFuVzGyMgI2+23Wi3W0yBVVAI1dOv1OqOVOo7DjOhHRkYwNTXFrkskEmEzBTzPM1l2utZEmaWaPmUV+Xye3T+C4JcTaKH3bA9aUYOS8qmivV6PBfF8Pg/ALwHWajXkcjkW2KnsJUkS63UIgoCRkREYggGtqiGtppmsM+2GTwd4gQef8EtZruXC0RxfgrpuAHW/ISwovoOZoAinNF0dDBBBC1jAv+dt22ZCi6shGCAgA9UDVSzMLiA3moMUkRCPxJEYTcDiLGiO5utKpU4++8VikQ01Koria04Jgh8oTAeu4ZvyWB1/wecEzg8Ukp9xOJofSND2NZhMd/NZXBgY1sAwgcHzPHS7XcRiMfb6tRYe4sTTDTbsjARxx6vV6qoT1CTPTZo91MjeSpAkA+nQkxQzaQ/F4/GhA0Or1YKmaX1aMoC/+y0UCuh0Okgmk6zHEMwYAAysayuKgpGREdRqNdTr9TUNWAzDwD//8z/jta99LStpWZaFer2OWCyGqakpFAoFlMtlaJqG2dlZVoePxWKsMa3rel/GJ4oia5QTrXZiYgLHjx9HuVxGq9XC1NQUGzSjIFupVBgtVVEUtNttjIyMQFVV5HI5TE1NwbIsNJtNNlkdnIkAcDIQyoAU93eTYkzsuyY0i0FKvfR96V4h0kSz2USj0WAzEU2jCbNjonekh8K5BfAiz8qh4+PjbIp8o9njMOClpQUwKcFzlnbUup9NeG3v5Gtkni2WvMRvOFjQcCOBMlDLstBoNBCPx1dM2nuuB9dy4ZouXMtFt9lFu9GGwzkQPRGGZUBS/XtWVEVE4hGkhFTfuuK6LutvBEu/RDRQVRXpbNp/rePC6BiADbi2HyxAb+WBZRodY/N2AWFgWAPDBIZGo8HKHmQOsxpo4QawJs9/EDKZDKMeVqvVgQqX5XKZsaGCQ2FbgeAEJn1GNptlCyr9fiPZiaZp0DSNsXmCCNJ8l08/rxUYAH/ylernlUoF+Xx+YO/j0ksvxc9+9jPcc889ePOb3wwArKdBQW7btm3I5/Mol8tIpVJsjmJmZobRT+fm5pBIJJDL5dixUcYxMzPTV4rq9XrQdR3tdhs8zyOdTmNxcZFRRqmHQqY9giCwBaPb7TLDHZ7n+/SQlsPzPGjQwJkcxLYIOXVy4rxcLqNUKjHxOXK8W45UKoV4PM4MaRKJBKpGFe1GG9XHqn5PYCkLqdVqbEFTVfW0+qQT24cG71zL9XfTpgPXdGF37b7X8iIPTlz6X8FnC3E8Bwg4qUk0YDPneR4810MilkCr2YJlWGjpLbRKLSiiAjWiQhEU1vtwXRetbsvfqUcBMSMiySehSArkEV+kj1RoRdU/fj7Cs+s5NTXFdLMMw4BpmmwIMfgsczyHUr3Uf6yuB8/2MwtVUjGSGIHT2bzBWBgY1sB6gYEGmgAMVY8kHX1i12z0WHK5HJOaaDabK8okpLMzPj6+pQ8mmQupqsoYWrRIEjZDp1UUBZqmsQWF2E3Lsyh6KKh0Q9+N5CwGBaNsNsvkKkqlEvL5/Ipz8trXvhY/+9nPcPfdd7PAkEql0O120el0UCwWmRJqcGKWJpgBMGvOZrPJjJcAMB8FatQbhoFMJoN2u80orqlUqk8baWJiom/ugQaykskk01JqNBool8tQVZUdq23bbHEnD4tms4lGqwG7bSNpJMHpHCzHYhRh13VZ6Y8mrykzCDb4g1lEIpHA8ePH0Wg1wFkcZFOGkTRY05oyq1qtxhrkvwxQdiAuLWdUp3dNF67tW126pt+vWOs+pSABr/9+FiAgw2dgCb4Jk2EZMHh/8Y7Go8iOZX32kAi0FlrgbZ4J53mO50uBdGx/Ajwlwe4uaS0t6n1Bjqbo6T4jajZVAAh0zwdLeBzPgZP90pIclf3Zh0SornpaQEJvg3ZTRDUETu6s1gIJewF+trCZhZvKJCS8pigK27ET3ZV0/rcKxGhxXRdHjhxhE7OrmeNshMkVHHTTdZ2dz+W6+sEMiHZXqVSKsXRWOw4SkzNNE+VyuU/lFQCuvPJK3H777bjvvvtYXZlq8ESTPXz4MKv9U7mw0+ngxIkTcBwH0WiU9RkWFxcZZZYyg2g0yjIXmlmguQYKaCMjI+h0Okyag2rZ7XYboiiynkAymUQikcChQ4dYOYlKTuTRrCgKCoUCksmkT63tlaA1NMTtOLi4/90jkQi2b9/O5kEOHz4MnuexZ88etFoteJ6HXC4HVVWZ2CLROiVJghpX4fQcqJyKZCIJTdPgOA5GRkYwNzfH5Fy2UhGYQOXU5UZXy689LZLL4bneyf8cD1haWz3Pn1aGBz84cACHpWxC4AAeUHkVKT4Fx3VYc96NuBCiAisJknEP3b+cyK2QF5ESEqSEb81qd2yWRQjK0txC1O+XUBlp+fMsCAKmp6fZcZMcDfvuQ5S010MYGNYANaSWg/TuAZ+yt55cBO0cAfSVXzaDRCIBXdfR7XZRKpUYvx44WY/cKlAfIZ1Oszp0NBodeE6CN+awCAaGYrEIAIhGowO/w/JzNowLHNlYFotFpNPpFce2f/9+7NmzBwcPHsS9996LP/zDPwRw8sGbnZ1lje5IJMJYSDRQFo1GWSmF5DRIBjqVSiEajSKVSjFJimazCc/zWHmIskzDMFi/RRAEFjxSqRTLMAnRaBQjIyNMZA/wzznRY5ne0ZLb3+LiIly4EGwBI5kRqHG1b6NDMuS9Xg/PPfcckskko9hSrySfzyMajSKRSGDXrl0olUrgwEGv6nDaDtLTaZbVkWR5tVpl52arQKZCtm1D07ShvcOD4HjulCXAPcdjVrNUFqRATDMj0WgU8XjcN4SK+fMZZt1k/Q/A94IQRgR4aQ+OtsS+qhvgGkvsq6gIIbJ2U50yxK1GOMewQdi2zUxQyMhkrZvfNE1mXk87vlMFDUERdXSr9JSCCPYsRFHEnj17kEgkMDo6umo9FthYYCC7yEajwQbBVqOYbhaCIGBiYqKvORw81iuvvBIAcPfdd/f9XTqdZpabtm33cf6prEc7Q7KZbDabfYsiBe1du3ahUCigUCiwTGG5Q1rQhCgoohcMiLQznJqaYgs47c7J45qyCwBs+C05noTrueC0k4sInQMyGqJ+BZXfqJ9BZTJCLBbDjh07kEgmIKdkOJaDVqXF+iDkJVEsFjE/P78ljCUSZ1xYWGCCf1vNthsGuq6jXC4zr2kAfQZBJFRIxk/FYhGzs7Oo1WpwVRfg4c+CLCtncfzSwNxoBOqECinlN9iNqj8FrVd0X1NqSNXWrUCYMayBYJoWnNSl+YD15C6Ak5LQ9OBuFahByXHcltt9knYTSSmMj49DUZQ1g9pmJTuooU4c/9Ue9qBBDw1t0QTvesE2eI1s20axWGSzI1deeSVuuukmPPjgg6hWq33ZUDKZhGVZTMWV5hqCrC/P8/wHf8kchiQrgl4XkiSxngRlYdVqFZOTkxAEAZFIBBMTE2yiutlsYn5+3reBDPSugg1Kz/NYmUxRFMYQI7iuixMnToDjOL/kobnoHOgg3omDk7i+TDMWi7Ems2mafbLckUgEhmFgYWGBGRZRNhKNRlF0itBbOnqdHtOsSqVSqNfrmJmZgWEYrB+1mWyWCBv03aLRKBsS/GWBznXw/FLgD14f2vgZhoFOp4NerwfHcVgWMTE+AaNs+LMg6cHnYlWKbs3/bEERfBOeiABO4rY0IwsiDAxrwPM8zMzMAAC2b98OjuMYu0QUxaFuztHRUTZJuxUXkTRxaDKTJL0XFxcZzfFUQR4CjUYDk5OTbAe8VmCj0sdG0tp2u82YRcHG7SDQkFg06k/zBhleGykptFotpnxrGAb27NmD/fv34/HHH8dDDz2EP/iDP+h7fSQSYX4GlBXQMdNOP1jvbjQaTCSPmEWAXwIk4xhSbj148CD27NkDQRBY2YvKOpZloVQqIZVKrTjvkUgE09PTzFAon8/DsixW5qJGMuDfL8lkEovGIuAAckOGnJP7vBSITttoNCDLMiYnJ1kAtCwLrusiGo323b/M1nTPdlSOVhAxfXG5WCyGnTt3QpZlNqlOvhLkEreRe4TmRmhSeStNq5bPnwS/GwVcACwYchyHWCyGZDK5apCjjRoFSU3T2CyIqIjwUh7MholyvQwlrrBy5KD7dwVFV3Ng634/wmya4HiOBYlgiWorEAaGNUAPAslC0M2wkR26KIrratYPCwoKNGQWnKIl1c6teHgSiQSjYNKw13rN8s1QY6l2XygU1u3TLKesUtpu27bvrDXklCotssS/1zQNt99+O/L5PF7wgheseH2v1+ur/R89ehTRaJQxhQCwZjjp/1cqFaTT6b77hMpPsVgM+Xwezz77LJrNJubm5tiwGzWAyTio1Wqt+r1isRiT0aD3JttOWmQmJydZgMhms+BsDmgDyogCOd6/sBUKBXafU9Ob5h1oOI/KOCQAqKqqL00/OQK7asNsmJAzMsrlMjMLchyHBbvlC7GmaYxtFYSmaZBlmb12q6eryZ/BMHxGFQV9ogz3ej24roupqak+j40gW2sY0EYy2IQXEyK0tgZr0YLlWexZjkQifd7VyzeRnODLb4hxfyLeNVw4hsN6E4BfkqKBP17ZOPMxiDAwrAGO49iAC8krD5MOBx2zthKVSqWP2UTvTyJrVKLodrvIZrNDM5+omZdIJGDbNqrVKvM8iEajfTXmrQQxX4bRggp6PxNoN0+zEMOAdp6RSATVahWWZWHXrl2Mqrn8nCUSCWaiQwsHsXNIqoBAJRaS417+cIuiyIL2xMQEYxaVSqW+mjkJ1AWDD+AHMxLpIxmSWq0Gx3FYSUuSJMzNzbGFlUpGFHh1T4fX9cAlVmavqVSKGQOlUikoisIc4AzDYJsFKrGS9DcAuLoLr+KBq3LweL/BPj8/j0QiwVhYwSyFVIVJ2oMa1b1ej8l3UL9pqwICDanRMVNZkRhXQZAyLn32VtG/OY5DbDwG13RheRZMyWQGXdSnCWaJg3p3HHcyU0BqacBuKVC4pgur6ctoaJ3hJMUHIQwMa8DzPDSbzT7u93oI0i7z+fyW1v+j0Sg0TcPY2NiK2nNwUlXXdczNzSEWizFO/KDvRg3VTqfDJJzJvpLkNIY1Yul0Okz4ba3gGZw7IP5+8JhWK7fRTo0WQdL26XQ6m/KriEajUBSlL9sin4HgMUQiEaZTNDo6ilQqxQyY5ufnVxU/JBCtsVAosEXG8zxks9k+L+hKpbKiZxVcEG3bRr1eZ43YTCbD3OyCu1rq1ZB6qiAIsCwLkUjED/YpGa3ZFjpzHYxO9Q/GURZC108UReRyOZYJEXtKEATk83k2oGiaJvgID1M34TZcTO6ZhGb4TfFyuYzDhw8jn89jamqKfZbjOIzxRdRvuo7BLIjOF2UbGy3HknS+aZqYmZnpGx6k6x8837TDD5oxbTUEUUA8H4exaCCdSoOLcKyHRVk0gc6NLMtMKoOm6Qkcz0FQBQjqSWKBa7nQhc37uISBYRWQ8QvtJIZxPXMchzGQyH5yK0GOW6uls0SRJAtPkmyg4yCdHdd1V3ghCIKAcrnMGqfLJ6fXS0tpgZYkadXA4HkeSqUSW3DowaOhKGKbDAItCuTTLEkS+16maa5aL14LgiAwnaAnnngCH/zgB7GwsIBHH32UlT8orScZEJpYJ6G1hYUFxONxpNPpFTtb0zRx/PhxdDodtNtt7NmzB6Iootfr4dlnnwUATE9Ps/JFpVJBLBZjMyrBiWae55FMJtFqtRi9lxZ7+lzy3CBr2Ha7DV3XGT22WCz676G14DU8yHEZqfTJIajV6M40G0GDleQrQZ9Pn2FlLXSLXfA6j7HxMei6jtnZWbiui4WFBTiOg+npaVYGJBq0ruuMoSYIAuLxeJ+shm3bmJubY9eMym4UQIgaCoDJhhNji6S1ATB12UKhAEVR4DgOTNNkZZytVApYD6Iqwok5sBoWIuMRJJNJJJPJFc8Z3XfBjILOg6IoA3tzHMdBkAVI8c1nOWFgGIBgLZ/jfIOP9RZ5onc6jrNltEsa5glKFqy3+JEUg2maaLVafTRN27b7MgByCKNeQrfbHRgUhsF6gYPOKS2otLjTcRAzaa2sgerb9Le0+zNNkzV2NwNZlrFr1y58+9vfhmVZeOqpp1jNXtM0VvMHwK7v+Pg4yzSIxhrc4dIiOzExgcOHD6PZbOLpp5/G9PQ0EokEYrEYy/BoOIqanKSDFARNX5NPAwViChCkyErssVgsxrwb6Dr3ej2ffTQhoHakhsWZRYiSOFDZl/oKwUBBu+ngtabJbzKWSo4n4TQd2F0bkVgE55xzDnieZ+ZVy3sMpLVFAnaSJK2Y3QhuYOi4gggujGQaRQtqOp1GNBqFJEnMV5kyPJJTP1OQ0zJ0Q4dZM6GMKX3DaQSauA/KZNBGqNfr9RETSPCReoLDZvuDEAaGZVje4KWIvN7CV6/XYRgGm7g9VTodqaSapgnbtlEoFDb09ySSFgSpZFJTMbibop3xoJ3vRrDaol6r1fqa5sGHmT57eZN/OYKBgRCLxWCaJnRdP6Wmey6Xwxve8AZ8+9vfxl133YWbb76ZPYiO4yCZTLIsgrSDtm/fjmQyiXq93vfZ1OuhLCcej+PYsWOo1+uo1Wp4yUteglgsxgKPZVn+orpEd+x0OsyKc1CfIpfLIZ1Oo9lsslIVqafSfULlxYWFBcRiMWQyGVYulGUZvXQP1bkqnnnqGUxMTbDhRVpQFhcX2XDbcgSPiUQhSTYFADidQ6QXQXo6DUVVkMvl0Ov10Gq1UK/XmdosybfTAB1heWlOURRs376dlYWorBukk1OWTHLnVALMZrOnRdRvK8DxHOQRGXpZh922ISVX7vCD0890j1HGH+yBAH5QJCYZgL5ZmY0iDAzLQPokAJjf73o+CN1ulxnukF/wqYCaYrRzHDRpvBksZxcRywQ42ThdjmDavlkEjX0GleQ4jmP+B/RgD8JyUT0AbLp0K2i6V199Nb797W/j61//Om699da+BSWVSuHIkSNs0pSkt5cPlQFY0ZNSVd84fm5uDrZt4xe/+AVGR0eZ2J9lWTAMo29ehlhAq91LQZloohaTtEir1YIo+pnAxMQE26UHF/TR6VHUFmrgNI41nIlkQeY/JOC21rklNhZlT7quw4CBarmKE6UTGJ32d+TBOn86nWb+4BzHMRYTzQUM2lwEJ3yX62XNzs6y11Hjnsqup6tPsFUQFMGXyG6ajHa6Hqg8PEgNIB6Ps81kcAO1UYSBYRlIl4cokMMY6FAfgmr8pwLTNFEqlVg9dKsF8QiapjHF0LWoosN4OAexPLNqtVqsDEMP7CCQdPdaO/9B50EQhC2TBLjsssuQzWZRLBbx0EMP4Xd+53fY7xRFQTweh+u6rNbfbreRSqVWBM1UKoVYLMZKYzSYNj09jYMHDzK6ZCKRYFpctVoN1WqV/btarbKZgrUWN3KBsywLnU6HTS8D/rmXJKmvZk+lG1ESsX3vdpSPlqFzfu2asjYKUvQeo6OjzCtg+SaBLDIzmQwbCDx48CBc2fUNZHo2pJhf3jx69Cja7TYOHTrEGFfUvNY0jfUqgnMppENFmSKp31IwpjkSQRDWnAk4myElfS8Fo2ogMh7ZtGQHufMRMeVU1o0wMAwA1WSHBdEfN/I3g0Aj97QjokG6rQbVhWlHuFZd/1TgOA5jfaTT6TVT+qBu0pmCLMu46qqr8F//63/FXXfd1RcYKAugchuVgCg4BEHlmuVIpVLYu3cvZmZmWHmFdrjdbhftdptNypPvAtXf17s+qVSKlaCy2SybFCcHung8jkqlAl3XGVsulo0hXo+D6/mDW7lcjtWyg32nVCq1JvMrmFFQ+YYf5cHpHARLQKqQgiALbJOg6zo7P5IksR4Tz/Ns7oGCFAA2KBecKwpiULnrVwkct7pD3hk7Ju9UpiB+TdBqtZBKpTA7O8ssHgme57GFc/nkJ3BqCobLP2dhYYFNXJ4uLZhms8kW62g0uqr20UaxsLAAwzAwOjral2VRHX09ORCScACAbdu2rWpERBaZW62pRPjpT3+Kiy++GIqiMPE9wO+R0MCZqqpwHAfNZhOCIGBqampD55AyCWLsRKNRRlslL2iaCk8mk2zRXu8zyuUyazDncjk2awCABQYKRuTSZms2mjNNJKeSkKL9O8xSqQRN0xCPx9m0eVDJEwBjsQ3aFHmuB72kAzwQGfPLHpqmsQY7NZKJUUaeI1QGoRJupVJhvRrymQ72x35dYLUtmA0TkdEIc8g7FdC61mw2N9xnCTOGAAbt8khjnkTTCDQ1Ozo6uiWlDGpaN5tNplWzlaABKKr10+DTep9DTUOixq2GbDbLMp1gBjKoFjoINBC4llcF6fcAfj31dKhK7t+/H5dffjkuvfTSvnNDDA/i7lPJh3a4G3nw6LgzmQwajQYWFxeRTCYRiURYfZi8GgzDQLfbZVTZta5XKpVCr9dDp9NhJIJgWY78PEiGvFAoQFRFxDIx2E0boir2vX8ymWSSDps53xzPQc7K/k64ZUFOyeuWWpf/3nEcdDqdvoZrvV4Hz/PMRnYrZTLOJMS46JeUagbUvHrKKrCngl+tYtxpxqAmGz0owcWK/HxpN7xZkBAcgRqKp2MnVKlUWFAYGRkZOvjQxO9qbmkEYoIYhoHZ2dmBfszrYWxsDLlcbtXyWbABeSqNtbXAcRy++c1v4gMf+AArERmGAdu2+4auer0eCwabvQeIt04quVRGS6fTGBsbQ6FQYMFA0zSUSqU1hyypCU/e0MtBTCUaeiOVYDklw7VdmG2f6klBMOist5nrCfjS0lLStxh1zJM0U2p2r/v3gsBc9Ig2TmUm6k/8uoDjfJYSPMCsn9nvdUYDwyOPPII3velNzEDl29/+dt/vPc/Df/kv/wUTExNQVRWvfOUr8fTTT/e9xjAMXHvttUyH5nd/93f7WAqniuWBITjEttHGbBBEiy0WiyzdP50ghgaxYU4HaNKVdtGnA+vZep4O0EJJAn6UKQiCgLGxsU27lXEch2w22yfF3W63ceDAARw/fpyVmcbHxxkldDmHfzlGR0cxNTW1apZGhAYa2qvVauBlHmJMRKvYQrvV7mtgk9f0qfTPpKQEXuJhVk1fvmFp4C1oXrUWSJiOGGDT09NMwnwYcsivEniRh5yWYfdspoF0Ro7jjH0y/CboRRddhDvuuGPg7z/1qU/hM5/5DO644w78+Mc/Rj6fx2//9m/3LTrXXXcd7rnnHvz93/89vv/976PT6eCNb3zjug/QsAgGBtJ3oSEnok9uFI7j9AWE09XmCb5vIpHoE1XbaiwuLuLYsWNMFmOz5ybYEB+E5WJ6pwvdbhdf+9rXcOeddyKdTjPznaCMR7fbPSUWWtBzgeiVwMkJ8UOHDjHJ9nw+PxRDjdzW1oIsy2ywi6xBpZSEqBqFZEtwXReVSsXPJgJidpsFNVc9x4PVtJhNKOD3bjZjc6soCiu//bpBjIkQoyLMugnXOXU/i83gjAaG3/md38HNN9+M3//931/xO8/z8LnPfQ4f+9jH8Pu///vYt28f7rrrLvR6PXzjG98A4DdSv/KVr+DTn/40XvOa12D//v34+te/jp///Of4zne+syXHGAwMzWaTeRSMjo5uqjlMMgrUaMzn85vOOtZCp9PB/Px8X4A8FYbTWg8vWV0SPfJUGtrz8/Ps/AzCLysw3H///bj66qvx0Y9+FI7j9JVV6HpRoxQAky3YCGgBNgyDiR5SFloul/Hcc88xKYjlFo/EiloNnucxp7lBICc+mnLnBV/eOSknwXkcK28FsVbAXg+8xENKSbA6FhzdYRLttm2zGaAQJ0HMJLN2ZkpKZ22P4ejRoygWi3jta1/LfqYoCn7zN38TP/jBDwAAjz32GCzL6nvNxMQE9u3bx15zqqAFTtf1PnvOzZiOaJrW50JVKBS2fMdDTWYaWjrdD12r1WKigaqqnnKPhHbEqy2yv6xS0u/+7u+yyeH//b//94pjoOtGFNHZ2VmUSqUNBaygpwft4ikjIWLAsWPHWIZJhjVkLbtWAC2VSiiXy2uWKZeb54hxEaIkIiX5vZVms8n6J/R5pySzEBchKAKMmgEOHCMzNBqNLcvwf11AU9GO7suL/LJx1rKSyAN4ef12fHwcx48fZ6+RZXkFW4Z8flcDPVwEYroMWkSp7ksDNpFIBK7rbnjBtSwL8/PzAPwAl0qlGMNlq0AuYvSeyWSSTehuFvT9bdteUWemkkdwFqLdbp+SnaNpmuzzBmVkhmEwaYrTXV9+61vfii984Qv4/Oc/j1e96lV9v3Ndt89zmaa2N0qlpeEuURRZaaTRaGBqagpPPvkkTNPEk08+yQJiuVyGJElMeK7VajE3tSBoxkLXdRQKhXWDNfUbRqIjcDoOPMlDR/enmQuFAhPlMwxjw/IsQbiiC72qo2t2IWdkJjty4sSJLZvw/3WC4Rhoz7QRGY+AFza2j6fnfjNZ3lkbGAjLb+hhhrHWe82tt96Km266acXPt23btrmDDPFrjX/5l39ZMcQWIsSvCqrV6obv37M2MNA0Y7FY7NuhlMtllkXk83nGaw5mDeVyGS972ctWfe+PfOQjuP7669m/XdfdUvvNEFuHVquFbdu2YWZm5qwVQ3u+Irw2ZzeazSamp6c3RQQ5awPDzp07kc/n8dBDD2H//v0A/LT74Ycfxm233QYAuPjiiyFJEh566CFcccUVAPwJ3Keeegqf+tSnVn3vQaJr61lLhjizIL36EGcfwmtzdmMzJJkzGhg6nQ6ee+459u+jR4/iiSeewMjICKanp3Hdddfhlltuwe7du7F7927ccsstiEajeNvb3gbAn/S85ppr8P73v5/xwT/wgQ/gwgsvxGte85oz9bVChAgR4lcaZzQw/OQnP+lr6lF55+qrr8add96JD37wg9A0DX/6p3+Ker2Ol7zkJXjwwQf7RuA/+9nPQhRFXHHFFdA0Da9+9atx5513nha5hBAhQoR4PiAU0QtxVsMwDNx66634yEc+siWeCyG2DuG1ObtxKtcnDAwhQoQIEaIPZ+2AW4gQIUKEODMIA0OIECFChOhDGBhChAgRIkQfwsAQ4qzHrbfeCo7jcN11153pQwmxhLm5OfzhH/4hstksotEoXvSiF+Gxxx4704f1vIdt2/j4xz+OnTt3QlVV7Nq1C5/4xCc2LFNz1g64hQgBAD/+8Y/xpS99CS984QvP9KGEWEK9XsfLX/5yvOpVr8L999+PsbExHD58OBwSPQtw22234W/+5m9w11134YILLsBPfvITvOMd70AqlcJ73/veod8nDAwhzlp0Oh1cddVV+PKXv4ybb775TB9OiCXcdttt2LZtG7761a+yn+3YsePMHVAIhh/+8If4vd/7PbzhDW8A4F+Xu+++Gz/5yU829D5hKSnEWYt3v/vdeMMb3hBOsZ9luO+++3DJJZfg8ssvx9jYGPbv348vf/nLZ/qwQgB4xStege9+97s4ePAgAODJJ5/E97//fVx22WUbep8wYwhxVuLv//7v8dOf/hQ//vGPz/ShhFiGI0eO4Itf/CKuv/56fPSjH8WPfvQjvOc974GiKPijP/qjM314z2t86EMfQrPZxN69e5kF7Sc/+UlceeWVG3qfMDCEOOswMzOD9773vXjwwQd/La0bf9Xhui4uueQS3HLLLQCA/fv34+mnn8YXv/jFMDCcYfz3//7f8fWvfx3f+MY3cMEFF+CJJ57Addddh4mJCVx99dVDv08YGEKcdXjsscdQLpdx8cUXs585joNHHnkEd9xxBwzDCLWwziAKhQJe8IIX9P3s/PPPxz/8wz+coSMKQbjhhhvw4Q9/GH/wB38AALjwwgtx/Phx3HrrrWFgCPGrjVe/+tX4+c9/3vezd7zjHdi7dy8+9KEPhUHhDOPlL385Dhw40PezgwcPYvv27WfoiEIQer3eCpltQRBCumqIX30kEgns27ev72exWAzZbHbFz0P88vG+970PL3vZy3DLLbfgiiuuwI9+9CN86Utfwpe+9KUzfWjPe7zpTW/CJz/5SUxPT+OCCy7A448/js985jP44z/+4w29TyiiF+JXAq985Svxohe9CJ/73OfO9KGEAPCP//iP+MhHPoJDhw5h586duP766/Ef/+N/PNOH9bxHu93Gn/3Zn+Gee+5BuVzGxMQErrzySvz5n/85ZFke+n3CwBAiRIgQIfoQzjGECBEiRIg+hIEhRIgQIUL0IQwMIUKECBGiD2FgCBEiRIgQfQgDQ4gQIUKE6EMYGEKECBEiRB/CwBAiRIgQIfoQBoYQIUKECNGHMDCECHEGcODAAeTzebTb7Q3/bbFYxG//9m8jFoshnU7DMAxMT0+H1pohtgxhYAgRYhne/va3481vfvNp/YyPfexjePe7341EIgEA+N73vgeO47Bv3z44jtP32nQ6jTvvvJP9+7Of/SwWFhbwxBNP4ODBg1AUBR/4wAfwoQ996LQec4jnD8LAECLELxmzs7O477778I53vGPF7w4fPoyvfe1ra/794cOHcfHFF2P37t0YGxsDAFx11VV49NFH8eyzz56WYw7x/EIYGEKE2AAefvhhXHrppVAUBYVCAR/+8Idh2zb7fbvdxlVXXYVYLIZCoYDPfvazeOUrX4nrrruOveab3/wmLrroIkxNTa14/2uvvRY33ngjdF0f+Pk7duzAP/zDP+BrX/saOI7D29/+dgBANpvFy172Mtx9991b+n1DPD8RBoYQIYbE3NwcLrvsMrz4xS/Gk08+iS9+8Yv4yle+gptvvpm95vrrr8e//uu/4r777sNDDz2ERx99FD/96U/73ueRRx7BJZdcMvAzrrvuOti2jTvuuGPg73/84x/j9a9/Pa644gosLCzg85//PPvdpZdeikcffXQLvmmI5zvCwBAixJD4whe+gG3btuGOO+7A3r178eY3vxk33XQTPv3pT8N1XbTbbdx11124/fbb8epXvxr79u3DV7/61RU9g2PHjmFiYmLgZ0SjUdx444249dZb0Ww2V/x+dHQUiqJAVVXk83mkUin2u8nJSRw7dmxLv3OI5yfCwBAixJB49tln8Ru/8RvgOI797OUvfzk6nQ5mZ2dx5MgRWJaFSy+9lP0+lUrhvPPO63sfTdPW9LK+5pprkMvlcNttt23o+FRVRa/X29DfhAgxCGFgCBFiSHie1xcU6GcAwHFc3/8f9BpCLpdDvV5f9XNEUcTNN9+Mz3/+85ifnx/6+Gq1GkZHR4d+fYgQqyEMDCFCDIkXvOAF+MEPftC30P/gBz9AIpHA5OQkzjnnHEiShB/96Efs961WC4cOHep7n/379+OZZ55Z87Muv/xyXHDBBbjpppuGPr6nnnoK+/fvH/r1IUKshtDzOUSIAWg2m3jiiSf6fvaud70Ln/vc53DttdfiP//n/4wDBw7gxhtvxPXXXw+e55FIJHD11VfjhhtuwMjICMbGxnDjjTeC5/m+LOJ1r3sd3vnOd8JxHAiCsOox/OVf/iVe97rXDX3Mjz76KP7iL/5iw981RIjlCANDiBAD8L3vfW/F7vvqq6/GP/3TP+GGG27ARRddhJGREVxzzTX4+Mc/zl7zmc98Bn/yJ3+CN77xjUgmk/jgBz+ImZmZvp7CZZddBkmS8J3vfGfNhf+3fuu38Fu/9Vt48MEH1z3eH/7wh2g2m3jrW9+6iW8bIkQ/Qs/nECFOI7rdLiYnJ/HpT38a11xzDfv5F77wBdx7773453/+5y35nMsvvxz79+/HRz/60S15vxDPb4QZQ4gQW4jHH38cv/jFL3DppZei2WziE5/4BADg937v9/pe9653vQv1eh3tdpvJYmwWhmHgoosuwvve975Tep8QIQhhxhAixBbi8ccfxzvf+U4cOHAAsizj4osvxmc+8xlceOGFZ/rQQoQYGmFgCBEiRIgQfQjpqiFChAgRog9hYAgRIkSIEH0IA0OIECFChOhDGBhChAgRIkQfwsAQIkSIECH6EAaGECFChAjRhzAwhAgRIkSIPoSBIUSIECFC9CEMDCFChAgRog//PyFvqgA9zNqWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from scipy.interpolate import make_interp_spline\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# ✅ Full reproducibility setup\n",
    "SEED = 20\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # Helps with determinism on CUDA >= 10.2\n",
    "\n",
    "start = time.time()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "AM = pd.read_csv(\"SLM.csv\")\n",
    "\n",
    "test_complete_number = 2\n",
    "\n",
    "Train_data = pd.read_csv(\"SLM_Dataset2.csv\")\n",
    "Test_data = pd.read_csv('SLM_TestDataset.csv')\n",
    "\n",
    "Train_S = Train_data['Smax'].fillna(0)\n",
    "Test_S = Test_data['Smax'].fillna(0)\n",
    "\n",
    "Train_R = Train_data['Ratio'].fillna(0)\n",
    "Test_R = Test_data['Ratio'].fillna(0)\n",
    "\n",
    "Train_V = Train_data['V'].fillna(0)\n",
    "Test_V = Test_data['V'].fillna(0)\n",
    "\n",
    "Train_P = Train_data['Power'].fillna(0)\n",
    "Test_P = Test_data['Power'].fillna(0)\n",
    "\n",
    "Train_H = Train_data['Hatch'].fillna(0)\n",
    "Test_H = Test_data['Hatch'].fillna(0)\n",
    "\n",
    "Train_thick = Train_data['Thickness'].fillna(0)\n",
    "Test_thick = Test_data['Thickness'].fillna(0)\n",
    "\n",
    "Train_temp = Train_data['Temperature'].fillna(0)\n",
    "Test_temp = Test_data['Temperature'].fillna(0)\n",
    "\n",
    "Train_time = Train_data['Time'].fillna(0)\n",
    "Test_time = Test_data['Time'].fillna(0)\n",
    "\n",
    "Train_N = Train_data['N'].fillna(0)\n",
    "Test_N = Test_data['N'].fillna(0)\n",
    "\n",
    "Train_delta = Train_data['Delta'].fillna(0)\n",
    "Test_delta = Test_data['Delta'].fillna(0)\n",
    "\n",
    "Train_N_log = np.log10(Train_N)\n",
    "Test_N_log = np.log10(Test_N)\n",
    "\n",
    "def scale(train_col, test_col):\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train_col.values.reshape(-1, 1))\n",
    "    test_scaled = scaler.transform(test_col.values.reshape(-1, 1))\n",
    "    return train_scaled, test_scaled\n",
    "\n",
    "Train_S_scaled, Test_S_scaled = scale(Train_S, Test_S)\n",
    "Train_R_scaled, Test_R_scaled = scale(Train_R, Test_R)\n",
    "Train_V_scaled, Test_V_scaled = scale(Train_V, Test_V)\n",
    "Train_P_scaled, Test_P_scaled = scale(Train_P, Test_P)\n",
    "Train_H_scaled, Test_H_scaled = scale(Train_H, Test_H)\n",
    "Train_thick_scaled, Test_thick_scaled = scale(Train_thick, Test_thick)\n",
    "Train_temp_scaled, Test_temp_scaled = scale(Train_temp, Test_temp)\n",
    "Train_time_scaled, Test_time_scaled = scale(Train_time, Test_time)\n",
    "\n",
    "Train_main = torch.cat((\n",
    "    torch.tensor(Train_V_scaled, dtype=torch.float32),\n",
    "    torch.tensor(Train_P_scaled, dtype=torch.float32),\n",
    "    torch.tensor(Train_H_scaled, dtype=torch.float32),\n",
    "    torch.tensor(Train_thick_scaled, dtype=torch.float32),\n",
    "    torch.tensor(Train_temp_scaled, dtype=torch.float32),\n",
    "    torch.tensor(Train_time_scaled, dtype=torch.float32)\n",
    "), dim=1).to(device)\n",
    "\n",
    "Test_main = torch.cat((\n",
    "    torch.tensor(Test_V_scaled, dtype=torch.float32),\n",
    "    torch.tensor(Test_P_scaled, dtype=torch.float32),\n",
    "    torch.tensor(Test_H_scaled, dtype=torch.float32),\n",
    "    torch.tensor(Test_thick_scaled, dtype=torch.float32),\n",
    "    torch.tensor(Test_temp_scaled, dtype=torch.float32),\n",
    "    torch.tensor(Test_time_scaled, dtype=torch.float32)\n",
    "), dim=1).to(device)\n",
    "\n",
    "Train_data_S = torch.tensor(Train_S_scaled.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "Test_data_S = torch.tensor(Test_S_scaled.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "Train_data_SR = torch.tensor(Train_R_scaled.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "Test_data_SR = torch.tensor(Test_R_scaled.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "Train_delta_tensor = torch.tensor(Train_delta.values.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "Test_delta_tensor = torch.tensor(Test_delta.values.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "Train_target = torch.tensor(Train_N_log.values.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "Test_target = torch.tensor(Test_N_log.values.reshape(-1, 1), dtype=torch.float32).to(device)\n",
    "\n",
    "# === مدل و توابع مورد نیاز (مثلاً ProbabilisticNN, init_weights, negative_log_likelihood_loss) را باید از قبل تعریف کنید ===\n",
    "\n",
    "# --- تنظیمات warmup ---\n",
    "base_lr = 0.05\n",
    "warmup_epochs = 10\n",
    "\n",
    "def warmup_lr_lambda(epoch):\n",
    "    if epoch < warmup_epochs:\n",
    "        return 0.1 + 0.9 * (epoch / warmup_epochs)\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "# پارامترهای ایست زودهنگام\n",
    "patience = 500\n",
    "min_delta = 1e-4\n",
    "\n",
    "all_y_smooth = []\n",
    "all_x_upper = []\n",
    "all_x_lower = []\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "\n",
    "for i in range(50):\n",
    "    seed = 45 + i\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    model = ProbabilisticNN(num_features=6).to(device)\n",
    "    \n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=base_lr)\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=warmup_lr_lambda)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    counter = 0\n",
    "    best_model_state = None\n",
    "    test_losses = []\n",
    "    num_epochs = 1000\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        Train_data_S.requires_grad_(True)\n",
    "\n",
    "        mean_output, std_output = model(Train_main, Train_data_S, Train_data_SR)\n",
    "        loss = negative_log_likelihood_loss(Train_target, mean_output, std_output, Train_delta_tensor, Train_data_S, physics_lambda=1.0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        model.constrain_sigma()\n",
    "        model.constrain_mu()\n",
    "        model.constrain_mu2()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            mean_output_test, std_output_test = model(Test_main, Test_data_S, Test_data_SR)\n",
    "            test_loss = negative_log_likelihood_loss(Test_target, mean_output_test, std_output_test, Test_delta_tensor, Test_data_S, physics_lambda=0)\n",
    "            test_losses.append(test_loss.item())\n",
    "\n",
    "        if test_loss.item() + min_delta < best_loss:\n",
    "            best_loss = test_loss.item()\n",
    "            counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            counter += 1\n",
    "\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} for seed {seed}\")\n",
    "            break\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            print(f\"Seed {seed}, Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss.item():.6f}, Test Loss: {test_loss.item():.6f}, LR: {current_lr:.6f}\")\n",
    "\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    predictions = mean_output_test.cpu().numpy().flatten()\n",
    "    lower_bounds = (mean_output_test - std_output_test).cpu().numpy().flatten()\n",
    "    upper_bounds = (mean_output_test + std_output_test).cpu().numpy().flatten()\n",
    "\n",
    "    sorted_indices = np.argsort(predictions)\n",
    "    x = predictions[sorted_indices]\n",
    "    y = Test_S.values.flatten()[sorted_indices]\n",
    "    std = (upper_bounds - lower_bounds)[sorted_indices] / 2\n",
    "\n",
    "    x_margin = 1.1 * (x.max() - x.min())\n",
    "    x_smooth = np.linspace(x.min() - x_margin, x.max() + x_margin, 300)\n",
    "\n",
    "    x_unique, unique_indices = np.unique(x, return_index=True)\n",
    "    y_unique = y[unique_indices]\n",
    "    std_unique = std[unique_indices]\n",
    "\n",
    "    spline_y = make_interp_spline(x_unique, y_unique, k=2)\n",
    "    spline_std = make_interp_spline(x_unique, std_unique, k=2)\n",
    "\n",
    "    y_smooth = spline_y(x_smooth)\n",
    "    std_smooth = spline_std(x_smooth)\n",
    "\n",
    "    x_upper = x_smooth + 1.96 * std_smooth\n",
    "    x_lower = x_smooth - 1.96 * std_smooth\n",
    "    y_upper = y_smooth + 1.96 * std_smooth\n",
    "    y_lower = y_smooth - 1.96 * std_smooth\n",
    "    y_lower_clamped = np.maximum(y_lower, 0)\n",
    "\n",
    "    all_y_smooth.append(y_smooth)\n",
    "    all_x_upper.append(x_upper)\n",
    "    all_x_lower.append(x_lower)\n",
    "\n",
    "    plt.plot(x_smooth, y_smooth, color='plum', linewidth=1,alpha=0.3)\n",
    "    plt.plot(x_upper, y_smooth, '--', color='gray', alpha=0.25)\n",
    "    plt.plot(x_lower, y_smooth, '--', color='gray', alpha=0.25)\n",
    "\n",
    "mean_y_smooth = np.mean(all_y_smooth, axis=0)\n",
    "mean_x_upper = np.mean(all_x_upper, axis=0)\n",
    "mean_x_lower = np.mean(all_x_lower, axis=0)\n",
    "\n",
    "plt.plot(x_smooth, mean_y_smooth, color='magenta', linewidth=1.5, label='Mean (average)')\n",
    "plt.plot(mean_x_upper, mean_y_smooth, '--', color='black', linewidth=1.5, label='95% CI (average)')\n",
    "plt.plot(mean_x_lower, mean_y_smooth, '--', color='black', linewidth=1.5)\n",
    "\n",
    "delta_1_mask = Test_data['Delta'] == 1\n",
    "delta_0_mask = Test_data['Delta'] == 0\n",
    "\n",
    "plt.scatter(\n",
    "    Test_target.cpu().numpy()[delta_1_mask],\n",
    "    Test_data['Smax'].values[delta_1_mask],\n",
    "    label='Failures', color='blue', marker='o', alpha=1\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    Test_target.cpu().numpy()[delta_0_mask],\n",
    "    Test_data['Smax'].values[delta_0_mask],\n",
    "    label='Runouts', facecolors='none', edgecolors='red', marker='^', alpha=1\n",
    ")\n",
    "\n",
    "plt.xlabel('Log(Nf)')\n",
    "plt.ylabel('Stress (S)')\n",
    "plt.ylim(100, 650)\n",
    "plt.xlim(2, 8)\n",
    "plt.xticks([4, 6, 8])\n",
    "plt.title(f'Data set 2 Predictions - Fold {test_complete_number}')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
